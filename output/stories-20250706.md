# Hacker News 故事摘要 - 2025-07-06

## 今日概述

Today’s top Hacker News stories cover Apple’s new AI safety filters, a retro web OS in the browser, and the big rise of AI projects in Show HN. Other stories talk about coding interview tricks, the slow progress of AGI, Jane Street’s India ban, simple Git-based project tools, using math in programming, tracking the ISS with DNS, and building Rust with GCC. Themes today include AI safety, retro tech, coding skills, finance, and fun technical hacks.

---

## I extracted the safety filters from Apple Intelligence models

- 原文链接: [I extracted the safety filters from Apple Intelligence models](https://github.com/BlueFalconHD/apple_generative_model_safety_decrypted)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44483485)

This project shares decrypted safety filter files from Apple’s new AI models, called Apple Intelligence. The files show how Apple’s models block or change certain output to keep things safe and follow rules.

The repository has scripts and instructions to help you get the encryption key, then decrypt the safety files from your own machine. It explains how to use LLDB (a debugger) to attach to Apple’s safety process, grab the encryption key, and then use a Python script to unlock the filters. The decrypted files are organized by model, and each contains JSON with lists of phrases or patterns. These rules tell the AI which words to block (reject), remove, or swap out. There are also regular expressions to catch bad words or phrases, not just exact matches. The example shows that if the AI output matches anything on the reject list, it will be blocked. There are also lists for words to just remove or replace, though some filters are empty. The rules are meant to stop the AI from saying or doing anything harmful or breaking Apple’s safety policies. The project includes everything you need to repeat the process, but also shares already-decrypted files from June 28, 2025, so you can look without extra work.

In the comments, some people think it’s good to see how Apple’s safety system works, as it makes the AI more transparent. Others worry that sharing the decrypted filters could help people find ways to trick or bypass the safety rules. A few say these kinds of filters are common in all big AI models, and argue there’s nothing surprising here. Some users ask if these filters block too much, making the AI less useful, while others say they’re important to protect users from harmful content. There’s debate about whether Apple’s approach is better or worse than other tech companies. One person notes that the process to get the key is not simple, so it’s not a big risk for regular users. Others worry that these kinds of safety controls might get stronger over time, and wonder who decides what should be blocked. Some suggest that people should be able to turn these filters off if they want, while others believe strong defaults are needed for safety. In short, the comments show a split between people who value openness and control, and those who focus on safety and compliance.

---

## Show HN: I wrote a "web OS" based on the Apple Lisa's UI, with 1-bit graphics

- 原文链接: [Show HN: I wrote a "web OS" based on the Apple Lisa's UI, with 1-bit graphics](https://alpha.lisagui.com/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44482965)

Someone built a web-based operating system that looks like the old Apple Lisa, using only 1-bit graphics. You can use it in your browser, and it does not use JavaScript.

The project is called LisaGUI. It runs in your browser and copies the style of the Apple Lisa, a computer from the 1980s. The graphics are black and white, just like the original Lisa. The developer made it so it works without JavaScript, which is unusual for web apps today. The interface has windows, menus, and icons that feel old-school. You can open apps, move windows, and try out features similar to what the Lisa had. The design is simple, with basic buttons and pixel art. Everything loads fast because it is lightweight. The creator says it is a technical demo, not a full OS. There is also a page with more details about how it works.

People on Hacker News are impressed by the no-JavaScript approach. Some are surprised it works smoothly, even without modern web tech. Others remember using the original Lisa or Macintosh and say this feels nostalgic. A few discuss how hard it is to make interactive sites without JavaScript today. Some users ask technical questions about how input and drawing happen—like whether it uses CSS or server-side rendering. Others point out this project could help teach web basics. There is also talk about accessibility, with some wanting keyboard support. A couple of people wish for more features or apps, while others just enjoy the retro look. Some users even share links to similar retro projects. Most agree it is a fun project that shows what is possible with simple web tools.

---

## More than 1 in 5 Show HN posts are now AI-related, get > half the votes/comments

- 原文链接: [More than 1 in 5 Show HN posts are now AI-related, get > half the votes/comments](https://ryanfarley.co/ai-show-hn-data/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44463249)

This article looks at how many Show HN posts are about AI and how people react to them. The author was annoyed by all the AI posts on Hacker News and wanted to check if there are really more of them now.

He used the Hacker News BigQuery dataset and SQL to count Show HN posts over the past years. In 2018, there were about 11,000 Show HN posts. By 2024, that number went up to over 17,000. The number is still rising in 2025. But the jump isn't as huge as the author expected. Some years, like 2020, had even more posts, maybe because of COVID.

To see how many posts are about AI, he searched for keywords like “AI,” “GPT,” or “.ai” in the titles and URLs. He found that in 2018, only 1 out of 63 Show HN posts was AI-related. By 2025, more than 1 out of every 5 posts is about AI. That’s a big increase.

He also checked if AI posts get more votes or comments. AI Show HN posts get fewer comments and, on average, fewer votes than non-AI posts. This means people talk less about them, and they are not more popular. The author thinks that building an AI wrapper is easier now, so maybe there is less effort in some of these projects.

He says it’s hard to tell if people on Hacker News actually like all these AI projects. There’s no data about downvotes or total users. Some AI posts might be anti-AI, but they still get counted as AI-related. In the end, the author feels less crazy after seeing the data, but he’s still annoyed.

In the comments, some people agree with the author and say there are too many low-effort AI projects. They feel the Show HN page is full of “Chat with your PDF” clones and simple wrappers. Others say it’s normal for new tech to flood Hacker News when it gets popular. Some users think the problem is not AI itself, but how easy it is to build and share simple projects now.

A few commenters defend the flood of AI posts. They say good ideas will still stand out, and more projects mean more innovation. Some point out that “Show HN” is meant for sharing all projects, even small ones. Others worry that too much AI content could drown out other interesting work.

Some suggest ways to fix the problem, like better filtering or tags to hide AI posts. A few like seeing new AI tools, even if most are simple. Others wish for higher posting standards or more manual review. There’s also talk about how hard it is to judge effort from just a Show HN link.

Overall, the comments show mixed feelings. Some want fewer AI posts, some don’t mind, and some see it as a normal part of tech cycles. Most agree that the community will need to adapt as the number of posts keeps growing.

---

## Async Queue – One of my favorite programming interview questions

- 原文链接: [Async Queue – One of my favorite programming interview questions](https://davidgomes.com/async-queue-interview-ai/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44482194)

This article talks about a common interview question for programmers: how to write an async queue so only one request goes to the server at a time. The writer explains why he likes this question and how it tests many useful skills.

First, the problem: the client app calls a server that cannot handle more than one request from the same user at once. So, we need a function, `sendOnce`, that makes sure not to send a new request until the last one is done. The original `send` function takes a payload and a callback—when the server finishes, the callback runs. A simple queue is not enough; you also need an `isProcessing` flag to know if a request is still in progress. The working solution adds requests to a queue, starts processing if nothing is busy, and moves to the next request when one is done.

The interview gets more complex: next, you add a delay, so each request waits at least a certain number of milliseconds before sending. In JavaScript, you use `setTimeout` for this. The point is to see if the candidate can adjust their code when new rules come in, and if they understand single-threaded code (like JavaScript), so they don’t accidentally block the whole program.

After these basics, the interviewer adds more twists: maybe you need to send repeated requests every few seconds, let users cancel a request, retry requests if they fail, or add priorities. You might even ask candidates to write tests. All these changes test if the candidate can keep their code clean and handle new problems.

The writer also tried this interview with AI tools, like Replit Agent using Claude Sonnet 4.0. The AI did well on the simple parts, but made mistakes as things got harder. Still, the writer thinks it’s good to let candidates use AI, because strong programmers now use these tools to help them work faster, but still need to check and fix the AI’s code.

In the comments, some people really like this interview question. They say it tests real understanding of async code and how to handle queues. Others point out that not everyone understands JavaScript’s single-threaded model, so the interview can be tricky for those with different backgrounds. A few think the question can be too focused on JavaScript and might not work as well in other languages. Some users warn that when people use AI, they might just copy code without understanding it, so you have to check if they really know what’s happening. Others agree that AI helps with simple code, but still struggles with more complex or changing requirements, so humans still have an edge. Some people wonder if interviews should focus less on coding puzzles and more on real work problems. Finally, a few think writing tests is the best way to check if someone really understands their code, with or without AI.

---

## I don't think AGI is right around the corner

- 原文链接: [I don't think AGI is right around the corner](https://www.dwarkesh.com/p/timelines-june-2025)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44483897)

This article says that AGI (Artificial General Intelligence) is not coming soon, even though AI is already very impressive. The writer has tried using large language models (LLMs) like ChatGPT to help with real work, but found they are not as useful as many people hope.

The main problem, the author says, is that LLMs do not learn and improve over time like humans do. When you give feedback to a human worker, they get better at their job. But with AI models, you cannot give high-level feedback that sticks. Each time you start a new session, the model forgets what it learned. Even if you try to give the AI detailed instructions or summaries, it does not gain the "tacit knowledge" that a person would. The author compares it to trying to teach someone to play saxophone just by reading instructions, instead of practicing.

There are ways to improve AI, like RL (reinforcement learning) fine-tuning, but these methods are slow and not as flexible as human learning. Human workers can notice small improvements on their own and adjust, but AI cannot do this yet. The author thinks that until AIs can learn on the job, they will not replace many white-collar jobs. Right now, AI can do some tasks, but not the whole job that a regular employee does, since it cannot remember context or get better with feedback.

The writer is hopeful that, in the long term, AI will become much more powerful when it learns to learn continuously. That will be a big jump, maybe leading to a kind of “intelligence explosion.” But this is not likely to happen in the next few years. The author also doubts that AI will soon be able to do complex tasks, like running taxes for a small business, from start to finish without mistakes. There are big challenges, like not having enough training data for computer tasks and the need for new algorithms.

The author thinks that AI progress will slow down after 2030 because we cannot keep increasing computer power forever. After that, improvements will need to come from new ideas, not just more hardware. So, if AGI does not arrive in the next 10 years, it may take much longer.

In the Hacker News comments, some people agree and say that AI hype is too high. They also notice that current AIs are not reliable for complex jobs and often make mistakes humans would not. Some share stories about trying to use AI tools at work and finding them helpful only for simple tasks, not for anything that needs judgment or memory.

Other commenters are more optimistic. They point out that AI progress has surprised people before, and that things that seem impossible now could become easy in just a few years. Some think that as long as AIs can be updated regularly, they do not need to learn exactly like humans do. There are also people who say that building better interfaces or using AI in teams with humans could solve some problems.

A few are worried about the risks of AGI and say we should still prepare for fast progress, just in case. Some argue about what “general intelligence” really means, and whether LLMs are already halfway there. Others think the real bottleneck is not technical, but about trust and responsibility—companies do not want to use AIs for important jobs because it is hard to check their work.

In the end, there is a mix of hope and doubt. Many agree that today’s AIs are powerful, but not yet ready to fully take over complex jobs. Most think that real, human-like AGI will need more than just bigger models—it will need new ways of learning and remembering.

---

## Jane Street barred from Indian markets as regulator freezes $566 million

- 原文链接: [Jane Street barred from Indian markets as regulator freezes $566 million](https://www.cnbc.com/2025/07/04/indian-regulator-bars-us-trading-firm-jane-street-from-accessing-securities-market.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44480916)

Jane Street, a big trading company from the US, is now banned from trading in India. The Indian financial regulator also froze $566 million of Jane Street’s money.

The article explains that Jane Street was accused of unfair trading. The Indian regulator said Jane Street did “pump and dump,” which means they pushed up a stock’s price and then sold it fast to make a profit. Jane Street is known for using computers to trade very quickly. The regulator thinks Jane Street and another company, Tower Research, worked together to move prices in the Indian stock market. These companies did many trades in a short time, which made prices jump up and down. The regulator said this hurt normal investors. Jane Street denies doing anything wrong. They say their trading helps markets work better and that they follow all rules. The regulator did a big investigation, looking at thousands of trades from 2021 and 2022. They found that Jane Street used fake trades to make stocks look more popular than they really were. The regulator says this is bad for trust in the markets. Now Jane Street cannot trade in India, and their money in India is frozen while the investigation continues.

People in the comments had many ideas about this news. Some thought the regulator did the right thing, saying fast trading companies can make markets unfair. Others said it is hard to know if Jane Street really did anything wrong, because high-speed trading is complex and sometimes looks strange even when it follows the rules. A few people pointed out that “pump and dump” is a strong accusation and needs clear proof. Some commenters said India is getting tougher on foreign companies, and this could scare away big investors. Others wondered if the regulator just does not like foreign trading firms, or if they are protecting local companies. One person said it is good for India to protect its markets from bad actors. Others worried that freezing so much money could make foreign companies afraid to do business in India. Some also noted that these kinds of bans happen in other countries too, not just India. A few people said it is important for markets to be fair for everyone, not just for big trading firms.

---

## Backlog.md – CLI that auto-generates task files (took my Claude success to 95 %)

- 原文链接: [Backlog.md – CLI that auto-generates task files (took my Claude success to 95 %)](https://github.com/MrLesk/Backlog.md)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44483530)

Backlog.md is a command-line tool that helps you manage project tasks in any Git folder using simple Markdown files. It was made to let both people and AI agents work together more easily in software projects.

The tool works by creating a “backlog” folder inside your Git repo. Each task is a Markdown file like `task-12 - Fix typo.md`, so you can read and edit tasks in any text editor. You can create, list, and edit tasks right from the terminal using commands like `backlog task create "Add feature"` or `backlog board` to see a live Kanban board in your terminal. There is also a web UI: running `backlog browser` opens a modern Kanban board in your browser, where you can drag and drop tasks, edit details, and see updates in real time. All changes in the web UI are saved as Markdown files, so everything stays in your Git history.

Backlog.md is private and works offline, because all data stays in your own repo. It runs on Mac, Linux, and Windows. You can assign tasks, add labels, mark status, set priorities, and manage dependencies with simple commands. There are also features for making sub-tasks, drafts, and archiving finished items. You can set defaults and preferences in config files, or use command-line flags. The tool is open source and free under the MIT license.

Some users on Hacker News liked that Backlog.md keeps things simple and offline, using plain text and Git instead of a big web service. They said it’s great for small teams or solo developers who want control and privacy. People also liked the easy Kanban view in the terminal and the quick setup—no need for extra accounts or servers.

Others pointed out that Markdown files can get messy if you have a huge project, and searching or filtering tasks might be slower than with a real database. A few users wondered if using Git for task storage would scale to big teams, and if there could be problems with merge conflicts if many users edit tasks at the same time. Some were excited about how the tool connects with AI agents, letting bots pick up tasks or help manage projects, while others said they’d like to see more details or examples of this AI use.

A few comments compared Backlog.md with other tools, like Todo.txt, Trello, or GitHub Issues. Some said this tool fits best for developers who already use Git and want everything in one place. There were suggestions for features, like better search or mobile support. But overall, many people liked the idea of managing work with simple files and clear commands, without giving up privacy or control.

---

## Functions Are Vectors (2023)

- 原文链接: [Functions Are Vectors (2023)](https://thenumb.at/Functions-are-Vectors/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44481464)

This article explains how we can think of functions as vectors with infinite dimensions, instead of just as rules that assign one number to another. By seeing functions this way, we can use the powerful tools of linear algebra (like vectors and matrices) to study and work with functions. The article starts by showing that vectors are often just lists of numbers, and as we add more numbers, these lists start to look like functions. For example, a vector with values for every real number is really just a function.

The author then explains how all the basic rules for vectors (like adding them, multiplying by numbers, and having an origin) also work for functions. For example, you can add two functions together by adding their values for each input. You can also scale a function by multiplying all its outputs by a number.

Next, the article talks about linear operators, which are like big matrices that can change one function into another. Differentiation (finding the slope of a function) is an example of a linear operator. The article shows how, for polynomials, differentiation can be written as a matrix that shifts and scales the coefficients.

The concept of diagonalization is then introduced. In regular linear algebra, diagonalizing a matrix makes it easier to work with. The same idea applies to functions and operators: if you find the "eigenfunctions" of an operator (functions that only get scaled when you apply the operator), you can simplify problems a lot. For example, exponentials are eigenfunctions for the differentiation operator.

The author also brings up the Laplacian, which is an operator involving the second derivative. On certain domains (like periodic functions), the Laplacian has very nice eigenfunctions: sines, cosines, and complex exponentials. This leads to the Fourier series, where any periodic function can be seen as a sum of waves. This idea is very useful for image compression and signal processing, because you can throw away small coefficients (high frequencies) to simplify or compress data.

The article goes further, explaining how this viewpoint helps in geometry processing and graphics, especially when dealing with shapes and images in two or three dimensions. It mentions spherical harmonics for working with functions on spheres, which is important in computer graphics and physics.

In the Hacker News comments, many readers say the article is a great and clear explanation of a tricky subject. Some like how the author connects ideas from calculus, linear algebra, and signal processing. A few people point out that thinking of functions as vectors is a big idea in functional analysis, and that this view is already used in physics and engineering (like quantum mechanics and control theory).

Others mention that, technically, there are some tricky mathematical details—like not all functions make a good vector space, and some function spaces are not Hilbert spaces. Some readers wish the article talked more about the limitations, such as where the analogy breaks down. A few ask about practical uses: how do you actually use these ideas in programming or machine learning?

Several commenters share related resources, like 3Blue1Brown’s videos, which also explain these topics with animations. Some people say this way of thinking helped them understand Fourier transforms, while others admit they still struggle with the jump from finite to infinite dimensions. There’s also discussion about how the Laplace and Fourier transforms are used in actual software and graphics work.

Overall, the comment section shows that many developers and math fans find the article helpful and inspiring, but also recognize that the real details can get complex. Some wish for even more simple examples or code to show how it works in practice.

---

## Get the location of the ISS using DNS

- 原文链接: [Get the location of the ISS using DNS](https://shkspr.mobi/blog/2025/07/get-the-location-of-the-iss-using-dns/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44480223)

This article shows a fun way to find the location of the International Space Station (ISS) using the DNS system. Instead of making a website or an app, the author updates a DNS LOC record with the ISS’s position every 15 minutes, so anyone can use a simple DNS query to get the latest coordinates.

The DNS LOC record is a special type made for sharing locations—latitude, longitude, and altitude. The article explains that, while most people use DNS for website addresses, it can do much more. The author uses an API from N2YO to get the ISS’s current position. The data comes in decimal degrees and kilometers, but the DNS LOC format needs degrees, minutes, seconds, and meters. The script handles the conversion.

To update the DNS LOC record, the author uses deSEC, a free DNS provider with an API. The script sends updates using HTTP PATCH requests. The TTL (Time To Live) is set at 15 minutes, matching the update rate. The author jokes this is a “silly” use of DNS, but it shows how flexible the system is. There’s also a hint that other strange records are hidden in the DNS for people to find. The author points out this system is not for real missions (like docking with the ISS) but just for fun and learning.

In the comments, many people say they love the idea and call it “cool” or “fun.” Some say it’s just the kind of geeky project they enjoy. One person points out you can also try contacting the ISS with amateur radio. Another says it’s “utterly unhinged” in a good way. A few readers discuss the technical side—some say Windows tools don’t support DNS LOC records well, but someone found a way using PowerShell and nslookup. Others joke about how there seems to be a DNS record for everything these days. Some think it’s a creative “abuse” of DNS, while others see it as a smart proof of concept. People also wonder what other live data could be shared this way. In general, the comments show a mix of joking, technical tips, and real interest in using old protocols for new tricks.

---

## Building the Rust Compiler with GCC

- 原文链接: [Building the Rust Compiler with GCC](https://fractalfir.github.io/generated_html/cg_gcc_bootstrap.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44484363)

This article is about building the Rust compiler using GCC instead of the usual LLVM, which is a big technical challenge. The author explains step by step how they try to make the Rust compiler work using the `rustc_codegen_gcc` backend and describes the main problems they faced.

First, the author describes the bootstrapping process. There are three stages: starting with the normal Rust compiler (which uses LLVM), then rebuilding the compiler with the GCC backend, and finally checking if the output is really the same by building it once more. If the compiler built with GCC gives the same result as with LLVM, it means the process works.

The author then talks about three main bugs they found. The first issue is with the `#[inline(always)]` attribute on recursive functions. GCC tries too hard to inline these functions, which leads to errors, while LLVM just treats the attribute as a suggestion. The author explains that a simple fix is to treat `#[inline(always)]` like a normal inline in some cases, but this might lead to slower code. They also discuss how checking for direct recursion is not enough, because indirect recursion (function A calls function B, which calls function A) can also cause the same bug. Instead, the author suggests a check that looks for other functions marked with `#[inline(always)]` being called, which is more reliable and cheap to do.

Another bug is about handling 128-bit integers in switch statements. The GCC JIT library used by the Rust backend can only handle 64-bit constants easily, but Rust sometimes needs 128-bit constants. The workaround is to replace the switch statement with a ladder of `if` statements, which GCC can optimize well enough for now.

The third main issue is a segfault (crash) that happens only when optimizations are turned on. By examining a core dump, the author finds the bug is due to misaligned memory access in a packed structure containing a 128-bit integer. The fix is to ensure the code produced by the compiler generates unaligned memory loads when needed, especially for 128-bit values.

The author notes that these fixes allow the compiler to build itself further, but there are still problems, like high memory usage and stack overflows in some GCC passes.

From the Hacker News comments, many people are excited to see progress in building Rust with GCC. Some think this could bring more compiler diversity and help with platforms where LLVM support is weak. Others worry about the complexity, and say that supporting two large compiler backends (LLVM and GCC) means more bugs and maintenance. One commenter points out that LLVM and GCC have different behaviors, so subtle bugs could show up only in one backend.

A few users discuss the technical details. Some say the workaround for 128-bit switches, while clever, might be slow for some programs. Others are impressed with the debugging techniques, like using core dumps to find alignment bugs. There are people who like the way the author explains complicated issues simply and shares practical solutions.

Some users raise concerns about the long-term viability, asking if GCC JIT will get better support for 128-bit types, or if the Rust project will keep investing in both backends. Others are hopeful the work will make Rust more accessible, especially on platforms that have only GCC. A few are surprised that even small differences in compiler attributes, like `#[inline(always)]`, can cause so many problems.

Overall, the commenters respect the effort and see this work as an important step for the Rust ecosystem, even if there are many challenges left. Some say it is great for learning how real-world compiler development works, with all its bugs and tricky edge cases.

---

