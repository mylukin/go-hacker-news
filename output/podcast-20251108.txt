Hello everyone, this is the 2025-11-08 episode of Hacker News Daily Podcast. Today, we bring you the latest stories and top discussions from the tech world.

First, let’s talk about Marko, a web framework designed for building web apps using a language based on HTML. Marko is made for developers who know HTML, CSS, and JavaScript, and it extends normal HTML with features for dynamic and reactive websites. You write simple HTML with a bit of extra code to handle things like buttons or counters, and Marko takes care of updates and fast loading. One big focus is performance: Marko streams content so users see pages quickly, even before all the JavaScript is loaded, and it only sends code needed for each part of the page. Its syntax is close to HTML, so you don’t have to learn a lot of new things. Marko works for both small templates and large apps, and it’s proven at scale—big sites like eBay use it. Features include file-based routing, TypeScript support, and many built-in tags. The docs and tutorials are good, and there’s an online playground for trying things out. Marko is open source and supported by the OpenJS Foundation.

In the Hacker News comments, people like that Marko uses HTML as the base, making it easy for new developers. The streaming and fast loading are seen as very good for modern apps. But some users note that Marko is less popular than React or Vue, so finding help or team members can be harder. Those who used Marko in big projects say it is reliable and scales well, but others wonder if Marko’s approach is different enough to stand out. There’s discussion about Marko’s fine-grained bundling, which helps performance, and some wish other frameworks did this, too. Some say the syntax is easier than JSX, while others find learning another way to write components confusing. The community is seen as friendly, but the ecosystem is small. Some people wish for more plugins and third-party tools. Overall, Marko’s tight HTML integration makes it a good fit for teams who know web basics, but people are divided on if they would switch from their current tools.

Next up, a study from Oxford and other universities shows that many tests for large language models, or LLMs, are not very strong or clear. Researchers looked at 445 different AI benchmarks and found that only a few use proper statistics, so some results could be just luck. Many benchmarks test things like “reasoning” or “harmlessness,” but do not explain what those words mean, making it hard to know if AI is really getting better. For example, if an AI writes the right answer in the wrong format, it can look worse than it is. AIs can do well on simple math or medical questions, but fail if the question is changed a little, showing a lack of true understanding. Also, high scores do not mean the AI could do a real job.

The researchers say benchmarks should have clear definitions and test real skills, and results should be checked with good statistics. They made a free checklist to help people build better AI tests.

On Hacker News, people agree that AI tests are too easy or do not match real-world needs. Some point out that companies want good scores for marketing, so they may choose easy tests. There’s worry that weak tests could be used by regulators, which is risky. People remember times in medicine or education when unclear tests caused problems. Some want more open, shared tests, while others ask who decides what is a “good” test, since ideas like “reasoning” are hard to measure. Many agree better methods and more honesty are needed, but no test will ever be perfect. A few suggest learning from fields like psychology, where test design is slow and careful. Readers find the study important and hope it will lead to stronger, clearer ways to test AI.

Now let’s look at WriterdeckOS, a new operating system that turns old laptops or Chromebooks into simple writing devices. The goal is to help people write without distractions—no internet, apps, games, or notifications. WriterdeckOS is based on Debian Linux and uses a basic text editor called Tilde. When you start the laptop, it goes right into the editor, with no desktop or browser. The system is very light and works well on old laptops. The install process erases the whole laptop, so you need to back up your files. You install it by putting the ISO on a USB stick, booting from the USB, and following instructions. The default login is “author” and “password.” There’s no autosave, so you need to save your work by hand. You can change color themes, turn on word wrap, and use basic commands. Advanced users can change text editors, keyboard layouts, connect to Wi-Fi, or encrypt the drive, but most people will just use it for writing.

In the comments, many like the idea of a distraction-free writing tool. They say modern computers are full of things that break focus, so WriterdeckOS is helpful. Some remember hardware like the AlphaSmart and think this is a good use for old laptops. Others worry about erasing the whole laptop and wish for a way to try it without wiping all data, maybe with a “live USB” mode. Some want autosave to prevent lost work. Others say you could just use Linux and a text editor with Wi-Fi turned off, but supporters say WriterdeckOS is easier for beginners. There are questions about battery life and support for different laptops, since some Chromebooks may not work. Some share tips for similar setups or ask if more formats could be supported. In general, people are excited about simple tools but cautious about wiping their laptops.

Next, we have a story about Avería, a font made by averaging all the fonts on one person’s computer. The creator is not a type designer but is interested in typography and creative programming. To make Avería, the author overlaid each letter from many fonts at low opacity, using ImageMagick and PHP, to see what the “average” letter would look like. This made blurry letters, but some shapes, like the baseline, were clear. Some letters, like “g,” had two very different forms. Wanting sharper edges, the author tried to turn the blurry images into clear shapes, but this didn’t work for all letters. Then, the author broke each letter’s outline into many points and averaged the positions from all the fonts. This worked well and was simple. After a month, the Avería font was ready. The name means “breakdown” in Spanish, related to “average.” The font is free to use, comes in several styles, and is made from hundreds of base fonts.

In the comments, people find the project creative and fun, and it’s a new way to think about “average” in design. Some point out how hard it is to average fonts, especially when letters have different shapes. A few mention other tools that can interpolate between fonts, like Superpolator or FontForge. Some are curious to see the font in use, and others talk about possible uses in art projects or as a unique alternative to standard fonts. Some note that the average font looks a bit odd, but that’s also what makes it interesting. There are also technical discussions about matching points on letters and how averaging works with very different shapes. Overall, people are impressed by the mix of creativity, programming, and design.

Now let’s talk about Cloudflare and the Aisuru botnet. Cloudflare noticed that strange domains linked to the Aisuru botnet were showing up above famous sites like Amazon and Google on their most-visited list. This happened because the botnet, made from hacked smart devices, sent huge numbers of requests to Cloudflare’s DNS servers, making their domains look popular. Aisuru can launch very big DDoS attacks, up to 30 terabits per second. The botnet used to use Google’s DNS but switched to Cloudflare’s 1.1.1.1 in October, making their command domains appear in Cloudflare’s rankings. Sometimes, the domains even included real addresses or copied names of cloud providers, which caused privacy worries.

Cloudflare reacted by hiding parts of these bad domain names and added warnings that not all top domains are safe or visited by humans. CEO Matthew Prince said their system just counts DNS queries, so the botnet could push its domains to the top by flooding the service. Cloudflare plans to improve the rankings to spot and filter out bot traffic better.

Experts like Renee Burton from Infoblox and Alex Greenland from Epi explained that rankings can be misleading due to technical reasons, and it’s not easy to show only real user data. Greenland said Cloudflare’s rankings failed to keep out obvious bot traffic, hurting trust in the list. He suggested having two lists: one for real users and one for all traffic, including bots. There are worries that many services trust Cloudflare’s top domains as safe, so letting malicious domains in could cause security problems. For example, the TRANCO list uses Cloudflare’s data, so errors could spread.

Cloudflare now hides Aisuru domains more completely, but some still show up in data files. Most requests came from the US, and the botnet controls hundreds of servers, mainly using the old .su domain, which is often abused. Experts suggest blocking .su domains or watching for them as a way to spot Aisuru.

In the comments, some agree with Cloudflare’s choice to hide the botnet domains, saying it protects privacy. Others worry this is just “security by obscurity,” and hiding data could make rankings less useful. Some argue that Cloudflare’s list was never meant to be a trust list, just a count of DNS requests, so the real problem is how people use the data. Some say services like TRANCO need to be more careful. There’s also debate about how hard it is to filter out bot traffic, since DNS queries don’t show if the user is human. Some share tips for blocking .su domains, and others talk about the risks of IoT devices with default passwords. Some say Cloudflare’s actions are too late, and call for better industry standards. Overall, people are concerned about the power of botnets and the trustworthiness of “top domain” lists.

Next, there is a new book about how programming languages let us control the flow of code, from early “goto” commands to modern ideas like algebraic effects. The book covers the history of control structures, starting with Fortran and Algol, moving to structured programming with “if,” “while,” and “for,” and then to advanced ideas like generators, coroutines, callbacks, and iterators. There are code examples in Java, Python, OCaml, C++, and Haskell. The book also explains control in functional languages, including continuations, CPS, callcc, algebraic effects, exceptions, and monads. It covers how to reason about code with type and effect systems, Hoare logic, and separation logic.

On Hacker News, readers are excited to see a clear history of control structures, with both theory and code. Some say it’s helpful for anyone learning about programming languages. There’s discussion about “goto”—some say it caused problems, while others say it can be useful if used carefully. Continuations and algebraic effects are seen as hard to learn but powerful. Not many real-world languages have full support for algebraic effects yet, but readers hope more languages will add them. Some like seeing code in different languages, while others wonder if all these advanced features are needed for most tasks. Several thank the author for sharing the book preview.

Now, let’s talk about a 1958 paper by John McCarthy, showing an early design for a new programming language that works with symbolic expressions, like math formulas or logic. The language is not finished but is already more flexible than older languages for things like algebra and theorem proving. It uses lists to store expressions, with lists inside lists, making complex data easy to build and change. The language uses algebraic notation, so you can write expressions without always naming results in the middle. Recursion is built in, and temporary results are handled with lists, not manual memory management. Conditional expressions are built in, reducing the need for “goto.” Functions and predicates can be used as arguments, and there are different types of data, like numbers, true/false, addresses, and functions. Lists can be erased, copied, searched, and mapped over with functions, and input is stored as lists.

In the comments, people are amazed at how modern this old paper feels. Many say this is the start of Lisp, an important language for AI and symbolic math. The basic ideas, like lists and recursion, are still core in many languages today. Some note the use of “cons,” “car,” and “cdr” for list processing, and how McCarthy’s focus on symbolic computation was different from most programming at the time. People praise the clear thinking and say reading old research is valuable. Some discuss the challenges of early computers and how clever these early designs had to be. Overall, readers feel inspired by the history and by seeing that many ideas we use now were already present in these early days.

Next, we have an article about building compilers by breaking the process into many small steps, called the “nanopass” approach. The author shares their experience in a compilers course, writing fifteen compilers in fifteen weeks, each one adding a bit more complexity. Each pass changes the program a little, and over time, it becomes more like the final output. The course used a “back-to-front” strategy, starting with the backend and working backwards, so students always had a working compiler. This approach is modular: each part is simple, easy to test, and easy to understand. The author says this made compilers feel possible, and helped them later when working on real-world compilers.

In the comments, many wish more courses used the nanopass approach. Some say it gives quick feedback and helps you avoid getting lost. Others point out that in industry, compilers often have fewer passes for speed, but for learning, many small passes are easier. Some share their own experiences and say this method helped them. A few wonder if it could work for other big projects. There are also comments about the open-source tools used for learning. Some worry that too many passes could slow things down, but others say modular code is easier to maintain. Several say the article made them want to try writing a simple compiler for fun.

Now, let’s talk about new research on the human sense of touch. Scientists found that humans can sense hidden objects in sand before touching them, much like sandpiper birds find food. In the study, people moved their fingers through sand to find a cube buried below, using only small changes in how the sand felt. People could notice tiny movements and had a success rate of about 70%. A robot arm with a special sensor could sometimes sense objects from further away, but made more mistakes. The study shows the human sense of touch can work at a distance, not just by direct contact. This could help make better robots or tools for archaeology or space work.

In the comments, people are surprised by how sensitive human touch can be. Some share stories about feeling objects under soil or sand. Others talk about similar tricks in search and rescue or cooking. Some wonder if this skill can be improved with practice, or what the limits are. There are ideas for uses like landmine detection or medicine. Some are excited about using this for robots on Mars or the ocean floor, while others doubt the practical value. Overall, the discussion shows excitement, curiosity, and practical thinking about where this research could lead.

Finally, there was a near mid-air crash at Los Angeles Airport when one plane made a wrong turn after takeoff and almost hit another plane. The ITA pilot turned left instead of following the planned path, coming very close to an American Airlines plane. Both pilots and air traffic controllers acted quickly to stop an accident. The video shows that these mistakes can happen when programming the flight computer, especially with runway changes or confusing instructions. The American Airlines pilot saw the problem and calmly told air traffic control, who gave new orders to both planes. Both crews responded quickly and avoided each other.

In the comments, people praise the American Airlines pilot for staying calm and professional, and thank the controllers for their fast work. Some pilots say these mistakes can happen and it’s important to double-check everything. There are jokes about not wanting to be in videos like this, and some suggest better training or procedures at LAX. People say this is why humans are still needed in planes—to see and fix problems quickly, not just rely on computers. Others mention that their airlines require triple-checking routes, and some suggest making a documentary about these close calls. Many agree that clear talking and teamwork are the keys to safety. This time, everyone did their job well, but it was a close call.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. See you tomorrow.