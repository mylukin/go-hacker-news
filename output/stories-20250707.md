# Hacker News 故事摘要 - 2025-07-07

## 今日概述

Today’s top Hacker News stories cover a big math breakthrough, new AI tools for writing and coding, and updates to programming languages like Lean. There are also stories about why honey lasts so long, quick ways to plant forests, web security improvements, and changes in design tools like Figma. Many stories discuss the mix of old ideas and new technology, and how AI is changing both work and daily life. If you like math, coding, AI, or the natural world, there is something interesting for you today.

---

## New sphere-packing record stems from an unexpected source

- 原文链接: [New sphere-packing record stems from an unexpected source](https://www.quantamagazine.org/new-sphere-packing-record-stems-from-an-unexpected-source-20250707/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44493196)

A mathematician named Boaz Klartag has made a big breakthrough in the sphere-packing problem, which asks how to fit spheres together as tightly as possible, especially in higher dimensions. For hundreds of years, this math puzzle has been very hard, and only small steps forward happened over time.

Klartag was not an expert in sphere packing, but he used ideas from a related field called convex geometry. He looked at an old method, first used by Rogers in 1947, where you start with an ellipsoid (an oval shape) instead of a sphere. In higher dimensions, ellipsoids can be stretched in many ways, making the problem tricky. Mathematicians had mostly given up on this approach because it was too hard to control.

Klartag realized that by using his knowledge of convex shapes, he could make better ellipsoids. He started with a way to randomly grow and shrink the ellipsoid along its axes. When the ellipsoid touched a point in the lattice, he stopped growing it in that direction. This random process made the ellipsoid bigger than before, sometimes big enough to set a new packing record.

He then used Rogers’ method to turn this larger ellipsoid into a denser arrangement of spheres. As a result, Klartag’s method could pack about d times more spheres in d dimensions than most older methods. This is a huge improvement, especially in very high dimensions.

His work has sparked new discussions about whether the best sphere packings are orderly and symmetric or more random. Before, some mathematicians thought disorder was needed for the best packings, but Klartag’s result suggests that order and symmetry might still be best.

In the comment section, some people are amazed that a newcomer could solve such a long-standing problem so quickly. Others say it shows the value of looking at problems from a fresh angle or a different field. Several users discuss the technical side, like how random growth of ellipsoids works and why it’s hard in higher dimensions.

Some commenters wonder about practical use, like whether this will help with data storage or error correction in computers. Others point out that, although the result is exciting, it may not be immediately useful for engineers. A few mention that math problems sometimes need someone from the “outside” to try something new, breaking the mental habits of experts.

There are also doubts: a couple of users think there could still be even better packings waiting to be found. Others believe Klartag’s method might be nearly perfect. Many agree that mixing ideas from different fields, like convex geometry and lattice theory, can lead to big progress. Several hope this will inspire more mathematicians to combine different ways of thinking.

---

## My first verified imperative program

- 原文链接: [My first verified imperative program](https://markushimmel.de/blog/my-first-verified-imperative-program/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44492986)

This post is about a new feature in Lean 4.22 that helps prove that imperative programs work as they should. The author uses a simple example: checking if a list of numbers has two different numbers that add up to zero.

First, the author explains a fast way to solve this problem. You look through the list and keep each number in a set. For each number, you check if its opposite (like -3 for 3) is in the set. If you find such a pair, you return true. If you finish the list without finding any, you return false. This method is faster than checking every possible pair.

Lean is usually a functional programming language, but it can also write programs in an imperative style (with loops and mutable variables), similar to Python. The new feature in Lean, called `Std.Do`, helps you write and prove properties about such imperative programs using something called Hoare triples: statements that say, "If something is true before running this code, something else will be true after."

To prove the program works, you need to write a "loop invariant"—a statement that's always true each time you go through the loop. In this case, the loop invariant is a bit tricky because the loop can end early. After writing the correct invariant, Lean divides the proof into five smaller steps. With the new `grind` tactic, most of these steps are checked automatically.

The author then compares Lean to other verification tools like Dafny and Verus. Those tools use automated solvers, but if something goes wrong, it's hard to fix or understand the problem. Lean, in contrast, is interactive: if automation fails, you can finish the proof by hand. Also, Lean’s proof checker (the kernel) is small and easy to trust, while other tools rely on big, complex solvers.

Another point is that Lean’s data structures (like sets) are written and checked in Lean itself, not just assumed to be correct. This makes it more trustworthy, especially for important uses like cryptography. The author believes Lean is a good tool for program verification in real projects.

At the end, the author shows that verifying a similar program written in pure functional style is also easy in Lean, using another proof technique.

Hacker News users liked the article and thought the example was clear and practical. Some readers were excited to see Lean moving further into program verification, not just math. A few people discussed how Lean compares to other tools like Coq, Agda, Dafny, and Verus. Some commenters mentioned that Lean’s interactive approach is both empowering and sometimes slow for bigger proofs, but many liked the control it gives when automation fails.

Others noted that having proofs and code in the same language is helpful for maintenance and trust. A few users wondered about real-world uses—like whether this could help with security or critical software. Some asked for more documentation and tutorials for the new Lean features, saying it’s still a bit hard to get started. One or two readers questioned whether formal verification is practical for most programmers, but others replied that better tools like Lean could change that in the future. Overall, the discussion was positive, with hope that these kinds of tools will be easier to use and more common soon.

---

## Mercury: Ultra-fast language models based on diffusion

- 原文链接: [Mercury: Ultra-fast language models based on diffusion](https://arxiv.org/abs/2506.17298)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44489690)

Mercury is a new type of large language model that uses diffusion methods to generate text, focusing on speed and coding tasks. The article explains that Mercury is built with Transformer technology but uses a different way to create text, letting it predict many words at the same time instead of one by one.

The main point is that Mercury is much faster than other language models. There are two versions: Mini and Small. On special NVIDIA H100 GPUs, the Mini version can write over 1,100 words per second, and the Small version writes about 740 words per second. This is up to ten times faster than other top models built for speed, but the quality of the output is about the same. Mercury was tested on many code tasks and in different programming languages. It was also tried by real developers on a platform called Copilot Arena, where it ranked second in quality but was the fastest overall. 

The article says Mercury is especially good for coding help, and it works well in real-world situations. There are links for people to try the model and use it through an API or a free online playground. The authors also note that Mercury uses a diffusion process, which is a new way to predict words, and this method might change how language models are built in the future.

In the comments, some people are excited about how fast Mercury works and think this could help make coding tools and AI chatbots feel much quicker. Others are curious about the diffusion method and ask for more details on how it is different from normal language models. Some users wonder if the high speed means the model uses more memory or power, and if this could be a problem for smaller companies or personal computers.

A few commenters are careful about believing the quality claims. They say that quality can be hard to measure and that real-world use is the best test. Some suggest that other teams might catch up soon, so Mercury might not stay ahead for long. There are also questions about open access—some people wish the full model was open source, not just available as an API. Finally, several users share their excitement about the new ideas in Mercury, hoping this leads to more research and better tools for everyone.

---

## The chemical secrets that help keep honey fresh for so long

- 原文链接: [The chemical secrets that help keep honey fresh for so long](https://www.bbc.com/future/article/20250701-the-chemical-secrets-that-help-keep-honey-fresh-for-so-long)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44463429)

The article explains why honey can stay fresh and safe to eat for many years, even though most sweet foods spoil quickly. Honey’s secret is its special chemistry, and the way bees make it from flower nectar. When bees collect nectar, it is watery and full of sugar—just what bacteria like. But bees remove much of the water, add enzymes to make the mixture more acidic, and break down the sugars. They put this mixture into honeycombs, then fan it with their wings to dry it even more. In the end, the honey has very little water—about 15% to 18%. This low water amount, plus its high sugar and acid, makes it hard for bacteria and mold to grow. Keeping honey in a sealed jar also keeps out extra moisture and oxygen, adding more protection. Most preserved foods will go bad after some time, but honey can last almost forever if you keep it sealed and clean. Still, once you open the jar and touch the honey with a dirty spoon or add water, it can spoil or even turn into mead (a kind of alcohol).

In the comments, some people share stories about finding very old honey that still tasted good. Others discuss how crystallized honey is still safe to eat—just warm it to make it liquid again. A few mention that not only does honey not spoil, it can even help heal wounds because of its anti-bacterial traits. Some commenters point out that if honey is mixed with water or gets dirty, it can go bad quickly, warning people to use clean spoons. There are also jokes about “ancient honey” and wondering if other foods could last as long. One person explains that honey with too much water content can ferment or spoil, so not all honey is the same. Others say they use honey as a backup food for emergencies, since it keeps so well. Some people are surprised to learn how much work bees do to make honey last. Finally, a few share curiosity about other natural foods that can last for a very long time.

---

## Launch HN: Morph (YC S23) – Apply AI code edits at 4,500 tokens/sec

- 原文链接: [Launch HN: Morph (YC S23) – Apply AI code edits at 4,500 tokens/sec](item?id=44490863)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44490863)

Morph is a new tool that helps developers make big changes to their code using AI. The team says Morph can edit code very quickly—up to 4,500 tokens per second.

Morph works by letting you describe what you want to change in your code, and then it writes or edits code to match your request. For example, you can ask it to rename functions, add comments, or move code to new files. Morph can work across many files at once, so it’s good for big projects. The tool is designed to work well with Git, so you can see the changes it makes and review them before accepting. Morph uses large language models, but it focuses on making practical edits, not just generating code from scratch. The team says they have made Morph faster than other tools by processing code in parallel and skipping parts that don’t need changes. They also designed Morph to be safe—every change is shown in a diff, and nothing is changed until you approve it. Morph supports many programming languages, and you can use it from the command line or in your favorite editor. The company hopes Morph will save developers time, especially for boring or repetitive tasks.

In the comments, some people are excited about the speed and practical focus of Morph. They like that it works with Git and shows every change before applying it. Others ask about Morph’s accuracy and how it handles tricky code changes. A few users wonder if it can really understand complex codebases or if it will make mistakes that are hard to find. Some people say the tool’s value depends on how well it fits into their workflow. There are also questions about pricing and if Morph is open source. A few developers share that they have tried similar tools, but were frustrated when AI made “dumb” changes. Others think Morph’s speed could make it popular for big teams, but only if it is reliable. Some suggest Morph could be great for code cleanup, migrations, or adding comments. A few are cautious, saying AI tools should not replace careful code review. Overall, the discussion shows interest, but also some worry about using AI for important code edits.

---

## I used o3 to profile myself from my saved Pocket links

- 原文链接: [I used o3 to profile myself from my saved Pocket links](https://noperator.dev/posts/o3-pocket-profile/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44489803)

Pocket, a popular “read-it-later” app, is shutting down, so the author decided to analyze nearly 900 saved articles from over seven years to learn more about themselves. They used simple CSV tools to look at their data and then tried using o3, an AI tool, to “profile” them based only on the list of saved links.

The analysis started by checking the range of articles, which covered topics like software, security, parenting, faith, and personal finance. The author used xsv, a CSV tool, to count and explore the data, showing articles dated from 2018 to 2025. Inspired by a recent o3 project, they asked o3 to guess details about their life—age, location, job, family, and more—just from these links.

o3’s response was detailed. It guessed the user was a mid-30s to early-40s male, living in coastal Virginia, working as a senior software engineer, earning $150k–220k, married with several young kids, and interested in tech, Catholic faith, personal finance, and DIY projects. o3 noticed patterns like seasonal interests (career planning in winter, homeschooling in summer, security in fall) and even picked up on deeper traits—like a tendency to over-research and a wish to write more.

The author was surprised at how accurate o3’s guesses were, especially details like family size and location. They also noted that o3 worked best when given the actual data in the prompt, not as a file attachment. The experiment showed how much can be learned about a person by just looking at what they save or “like” online.

Commenters had mixed feelings. Some were impressed by o3’s ability to build a profile from basic data, calling it “scary accurate.” Others worried about privacy, saying this shows how little data is needed for companies or AI to learn personal info. A few pointed out that this kind of profiling is what ad companies like Google and Facebook already do, but now these tools are available to anyone. Some users thought the analysis was only possible because the author’s data was so detailed and organized, and that many people’s saved links might be too random for such clear results. Others were excited to try similar experiments with their own reading lists or bookmarks. A few developers suggested ways to improve the process, like using more advanced data exploration tools or blending in other sources like browsing history. Some people liked the idea of making a personal recommendation system based on their own data, while others stayed cautious about sharing too much online. Overall, the post sparked a lot of talk about privacy, self-knowledge, and the surprising power of simple data plus AI.

---

## The Miyawaki Method of micro-forestry

- 原文链接: [The Miyawaki Method of micro-forestry](https://www.futureecologies.net/listen/fe-6-5-the-method)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44470942)

The article is about the Miyawaki method, a special way to plant small, dense forests quickly, even in cities or poor soils. Dr. Akira Miyawaki, a Japanese botanist, created this method after studying native forests and plant communities in Japan.

The Miyawaki method starts by looking at what plants would naturally grow in an area if humans had not changed it. The ground is dug up and mixed with things like compost to help plants grow. Many different native trees and shrubs—sometimes up to 5 per square meter—are planted very close together, using four layers: tall trees, smaller trees, bushes, and ground plants. This makes the little forest very dense. Because the plants are so close, they compete for light and grow faster and taller than normal. The ground cover helps keep moisture in and stops weeds from taking over. People claim these forests can grow 10 times faster and be 100 times more biodiverse than normal tree plantings. The method has become popular worldwide, especially after TED Talks and YouTube tutorials made it seem easy, like following a recipe.

But the podcast also explains that not everyone agrees the Miyawaki method is perfect. Some ecologists worry it is too much like a “one-size-fits-all” formula. They say it ignores the special needs of local plants and soil. If you plant trees meant for wet, dark forests in dry or open places, many will die or not grow well. Critics from India, for example, say the method is being used to plant forests where only grassland should be, harming rare animals and plants. Others worry that the method uses too many resources: lots of plants, lots of soil changes, and lots of water, making it expensive. Studies show that while many trees survive the first years, as many as 60–80% can die after 10 years due to overcrowding.

Some people, like landscape architects, like parts of the method but change it to fit local conditions. They may call their projects “mini-forests” instead of Miyawaki forests. They think the best idea is to use the method as a starting point but pay attention to what the land really needs. The company Afforestt, which helped make Miyawaki forests famous in India, says the method should not be a strict recipe—people should learn from nature and adapt.

In the comment section, many Hacker News readers are excited by the idea. They like that the method can turn empty lots or lawns into green spaces quickly. Some say it helps get people, even those with no science background, interested in ecology and tree planting. Others are more careful, pointing out that planting the wrong trees in the wrong place can cause problems later. Some users share stories where local governments pushed Miyawaki forests for good publicity, but did not check if the ecosystem was right. A few mention that the method can be expensive and sometimes wastes rare native plants. Others think it is still better than having only grass or empty land, and that mistakes can be fixed as people learn. Some wish the media would be more honest about the real results, not just repeat big claims from companies. There’s also a group who see the Miyawaki method as a “gateway” to caring more about the environment, even if it is not perfect. Overall, readers agree that it is good to plant more trees, but it is important to listen to local ecologists and not just follow trends.

---

## Adding a feature because ChatGPT incorrectly thinks it exists

- 原文链接: [Adding a feature because ChatGPT incorrectly thinks it exists](https://www.holovaty.com/writing/chatgpt-fake-feature/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44491071)

This article tells a story about a music website called Soundslice. The site lets people scan sheet music so they can listen, edit, and practice songs.

Recently, the owner noticed many people uploading screenshots that were not normal sheet music, but ASCII tabs—simple text versions used for guitar. He found out that ChatGPT was telling users that Soundslice could import these ASCII tabs and play them back. This was not true; the site never had this feature. Because so many new users expected this, the owner had to decide what to do. He thought about adding warnings to tell people that ChatGPT was wrong. Instead, he chose to actually build the ASCII tab importer, making the false feature real. He updated the website to explain this new feature.

The writer feels strange about this. He is glad to help users, but also worried because he only made this feature due to wrong information from ChatGPT. He wonders if it is good to build things just because AI tools make mistakes.

In the comments, some people find the story funny and surprising. They talk about how AI can change what customers expect from products, even when it is wrong. A few say this is a smart way to spot real user needs—maybe ChatGPT is showing what people want. Others warn that this could waste time, adding features that are not important. Some worry that AI spreading wrong facts could cause more problems for other companies. One person says it is clever to meet demand, but risky to chase every AI mistake. Another thinks companies will need to watch what AI says about them in the future. People also discuss how hard it is to keep up with false information online. Overall, the comments show both the good and bad sides of responding to AI-driven user beliefs.

---

## You Should Run a Certificate Transparency Log

- 原文链接: [You Should Run a Certificate Transparency Log](https://words.filippo.io/run-sunlight/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44494430)

This article says more people and groups should run Certificate Transparency (CT) logs. CT logs help keep the web safe by tracking SSL certificates and making sure no one can secretly issue bad ones. The author explains that running a CT log used to be hard and expensive, but now it is much easier and cheaper, thanks to new tools.

CT is important because it makes Certificate Authorities (CAs) honest and helps website owners spot problems. Right now, there are not many independent CT logs, so adding more is good for everyone's security. The new Static CT API lets you serve logs using simple static files, which means you can use things like S3 storage or any HTTP server. The Sunlight tool, made with help from Let’s Encrypt, makes it simple to set up and run a CT log without lots of extra software.

If you want to run a CT log, you only need one server, 3–5 TB of SSD or object storage, 2–3 Gbps of bandwidth, four CPU cores, 2 GB of ECC memory, and two people to watch over it. The system is designed to handle some downtime, and you do not need to make backups, just make sure you do not lose data. Operating the log does not take much time—you mostly watch mailing lists for updates, keep the server healthy, and do a few updates every year. You should expect to run it for at least three years.

The article shares that Geomys, an open-source group, can run a CT log for about $10,000 per year, and it might be even cheaper for others. There are links to guides and communities to help new operators get started. The author encourages anyone interested to join and says the community is welcoming.

In the comments, many people like the idea and thank the author for making it easier to help web security. Some are surprised at how low the hardware and bandwidth needs are compared to the past. A few people worry about the long-term commitment, asking what happens if someone wants to stop running a log. Others point out that two people might not be enough for good coverage and ask about ways to avoid losing data. Some readers wonder if smaller groups or individuals really have enough resources, and if the internet giants might still dominate CT logs. There are also technical questions about ECC memory and using normal disks instead of SSDs.

Overall, most commenters feel this is a positive change and are glad the process is now simpler and more open to new operators. Some are even thinking about running their own CT logs or teaming up with others. A few share tips about cloud storage, monitoring, and keeping logs stable. There is excitement for more independent logs and hope that this will make the web even safer.

---

## When Figma starts designing us

- 原文链接: [When Figma starts designing us](https://designsystems.international/ideas/when-figma-starts-designing-us/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44479502)

This article talks about how Figma has changed the way designers work, especially as more people use it for remote design. The author is worried that Figma’s features are making designers think and work more like engineers, which can hurt creativity.

Figma has added things like Auto Layout, Smart Components, and Dev Mode. These features help make designs more structured and easier to hand off to developers. But the author says that when teams use Auto Layout right from the start, it becomes hard to move things around or try new ideas. The tool snaps everything into place, so designers can’t be messy or try crazy layouts. This limits creative thinking, especially in the early stages when designs should be loose and open.

Dev Mode is supposed to help designers and developers work together, but it can also make designers spend a lot of time making fancy prototypes that will be thrown away later. The author thinks it’s better to start with sketches and move to code quickly, because some things—like animation or data loading—can only really be designed in code. The idea of a design being “ready for dev” is a problem, because it stops developers from adding their own ideas and asks them only to follow instructions.

The author says these features lead to premature decisions and too much structure, which makes all digital designs start to look the same. This happens because everyone uses the same tools and follows the same rules, not because they want the same thing. The author believes good design needs freedom, play, and a willingness to make a mess before things are organized.

From the comments, some people agree and say they’ve felt the same pain: Figma makes it hard to experiment or break the rules, and sometimes small changes are a headache. A few designers share stories about fighting with Auto Layout or feeling like everything looks too similar now. Others argue that these features save time and make it much easier to hand off designs to developers, especially in big teams. Some developers like having more structure, because it means they get cleaner files and clearer instructions. A few commenters point out that every tool shapes how people work, and this is just the latest example. Some suggest that messy, early design can still happen—just not in Figma, maybe in a sketchbook or another tool. Others wonder if the problem is with the tool, or with how teams use it and what they expect from designers. Overall, the discussion shows a split: some miss the old, freeform design style, while others like the order and speed Figma brings.

---

