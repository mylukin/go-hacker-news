Hello everyone, this is the 2026-02-20 episode of Hacker News Daily Podcast. Today, we bring you the top tech stories and community discussions from around the world.

First, F-Droid is warning users that Google is still moving forward with plans to close up Android, making it harder to use open app stores like F-Droid. Many people thought Google had stopped these changes, but that’s not true. F-Droid says Google’s public messages are confusing, and the new app install system Google talked about is not finished and has no clear details. Because of this, open app stores are showing warning banners and asking users to tell their local governments to help keep Android open.

F-Droid also shared updates about its apps. F-Droid Basic has a new test version with better translations, an app export feature, install history, and small improvements. Some apps, like Conversations, are trying to work without Google code, which could help make apps fully open source everywhere. Other popular apps such as Dolphin Emulator, ProtonVPN, and Nextcloud also received updates, and more than 287 apps were updated this week. F-Droid also asks users to subscribe to their news feed and to donate if possible.

In the comments, many people worry that Google is slowly making Android like iOS, where users can only get apps from one store. They think this will hurt user freedom and small developers. Others say tighter controls might make phones safer, and most people do not care about open app stores. Some believe Google has too much power and ask for government action. Others say users should just switch phones or systems if they do not like it. A few hope open-source communities will find workarounds, while some doubt F-Droid’s warnings and want to see real actions first. Many agree it is important to talk about this issue so people do not forget.

Next, we look at a story about Dependabot, GitHub’s tool for updating dependencies. The article says that for many projects, especially in Go, Dependabot creates too much noise. It sends security alerts and pull requests even when the real risk is very low or not present. For example, after a small security fix in a Go library, Dependabot sent thousands of alerts to projects that were not really affected. This happens because Dependabot only checks if a library is used, not if the risky part is used. The author suggests using smarter tools like govulncheck, which checks if your project really uses the risky part of a library. The article also advises not to update all dependencies blindly, but to run tests daily and update only when needed.

In the comments, many agree that Dependabot is noisy and often not helpful. Some still find it useful, especially for big projects. Some users want more smart tools like govulncheck. For non-Go languages, people say Dependabot is still the best option. Some maintainers are tired of too many pull requests and start to ignore all alerts, which is risky. Others defend Dependabot, saying it helps fix important issues quickly. There are also calls for GitHub to improve Dependabot and for better teamwork between security teams and open-source maintainers. Most agree that smarter risk checking is needed.

Now, about open-source AI: ggml.ai, the team behind llama.cpp, is joining Hugging Face to keep local AI strong and open. The team will continue working on ggml and llama.cpp, but with more support and resources from Hugging Face. Nothing big will change for users or the open-source community. The projects will stay open and community-driven, and the team will still make all important choices. Hugging Face will help with funding, user experience, and better links to their Transformers library, making it easier to run AI models on your own devices.

In the comments, most people are happy and say thanks to the team. Some Hugging Face members welcome ggml.ai. Many are glad that the project was not bought by a big company that might close things down. One person worries about U.S. rules and privacy. Another hopes the project will keep its simple C++ style, even as it works more with Python tools. There are questions about other projects like whisper.cpp, and some wish there was more open talk before the partnership. Overall, people are excited and hope the project stays open and free.

Next, a security engineer found a big problem at a diving insurance company. Every user got a number as an ID and the same default password—which most never changed. Anyone could guess IDs, type in the default password, and see private info, including children’s details. The engineer made a script to check and found the problem was widespread. After reporting it to the company and Malta’s national security office, the company’s lawyers threatened the engineer, asking for silence and a passport copy, instead of fixing the issue. The company blamed users for not changing passwords, even though the system was weak by design. The engineer reminded them that GDPR says the company must protect user data and inform users if their data is at risk.

In the comments, people are angry at the company for sending lawyers instead of fixing the root cause. Some say this is why many security problems go unreported. Others point out that blaming users is wrong when the system is badly made. Some share their own stories of being threatened after reporting bugs. Many agree: it’s a big problem when companies care more about their image than user security.

Wikipedia has decided to block and remove all links to Archive.today, an archive site that took part in a DDoS attack and changed saved web pages. Archive.today was used on almost 400,000 Wikipedia pages, with about 695,000 links. The main reason for the ban is that Archive.today’s owner attacked a blogger and changed saved pages to harm the blogger’s reputation. Wikipedia says this breaks trust—archive sites should not change history. Editors now ask users to use the original source or trusted sites like the Internet Archive.

People in the comments have mixed feelings. Some say Wikipedia made the right call, because trust and safety are most important. Others are sad to lose Archive.today, since it could save pages the Internet Archive could not. Some worry it will be hard to replace all the old links. Others hope Wikipedia will make its own archive tool.

Now, let’s talk about Facebook. The article says Facebook’s main feed is now full of strange, low-quality content, much of it made by AI. The author saw “thirst trap” photos, odd AI videos, and relationship memes—most not from real friends. Many posts seemed to be bots talking to other bots. The author felt uncomfortable and left Facebook again.

In the comments, people agree Facebook’s feed is now bad and full of spam. Some say this started when Facebook began showing more algorithm-chosen posts. AI-generated images and spam have made it worse. Some think it’s different for active users, but most say the main feed is mostly junk now. Some users say they only use Facebook for groups or messages, not the main feed.

Next, we look at OpenScan, a project making open-source 3D scanners for people who want to create 3D models. The Scan Gallery shows what users can do, with models like a butterfly, a fossil, and even a security key. Scans use professional cameras or phones, and models are uploaded to Sketchfab. OpenScan offers different hardware and cloud software, and its community helps each other.

In the comments, people are excited about OpenScan being open-source and affordable. Many like that you can use regular cameras, and some compare scan quality with expensive scanners. Some share their own experiences, and others want even simpler software or more guides. There are questions about privacy and cloud use, and ideas for education or museums. Overall, the comments show strong support for OpenScan.

Another story is about mines.fyi, a website with an interactive map of all US mines. You can see details about each mine, such as its name, operator, location, and what it produces. The map is easy to use, and you can filter and search for mines. The goal is to make mining data open and easy to see, whether you’re curious, work in mining, or want to know about your area.

In the comments, users are impressed by how clear and fast the site is. Some say it’s useful for those interested in environmental impact or mining jobs. Others ask about the data source and suggest adding more filters. Some worry about privacy or safety. Many praise the project for making public data easy to use.

The next article says blue light filters on screens do not really help you sleep better. The writer, a neuroscientist, explains that the body’s clock reacts to cyan light, not just blue, and most filters only block a little. Studies show that cutting blue light from screens barely changes melatonin or sleep, except in very dark rooms. Using dark mode or lowering brightness works much better.

In the comments, many agree that blue light filters do not make a big difference. Some use them for comfort, not for sleep. Others say dark mode and dimming the screen help more. Some notice no change in sleep from filters, but do see a difference with lower brightness. A few warn not to take too much melatonin and agree that low doses are best.

Finally, Anthropic has launched Claude Code Security, an AI tool to help teams find and fix security problems in code. Unlike standard tools, Claude reads code like a human expert, tracing data and finding complex bugs. It gives each finding a severity and confidence score, and all changes are reviewed by humans.

In the comments, some people are excited to use AI to catch more bugs, especially for small teams. Others worry that attackers will also use AI to find bugs faster. Some talk about the risk of false positives, but are glad that nothing is fixed automatically. There are requests for more programming language support, free access for open-source projects, and better ways to handle many bug reports. Overall, people see this as a big step forward, but with new risks to think about.

That’s all for today’s main stories and discussions. Thank you for listening to Hacker News Daily Podcast. We’ll see you next time.