# Hacker News 故事摘要 - 2025-12-22

## 今日概述

Today’s top Hacker News stories cover new ideas in AI, medical tech, and security. There are deep dives on how AI models work, breakthroughs in cancer treatment, and new tools for coding. Other stories look at water shortages, timekeeping errors, and big privacy risks in security cameras. Readers also discuss memory management books, using AI with large codebases, and safer ways to log in online. If you like stories about new tech, real-world problems, or safety and privacy, there’s something for you today.

---

## The Illustrated Transformer

- 原文链接: [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46357675)

This article explains how the Transformer model works, which is a special type of neural network used for tasks like language translation. It starts by saying that Transformers are better than older models because they use attention mechanisms, allowing them to handle long sentences and train faster.

The model has two main parts: an encoder and a decoder. Both are made of several layers stacked on top of each other. Each encoder layer has a self-attention part, which helps the model understand the meaning of words by looking at other words in the sentence, and a feed-forward network. The decoder layers are a bit different—they also include an attention part that helps focus on the input sentence, making translation more accurate.

To process words, the model first changes each word into a vector using an embedding method. One big improvement is that Transformers can process many words at the same time, thanks to how the layers work. The self-attention part creates three new vectors for each word: a query, a key, and a value. The model uses these to figure out which words should be connected or focused on when translating.

The article uses a simple sentence to show how the model knows that the word “it” refers to “the animal” and not “the street.” The math behind self-attention is explained step by step, first using single words and then using matrices for speed. The model also uses something called multi-head attention, which means it looks at the sentence in different ways at the same time, making the understanding even better.

Transformers also need to know the order of words, so they use positional encoding. This adds extra numbers to each word’s vector, helping the model remember the order. Each layer in the encoder and decoder also includes shortcuts, called residual connections, and a layer-normalization step to make training smoother.

On the decoder side, the model creates the output sentence one word at a time, using the information from the encoder to choose the right words. The decoder only looks at previous words in the output, never future ones, so it doesn't cheat.

To turn the decoder's output into words, the model uses a final linear layer to get scores for each word in the vocabulary, then uses softmax to turn these scores into probabilities. The word with the highest probability is chosen as the output for each step.

For training, the model compares its guesses to the correct answers and adjusts itself to get better. The article also explains different ways to choose the best translation, like greedy decoding or beam search.

In the Hacker News comments, readers praised the article for its clear and simple explanations, especially the use of pictures and step-by-step visuals. Some said it helped them finally understand how Transformers work, after being confused by other sources. Others noted that the article is a great resource for beginners and is even used in university courses.

One commenter mentioned that the visualizations made complex math much easier to follow. Another pointed out that understanding Transformers is important because they are used in popular AI models like GPT and BERT. Some people discussed the strengths of Transformers, such as being fast and able to handle long texts, while others warned that training them from scratch can be expensive and tricky.

A few readers shared links to other resources for learning about Transformers, showing that the community thinks this topic is important and interesting. There were also suggestions for improving the article, like adding more technical details or showing real code examples. Overall, most commenters agreed that this article is one of the best introductions to Transformers available online.

---

## Ultrasound Cancer Treatment: Sound Waves Fight Tumors

- 原文链接: [Ultrasound Cancer Treatment: Sound Waves Fight Tumors](https://spectrum.ieee.org/ultrasound-cancer-treatment)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46357945)

This article is about a new cancer treatment that uses strong sound waves, called ultrasound, to destroy tumors without surgery. The system, made by HistoSonics, sends focused ultrasound into the body using a special water-filled membrane.

The ultrasound creates tiny bubbles inside the tumor. These bubbles quickly grow and then collapse, breaking up the cancer cells and turning the tumor into liquid. This process is called “histotripsy.” In the past, bubbles were seen as a problem in medical ultrasound, but now scientists use them to fight cancer. To make this work, the ultrasound must be very powerful and used in short bursts, with breaks in between. This way, the bubbles break the tumor without making too much heat, so healthy tissue nearby is safe.

The idea started in 2001 at the University of Michigan. Zhen Xu, a researcher, found that this method could destroy tissue without cutting or burning. She later helped start HistoSonics to turn this into a real medical tool. The HistoSonics Edison system got approval in 2023 to treat liver tumors. Studies for kidney and pancreatic cancer are happening now. Pancreatic cancer is very deadly, so a good treatment would help many people.

One big benefit is that histotripsy does not leave scars, and the body cleans up the destroyed tumor on its own. The system is very precise, so it can avoid damaging blood vessels near the tumor. Early tests show it works well, even in hard-to-reach places like the pancreas. Researchers think combining histotripsy with other treatments, like immunotherapy, could work even better. When tumors are destroyed by histotripsy, the body’s immune system may learn to attack more cancer cells.

HistoSonics was bought by a group of investors, including Jeff Bezos, for $2.25 billion. The company is working on new ways to guide the ultrasound, using X-rays and better feedback systems to see if the tumor is fully destroyed. In the future, this technology could help treat more kinds of cancer without surgery.

People in the comments are excited about this new approach. Many say it could be a big step forward for noninvasive cancer treatment. Some doctors in the discussion think the lack of heat and cuts is a big advantage over old methods. Others wonder about costs and if hospitals will be able to offer this treatment soon. A few are curious if the technology could help with other diseases, not just cancer.

Some users point out that using bubbles in medicine was once thought dangerous, so it’s interesting to see this change. Others share stories of family members with cancer who might benefit from new treatments. There are also questions about how well the immune system boost works and if it will help stop cancer from coming back.

A few people are careful, saying new treatments often take years to become widely used. Some worry about possible risks or mistakes if the machine is not used correctly. Others are hopeful that, with more research and support, histotripsy could save many lives and make cancer care easier for patients.

---

## The Garbage Collection Handbook

- 原文链接: [The Garbage Collection Handbook](https://gchandbook.org/index.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46357870)

The Garbage Collection Handbook is a book about how computers manage memory automatically, called garbage collection. It explains the history, new problems, and advanced solutions for making programs use memory well. The book covers old and new garbage collection methods, including fast and real-time systems. It shows how new hardware and software make memory management harder, and why programmers need to understand these changes. The authors compare many ways to collect unused memory, using simple code and pictures to help explain. There are new chapters about saving energy and keeping data after a restart. The book is useful for anyone working with programming languages that use garbage collection, because most modern languages do. The second edition has more pages and newer information than the first. There is an e-book with many links to research and extra details. The book is also translated into Chinese and Japanese. There is a big online database with thousands of articles about garbage collection, which can be searched or downloaded.

People in the comments say the book is a great reference for learning about garbage collection. Some remember using the first edition when they started programming. A few users note that the book can be quite technical and is not easy for beginners. Others say that real-world garbage collectors, like the ones in Java or Go, are even more complex than what the book covers. Some wish more programmers understood how garbage collection really works, because it can affect program speed. Others point out that, even with garbage collection, programmers should still think about memory use. A few share stories about bugs caused by wrong ideas about garbage collection. One person says the book helps them compare different memory management systems. Another likes the big bibliography for research. Some wish there were more examples in modern languages. Others think the book is important as computers get more memory and run bigger programs. Some discuss how garbage collection is also important for mobile and cloud apps. A few ask if the book is good for learning about garbage collection in Rust or C++. There are also comments about the value of open resources and translations for students around the world.

---

## GLM-4.7: Advancing the Coding Capability

- 原文链接: [GLM-4.7: Advancing the Coding Capability](https://z.ai/blog/glm-4.7)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46357287)

GLM-4.7 is a new AI model made to help with coding and technical tasks, building on the older GLM-4.6. The article shows that GLM-4.7 is better at coding, especially in many languages and in tasks that use the command line. It scores higher on tests like SWE-bench and Terminal Bench 2.0, and is also much better at using tools, making websites, slides, and posters. GLM-4.7 is smarter at solving math and logic problems, getting much better results than before. It can also chat, write stories, and act in role-play situations.

The article gives a table comparing GLM-4.7 to other big models like GPT-5, Claude Sonnet, and Gemini. In some tests, GLM-4.7 is the best, but in others, models like Gemini or Claude Sonnet do better. The creators say that numbers are useful, but what matters most is how good the model feels to use. They show examples where GLM-4.7 builds web pages and creative projects with simple instructions.

GLM-4.7 introduces new thinking features: interleaved thinking (pausing to think before each step), preserved thinking (remembering how it solved things in past steps), and turn-level thinking (choosing when to think more or less, depending on the job). These help it do complex tasks with fewer mistakes.

You can use GLM-4.7 through APIs, on coding agents, or even run it on your own computer using open weights from HuggingFace or ModelScope. It is cheaper than some other coding AIs, and easy to upgrade if you use their services.

In the comments, some people are impressed by the progress, saying the scores show GLM-4.7 is quickly catching up to or even beating top models in some areas. Others point out that raw benchmark numbers do not always show how helpful the model is in real life. A few users ask about real-world use: Can it debug tricky code? Does it understand different programming languages well, or just a few? Some users are happy that the model weights are open, making it possible to run GLM-4.7 locally and check its code. Others warn that benchmarks can be “gamed” and want to see more examples, not just numbers. A few are excited about the new thinking features and wonder if this makes the model more “agent-like.” Overall, the community is interested and hopeful, but they want to see more real tests and daily use before calling it a top choice.

---

## Claude Code gets native LSP support

- 原文链接: [Claude Code gets native LSP support](https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46355165)

Claude Code just got native support for the Language Server Protocol (LSP), which helps with things like “go to definition,” finding references, and showing documentation when you hover over code. This means Claude Code can now give smarter code help, like most modern code editors do.

The changelog shows that LSP support is only one of many recent updates. Other changes include new terminal setup support for Kitty, Alacritty, Zed, and Warp terminals, a ctrl+t shortcut to turn syntax highlighting on or off, and improvements for macOS keyboard shortcuts. There are also new fixes, such as better crash handling when syntax highlighting fails and visual bug fixes in the plugin discovery screen. The update made context grouping better for skills, agents, and slash commands, and improved Windows rendering. For VSCode users, a new “gift tag” icon was added for a promotion.

Looking at the bigger picture, Claude Code has seen frequent updates: adding a Chrome extension, new session management tools, improved theme pickers, and features for both regular and pro users. The tool now works better with different shells, supports custom agents, and has expanded plugin support. Many small bug fixes and performance improvements make the app smoother and more reliable.

From the Hacker News comments, many users are excited about LSP support, saying this is a big step for Claude Code to be more useful for developers. Some wonder how well Claude’s LSP features compare to those in VSCode or other editors. A few point out that LSP can sometimes be slow or hard to set up, so they hope Claude makes the process simple. Others are asking about how Claude Code handles privacy and sends code to servers, which is important for company use. Some users want to know if they can bring their own LSP servers, or if only certain languages are supported. A few readers also mention that updates like this show how AI tools are getting closer to being full code assistants, not just chatbots. There’s interest in trying it out, but some say they will wait for more stable releases. Others think the frequent updates are a good sign, showing the tool is still growing fast.

---

## Feds demand compromise on Colorado River while states flounder

- 原文链接: [Feds demand compromise on Colorado River while states flounder](https://nevadacurrent.com/2025/12/22/feds-demand-compromise-on-colorado-river-states-flounder-despite-water-shoratge/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46359042)

The article talks about how seven western U.S. states are struggling to agree on how to share the Colorado River’s water, while the federal government is telling them to find a compromise soon. The river’s water levels are very low, and if the states can’t make a deal, the federal government might step in with its own plan.

The states—Arizona, California, Nevada, Colorado, New Mexico, Utah, and Wyoming—met in Las Vegas to discuss new rules before their current agreement ends in 2026. They only have until February 14 to work things out. The main problem is that there is less water in the river because of climate change, overuse, and more people needing water. Each state says it has already made sacrifices and can’t cut back more, but also argues that other states should do more. Nevada’s water manager said that these same arguments are going nowhere and that everyone keeps blaming each other.

Water levels in Lake Mead and Lake Powell are at record lows. Last winter, there was not enough snow, so not much water flowed into the river this year. The federal government says that next year could be even worse, with water flows 27% lower than normal. If things don’t improve, power plants on Lake Powell might stop working, and there might not be enough water for states downstream.

The federal government wants the states to agree on new rules themselves, but is also ready to step in if needed. Soon, federal officials will share different ideas for managing the river, but won’t pick a favorite yet. Some states, like California, say they’re willing to compromise on legal matters to reach a deal. But a long-term agreement for the next 20–30 years seems impossible now; the best hope is a short-term five-year deal.

Every state says it has tried to save water, but now their “savings accounts” are empty. The big fight is between the Upper Basin states (Colorado, Wyoming, New Mexico, Utah) and the Lower Basin states (Nevada, Arizona, California). The Lower Basin has already agreed to big water cuts, but says the Upper Basin should help more when things get worse. The Upper Basin argues they use less water already and shouldn’t have to cut more. Arizona’s negotiator says he can’t get new rules approved unless the Upper Basin agrees to share cuts equally. New Mexico’s negotiator says their state won’t agree to any more mandatory cuts.

In the comments, some people say states should have planned better and that fighting over water is not new in the West. Others point out that climate change is making everything harder, and no one wants to be the first to give up more water. Some think the federal government should just force a solution since the states can’t agree. A few commenters ask if cities could use less water or recycle more, while others say farmers use most of the water, so changes should start with agriculture. There are worries about power loss if the dams can’t run, and some users think water prices should go up to encourage saving. Some believe only a big crisis will finally push everyone to act, while others remain hopeful that a fair deal is still possible if everyone works together.

---

## NIST was 5 μs off UTC after last week's power cut

- 原文链接: [NIST was 5 μs off UTC after last week's power cut](https://www.jeffgeerling.com/blog/2025/nist-was-5-μs-utc-after-last-weeks-power-cut)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46355949)

NIST, the group that keeps official time in the US, was 5 microseconds off from Universal Time after a big power outage at their Colorado site. A strong windstorm caused the power cut, backup generators failed, and their main clock lost track for a short while.

Even with all this trouble, their Network Time Protocol (NTP) servers stayed pretty accurate, never more than 5 microseconds off. For most people, this small error doesn’t matter—your computer, phone, or regular website won’t notice. But for scientists, universities, or aerospace companies who need exact time, even a few microseconds can be a real problem.

The NIST team had to make tough choices. They thought about shutting down the time servers to avoid spreading wrong time, but since their error was so small, they decided to keep them on. NTP is built to check multiple servers, so if one is off, it won’t break your system. Also, NIST had another building with working clocks ready to help if needed.

Staff on-site managed to switch emergency power and battery backups to keep the clocks running. After all this, the time was only a tiny bit off, and services like GPS switched to backup locations with no big issues. The system’s design, which includes many backups and safety checks, worked just as planned.

The article’s writer shares his own setup: he uses GPS clocks and backup atomic clocks for his home studio, showing how people who care a lot about time add extra layers of protection. But he also warns that most precise time systems, including GPS, are fragile. If GPS or NIST fails, many parts of our world—like science, finance, and even daily technology—could be in trouble.

Many top Hacker News comments focus on how amazing it is that such a tiny time error can cause so much worry. Some joke that 5 microseconds is “close enough” for normal folks, but others point out that in high-speed trading or physics labs, every microsecond really counts.

A few users praise NIST’s team for handling the emergency well and for being honest about what happened. Some share stories about their own backup systems, including using multiple NTP servers and even old radio clocks.

There is discussion about the risks of relying too much on GPS for time. Some users mention that countries are looking for other ways to keep time in case GPS fails or is jammed. Others argue that most software and devices are not built to handle even small time jumps, so keeping time stable is a huge challenge.

One commenter wonders why more people don’t care about time accuracy, while another says the NTP protocol is “good enough” for almost everyone. Finally, a few readers are just impressed by how much care and planning goes into making sure the world’s clocks are always in sync, even when disaster strikes.

---

## Scaling LLMs to Larger Codebases

- 原文链接: [Scaling LLMs to Larger Codebases](https://blog.kierangill.xyz/oversight-and-guidance)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46354970)

This article talks about how to use large language models (LLMs) like ChatGPT for big codebases in software engineering. The author says that to get the most from LLMs, teams should focus on two things: giving good guidance (context) to the model and having strong oversight (skilled people checking the model’s work).

The article explains that LLMs work best when they can do a task right the first time, called “one-shotting.” If the model makes mistakes, fixing them often takes longer than writing the code by hand. To help the model “one-shot,” teams should build a “prompt library”—a set of clear documents, code maps, and best practices that the LLM can use as context. This helps the model understand how things are done in your codebase without making the prompt too long or confusing.

The author gives an example of a prompt library for a Django project. This library might include guides on how to write tests, where to find important files, and rules for naming things. The article says that even with good prompts, you must always read the model’s code carefully, because it might not follow all instructions.

The article also talks about the “environment” for LLMs. If the codebase is messy and full of technical debt, it’s hard for the model (and people) to understand. Making the code cleaner, more modular, and well-named helps both humans and LLMs. For example, using well-defined API files in Django apps makes it easier for the model to find and use the right code.

Oversight is also important. Even if LLMs can write code, humans need to check if the choices made are right for the project’s future. Teams should invest in growing everyone’s design and architecture skills, so they can spot good or bad decisions from the model. The article suggests learning from reading good code, copying masterworks, and practicing new skills.

Some oversight can be automated, like writing scripts or lint rules to check if code follows the team’s rules. For example, you can write a tool that checks if code is using APIs the right way, not reaching into the wrong parts of other modules.

The article also discusses the need for better ways to verify code, like making testing easier, improving documentation, and letting LLMs help with code review when possible.

In the comment section, some readers agree that LLMs are most useful for “greenfield” (new) projects because there are fewer rules and less messy context. Others say that as codebases get bigger and older, it gets harder for LLMs to help unless the code is very clean and well-organized. Some people think the idea of prompt libraries is smart, but worry it could be hard to keep the documentation up to date.

A few comments point out that oversight and human judgment will always be needed, especially for big design choices. Some readers are hopeful that better tools will make it easier to automate checks and keep code quality high, while others wonder if LLMs can ever really understand complex, real-world codebases. There is also talk about the limits of LLMs, with some saying they work best as helpers, not as replacements for skilled engineers.

Some developers share their own experiences using LLMs: they find them helpful for writing small functions or tests, but less reliable for big changes or understanding large systems. Others say that improving code quality and documentation helps everyone, not just LLMs, so these investments are worth it no matter what. Overall, readers see value in the article’s advice but think that combining LLMs with strong teams and good practices is the best path forward.

---

## Flock Exposed Its AI-Powered Cameras to the Internet. We Tracked Ourselves

- 原文链接: [Flock Exposed Its AI-Powered Cameras to the Internet. We Tracked Ourselves](https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46355548)

Flock is a company that makes AI-powered security cameras, and many of their cameras were left open on the internet without any password protection. This means anyone could watch live video, download old video, and even control the cameras.

The article’s author tested this by going to a camera in California, standing in front of it, and watching himself live on his phone, while friends across the country watched too. There were at least 60 cameras like this, showing places such as playgrounds, parking lots, streets, and even shopping areas. The cameras can zoom in to follow people’s faces, track them as they move, and record high-quality video.

Security researchers found these cameras with a tool called Shodan, which finds devices that are not properly secured on the internet. They were able to see people shopping, kids playing, and even identify people using other tools, showing how dangerous this is. One researcher said it was scary to see kids alone on playgrounds, and he wanted people to know about this risk. The exposed camera feeds let anyone change camera settings, see logs, and more, making the problem even worse.

The article explains that Flock’s Condor camera is different from their usual cameras because it is made to follow people, not just cars. The author checked public contracts and company documents to confirm that these cameras are in many cities across the US. The cameras are supposed to keep places safe, but this mistake made people less safe instead.

In the Hacker News comments, many people were worried about privacy and security. Some said this shows why putting cameras everywhere is risky, especially if companies don’t secure them well. Others pointed out that it’s not just Flock; many internet-connected devices are left open by mistake. A few people discussed how easy Shodan makes it to find these unsafe devices, and that this is a common problem with “Internet of Things” gadgets.

Some commenters were angry at Flock, saying they should have done more to protect people’s data. Others blamed cities and businesses for not checking the camera security before using them. There was debate about whether more government rules are needed to stop this from happening again. A few people were surprised by how powerful the cameras are, and worried about how they could be misused. Others thought the story was a good warning for anyone who uses smart devices without proper security. Some even joked that you should always wave at random cameras, because you never know who is watching.

---

## Things I learnt about passkeys when building passkeybot

- 原文链接: [Things I learnt about passkeys when building passkeybot](https://enzom.dev/b/passkeys/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46357451)

This article talks about lessons learned while building Passkeybot, a tool to help websites add passkey logins. The author explains how passkeys work on different devices and what makes them secure.

Apple devices have a special chip called the Secure Enclave Processor (SEP). It keeps secrets safe and never lets the private key leave the chip. Other devices have similar secure hardware, and even SIM cards work in this way. Passkeys use two main ideas: user presence (just tapping a button) and user verification (using biometrics or a passcode). Verification is more secure, as it always needs the user to prove who they are.

An "authenticator" is the hardware and software that stores and uses the passkey, like the SEP or a Yubikey. Browsers use APIs to talk to these devices, making it easy to support many types. There is a tool in Chrome Dev Tools to help test passkeys without needing to enter your password every time.

Attestation shows that a passkey was created on trusted hardware, but it can also reveal which device is being used. This could be a privacy risk. Apple does not enable attestation by default unless you use special enterprise settings. Passkeys are for authentication only; they cannot be used to sign other types of data.

If a website’s JavaScript is hacked, attackers can trick users into signing bad data. There is no way for the user to see exactly what they are signing. The browser has some protection, but it is not perfect. A new Chrome feature called "immediate mediation" allows faster sign-in for users who already have a passkey.

There are also features like Related Origin Requests, which let one domain trust another for passkeys, and Bluetooth sign-in, which lets you use your phone’s passkey on another computer. You cannot delete or list passkeys from JavaScript; only the browser or OS can do that. Some APIs let you hint that a passkey should be deleted. The user ID connects many passkeys to one account, but if you use a new ID for each, you lose some grouping.

The article also talks about making keys that cannot be copied out of the browser and how PKCE helps protect login tokens. PKCE was added to OAuth to fix security problems. Lastly, the Digital Credentials API will let browsers talk to your phone’s wallet for IDs or tickets.

In the comments, many people liked the clear explanations about secure enclaves and hardware security. Some were surprised that SIM cards have similar secure areas. Others pointed out that passkeys are still new and not all browsers support every feature, especially on iPhones or Firefox. Some said that attestation can be a privacy worry, and that most sites disable it for safety.

A few commenters discussed problems with deleting passkeys, since users cannot fully control them from the website. Some worried that if JavaScript is compromised, attackers could still trick users—even with all these new security tools. Others liked the new "immediate mediation" feature and hope it makes passkeys faster to use.

There was debate about whether passkeys are really easier than passwords for normal users. Some developers like passkeys, but worry that regular people might get confused or have trouble moving passkeys between devices. A few people asked for more real-world examples and best practices for using passkeys, especially for teams or shared accounts.

Overall, the comments showed both excitement for passkeys and some concerns about privacy, support across devices, and the limits of browser security.

---

