Hello everyone, this is the 2025-10-31 episode of Hacker News Daily Podcast. Today, we have a rich set of stories for software developers and tech enthusiasts. Let’s get started.

First, let’s talk about a subtle bug in async Rust called “futurelock.” This happens when a future is waiting for a resource, like a Mutex, but its task stops polling it. At the same time, another future in the same task also wants that Mutex, but can’t get it. Even though the code looks fine, the program hangs forever. 

The article gives an example using Tokio and Mutex. A background task grabs a lock, waits, and then releases it. In the main code, `tokio::select!` runs two futures—one waits for the lock, and another waits for a timer. After the timer, it starts another future that also needs the lock. Now, both futures are waiting, but the main task only polls one. When the lock is finally free, the first future is not polled anymore, so the program gets stuck.

The article explains that this is not a problem with how fair the Mutex is. The Mutex will wake the right future, but if the main task is not polling it, nothing happens. The real problem is that one task owns several futures that can block each other, but only one is polled at a time.

The suggested fix is to use `tokio::spawn` so each future runs in its own task. That way, each task only has one future, and polling is not blocked. Using `join_all` is also safe, since it polls all futures until they finish.

Debugging “futurelock” is very hard—programs just hang, and tasks wait forever. The article gives tips, like not using `&mut future` with `tokio::select!`, and being careful with `await` inside select branches.

In the comments, many people thank the author for a clear explanation. Some say they have run into similar problems, and spent hours or days finding the cause. Others say this shows how async code with shared resources can be hard to reason about. Some hope Rust will get better tools to catch this, but others say false positives might be a problem. A few now prefer to always spawn new tasks for real concurrency. Some compare “futurelock” to classic deadlocks, but say it’s even trickier, because simple code can get stuck. A few want better docs about these risks, but most agree this is the price for Rust’s powerful async system. Some readers point out that async deadlocks are common in other languages too.

Next, Ubuntu 25.10 is adding support for “architecture variants,” starting with special packages for amd64v3, a newer CPU type. This means some Ubuntu packages can now run faster on modern machines, without dropping support for older ones.

Ubuntu has always tried to work everywhere, but that limits performance. Processors with amd64v3 have new features, so programs built just for them can be about 1% faster—sometimes more for special software. Ubuntu has built systems to rebuild some packages for amd64v3, but only in the “main” part for now, and the new packages are not fully tested.

To try amd64v3 packages, you need a modern computer—most from the last 10 years work. The article shows how to check your CPU and update your system. There’s a warning: if you install these new packages, you cannot move your hard drive to an older computer, because it won’t work. By the next LTS release, Ubuntu plans to rebuild all packages for amd64v3 and test them well.

There are some small problems: package managers may show confusing messages about “downgrading” or about missing amd64v3 versions in third-party repos. These will be fixed in future updates.

In the comments, some users are happy about the speed boost. Some people ran into errors during the upgrade, often with changelog files causing conflicts. Workarounds like deleting or renaming those files helped. Some were confused by warning messages from apt, but others explained these are normal and will get better. A few said driver tools stopped working or icons changed after reboot, but running the upgrade again or removing old packages fixed things. One user asked about building their own amd64v3 packages. Most agree the process is still rough, but the Ubuntu team is helpful and quick to fix bugs. The community is testing, sharing fixes, and looking forward to the next release.

Now, let’s look at Google’s new developer verification for Android. Google now wants most apps to be linked to a verified developer, even for apps loaded outside the Play Store. There is a paid license for $25 and a free “hobbyist” license, but the free one may have strict limits, and the full rules are not clear yet. Google says you can still install apps with ADB, but this is not easy for normal users, and details could change.

The article’s author worries that this will make it harder for small developers to share apps. Older apps using old Android features may not pass new checks. The author suggests a workaround: a “loader” app that is verified once, and can load other apps without installing them the normal way. This uses Android’s Java system to load code from another file, but it’s technically hard and could be blocked by Google. Even the loader app would need to be verified, and could be flagged by Google. The idea is just a concept for now.

In the comments, many are unhappy with Google’s new rules. Some worry this makes Android as closed as iOS, hurting indie developers and open source apps. Others say the paid license is not the main problem—the issue is confusing rules and a lack of clear information. Some think the loader idea is clever, but will not work long, since Google can block it. Some share stories about their apps being removed for rule changes, and worry about trusting Google. Some think this will push people to use alternative app stores, but those are getting harder to use too. Many agree this hurts users who want old apps or apps outside the Play Store. Some think the rules help stop malware, but most say the balance is wrong. A few suggest moving to open platforms like Linux phones, but most agree that’s not realistic for most people. The overall feeling is that these changes make life harder for small developers and power users.

Next, a security researcher found big problems with Tata Motors’ websites. Tata Motors is India’s largest car company. The researcher found two sets of AWS keys on their sites, which gave access to over 70 terabytes of company data, including customer info and business reports. One key was hidden in plain sight, and another was “encrypted,” but the decryption code was also on the site, so it was easy to break.

The researcher also found a Tableau backdoor—anyone could log in with just a username and see private dashboards and documents. Another site for car fleet management had the key for Azuga, a car tracking service, left in public code.

The researcher reported the problems to Tata Motors, but the company was slow to fix them. It took months and several reminders before all problems were solved.

In the comments, people were shocked that such a big company could leave secrets out in the open. Some said AWS keys should never be in public code—this is a basic rule. Others said this shows how often companies ignore simple security, especially when teams are under pressure. Some said client-side encryption does not work if the code is public. Tata Motors was lucky the researcher was ethical—someone else could have done much worse. Many agree that companies need better bug bounty programs and should respond faster to security reports. Some praised the researcher for being patient and responsible. Others want stronger rules and more training to protect user data in the future.

Now, Tim Bray shares his thoughts after reading his own entry on Grokipedia, a new site that uses AI to auto-generate long articles. His Grokipedia entry is over 7,000 words, much longer than his Wikipedia page. He says it covers every part of his life but is too long and boring, even for him. He finds mistakes in every paragraph—some obvious, some only he would know. The writing is flat and generic, and many references do not really support the claims.

Bray also checked how Grokipedia handles “woke” and “anti-woke” topics. He saw that Grokipedia often tries to balance or push back against “woke” arguments, sometimes using right-leaning sources or questionable citations. He does not find these attempts convincing.

He concludes that, unlike Wikipedia, Grokipedia is not good as a reference or for research. Right now, it is not very useful, but maybe it will improve.

In the comments, some users agree that AI-written articles sound flat and miss context. Others think Grokipedia could be interesting if it improves. Some worry about bias, while others say Wikipedia also has bias, so competition is good. Some point out that AI content can quickly spread mistakes. Others wonder if Grokipedia can ever replace Wikipedia, or if it will just be another echo chamber. Some joke about the article length and wonder who would read them. Finally, some hope both sites will push each other to improve.

Next, a new leak shows that some Google Pixel phones can be hacked by Cellebrite, a company that makes tools to unlock phones for police. The leak lists which Pixel phones are vulnerable—older models like Pixel 2, 3, and 4 are at risk. This means Cellebrite’s tools can unlock them and copy data. Newer models like Pixel 7 and 8 are not on the list, likely because they have better security. Google updates software, but sometimes hardware is the real problem. If you have an old Pixel, just updating software might not make it safe. The article also says other phone brands could have similar risks.

In the comments, some are surprised that even newer Pixels were once at risk. Others say it’s normal for law enforcement to have ways to unlock phones, and users should not assume their data is safe if police have their device. Some remind us that security is always a race—hackers and companies compete all the time. Readers share tips: use strong passwords, turn off your phone if worried, buy phones with regular security updates. Some worry about privacy, and if any phone can really be secure. Others say this leak helps people understand phone security, and it’s good that Google is making progress. Some think the leak will push companies to work harder on security. A few joke about how hard it is to keep up with security news. Finally, some remind everyone that no device is 100% safe.

Let’s move on to a new way to search huge public data archives right in your browser, thanks to Harvard’s Library Innovation Lab. Before, searching and filtering big collections needed servers and databases, which are expensive and need people to maintain. When projects lose funding or staff, websites break or disappear. The cheap way is to store files as static files online, but then users can’t really search or filter.

Harvard’s team wanted people to search their 18-terabyte Data.gov Archive, but without servers. They used tools like DuckDB-Wasm, which lets the browser run database queries. Data is stored as compressed Parquet files on static storage. When a user searches, the browser runs DuckDB-Wasm and only downloads the needed data. No server is involved.

They hit some problems, like the DuckDB-Wasm file being large and slow to load. They are still looking for ways to speed it up. But overall, it’s cheap, easy to keep running, and people can search huge archives from their browsers.

This idea is important for libraries and digital projects—it means lower costs, less work, and archives stay online longer. The team invites others to try this for their own big, mostly unchanged datasets.

In the comments, people are excited about using DuckDB-Wasm to avoid expensive servers. Some say this helps universities and small projects. Others point out it works best for data that doesn’t change much, since updating static files is tricky. Some worry about browser memory limits, or about privacy if all data is sent to users. There’s a discussion about making DuckDB-Wasm smaller and faster. Some share projects using SQLite in the browser, or building static sites for open data. Others see this as a big win for the open web. Overall, the idea is popular and people are sharing ways to make it better.

Now, let’s talk about Perfetto, a set of tools to help Linux and embedded developers trace and fix performance problems. Perfetto has tools to collect data, a special file format, and a trace processor that lets you run SQL queries on your trace data. You can collect traces from many sources, and the Perfetto UI is a web tool that shows timelines, flame graphs, and tables. All analysis is done in your browser for privacy.

The article gives an example with a Rust app that renders fractals. The app sometimes drops frames. Perfetto helps the author zoom in on specific times and see how only one thread runs at a time. By looking at scheduler traces and application-level traces, the author finds that a function to update quality is blocking everything. After moving this to a background thread, performance improves.

Perfetto supports many trace formats and can merge traces together. The UI has powerful features like area selection, custom filters, and SQL queries. It is used in many projects, and there are scripts to make it easier to use.

In the comments, users praise Perfetto as very useful for deep debugging. They like that it is easier than older tools and that the UI is web-based. Some say setup can be confusing at first and want better guides. Some like the privacy focus, but want even stronger guarantees. Developers use Perfetto with Rust, Python, and kernel development. Some compare it with tools like pprof or Speedscope, saying each has its strengths. Some thank the Perfetto team for being open to contributions. Overall, Perfetto is popular, flexible, and getting better, though it still has a learning curve.

Next, we have a detailed list of all 1-byte opcodes in x86, showing what each code does and how it changes with different CPUs and modes. It covers instructions like ADD, SUB, MOV, and XOR, plus special and legacy instructions like PUSH and POP. The article explains how prefixes like REX and VEX let x86 handle more registers or add new instructions. There are notes on NOP instructions, showing how NOP changes between 16-bit and 64-bit modes. The author also points out less-used or reserved opcodes, and how some are now used by companies outside Intel or AMD. Links are given to more tables and technical notes.

In the comments, people say this table is a “must-have” for anyone working close to hardware. Some point out how complex x86 has become, and compare it to simpler architectures like RISC-V. Some share stories about debugging bugs due to missing documentation. Others are amazed at how many instructions fit into one byte, and some are surprised by old or strange instructions that are still supported. Many use this table for writing JIT compilers or disassemblers. There is talk about special uses for NOPs, and jokes about the “arcane magic” of x86. Some wish x86 was designed more cleanly, but others respect its history. Several thank the author for keeping this resource up to date.

Finally, let’s talk about Corrosion, a new system Fly.io built to handle global state sync for their platform. They needed a way to keep track of all servers and apps around the world, since old systems like Consul and SQLite were too slow or broke at global scale. Corrosion borrows ideas from network routing protocols like OSPF. Each server keeps its own data and shares updates with others using a gossip protocol, like routers sharing new links. It uses SQLite for storage, but without central control. It uses CRDTs to handle updates and avoid conflicts.

The team learned from outages, like a deadlock bug that spread fast and brought down proxies, and problems from database changes causing huge network traffic. Running Corrosion and Consul at the same time also caused overload when Consul failed.

To fix things, they added watchdogs to restart stuck services, improved testing, and now keep backups. They changed how updates are sent—now sending full data for each server to avoid bugs. Recently, they split Corrosion into regional clusters, so problems only affect small parts of the network.

In the comments, many are impressed by the honest sharing of failures and lessons learned. Some like the move from consensus to gossip protocols. Others say CRDTs and gossip need careful handling. Some ask if Corrosion could be used by others, or if it is too specialized for Fly.io. Some worry about not having a central source of truth, but others say regionalization and backups help. There are questions about how Corrosion compares to tools like Etcd or Zookeeper, with answers explaining the design differences. Many praise the technical depth and the value of sharing “war stories” from real distributed systems.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. We hope you found these stories interesting and helpful. See you next time.