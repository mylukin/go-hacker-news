# Hacker News 故事摘要 - 2025-09-01

## 今日概述

Today’s top Hacker News stories cover tips for better public speaking, Amazon’s slow approach to AI, and ways to pick the best AI models for each task. Other stories look at new graphics effects, updates for Raspberry Pi and Linux, and ideas to improve computer memory. There are also reports on AI web bots and a fun project making a round Minecraft world. If you like software, hardware, AI, or creative tech ideas, there is something interesting to read today.

---

## Patrick Winston: How to Speak (2018) [video]

- 原文链接: [Patrick Winston: How to Speak (2018) [video]](https://www.youtube.com/watch?v=Unzc731iCUY)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45095849)

This talk is about how to speak well in public, given by Professor Patrick Winston at MIT. He shares simple rules and tips to help anyone become a better speaker, whether for teaching, job talks, or sharing ideas.

He says your ability to speak is even more important than writing or your ideas alone. To begin a talk, you should not start with a joke. Instead, promise your audience what they will learn by the end. He explains four main techniques: repeat your main idea several times (cycling); make your idea clear and different from others (fencing); use verbal punctuation—pause and summarize to help people refocus; and ask questions to keep listeners engaged. Good timing and place matter too—11 a.m. is best, and the room should be well lit and filled enough to feel lively. 

For tools, use chalkboards or whiteboards for teaching, because drawing helps people understand and gives your hands something to do. Props can be useful to make ideas more memorable. When using slides, keep them simple: few words, big text, and no laser pointers, so you keep eye contact. To inform and inspire, show your passion, give strong examples, and teach people how to think by sharing stories and asking good questions. For job talks and persuading people, explain your vision, list clear steps, and show your achievements quickly. If you want your ideas to be remembered, use the “5 S” method: create a symbol, make a short slogan, add a surprise, highlight the main idea, and tell a story. 

To end your talk, do not say “thank you for your attention”—it is weak. Instead, summarize your main contribution, give a call to action, or finish with a joke so people remember your talk with a smile.

In the comments, many people thank Professor Winston for his dedication and teaching style. One person shares a story about seeing him rehearse early every morning, showing how much he cared about his students. Some say his tips helped them pay attention for the whole talk, even if they usually struggle to focus. Many share their own summaries, listing his rules about starting, using repetition, keeping slides simple, and ending strong. People love how he uses his own advice during the talk, showing instead of just telling. Some wish they had teachers like him, while others say this talk finally helped them feel able to speak in public. A few note that not starting with a joke is funny in itself, and that he makes even complex advice feel simple. There is also some debate about never saying “thank you” at the end, but most agree it’s better to summarize your message or end with a story. Overall, people feel inspired and grateful for Winston’s wisdom and his clear, kind way of teaching.

---

## Amazon has mostly sat out the AI talent war

- 原文链接: [Amazon has mostly sat out the AI talent war](https://www.businessinsider.com/amazon-ai-talent-wars-internal-document-2025-8)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45095603)

Amazon is not hiring as many AI experts as companies like Google, Microsoft, or OpenAI. The article says that while other big tech companies are racing to get the best AI people, Amazon is moving much more slowly.

Amazon has not made big public deals or hired famous AI researchers. They are not spending as much money on AI talent or big partnerships. Instead, Amazon is using its own teams and building things step by step. The company’s main AI project right now is called Bedrock, which helps other businesses use AI models. Amazon is also adding AI to Alexa and its cloud services, but these are not as flashy as the big AI launches from other companies.

Some people think Amazon is going slow because they want to be careful and save money. Others say Amazon is waiting to see what works before they spend more. The article points out that Amazon's leaders believe their slow and steady way will win in the long run. They also think they can use their strong cloud business (AWS) to help customers use AI, instead of building everything themselves.

In the comments, some people think Amazon is smart for not joining the expensive AI race. They say Amazon has always moved carefully and waited to see what works before spending big. Others worry Amazon might fall behind if they don’t invest more now, because AI could change everything fast. A few commenters say Amazon’s slow pace means they miss out on hiring the best AI talent, who will go to more exciting companies.

Some people point out that Amazon has lots of data and cloud power, so they can catch up later if they want. Others say Amazon’s culture is more focused on selling and logistics, not on research, so it makes sense they would not lead in AI. A few think Amazon is quietly working on AI behind the scenes and will surprise people later. Some just believe Amazon is being cheap, but others think it’s a smart business move. Overall, people are split on whether Amazon’s slow approach is wise or risky.

---

## Adaptive LLM routing under budget constraints

- 原文链接: [Adaptive LLM routing under budget constraints](https://arxiv.org/abs/2508.21141)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45094421)

This article talks about how to choose the best large language model (LLM) for each task, while also keeping costs low. The main idea is that using big LLMs can be very expensive, but not every request needs the most powerful (and costly) model.

The authors explain that earlier systems tried to match each question to the best LLM by using supervised learning, needing lots of data that shows which model is best for every type of input. In real life, we do not have this perfect data, and user needs change over time. So, they suggest using a “contextual bandit” method. This lets the system learn by trying different LLMs for new questions and getting feedback—sort of like trial and error.

They build a shared “embedding space” where both the questions and the LLMs are turned into vectors, so the system can see which questions and models are similar. At first, this space is made from past human feedback, but it keeps getting better as the system tries more things and learns from results.

Their method is called PILOT, which is an improved version of an older bandit algorithm called LinUCB. PILOT helps the system pick which LLM to use for each question, while also watching the cost. To do this, they use a math problem called the “multi-choice knapsack problem,” which helps spread the budget wisely across many requests.

The system can change how it routes each request, based on user needs and how much money is left. This approach makes it possible to use expensive LLMs only when they are really needed, and use cheaper ones for easier tasks.

In the comments, some people are happy to see research that makes LLM use more efficient, since costs can be a big problem for startups and developers. Others ask if this approach can work with open-source models, or only with paid APIs. Some wonder how well the system can adapt if a new, better LLM comes out.

One commenter points out that “contextual bandits” are a smart choice, because they work well when you do not know all the answers up front. Another person is worried that the method might depend too much on good feedback—if users do not give feedback, the system might not learn fast enough.

A few users discuss the math part (the knapsack problem), saying it is a neat way to handle budget limits, but it could get slow if there are many requests at once. Some also raise privacy concerns: if user queries are sent to many LLMs, is the data safe?

Someone else asks if this routing approach could be used for things other than LLMs, like picking the best database or translation service. Lastly, a few developers say they would like to try this system in their own projects, but hope there will be open code or tools shared soon.

---

## Implementing a Foil Sticker Effect

- 原文链接: [Implementing a Foil Sticker Effect](https://www.4rknova.com/blog/2025/08/30/foil-sticker)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45095460)

This article explains how to make a foil sticker effect in Three.js using custom shaders. It shows how to create the shiny, rainbow look you see on holographic stickers or trading cards, including the way the colors change with the viewing angle and how the sticker sparkles with tiny foil flakes.

The main effect uses two ideas: iridescence and foil flakes. Iridescence is when colors shift like a rainbow when you move the sticker or change the light angle. The shader does not copy real physics, but instead changes the color hue based on the angle between the sticker surface and the camera. This gives a believable “alive” feeling as you move the sticker.

Foil flakes are the little sparkles you see on real foil. The shader makes these by adding random bright spots using a noise function and lighting tricks. These flakes catch the light and twinkle as the sticker moves, making the surface look more special.

The article describes the code for the vertex shader, which handles the shape of a peeling sticker and passes needed data to the next step. It shows how to rotate parts of the sticker to make it look like it is peeling away from a corner. The code also darkens lifted parts to make them stand out.

The fragment shader is where the color magic happens. It mixes the base sticker color, reflections from the environment, bright foil flakes, and the angle-based iridescence. It uses several controls, so you can adjust how sparkly, shiny, or colorful the sticker looks. There’s a live demo where you can try different settings and see the effect in real time.

The code is shared under a Creative Commons license for non-commercial use, but you need to ask the author for a commercial license.

In the Hacker News comments, some readers are impressed by the visual quality and how the effect can run in real time on the web. Others like that the article shares full shader code and clear explanations, making it easy to learn even for people new to graphics programming. A few commenters discuss the trade-offs between realism and performance—some prefer this “plausible but not physical” approach for speed, while others wonder how close it really gets to actual thin-film physics.

People share ideas about how the effect could be used, like for digital trading cards, game items, or playful UI elements. Some mention possible improvements, such as adding more types of flakes or using different noise patterns for even more realism. One commenter warns about browser differences in shader support and suggests fallback options for older devices.

A few developers ask questions about integrating the shader with other Three.js materials or about performance on mobile. Others mention alternative tools, like Unity or Godot, and discuss how easy or hard it would be to port the effect. Overall, most agree that this is a great example of modern web graphics and a fun project to try.

---

## Raspberry Pi 5 support (OpenBSD)

- 原文链接: [Raspberry Pi 5 support (OpenBSD)](https://marc.info/?l=openbsd-cvs&m=175675287220070&w=2)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45096585)

OpenBSD has added support for the Raspberry Pi 5 Model B in their system. This means you can now run OpenBSD on this new version of Raspberry Pi, but there are still some things that do not work well yet.

The update changed files that help build the ARM64 version of OpenBSD, so it can now make images that boot on the Raspberry Pi 5. The developers made a special note that this support is for RAMDISK, which is a part of the system used during installation and recovery. There are some known problems. First, you cannot boot from PCIe storage HATs because OpenBSD does not yet have the needed U-Boot support. Second, WiFi does not work on some Raspberry Pi 5 boards, called "d0" boards. Third, the active cooling fan does not work, because OpenBSD does not have the right drivers for the fan’s control system. The developers are working on these issues, especially for the fan.

The update was approved by two other OpenBSD developers, showing it passed review and is ready for users to try. This support is a good step for people who want to use OpenBSD on cheap, small computers.

In the comments, some people are happy to see OpenBSD running on the newest Raspberry Pi. They say this can help make the Raspberry Pi 5 more useful for experiments and secure projects. Other users note that hardware support is still not complete. Some wish for better WiFi and fan support, and hope these features come soon. A few people discuss the slow speed of adding new hardware support to OpenBSD, but others remind them that OpenBSD is focused on safety and simple code, so support often comes later. Some comment that not having PCIe storage or WiFi is a big problem for their projects. Others say that even with these missing parts, OpenBSD on Raspberry Pi is good for learning and testing. A few users thank the developers for their hard work and for making OpenBSD better for everyone. Some also compare OpenBSD support to Linux, and say Linux often works with more hardware sooner, but OpenBSD brings unique safety features. Overall, people are hopeful about future updates and happy to see progress.

---

## The future of 32-bit support in the kernel

- 原文链接: [The future of 32-bit support in the kernel](https://lwn.net/SubscriberLink/1035727/4837b0d3dccf1cbb/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45095475)

This article talks about the future of 32-bit support in the Linux kernel. The main point is that 32-bit systems are mostly old, and new products do not use them anymore.

Most desktops, servers, and even phones have moved to 64-bit for many years. Only some old hardware and some embedded devices still use 32-bit. In embedded systems, Arm processors are most common, but now, more new 64-bit Arm boards are coming than 32-bit ones. Some very old Arm hardware is still supported in the kernel, but many are not made anymore, and support for some could be removed soon. There is no fixed time to stop support; it depends on whether people still use those devices.

Other 32-bit systems like arc, microblaze, nios2, openrisc, rv32, sparc/leon, and xtensa are also getting replaced by RISC-V. Some very simple processors without a memory unit (nommu) are now only for special cases or old systems. If you need to run old 32-bit apps, it is best to use a 32-bit user space on a 64-bit kernel. Keeping 32-bit kernels creates problems, especially with managing memory. On 32-bit, it is hard to use a lot of memory, and support for this is complex. Soon, the kernel will not support 32-bit systems with more than 4GB of memory.

There are ideas to help with memory, like new "densemem" models or using extra memory for swap, but these are not easy to get working well. Another big issue is the year-2038 bug, which breaks time on 32-bit systems. The kernel and some libraries are fixed, but many programs are not, so most 32-bit desktops will stop working in 2038. Some support, like big-endian or old CPUs, is only kept because a few companies still need it. Other very old CPU support will be dropped soon.

The article says that Armv7 systems will still need support for about 10 more years, but other 32-bit systems may lose support much sooner. Removing complex memory support is planned around 2027, and nommu support around 2028. It is not always easy to know if anyone still uses very old hardware, so developers look for signs like bug reports or recent code changes.

From the comments, some people agree that 32-bit is not needed anymore and should be removed to make the kernel simpler and easier to maintain. Others say there are still real users, especially for old devices in the field or for special projects. Some worry that dropping 32-bit support will make it harder for people in poorer countries or for hobbyists who use old hardware. A few mention that dropping high-memory support will break some rare systems, but most people do not need them. There are users who want to keep support for fun, learning, or retro projects.

A few commenters explain that keeping 32-bit support is a lot of work and causes bugs, especially in memory management. Some say it is fine to keep 32-bit user space for running old programs on new hardware. Others discuss the year-2038 problem, saying most 32-bit systems will be dead by then anyway. Some developers think the kernel team is handling the changes carefully and with good balance. A few ask for clear warnings before old support is removed, so users have time to prepare. There are some who just feel sad to see old systems go, but most agree it is part of progress.

---

## Thoughts on (Amazonian) leadership

- 原文链接: [Thoughts on (Amazonian) leadership](https://www.daemonology.net/blog/2025-09-01-Thoughts-on-Amazonian-Leadership.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45095545)

The article looks at Amazon’s famous Leadership Principles and shares ideas on how they work in real life. The writer is an AWS customer and community member, not an Amazon employee, but has watched Amazon closely for many years.

First, the article talks about “Customer Obsession.” Amazon says leaders should focus on customers and work backwards. The writer likes this, but thinks Amazon sometimes follows it too simply. For example, instead of only building what customers ask for, Amazon should also think about what customers really need—even things they might not know to request. The article mentions early AWS products that were creative and useful, even if customers did not ask for them first. But later, AWS started only building what customers or analysts requested, and this was a mistake. For example, Amazon tells customers to make their apps resilient, but does not give them the best tools or fair prices to do this. The writer says AWS should return to creating helpful building blocks, not just following requests.

Next, the article covers “Ownership.” Leaders should think long-term and for the whole company, but the writer says Amazon should go even bigger and think about the whole tech ecosystem. He gives an example of an Amazon engineer helping with FreeBSD, even though Amazon does not use that software. This helps everyone, not just Amazon. However, the writer says Amazon is often too secretive, with teams working in silos and not sharing with each other. This leads to wasted effort and makes it hard for leaders to truly own company-wide goals.

Then, “Bias for Action” is discussed. Amazon wants leaders to act fast and take risks. The writer agrees speed is good, but warns that moving too fast can hurt customer trust, especially if products are not ready. He shares his own experience in security, where waiting to release the right patch was better than sending a broken one quickly. He suggests Amazon needs more senior engineers who can stop bad projects before launch, just like “bar raisers” can veto bad hiring choices.

In the comments, people share many views. Some agree that Amazon’s leadership ideas are good, but not always followed in practice. Others say the principles sound great, but are often used as buzzwords or to justify management decisions. A few ex-Amazonians say silos and secret work are real problems inside the company, causing teams to repeat work or miss big problems. Some people think the customer focus has become too much about pleasing big business clients or Wall Street, not regular users. Others defend Amazon, saying the company is so big it’s hard to avoid silos, and that fast action is needed to beat competitors. One commenter thinks Amazon should be more open with its tools, sharing them with the tech world. Another adds that focusing too much on quick wins can hurt trust, especially in cloud services. Overall, people like the writer’s balanced view: the principles are good but need better use and real leadership to make a difference.

---

## Towards Memory Specialization: A Case for Long-Term and Short-Term RAM

- 原文链接: [Towards Memory Specialization: A Case for Long-Term and Short-Term RAM](https://arxiv.org/abs/2508.02992)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45096140)

This article talks about a new way to design computer memory, suggesting we should split RAM into two types: long-term RAM for data that stays and is read often, and short-term RAM for data that changes a lot and does not last long. The authors say that today’s main memory types, SRAM and DRAM, are not getting cheaper or better, so memory is now a big part of the cost for computers. They think the old system, which uses just a simple memory hierarchy, is not enough for new needs. Instead, they propose adding new memory types that better match how programs use data. 

Long-term RAM (LtRAM) would store things that do not change much but need to be read many times, like reference data or large models. Short-term RAM (StRAM) would hold data that changes a lot and is used only for a short time, like temporary files or buffers. The paper looks at different hardware ideas that could make these new RAM types real, and how they could fit in today’s computers. The authors also talk about the need for the operating system to help manage these memory types, so software uses them well. They believe that if we do this, computers will be faster and cheaper, as memory would better match the needs of programs.

Now, in the Hacker News comments, some people say this idea is like what has already happened with storage: we have both SSDs and hard drives for different needs. Others think this could make programming more complex, since developers or operating systems would have to decide which memory to use. A few say this split could help with power saving and make data centers work better. One commenter notes that similar ideas have come and gone before, so they wonder if it will really catch on this time. Some are excited about the potential for new hardware, while others are worried about costs or the risk of new kinds of bugs. There’s a debate about whether software or hardware should be in charge of picking memory types. A few bring up that some big tech companies already do custom memory tricks for their workloads. Others ask if this will help everyday users or just the big cloud providers. Some believe this could make open-source operating systems more important, while others fear it might lock users into certain hardware. A couple of people say this is a much-needed change, and others just want to wait and see if it becomes real.

---

## Cloudflare Radar: AI Insights

- 原文链接: [Cloudflare Radar: AI Insights](https://radar.cloudflare.com/ai-insights)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45093090)

Cloudflare Radar’s AI Insights shows data about how AI bots visit and scan websites on the internet. The report looks at which AI bots are most active, why they scan sites, and how website owners can see and manage this traffic. The top five AI bots are GPTBot, ClaudeBot, Meta-ExternalAgent, Amazonbot, and Bytespider, and together they make up most of the AI-related traffic. About 78% of the AI bot scanning is for training new AI models, while 17% is for search engines, and only 4.5% comes from real users doing actions. The report also shows that AI bots crawl many web pages but send back much less traffic in return, meaning they take more data than they give back in visits. Cloudflare shares best practices for bots, recommends using robots.txt files to control bot access, and shows which AI services and models are most popular on their platform. There are also stats about how AI is used in Cloudflare’s own Workers service, which lets people run AI tasks at the edge of the network.

In the Hacker News comments, some people worry that AI bots are “scraping” too much data from the web without giving credit or value back to site owners. Others think it’s helpful to see this level of detail, so website owners can understand and maybe block unwanted bots. A few users say robots.txt files are not always respected by bots, especially some AI crawlers, making control harder. Some developers talk about the big gap between how much data AI bots take and how few users actually come from AI-powered search, calling it unfair for content creators. Others point out that blocking all bots might hurt discovery or reduce traffic from legitimate search engines. There are also comments about how Cloudflare’s tools make it easier to spot and manage bot traffic, and some appreciate the transparency of this data. A few people discuss ethical issues with large AI companies using public data to train their models without permission. Some suggest more technical solutions, like better bot identification or new standards to manage AI bot access. Other users think that the rise of AI bots will force websites to change how they share and protect information online. Overall, the discussion shows a mix of concern, interest, and hope for new tools to balance AI growth with fair use and website control.

---

## Making Minecraft Spherical

- 原文链接: [Making Minecraft Spherical](https://www.bowerbyte.com/posts/blocky-planet/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45055205)

This article talks about making a Minecraft-like world, but as a round planet instead of a flat land. The author made a demo called Blocky Planet using the Unity game engine, where you can build and destroy blocks on a sphere.

The main challenge is that making a blocky sphere is harder than making a flat world. On a flat world, blocks line up with gravity, but on a sphere, the surface curves, and gravity points to the center. The author explains that to solve this, he used a “quad sphere” method: he starts with a cube, splits each face into a grid, and then pushes those points out to make a sphere. This helps keep the blocks less stretched and weird-looking.

Still, stretching happens, so he improved the mapping to make the blocks look more like squares instead of rectangles. For the inside of the planet, he split it into “shells”—as you move away from the center, shells get bigger, and each new shell has more blocks per layer. This keeps the block size almost the same everywhere, but it does mean some blocks are bigger than others in the same shell.

The world is split into six “sectors,” like slices of an orange. Each sector is made of shells, and each shell is split into chunks of 16x16x16 blocks, just like how Minecraft uses chunks. This makes it easier for the computer to process and draw the world. The code for finding a block’s position uses sector, shell, chunk, and block numbers, like an address.

Finding neighboring blocks is tricky, especially at the edges between shells or sectors. Sometimes, a block has four neighbors above it instead of just one. The author made special code to handle these cases. For gravity, he made it always pull you toward the center of the planet. As you dig deeper, gravity gets weaker.

To make terrain, he uses 3D noise, which makes smooth hills and valleys without visible seams. There are two biomes—forest and arctic—based on how close you are to the poles. Placing trees and houses is hard near the corners where three sectors meet, so he uses a trick of growing the structure from a starting block.

In the future, he wants to add things like caves, more biomes, better lighting, and maybe even more planets.

Hacker News commenters found the project impressive and fun. Some said it reminded them of older demos and games that tried to make round Minecraft worlds. Others discussed the technical challenges—like mapping grids to spheres and handling block neighbors. A few pointed out similar games, such as PlanetSmith or games that use hexagons instead of squares.

Some people worried about performance, especially as the planet gets bigger. Others thought the idea could be useful for learning about geometry or math. A few asked if the source code would be available, and the author said he might share it later.

There was talk about possible gameplay, like digging to the core or flying around the planet. Some commenters were curious about how gravity feels in the game and if there would be problems with motion sickness. Others liked the use of 3D noise for world generation and thought the biome idea was clever.

A few people wondered if the game could support multiplayer or if it could be used as a tool for education. Many said they would like to see more features, like caves, more block types, or even planets that crash into each other. The overall feeling was that this is a creative and interesting tech project, even if it’s just a demo for now.

---

