# Hacker News 故事摘要 - 2025-12-30

## 今日概述

Today's top Hacker News stories are about new ways to build and manage software, with teams using monorepos and AI tools. There are cool projects like a global weather service on a small server, a big Hacker News data archive, and a new fast PDF text tool. Other stories cover a server upgrade for F-Droid, cleaning up soil pollution, a cryptography bug fix, unikernels, AI agents for coding, and running Windows apps on Linux. Many stories focus on open source, speed, and making tech easier or safer.

---

## Everything as Code: How We Manage Our Company in One Monorepo

- 原文链接: [Everything as Code: How We Manage Our Company in One Monorepo](https://www.kasava.dev/blog/everything-as-code-monorepo)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46437381)

This article is about how the company Kasava runs everything—from code to docs to marketing—in one big repository (a “monorepo”). The writer explains how this helps the team move fast and keeps everything in sync, since all parts of the company’s work live together.

At Kasava, every part of the business—frontend, backend, website, docs, marketing, emails, and even investor slides—is in the same repo. There’s one source of truth, so when something like a pricing limit changes, you only change it in one JSON file. This update then appears correctly in the app, on the website, in the docs, and anywhere else, all at once. The company’s AI tools can read this repo, so when you ask the AI to update something, it checks and updates all the places that need it. For example, if you ask to change the pricing page, the AI can make sure the backend, frontend, website, docs, and even blog posts match.

The team uses a simple workflow: to make changes, you just edit the code and do a ‘git push’. There’s no need for different tools for content, marketing, or docs—everything is code, reviewed and shipped the same way. This helps avoid confusion and broken links between teams or tools. All types of updates—features, bug fixes, new blog posts—follow the same process and review steps. The company avoids using complex tools like workspaces; each project (frontend, backend, etc.) has its own dependencies, which makes things easier to manage.

To keep things clear, every main folder has a ‘CLAUDE.md’ file that explains what it does, the tech used, and how to get started. This helps both people and the AI assistants understand the project quickly. CI/CD (testing and deployment) is set up so only the parts that change get rebuilt or tested. Even big files or assets are handled outside the repo if needed.

The article also talks about some challenges. The repo is big, but not too big yet—cloning it is still fast. Build times are not a problem, because each part builds on its own. Right now, everyone on the small team can see everything, but if the team grows, they can add more controls. Switching between different types of projects and code can be hard, but they use the same tools and patterns everywhere to help with this.

In the comments, many people agree that a monorepo makes life easier, especially for small teams. They like how it avoids confusion about where things live and keeps everything connected. Some commenters say that this setup works well until a company gets very big or has many different teams working on unrelated things. Others think that having everything as code—even docs and marketing—makes updates faster and review easier. But a few warn that very large monorepos can get slow, or that it can be hard to control who can see or change what. Some say that tools like Google Docs or WordPress are still useful for some teams, especially for non-technical people. Overall, most agree this approach helps small, fast-moving teams stay organized and ship updates quickly.

---

## FediMeteo: A €4 FreeBSD VPS Became a Global Weather Service

- 原文链接: [FediMeteo: A €4 FreeBSD VPS Became a Global Weather Service](https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46436889)

This article is about how one person built a global weather service, called FediMeteo, using a very cheap FreeBSD VPS for just €4 a month. The service started as a way to get weather updates for local cities directly in the Fediverse, but it grew to support thousands of users around the world.

The creator chose FreeBSD because its jails make it easy to separate countries and manage security. At first, he thought only a few people would care, but soon many users wanted updates for their own cities. He used open weather sources like Open-Meteo and wttr.in for the data. Accessibility was important: the service works without JavaScript, supports local languages, uses emojis, and can be read with text browsers.

The project uses simple Unix tools—small scripts working together. For each city, there’s a “user” in the software snac, which posts weather updates. The main program is a Python script that pulls weather data, formats it in Markdown, and posts it through snac. Updates run every 6 hours, and everything is monitored so problems can be fixed quickly.

As people found out about FediMeteo, they asked for more countries and features. The developer added support for different languages, time zones, and measurement units (like Fahrenheit for the USA). He had to handle cities with the same name in different regions. The VPS proved strong enough to run the whole service, even as it grew to cover nearly 3,000 cities and 38 countries.

Problems did come up: for example, he once leaked his API key by accident, but users reported it and the weather provider gave him a new one. Sometimes the tool for finding city coordinates failed, so he added caching to fix that. The VPS runs with very low memory and CPU use, and regular backups keep the data safe.

In the end, the article shows that you can build something useful and global with simple tools and a small budget. The creator says it’s proof that “less is more”—you don’t need huge cloud services or complex systems. The project also brought people together, just like his grandfather did when talking about the weather.

Hacker News readers had a lot to say about this. Some loved how the project sticks to the Unix philosophy—doing one thing well and using simple tools. Others praised the use of FreeBSD, saying it’s nice to see it used for something modern and big. Many liked that the weather data is open and the service is accessible in different languages and without JavaScript.

A few commenters worried about scaling—would the VPS hold up if even more cities or users joined? Some thought the approach of one jail per country was clever but might get tricky to manage long term. People also discussed the importance of good backups and were glad to see the creator takes this seriously. Some shared stories of their own simple projects that grew bigger than expected, showing that this experience is common in the tech world.

There was praise for the developer’s openness about problems, like the API key leak, and for quickly fixing them. Others liked how the project helps people who aren’t served well by big tech services or who want more privacy. A few users wondered if something like this could be used for other kinds of public data, not just weather.

Overall, the comments were positive, with many hoping the project keeps growing and inspiring others to build useful tools with simple, open tech.

---

## A faster heart for F-Droid. Our new server is here

- 原文链接: [A faster heart for F-Droid. Our new server is here](https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46436409)

F-Droid has upgraded its main server, which builds and publishes free Android apps, thanks to community donations. The new server replaces 12-year-old hardware and brings a big speed boost to the whole F-Droid project.

The team waited to upgrade because global supply chains made it hard to find the right parts. They wanted hardware that would last and fit their needs, so they took extra time to plan and source everything carefully. The new server is not in a random data center; it’s managed by a trusted long-time contributor, so the team knows exactly who has access and where it’s located. This setup matches F-Droid’s values about security and transparency.

With the old server, updates for apps were published every three or four days. Now, updates go out every day or even twice a day, so users get new versions faster. The extra server power lets F-Droid do more builds in less time, which helps both developers and users. The team is happy with the performance but plans to stay careful, since running servers always brings surprises.

Donations made this upgrade possible. The team thanks everyone who gave support, saying that a faster server makes the whole project safer and more reliable for everyone.

In the comments, many people are happy about the upgrade and thank the F-Droid team. Some say better speed will help them trust F-Droid with more of their apps. Others ask about the server specs—curious if it’s still consumer hardware or more like enterprise gear. A few worry about the single location, wondering what happens if the server fails or needs maintenance. Some suggest using cloud hosting for even more reliability, but others support F-Droid’s choice to keep control in trusted hands. One commenter mentions that open hardware would be even better for transparency. Another says that F-Droid’s careful approach to security and independence is why they use it. Overall, the community response is positive, with a few suggestions for future improvements.

---

## Show HN: 22 GB of Hacker News in SQLite

- 原文链接: [Show HN: 22 GB of Hacker News in SQLite](https://hackerbook.dosaygo.com)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46435308)

This article is about a project called “Hacker Book,” which lets you download the entire history of Hacker News—about 22 GB of data—in a single SQLite file. The project includes all posts, comments, and user profiles from October 2006 up to December 2025, making it a full archive of the site.

The main idea is to give people free, easy access to Hacker News data. The data is stored in SQLite, so anyone can search, analyze, or build tools with it. The dataset covers over 46 million items and is divided into many parts (called shards) for easier handling. The creator wants people to use this data for research, fun projects, or to make new websites and visualizations. 

The website also acts like an alternative Hacker News frontend, letting you search or browse stories by user, category, or time. There are features like sorting by comments or points, and you can even view deleted stories and comments. This makes it easier to study trends, see how conversations change over years, or find hidden gems from the past. The SQLite format is popular because it’s easy to use—just download the file and open it with any database tool.

Some examples of what you can do: find top stories from certain years, look at how certain topics became popular, or follow the activity of famous users over time. The project is free to use, and the data updates regularly. The creator hopes this will help journalists, researchers, or anyone interested in tech history.

In the comments, many users praise the project, calling it a treasure trove and a good resource for learning about tech trends. Some people talk about using the data for personal analysis, like tracking popular topics or making visualization tools. Others are excited about using it for machine learning or language models. A few mention privacy concerns, since all user comments are included, but most agree it’s public info already.

Some users share tips on how to handle such a large SQLite file, suggesting tools or ways to make queries faster. A few worry about the size, saying 22 GB is too big for some people to download or store. Others ask about updating the data, and the creator replies that there will be regular updates. There are also comments from people who want to build their own Hacker News frontends or search engines using this data.

People debate if this makes it easier to spot trends or see how discussions have changed over time. Some think it would be cool to compare Hacker News with other sites, or to find the best comments and stories ever posted. One person wonders if this could help stop spam or fake accounts by analyzing posting behavior. Overall, the community seems happy with the project and eager to see what people build with it.

---

## Electrolysis can solve one of our biggest contamination problems

- 原文链接: [Electrolysis can solve one of our biggest contamination problems](https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46436127)

This article explains a new way to clean up dangerous chemicals like DDT and lindane from soil using electrolysis. These chemicals have polluted the environment for many years and are very hard to remove because they do not break down easily. The ETH Zurich team created a process that uses electricity to break these chemicals into safe parts right where the pollution is, turning them into simple table salt and useful raw materials for industry. The process uses alternating current, which is cheap and helps avoid unwanted side effects, like making poisonous chlorine gas. The equipment is simple and can be moved to the polluted site, so there is no need to transport dangerous soil. This method not only makes the soil clean, but it also recycles parts of the old chemicals into things factories use, like materials for plastic or medicine. The process works for mixed or dirty soil, not just pure chemicals, and has already shown good results in tests. The team believes this is a big step for both cleaning up the environment and supporting a circular economy, where waste can become useful again. They hope it will stop pollution from being a problem for future generations.

In the comment section, some people are excited about this new technology and think it could finally help solve the problem of old chemical pollution. Others are curious about how well the method works on a big scale, and if it can be used in many different places. A few readers ask if the process is safe and if it could create new problems, like different kinds of pollution. Some commenters want to know more about the cost and if cities or companies will want to use it. There are questions about what happens to the new raw materials—will they really be used, or will they also become waste? A few people share memories of how DDT hurt animals and people in the past, and they hope this method will help protect health. Some readers wonder if there are other chemicals this technique could clean up, not just DDT and lindane. Others point out that it is good the equipment is mobile, because many polluted places are far from big cities. Finally, someone says it is important for governments to support this kind of research, so the technology can spread and help more quickly.

---

## A Vulnerability in Libsodium

- 原文链接: [A Vulnerability in Libsodium](https://00f.net/2025/12/30/libsodium-vulnerability/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46435614)

Libsodium, a popular cryptography library, had a security bug in its low-level function for checking if a point on the Edwards25519 curve is valid. The bug meant that some points that should have been rejected were accidentally accepted as valid because the check was missing a second condition.

The function in question, crypto_core_ed25519_is_valid_point(), is supposed to confirm that a given point is in the main cryptographic group (order L) by multiplying the point by L and making sure the result is the identity point. The identity point has X = 0 and Y = Z in libsodium’s internal math. The old code only checked if X = 0, and forgot to check if Y = Z. This meant some invalid points (with X = 0 but Y ≠ Z) slipped through.

This bug matters if you use this function to check points from untrusted sources or if you build custom crypto on top of Edwards25519. The high-level APIs (like crypto_sign_*) are not affected, and public keys made with the usual keypair functions are not at risk. The fix was simple: add the check for Y = Z.

If you need a quick workaround and cannot update libsodium, the article gives a code snippet to check if a point is in the main subgroup. The article also suggests using Ristretto255, which solves these types of issues and is safer for custom protocols.

All official libsodium packages released after December 30, 2025, are fixed. The author also reminds readers that libsodium is maintained by one person and asks for donations to support the work.

In the comments, some people thank the author for the transparency and fast fix, saying it helps build trust in open source. Others ask if this bug could have affected any big projects, but most agree that it’s a rare edge case only if you use the low-level API directly. A few users point out that it’s another reminder not to use low-level crypto functions unless you really know what you’re doing. There is some praise for the Ristretto255 group and how it helps avoid such math mistakes. One comment discusses how tricky it is to get subgroup checks right and that similar bugs have happened in other crypto libraries before. Some users share stories of how hard it is to keep security libraries bug-free, and others say this shows the value of public code and quick community response. A few are surprised that libsodium had zero CVEs until now, and they see this as proof of its good design. Some suggest more funding for maintainers to prevent burnout and future mistakes.

---

## Zpdf: PDF text extraction in Zig – 5x faster than MuPDF

- 原文链接: [Zpdf: PDF text extraction in Zig – 5x faster than MuPDF](https://github.com/Lulzx/zpdf)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46437288)

This article is about zpdf, a new open-source library written in Zig for extracting text from PDF files. The library claims to be much faster than MuPDF, a popular tool for the same job.

zpdf uses memory-mapped file reading, which helps handle large PDF files without loading all data into memory. It works with many PDF compression types, such as FlateDecode and LZW. The library supports different font encodings and can read both simple and complex PDF files, including those updated many times. zpdf also uses SIMD instructions to speed up string searching inside PDFs. One of its biggest features is parallel extraction: it can use multiple CPU cores to extract text from many pages at once. In benchmark tests, zpdf is 3 to 5 times faster than MuPDF for single-threaded jobs, and up to 18 times faster when using all CPU cores. The tool is available as both a library and a command-line program. Building zpdf needs Zig version 0.15.2 or newer. The project is open source and uses the MIT license. The code is organized in clear modules for parsing, decompressing, and interpreting PDF content.

In the comments, some users are excited to see a Zig-based project outperforming established tools like MuPDF. People note that memory-mapped files and SIMD are smart choices for fast processing. A few ask if zpdf handles tricky PDFs with odd fonts or encryption. Some worry about how well it works with real-world, messy documents, since many PDF files are not standard. There are questions about support for Asian fonts and right-to-left languages. One user says parallel extraction is useful for big PDF archives. Another warns that speed is good, but accuracy is just as important, since text extraction often fails on complex layouts. Others ask if zpdf can become a drop-in replacement for MuPDF or PDFMiner in their scripts. Some like that Zig programs can be small and easy to deploy. A few developers say they want to try zpdf for their own PDF processing needs. There is also a reminder that benchmarks may not show all edge cases, as some PDFs are much harder than others. Overall, people are interested but want to see more real-world testing.

---

## Toro: Deploy Applications as Unikernels

- 原文链接: [Toro: Deploy Applications as Unikernels](https://github.com/torokernel/torokernel)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46435418)

Toro is an open-source unikernel that helps you run applications as small virtual machines, called microVMs. It is built for speed, small size, and simple deployment, using modern Linux virtualization tools. Toro supports x86-64 computers, can use up to 512GB of RAM, and works with QEMU-KVM and Firecracker. It uses a cooperative scheduler for threads and supports fast boot-ups. For networking, Toro uses virtio-vsocket, and for file access, it uses virtio-fs. There are examples included, like HelloWorld, a static web server, and core-to-core communication. You can try Toro quickly using Docker, or build it yourself by following the steps in its README. The project uses the GPLv3 license and is written mostly in Pascal, with some Assembly and Python. Toro aims to make microservices faster and more efficient, and has been used in talks and research about cloud systems.

In the comments, some people are excited about unikernels and Toro’s focus on microVMs. They like how Toro uses modern tools like virtio and KVM for better speed. Others point out that unikernels often have trouble with hardware support and debugging, but they see Toro’s built-in gdbstub as a good step. Some developers wish Toro supported more architectures, like ARM, not just x86-64. There are questions about real-world use, and a few users ask if unikernels will ever become popular outside of research or small projects. One comment says unikernels are great for special cases, like serverless or edge computing, but not for all apps. Someone likes that Toro is written in Pascal, which is rare today, and wonders if this brings special benefits or challenges. Others discuss the security model, saying that unikernels can be safer since there is less code, but updates and patching can be harder. A few users are worried about the difficulty of debugging unikernels compared to standard Linux. Finally, some people are happy Toro is open source and easy to try with Docker, making it more friendly for new users.

---

## Prof. Software Developers Don't Vibe, They Control: AI Agent Coding Use in 2025

- 原文链接: [Prof. Software Developers Don't Vibe, They Control: AI Agent Coding Use in 2025](https://arxiv.org/abs/2512.14012)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46437391)

This article looks at how professional software developers use AI agents to help write code in 2025. The authors wanted to know if AI agents really change how experts work and how much control developers keep over the process.

The study used field observations and surveys with 112 experienced developers. Many developers said AI agents help them do tasks faster and can handle several jobs at once. Some developers tried letting the AI write whole parts of a program using only natural language instructions. But even with these tools, most professionals did not just “vibe” and let the AI do everything. Instead, they stayed in control—checking, guiding, and correcting the AI’s work carefully.

Developers said software quality, like how safe, correct, and maintainable the code is, remains very important. They used their own skills to make sure the AI’s code fits these standards. Some developers liked using AI agents for simple, repetitive, or boilerplate tasks. Others used agents for brainstorming or to help find bugs. But for complex design, tricky logic, or important system decisions, they wanted to keep the main control themselves.

The article says developers are mostly positive about using AI agents, but they do not fully trust the AI to replace their own thinking. Instead, they see the AI as a helper or tool, not a full replacement. The authors think best practices in software engineering are still key when using AI, and they suggest new ways to design agent interfaces and guidelines for the future.

In the comment section, some people agreed that experienced developers should keep control and not trust AI blindly. Others felt that over time, as AI gets better, it will handle more complex work, and developers may need to adapt. A few worried that new or junior developers might not learn basic skills if they rely too much on AI agents. Some pointed out that AI can make mistakes that are hard to spot if you don’t understand the code yourself.

There were comments about the need for better tools to watch and direct AI agents, so mistakes can be caught early. Other users said AI is best used for small tasks or to save time, but not for critical work. A few shared personal stories about using AI at work—they liked the speed boost but still had to double-check everything. Some people argued that the real value of AI is to free up time for more creative or strategic work.

One comment worried about companies pushing AI use for speed, even if quality drops. Others were hopeful that, with good guidelines, AI agents and human developers could work together well. In general, most commenters agreed that AI is useful, but humans still need to stay in charge.

---

## Loss32: Let's Build a Win32/Linux

- 原文链接: [Loss32: Let's Build a Win32/Linux](https://loss32.org/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46424173)

This article talks about “loss32,” a project that wants to make a Linux desktop where everything runs Win32 software through WINE. The idea is to let users download and run Windows .exe files on Linux easily, giving a Windows-like experience but built on top of Linux.

The project’s main goal is to use the stable and familiar Win32 system for the desktop environment, instead of the usual Linux desktop tools. Unlike ReactOS, which tries to copy the Windows NT kernel, loss32 uses the Linux kernel with WINE and some ReactOS userland parts. This means loss32 should have better hardware support and stability than ReactOS, and it can still run normal Linux software when needed.

The article explains that many people use WINE only as a last resort because it’s not perfect. But if the whole desktop runs on WINE, it can make WINE better for everyone, since more people will find and fix problems. The writer says Win32 is a “stable ABI” (application binary interface) because .exe files from decades ago can still run today, which is not true for most Linux or macOS software. This is helpful for creative users who often need to use old software that only runs on Windows.

There’s a real screenshot showing this working, but the author says it’s still rough and not comfortable for daily use yet. The project is looking for help, especially from people who know about WINE, ReactOS, Wayland compositors, or other Linux desktop details. There should be an early version to try in January 2026, but it will have many missing parts at first.

In the Hacker News comments, some people are excited about the idea, saying it’s fun and could help make WINE better. Others remember using WINE to run old Windows programs on Linux and think making this process smoother is a good goal. Some worry that relying on Win32 could cause problems, especially with software updates and security. 

A few users compare this project to ReactOS and point out that ReactOS has struggled with stability and hardware support. They hope loss32’s Linux base will avoid those issues. Others say they like the freedom to run both Windows and Linux apps, but wonder if mixing them will cause confusion or bugs.

Some commenters are skeptical about how well this could work in practice, since WINE is not perfect and some Windows programs still have problems. Others think the project is a bit of a joke, but still interesting as an experiment. A few people share technical advice, such as which Linux tools might help glue everything together.

Overall, the community seems curious but cautious, with some thinking this could be a niche solution for power users who rely on old Windows software, and others doubting it will ever be smooth enough for daily use.

---

