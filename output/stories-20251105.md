# Hacker News 故事摘要 - 2025-11-05

## 今日概述

Today’s top Hacker News stories focus on new technology and its real-world impact. There are reports on solar power spreading in Africa, a fast web browser for old computers, and a new dental gel that repairs teeth. Other big topics include updates to OpenAI’s advice rules, programming in Rust and parallel computing, the history of Ruby and Smalltalk, a new way to graph math, and a rare IBM BIOS discovery. Readers share hopes, worries, and personal experiences about how these changes may help or challenge people worldwide.

---

## Solarpunk is already happening in Africa

- 原文链接: [Solarpunk is already happening in Africa](https://climatedrift.substack.com/p/why-solarpunk-is-already-happening)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45827190)

This article explains how millions of people in Africa are skipping old power grids and using solar panels instead. Instead of waiting for governments to build expensive and slow electricity networks, startups are selling solar systems directly to people, often through small, daily payments.

The article says that extending traditional power lines to rural homes is just too costly—sometimes $2,000 per house—while people only spend around $10 to $20 per month on electricity. The math does not work for companies or governments, so they often give up. As a result, many people still use kerosene or diesel, which are dirty and expensive.

Solar panels have become much cheaper over the years. In 1980, they cost $40 per watt, but by 2025, the price is down to $0.20 per watt. Solar home systems are also much cheaper now, and batteries plus other parts have dropped in price too. But for most rural families, even a $120 solar system is a lot of money.

The big change came with mobile money services like M-PESA in Kenya. These let people pay for solar systems in small amounts each day, using their phones. If someone stops paying, the company can turn off the solar system remotely. After a few years of payments, the customer owns the system and has free power. Repayment rates are over 90% because people really need the electricity.

The article gives examples of companies like Sun King and SunCulture. Sun King sells solar lights and home systems, reaching millions of people. SunCulture provides solar-powered water pumps for farmers, helping them grow more food and earn more money. Both companies use a pay-as-you-go model, and both have over 50% market share in their fields.

Another important idea is carbon credits. When a farmer uses solar instead of diesel, it saves carbon. Companies can sell this saved carbon on international markets, making solar systems even cheaper for users.

The author says this model is a blueprint for the future: instead of slow, central projects, small, private companies use cheap technology, mobile payments, and carbon credits to scale fast. This approach is already spreading to other regions like Asia and Latin America.

However, there are risks. Currency changes, politics, defaults, maintenance, and carbon price swings can all cause problems. The model works well for homes and small farms, but not for factories or big cities.

Hacker News commenters have a lot to say. Some are excited by how Africa is skipping old infrastructure and using new tech right away. They call this “leapfrogging” and say it could help other developing regions too. Others question if pay-as-you-go is fair, worrying it could lead to high interest rates or companies shutting off power for late payments.

A few commenters talk about local jobs. They like that solar companies are now building and repairing systems in Africa, rather than importing everything. Some point out that the need for maintenance and the risk of broken systems could be hard over time.

There are concerns about carbon credits—some people doubt these markets are always honest or useful. Others think solar is only part of the answer, and that grids or other sources will still be needed for big businesses and cities.

Several commenters share personal stories. Some have visited villages using solar and say it changed lives—kids can study at night, and families save money. Others are skeptical about how easy it is to scale this everywhere and warn that politics or corruption could slow things down.

Some like the idea that Africa can build its own future, not just copy the West. Others worry that if foreign companies own the systems, profits might not stay local. A few think this “solar leap” shows how tech can solve big problems when old ways do not work.

Overall, the discussion is hopeful but realistic. People agree solar is making a difference, but it is not a perfect fix for every problem. Many are watching to see if this model can work in other places around the world.

---

## Dillo, a multi-platform graphical web browser

- 原文链接: [Dillo, a multi-platform graphical web browser](https://github.com/dillo-browser/dillo)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45826266)

Dillo is a very small and fast web browser that works on many systems. The project is on GitHub and people can see the code, updates, and files for the browser.

Dillo is made for users who want a simple browser without many extra features. It uses little memory and CPU, so it works well on old computers or with light Linux systems. Dillo is written in C and uses the FLTK toolkit for its graphics. It can open web pages, follow links, and show images, but it does not support JavaScript or advanced CSS. This means some modern websites will not load or look right, but simple sites work well. The code is open source and easy to read, so people can study or change it as they like. Developers keep fixing bugs and adding small features, such as better cookie handling for logins, support for special mouse buttons, and making long links shorter. There is also a simple search engine setting and updates to help Dillo work with new Linux versions.

Many people in the comments like Dillo because it is fast, light, and starts quickly. Some say it is great for reading documentation, browsing offline files, or using on old hardware. Others mention that it is not good for most modern websites because it does not support JavaScript, so things like Google Docs or many news sites do not work. A few users wish Dillo would support more web standards but agree it is hard to do without making the browser slow or big. Some people enjoy the old-school style and find the code easy to understand. Others think it is mainly for special cases, not for daily use. There is respect for the project’s long life and for keeping things simple. People also talk about using Dillo when privacy is important, since it does not run scripts or track users much. A few wonder if it could be updated to work on mobile devices or other platforms. Overall, the comments show both nostalgia and real use, but most agree Dillo will not replace main browsers for most people.

---

## The state of SIMD in Rust in 2025

- 原文链接: [The state of SIMD in Rust in 2025](https://shnatsel.medium.com/the-state-of-simd-in-rust-in-2025-32c263e5f53d)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45826348)

This article talks about how to use SIMD (Single Instruction, Multiple Data) in Rust in 2025. SIMD lets computers do the same math operation on many numbers at once, so things can go much faster, especially with big data.

The article explains SIMD by saying that CPUs have a lot of hardware for math, but can’t always use it fully because of how instructions are handled. SIMD helps by letting you add, subtract, or do other math on whole groups of numbers (called vectors) all at once. On some CPUs, these groups can be large, so one instruction can do work for eight or more numbers at the same time.

Different computers have different SIMD instruction sets. For example, ARM chips use NEON, x86 chips can use SSE2, AVX2, or AVX-512, and WebAssembly has its own simpler SIMD system. The problem is, not every computer will have the same SIMD instructions, so Rust can’t always use the fastest one by default.

There are two ways to solve this: if you know exactly what computers you’ll run your program on, you can build it for those CPUs only. If you want your program to work everywhere, you can use “function multiversioning”—this means you write or compile several versions of your code, one for each SIMD type, and pick the right one when the program runs.

The article then lists four main ways to use SIMD in Rust:
1. Let the compiler do it automatically (autovectorization).
2. Use special iterators that help with SIMD (but this approach is mostly abandoned).
3. Use libraries (crates) that give you higher-level SIMD types you can write code with, and they handle the details.
4. Write raw intrinsics—very low-level code, close to the CPU instructions, but you must handle every platform yourself.

Autovectorization is easiest, but not always reliable. The compiler may stop optimizing some code in later versions, and it can’t handle floating-point numbers well unless you use nightly Rust builds.

For portable SIMD abstractions, there are several crates:
- `std::simd` is powerful but only works on nightly Rust.
- `wide` is mature but doesn’t support function multiversioning.
- `pulp` is good for AVX2/AVX-512, but not older x86 or WASM.
- `macerator` supports many platforms but isn’t widely used yet.
- `fearless_simd` is new and still being developed.
- `simdeez` is old, supports most types, but isn’t widely adopted.

If you want the lowest-level control, you can write raw intrinsics. This means more work, and your code will be longer and harder to read. But you can use the newest features in Rust to make this a bit safer and less error-prone.

In the end, the article says: use autovectorization if you want something simple, use intrinsics if you need exact control for special hardware, and use portable SIMD crates for most other cases.

From the Hacker News comments, people share different views. Some love using SIMD in Rust and say it’s much better than before, but still wish `std::simd` was stable and not just on nightly Rust. Others point out problems with making code portable across many CPU types—sometimes you end up writing a lot of special code. A few mention that for most real-world programs, simple compiler vectorization is enough and you don’t need to worry about these details unless you need maximum speed. Some users talk about the pain of supporting old CPUs, while others say that in cloud or server work, you can just require new hardware and ignore old ones. One comment warns that using SIMD with floating-point numbers can be tricky and may give surprising results. Others say the situation is much better than in C or C++, where SIMD is even harder to use. A few note that libraries like `pulp` are working well in practice, but some wish there was more official support and less need for third-party crates. Some are excited about the progress in WebAssembly SIMD support. Lastly, a few people worry that most Rust users won’t ever need to use SIMD directly, and that for many, this is still an advanced topic.

---

## New gel restores dental enamel and could revolutionise tooth repair

- 原文链接: [New gel restores dental enamel and could revolutionise tooth repair](https://www.nottingham.ac.uk/news/new-gel-restores-dental-enamel-and-could-revolutionise-tooth-repair)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45826995)

A group of scientists has made a new gel that can repair tooth enamel, which could change how dentists fix teeth. This gel is different from normal treatments because it can help regrow the hard outer layer of teeth instead of just stopping more damage.

The gel is protein-based and does not use fluoride. It works by copying how our bodies build enamel when we are babies. When you put the gel on a tooth, it forms a thin layer that fills cracks and holes. This layer then takes minerals from your saliva and helps grow new enamel in the right way, just like natural enamel. Pictures from special microscopes show that teeth treated with the gel get new, strong enamel crystals after just two weeks. The gel can also be put on exposed dentine, which is another part of the tooth, to help with sensitivity and make other dental repairs stick better.

Enamel loss is a big problem for almost half of all people in the world. When enamel is gone, it does not grow back on its own, and current treatments only help with pain, not real repair. The new gel, however, can actually rebuild enamel, making teeth stronger and healthier. Tests show that the fixed enamel works just like normal enamel, even when brushing or eating acidic foods. The gel is safe, easy to use, and can be made in large amounts. The team has started a company to bring this to the market, and they hope people can use it soon.

In the comments, many people are impressed and hopeful about this new gel. Some say this could make going to the dentist much easier and cheaper. Others wonder if the gel will be too expensive or if dentists will be slow to use it, since fixing teeth is a big business. A few people ask about safety, wanting to know if there are any long-term side effects. Some users are excited because they have dental problems and hope this gel will help them. Others talk about similar past inventions that never became common, so they are waiting to see if this one really works. One person points out that if the gel is easy to use at home, it could help many people who cannot see a dentist. Another commenter says they hope the gel will be covered by health insurance. Some are curious if the gel can also be used for kids’ teeth or for people with very bad tooth decay. Overall, most people feel this is a big step forward in dental care, but they want to see real-world results.

---

## ChatGPT terms disallow its use in providing legal and medical advice to others

- 原文链接: [ChatGPT terms disallow its use in providing legal and medical advice to others](https://www.ctvnews.ca/sci-tech/article/openai-updates-policies-so-chatgpt-wont-provide-medical-or-legal-advice/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45825965)

OpenAI made it clear that people cannot use ChatGPT to give others legal or medical advice. The company updated its rules to say users must not use the service for advice that only licensed professionals should give, unless a real professional is involved. This is not a new rule, but the company wanted to make it more clear after some confusion. ChatGPT can still help people understand general health or legal topics, but it should not be used as a replacement for a doctor or lawyer. Studies show that ChatGPT sometimes gives wrong or unclear answers to health questions. One study found only about 1 in 3 medical answers from ChatGPT were fully correct. Another study showed ChatGPT’s answers can sound very confident and convincing, even when they are wrong, which can make people trust it too much. Some doctors are now seeing patients who have already decided what is wrong with them, based on what AI told them.

In the comment section, some people say this rule is important because giving medical or legal advice can be risky and even dangerous. Others think the rule is mostly to protect OpenAI from being sued if someone gets hurt by following AI advice. A few users point out that people will likely still use ChatGPT for these reasons, but at least the company is clear it is not allowed. Some discuss how hard it is for AI to know the real details of someone’s health or legal situation, so mistakes can happen easily. There are also comments about how people sometimes trust technology too much, especially when it sounds sure of itself. Others say this rule might not stop people from using ChatGPT for advice, but it helps set the right expectations. A few wonder if this will make real doctors and lawyers more trusted again. Some are worried that people who cannot afford professional help might rely on AI anyway, even with these rules. Finally, some say it is good that OpenAI is being honest about what AI can and cannot do.

---

## Ruby and Its Neighbors: Smalltalk

- 原文链接: [Ruby and Its Neighbors: Smalltalk](https://noelrappin.com/blog/2025/11/ruby-and-its-neighbors-smalltalk/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45823831)

This article talks about how the Ruby programming language was influenced by another language called Smalltalk. The writer explains that, while Ruby didn’t copy Smalltalk’s syntax, it took many ideas about how objects work from Smalltalk.

Smalltalk was created at Xerox PARC in the 1970s, a place famous for many tech inventions. The version most people know is called Smalltalk-80. In the 1980s and 1990s, companies paid a lot of money to use Smalltalk and tools like ObjectWorks and VisualWorks. It was popular in fields like aviation and big business software. The writer used it in school and later for real projects, and remembers it fondly.

In 1995, a group from Apple released Squeak, a new open-source Smalltalk system. Squeak was special because almost all of it was written in Smalltalk itself, making it easy to move to different computers. Smalltalk is different from most other languages because it is not based on C or Unix. It’s almost like its own operating system, with unique features. For example, arrays start at 1, not 0.

Smalltalk development happens inside a special environment, with tools called the Workspace (for running code) and the Browser (for editing code). You can see and change all the code in the system, even the deep parts. This can be powerful and risky. Creating new classes or methods is done by writing code and running it, not just by editing files.

Sharing code in Smalltalk can be hard because everything lives in one big “image.” People use “change sets” to share updates, but it’s not as smooth as with text files in other languages.

Smalltalk’s syntax is very simple. Every piece of data is an object, and every action is a message to an object. There are no basic types outside the object system. There are three types of messages: unary, binary, and keyword. All messages are read left-to-right, and there’s no operator priority. Loops and conditionals are also done by passing messages, not by using special keywords.

Smalltalk’s object model is a big influence on Ruby. Both have a base class called Object. Both use method lookup at call time. There are some differences, like how Smalltalk handles meta classes and that it doesn’t have modules or mixins. But the overall style is similar, and the writer says many Smalltalk patterns work in Ruby.

The writer misses working in Smalltalk, especially because of its fast tests, powerful debugging, and the way you can interact with the whole running system. But Smalltalk’s all-in-one environment made it hard to connect with other systems and tools as Unix and the web took over. It also made team work and deployment tricky.

Ruby took the idea that everything is an object from Smalltalk and mixed it with a more familiar syntax. The writer’s style of making many small classes in Ruby comes from Smalltalk habits and feels that Ruby encourages this more than other languages.

In the Hacker News comments, many developers say they love Smalltalk’s environment, especially its live coding and debugging features. Some think Smalltalk failed because it didn’t work well with Unix and text files, making teamwork and version control difficult. Others wish modern languages would copy more from Smalltalk, especially the idea of everything being an object and the live development experience.

A few people say Smalltalk’s “image” system is both its best and worst feature—it makes coding feel magical, but sharing and deploying code is hard. Some mention that Smalltalk’s syntax is simple but very different from what most programmers know, which can be confusing at first.

There are stories from people who learned programming with Smalltalk and remember it fondly. Others point out that Smalltalk’s ideas live on in Ruby, Objective-C, and even JavaScript, though those languages use more familiar syntax.

One commenter notes that Smalltalk’s tools felt ahead of their time, while another says the language’s lack of popularity today is sad given its big influence. Some people discuss Squeak and Pharo, which are still around and let you try Smalltalk today.

Finally, there’s debate about whether Smalltalk could ever make a comeback, with some hopeful and others thinking its time has passed. Overall, most commenters agree that Smalltalk changed how people think about programming, even if few use it now.

---

## The shadows lurking in the equations

- 原文链接: [The shadows lurking in the equations](https://gods.art/articles/equation_shadows.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45823141)

This article talks about a new way to draw graphs of math equations called FuzzyGraph. Usually, when you graph an equation, you only see where the answer is exactly right—like in black and white. But this new method shows more: it shows places where the answer is almost right or very wrong, making “shadows” appear in the graph.

The article gives many examples. For the “Slash Dot” equation, a normal graph only shows some lines, but FuzzyGraph shows a big dark spot, which means there is a large error there. Another example, the “Quasar” equation, also has hidden “eye” shapes that only show up with FuzzyGraph. 

With simple equations like x² + y² = 0, a normal graph just shows one point, but FuzzyGraph makes it look like a fuzzy particle. When you look at 1/(x² + y²) = 0, a normal graph shows nothing, but FuzzyGraph shows a “black hole” shape. The article also talks about how you can combine or flip equations to make new shadow lines or circles that are invisible in normal graphs but clear with FuzzyGraph.

In the last example, the article shows how FuzzyGraph can help find “underwater islands”—places that are almost solutions to the equation. By changing the equation just a little, these hidden places can become visible in normal graphs too.

People in the comments had mixed feelings. Some said this is a clever idea that helps us see more about how equations work. Others pointed out that tools like heat maps or contour plots do something similar, so maybe it’s not brand new. Some liked the “shadows” for teaching math, saying it helps students understand errors and near-misses. A few worried that showing too much extra information might confuse people, especially beginners. One person asked about how FuzzyGraph works for 3D graphs or more complex equations. Another pointed out that these “shadows” might help with debugging code or finding bugs in math software. Overall, many agreed that seeing not just the exact answer but also the “almost” answers can be useful, even if the idea is not completely new.

---

## Why aren't smart people happier?

- 原文链接: [Why aren't smart people happier?](https://www.theseedsofscience.pub/p/why-arent-smart-people-happier)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45824864)

This article looks at why smart people are not always happier than others. It explains that being intelligent helps you solve clear, well-defined problems, but happiness is a much more confusing and messy problem.

The writer points out that intelligence is usually measured by tests with clear answers, like math questions or vocabulary. Studies show that smarter people are not much happier, and sometimes are even a little less happy. This is surprising because we expect that people who are good at solving problems should have better lives. The article discusses the history of intelligence testing and how it often misses important parts of life. Many famous smart people have made big mistakes or have strange beliefs, which shows that being smart in one area does not mean you will always make good choices in life.

The main idea is that there are two types of problems: well-defined (like chess or math) and poorly defined (like how to be happy or how to live a good life). Intelligence tests only measure how well people solve well-defined problems. But real life is full of poorly defined problems, where the rules are not clear and everyone’s answer is different. Wisdom, creativity, and self-knowledge help with these, but they are hard to measure and often not respected as much as regular intelligence.

The article also says that our progress in solving well-defined problems (like landing on the moon or inventing new technology) has not made people much happier. It suggests that happiness depends on solving poorly defined problems, like finding meaning, building relationships, and dealing with change. The writer argues we should value the people who are good at this, like wise grandparents, just as much as we value scientists or chess champions.

In the comments, some people agree, saying that being smart can make you overthink and notice more problems, which can hurt happiness. Others mention that smart people may be more aware of the world’s problems or their own flaws, making it harder to be happy. Some readers talk about how social skills or emotional intelligence are just as important as book smarts for a good life. A few comment that smart people often feel lonely because it is hard to find friends who think like them.

There are also people who doubt the article’s ideas, arguing that intelligence can help you avoid trouble and succeed in life, which should lead to more happiness. Others say that happiness depends more on personality, family, health, or luck than on intelligence. Some mention that intelligence can help with money and success, but these things only help up to a point. A few point out that the idea of what makes someone happy is very personal and hard to measure. Overall, the comments show that people have many different views about the link between intelligence and happiness.

---

## I want a good parallel language [video]

- 原文链接: [I want a good parallel language [video]](https://www.youtube.com/watch?v=0-eViUyPwso)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45807993)

This talk is about finding a better programming language for parallel computing. Raph Levien explains that while we have many good languages for normal, single-threaded programs, writing code that runs well on many processors at once is still hard and messy.

He says that parallel computing is important because it lets us make programs faster as computers add more cores, but current tools don’t make this easy. Raph looks at current ways of doing parallel work, like using threads, array programming (like in MATLAB or NumPy), shader languages for GPUs, and new tile-based models. Each of these has problems. Threads are hard to use safely and get right. Array languages can be fast, but only work well for some problems. GPU languages are powerful, but have strange limits and are hard to use for general tasks.

He mentions that parallelism comes in different sizes. Sometimes you want thousands of tiny tasks, sometimes just a few big ones. Hardware is also different—GPUs, CPUs, and clusters all have their own rules. Because of this, there is no “one size fits all” language for parallel programming. Raph shares a wish list for a new language: it should be easy to use, safe, flexible for different types of parallel work, and able to run well on many kinds of hardware. But, he ends by saying that no one has yet made a language that checks all these boxes, so this is still an open problem.

Since YouTube comments are off, let’s turn to reactions from the Hacker News community. Some users agree with Raph that parallel programming is still too hard, even after many years of research and new languages. Others point out that functional programming languages like Haskell or Erlang are supposed to help with parallelism, but they still have learning curves and practical limits. A few people say that hardware changes so quickly that software cannot keep up, so languages always lag behind.

One comment notes that most real-world programs don’t need massive parallelism—so maybe that’s why no one has solved this problem yet. Another person mentions that languages like Rust and Go make it easier to write safe concurrent code, but they don’t hide all the hard parts. There are also mentions of dataflow languages or actor models as possible solutions, but users admit these are still not fully mainstream.

Some wish for better tools to help debug and test parallel programs, saying bugs are hard to find and fix. A few users share that they just avoid parallel code when they can, because it adds so much risk. Others are hopeful, saying that new hardware and interest in AI may finally push for a better solution. In the end, there is wide agreement: finding a good parallel language is an interesting challenge, and the search is not over yet.

---

## A Lost IBM PC/at Model? Analyzing a Newfound Old Bios

- 原文链接: [A Lost IBM PC/at Model? Analyzing a Newfound Old Bios](https://int10h.org/blog/2025/11/lost-ibm-at-model-bios-analysis/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45827661)

This article is about a rare IBM PC/AT BIOS (the software that starts up a computer) found on old chips with no clear origin. The writer studies these chips to see where they came from and what they can tell us about forgotten computers.

The main focus is on one BIOS from 1985, which does not match any known IBM PC/AT models. The author compares it to three official BIOS versions, finding that this one sits between the first and second versions—so he calls it “rev. 1.5.” He loads the BIOS into an emulator and sees it works like a normal AT, passing all the startup tests. Then, by looking at the code, he finds it is not just a small patch, but a whole different version, made during a time when IBM was changing the PC/AT’s design.

The article explains some technical differences. For example, this BIOS supports 720KB floppy disks (a newer format at the time) before any other IBM PC. It also has support for more types of hard drives than the first BIOS, but fewer than later ones. There is some support for newer keyboards, though not complete. Some parts of the code look like the older BIOS, and some like the newer one; others are unique.

One very interesting finding is about how the BIOS checks computer memory. It seems this BIOS was made for a board with more RAM (up to 1MB or 640KB directly on the main board), which was unusual for IBM ATs. The code checks special bits from the hardware to see how much RAM is present and how to test it for errors. The writer finds clues in old IBM documents about a “BASE_MEM8” bit, and figures out that this BIOS is the only one to actually use it.

The article suggests this lost BIOS might be from a cancelled IBM project called “Skyrocket,” which was supposed to be an AT with more memory. There are old forum posts from a former IBM worker describing such a machine, with extra RAM and a special logo. The writer’s findings fit this story well, although not perfectly. He says this BIOS might be from “Skyrocket” or a similar prototype.

In the Hacker News comments, some people are excited to see this kind of digital archaeology and praise the author’s deep dive. Others share memories of working with old IBM machines and BIOS chips, or stories of finding odd hardware. A few users point out how careful and detailed the analysis is, and say it’s great to have the ROMs preserved for history.

Some commenters discuss how hard it was to figure out these old BIOS versions, and how small changes could break software. Others are curious if more lost hardware will be found, or if there are other secret IBM projects still hidden. A few technical users mention how even small BIOS changes could affect compatibility, and what that meant for clone PC makers in the 1980s.

One person wonders if modern computers will have similar “lost” versions in the future, while another jokes about how much more complex today’s BIOS and firmware are. Some debate if the “Skyrocket” theory is right, asking for more proof, but most agree this find is rare and valuable. Many thank GearTechWolf for saving the chips and sharing them. Overall, the community is happy to see lost computer history come back to life.

---

