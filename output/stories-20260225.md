# Hacker News 故事摘要 - 2026-02-25

## 今日概述

Today’s top Hacker News stories cover creative tech in music, new programming languages, AI privacy risks, and software upgrades. There are also stories about city transit, solar power growth, and street repairs. Many posts discuss how old ideas are used in new ways, and how technology can both help and harm. If you like music tech, AI, or city life, there is something interesting to read today.

---

## Jimi Hendrix was a systems engineer

- 原文链接: [Jimi Hendrix was a systems engineer](https://spectrum.ieee.org/jimi-hendrix-systems-engineer)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47157224)

This article is about Jimi Hendrix and how he used technology and engineering to create new sounds with his electric guitar. It explains that Hendrix worked with sound engineers and used special pedals and amplifiers to make effects that were new for his time.

Hendrix’s famous song “Purple Haze” was recorded in 1967 using the Octavia pedal, built for him by Roger Mayer. This pedal, along with the Fuzz Face and wah-wah, changed the guitar’s sound in ways that had never been heard before. When the song was sent to the US for remastering, engineers had to be told that the strange sounds were on purpose, not a mistake. Hendrix showed that an electric guitar can be more than just a string instrument—it can act like a wave synthesizer, making many different sounds.

Each effects pedal in Hendrix’s setup had a special job. The Fuzz Face pedal turned the string’s smooth sound into a rough, almost square wave, giving the famous “fuzz” effect. The Octavia pedal doubled the sound’s frequency, making notes an octave higher. The wah-wah pedal made the guitar sound like it was “talking” by changing the frequencies. The Uni-Vibe pedal added a moving, airy sound by shifting phases. Hendrix also used the amplifier and the room itself as part of the sound system, moving his guitar to control feedback and create long, singing notes.

The author, who works with computers, used circuit simulations to model Hendrix’s signal chain. They used real circuit diagrams and open-source tools to study how each pedal worked. They found that Hendrix’s genius was in how he connected everything and used his body to control the system, not just in playing notes.

The article says Hendrix didn’t know or talk about technical terms like decibels or ohms, but he worked closely with engineers who did. He adjusted and experimented, acting like a systems engineer, and was able to shape the electric guitar’s sound in new ways.

Looking at top comments from Hacker News, people had different views. Some readers loved the idea that Hendrix was like an engineer, saying musicians often use technology in creative ways. Others pointed out that artists and engineers think differently—Hendrix may not have used technical language, but he understood systems intuitively. Some users shared stories about trying to copy Hendrix’s sound with modern digital tools, finding it hard to get the same feeling as the old analog equipment.

A few commenters discussed the importance of physical movement and feedback, which is hard to recreate with software. Some were surprised by how much science and math go into music, while others felt that focusing too much on engineering takes away from the magic of art. There were also comments about how today’s musicians rely on plugins and presets, but Hendrix had to build his sound from scratch.

One person noted that working with engineers like Roger Mayer was key to Hendrix’s success, showing the power of teamwork between art and science. Another comment said that this story is a good reminder that technology and creativity often grow together. Finally, some readers simply celebrated Hendrix’s music, saying that no amount of explanation can take away from how groundbreaking and exciting his sound still is today.

---

## The Om Programming Language

- 原文链接: [The Om Programming Language](https://www.om-language.com/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47154971)

The Om programming language is a new, very simple language for writing programs and algorithms. It is designed to be easy to parse, uses only three basic elements, and works with any kind of data because it has no fixed data types.

Om is a concatenative language, which means programs are made by joining smaller programs together. Unlike most concatenative languages, Om uses prefix notation, so functions come before their inputs. This has some benefits: it avoids stack errors, makes it easier for tools to help the programmer, and allows the computer to read and run code more quickly. In Om, every value is just an "operand," and there are no data types—every operation can work with any operand. This is called "panmorphic typing." The language is also "homoiconic," meaning code and data have the same structure, much like Lisp.

Om is written as a C++ library, so you can use it in C++ or Objective-C++ projects. You can build a stand-alone interpreter or include it as a header-only library. The source code is available on GitHub under the Eclipse Public License. To build Om, you need some common tools and libraries, like CMake, Boost, and ICU4C.

The language itself has only three elements: operators, separators, and operands. Programs are made by combining these. Om does not care about separators in most places, but they matter inside operands. Functions in Om are either identity (doing nothing), constant (adding something), or operations (doing some work). If an operation doesn't get enough input, it just stays in the program for later.

There are already some basic operations, like "drop" to remove operands, "copy" to duplicate them, "choose" to pick between values, and "quote"/"dequote" to add or remove layers of braces. You can also define new operators on the fly. The language is fully Unicode-correct, so it works with any UTF-8 text. Recursion is efficient, and Om makes it easy to break down and follow each step of how a program runs.

To contribute, you can add new operations, report issues, or even help fund the project. Adding new features means writing some C++ code and including it in the right place. The project is still young and changes often, and the creator welcomes help and feedback.

In the Hacker News comments, many people found the idea of prefix concatenative languages interesting, as most such languages use postfix notation (like Forth or Joy). Some said prefix notation could make it easier to read and reason about code, but others felt it might be confusing without clear grouping, especially in complex programs. A few liked how Om treats all data the same way, similar to Lisp, and thought this could be powerful for metaprogramming.

Others pointed out that Om is still missing many basic operations, so it's not ready for practical use yet. Some were unsure how easy it would be to write real programs in Om, since the examples are quite abstract. There was appreciation for full Unicode support and the simple, uniform design. A few asked if Om could be used as a data format, since it is easy to parse and read.

Some commenters wondered how Om compares to other experimental languages and whether it could find a real-world niche. A few suggested that the main value might be in the ideas, rather than the current implementation. Some encouraged the creator to keep going and praised the clear documentation. Others said they would wait until Om has more features before trying it out. Overall, people liked the creativity and simplicity, but agreed Om is still an experiment.

---

## Making MCP cheaper via CLI

- 原文链接: [Making MCP cheaper via CLI](https://kanyilmaz.me/2026/02/23/cli-vs-mcp.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47157398)

This article talks about how the author made using MCP (a tool for AI agents) much cheaper by switching to a CLI method with just one command. The main point is that AI agents spend too many tokens (and money) because MCP loads all tool information at the start, but a CLI can do the same thing with fewer tokens.

MCP sends a big list of all tools and their details to the AI at the beginning of each session. This uses a lot of tokens—about 15,540 for 84 tools. With CLI, only a short list of tool names and locations is sent, using about 300 tokens for six tools. When the agent needs to use a tool, MCP is still simple, but CLI asks the agent to look up details as needed, which uses more tokens only when needed.

The article shows that using CLI instead of MCP can save about 94% of token costs. Even if the agent calls many tools, CLI is still much cheaper. The author also compares this to Anthropic’s Tool Search, which also tries to save tokens by loading tool info only when needed. But CLI is even cheaper than Tool Search and works with any model, not just Anthropic.

The author built CLIHub, a directory and converter to help people make CLIs from MCPs easily. This helps agents use tools in a cheaper way.

In the comments, some people think this is a smart way to save money, especially for big projects. Others wonder if the extra work to build and use CLIs is worth the savings for small teams. A few users point out that this method may slow down agents because they have to fetch tool info as they go. Some say that tool discovery could be confusing if there are many tools or if tools often change. Others like that CLIHub is open source and easy to try. A few mention that saving tokens is important as AI use grows, so ideas like this help everyone. Some people think that Anthropic’s Tool Search is simpler, but agree that being model-agnostic is a big plus for CLI. One person jokes that everything old (CLI) becomes new again. Another asks if there are security risks with exposing so many CLIs. Overall, most agree that this is a clever and practical idea to cut costs.

---

## Bus stop balancing is fast, cheap, and effective

- 原文链接: [Bus stop balancing is fast, cheap, and effective](https://worksinprogress.co/issue/the-united-states-needs-fewer-bus-stops/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47153798)

This article says that U.S. cities have too many bus stops, and that bus stop balancing—removing some stops—can make bus service much faster and better. Most plans to improve transit focus on big projects like new trains, but the article argues that buses are more important and have bigger daily impact.

The main problem is that buses in U.S. cities stop too often, sometimes every 200 meters or less, much closer than in European cities. This frequent stopping makes buses slow, unreliable, and expensive to run. Buses spend a lot of time stopping and starting, which also increases costs because drivers are paid by the hour. When buses are slow, fewer people want to ride them, and agencies can’t afford to make each stop nice with benches or shelters. In Europe, because there are fewer stops, agencies can spend more to make each one comfortable and safe.

Bus stop balancing means removing some stops so the distance between them is more like in Europe (about 400 meters apart). This can be done quickly and cheaply—just remove some signs and update schedules. Studies show that this makes buses faster (saving up to 24 seconds per stop removed) and more reliable. Cities like San Francisco and Vancouver saw big improvements in speed after removing stops. Riders end up walking a bit farther, but the total area served by buses only goes down a little. Cost savings are large, because fewer stops and faster buses mean fewer drivers are needed and money can be used to make the remaining stops better. With fewer, better stops, buses can compete better with cars, and more people might choose to ride.

In the comments, some people agree with the article and say their own cities improved bus service by removing stops and making the remaining ones better. They say that faster buses mean happier riders and lower costs. Others worry about people who have trouble walking—like the elderly or disabled—who might find it harder if their closest stop is removed. Some suggest that agencies should carefully pick which stops to close and make sure important places (like hospitals or schools) still have stops nearby. 

A few commenters say that in some places, buses are already too far apart and removing stops would hurt service. Some point out that people do not like changes, and removing stops can make people angry, even if it makes the system better in the long run. Others share that in their cities, stop balancing did help, but only worked well when buses also got dedicated lanes or better traffic signals. There are also comments about how the U.S. should copy European ideas more often, and that even small changes like this can make a big difference. Overall, most agree that bus stop balancing is a good, simple way to improve public transit, but it needs to be done with care.

---

## Windows 11 Notepad to support Markdown

- 原文链接: [Windows 11 Notepad to support Markdown](https://blogs.windows.com/windows-insider/2026/01/21/notepad-and-paint-updates-begin-rolling-out-to-windows-insiders/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47154399)

Microsoft is updating Notepad and Paint for Windows 11, starting with users in the Windows Insider program. The big news is that Notepad now supports more Markdown, and Paint gets new AI features.

Notepad now lets you use more Markdown formatting, like strikethrough text and lists inside lists. You can use these features with the toolbar, keyboard shortcuts, or by writing Markdown directly. There’s also a new welcome screen that helps you learn about Notepad’s new tools. This screen pops up when you open Notepad for the first time after the update, but you can close it and bring it back later. Another new thing is faster streaming results for the Write, Rewrite, and Summarize features, which use AI. You’ll see the results appear bit by bit, so you don’t have to wait for everything to finish before you can start reading. To use these AI tools, you must sign in with your Microsoft account.

For Paint, the update brings two things. First, there’s a “Coloring book” feature, powered by AI. You type a short description, like “cat on a donut,” and Paint makes a coloring book page for you. You can pick your favorite and add it to your canvas or save it. However, this only works on special Copilot+ computers, and you need to be signed in. Second, there’s a “fill tolerance” slider for the Fill tool. This slider lets you control how much color spreads when you use the paint bucket, so you can make your fills more exact or more loose, depending on what you want.

In the comments, many people are happy to see Notepad get Markdown support, saying it’s useful for quick notes and coding. Some wish Notepad could handle even more Markdown features, like tables or images. Others think Notepad should stay simple and not try to replace bigger editors like VS Code. A few users are worried about needing a Microsoft account for AI features, saying they prefer privacy and offline use. Some like the welcome screen, but others think it might get annoying. For Paint, people are excited about the AI coloring book, especially for kids or quick sketches. But a few are sad that the best features only work on Copilot+ PCs. Some think the fill tolerance slider is a small but good change, making Paint easier to use. Overall, users are glad Microsoft is updating old apps, but they hope the new features don’t make things too complicated or force everyone online.

---

## Large-Scale Online Deanonymization with LLMs

- 原文链接: [Large-Scale Online Deanonymization with LLMs](https://simonlermen.substack.com/p/large-scale-online-deanonymization)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47139716)

This article shows that AI models called LLMs can figure out who you are from your anonymous posts online. The researchers tested this on sites like Hacker News, Reddit, and LinkedIn, and found that LLMs can match anonymous accounts to real people with high accuracy, even from just a few comments.

Before, finding out who someone was online needed a person to search and think about clues. Now, LLMs can look at what you write and guess where you live, your job, and your hobbies. Then, they can search the web to find your real identity. The article explains how the team tested this: they took real accounts with public links between different sites, removed all clear personal information, and then asked the AI to match the anonymous account to the real person. The LLMs did this very well, using a mix of searching and reasoning.

They also did tests on Reddit by splitting a user's post history into two and seeing if the AI could connect the parts. The LLMs did much better than older methods that just looked at which forums people used. As the number of users grew, LLMs still worked well, showing that these attacks can scale to millions of people.

The article warns that this could make privacy much harder. Bad actors could use these tools for scams or to attack people. To help, the authors suggest that social sites should stop easy data scraping, limit how much data can be downloaded, and not rely only on pseudonyms for privacy. LLM companies can try to add safety rules, but these are easy to get around, especially with open-source models.

The researchers also give advice for users: be careful about what you share online. Even small details, like your city or job, can make you easy to find if someone puts the clues together.

In the Hacker News comments, some users were surprised at how powerful these AI tools are, while others said this problem is not new—LLMs just make it faster and easier. A few people worried that this could be used by governments or companies to watch people more closely. Some users talked about how hard it will be to really protect privacy now, since even using fake names may not help. Others pointed out that restricting data access might just slow attackers down, not stop them. There were suggestions to use less personal information and to use platforms that care about privacy. Some thought that open-source AI models make the problem worse, since anyone can use them for this purpose. A few people wondered if new laws or tech solutions could help, but most agreed that AI is changing online privacy in big ways. Many commenters said that users need to think more about what they share, because AI can connect the dots much better than before.

---

## Show HN: I ported Tree-sitter to Go

- 原文链接: [Show HN: I ported Tree-sitter to Go](https://github.com/odvcencio/gotreesitter)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47155597)

This project is a pure Go version of the tree-sitter runtime, so you can use tree-sitter in Go without needing any C code. The main feature is that it does not use CGo, so it works out of the box on any platform, helps with cross-compiling, and makes builds simpler. 

The library lets you parse code, run queries, do syntax highlighting, and tag symbols, all from Go. It supports incremental parsing: if you change the code, it only reparses what is needed, making it much faster than the standard CGo bindings—up to 90 times faster for small edits. It works with 205 programming languages, using the same grammar files as upstream tree-sitter, and you do not need to recompile grammars. The library has tools for picking the right grammar by filename, and features for caching, memory tuning, and working with smaller binaries. You can use it for things like code editors, language servers, or static analysis tools. There are many tests and benchmarks showing that it is faster than the CGo binding, especially for incremental changes. The API covers the usual tree-sitter features, like S-expression queries, syntax highlighting, and symbol extraction. The documentation explains how to add new grammars, how to tune performance, and what features are supported.

In the comments, some people are very excited about having a pure Go version, because cross-compiling with CGo is hard and can break things. Many say this will help Go projects that want to use tree-sitter, especially for WASM or cloud builds. Others ask about performance and are surprised it is faster than the C version in many cases; they discuss how Go’s memory management can help. A few comment on the large number of supported languages and how easy it is to add new ones. Some users share stories about struggling with CGo in CI or with deployment, and think this project will help a lot. There are questions about how hard it was to port the runtime, and the author explains that tree-sitter’s design made it possible. A few worry about the increase in memory use compared to C, but most agree the trade-off is worth it for easier builds. People also ask about edge cases and missing features, and the maintainer says only one language (“norg”) is partial right now. Some want to know if this could be used in editor plugins or other tools, and others are interested in the plans for more features or tighter parity with the original. Many say thanks and star the project, and a few mention that they want to help or try it out in their own projects.

---

## Following 35% growth, solar has passed hydro on US grid

- 原文链接: [Following 35% growth, solar has passed hydro on US grid](https://arstechnica.com/science/2026/02/final-2025-data-is-in-us-energy-use-is-up-as-solar-passes-hydro/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47154009)

Solar power in the US grew by 35% last year and, for the first time, produced more electricity than hydropower. This happened while overall energy use in the country also went up, and some of that extra demand was met by burning more coal.

The article says that while energy use in the US had stayed about the same for many years, it rose 2.8% last year. This is partly because people are switching to things like heat pumps and electric cars, which use electricity instead of gas or oil. Solar power grew fast, adding enough energy to almost cover the extra demand, especially when combined with wind power. But because demand rose so much, coal had to be used more too. Coal power went up by 13%, partly because natural gas power plants have become more expensive and slow to build, and exports of US gas have increased prices at home. With solar and wind growing, they are now both ahead of hydropower, and renewables (solar, wind, hydro) are close to making up a quarter of all US electricity. More solar, wind, and battery storage are planned for next year. Batteries will help store extra solar energy for use at night. But the article says that even with renewables growing fast, more coal use might offset the good effects for the environment.

In the comments, some people are excited that solar is growing so quickly and think this shows the future is renewable. Others worry about the rise in coal use, saying it's bad for the climate and means the US is taking a step backward. A few readers discuss how cheap solar panels have become, making it easier for people and companies to add solar power. Some commenters point out that hydropower is limited by geography and weather, so it can’t grow much more, while solar still has lots of room to expand. There are also questions about grid stability, with people wondering if batteries and flexible systems will be enough to handle all the new solar and wind. Some users express concern about political actions, saying government rules can help or hurt renewables and that this affects how fast things change. A few people share stories about their own solar panels at home and say they are happy with their decision. Others say that while solar is great, we also need to use less energy overall to really help the planet.

---

## Dissecting the CPU-memory relationship in garbage collection (OpenJDK 26)

- 原文链接: [Dissecting the CPU-memory relationship in garbage collection (OpenJDK 26)](https://norlinder.nu/posts/GC-Cost-CPU-vs-Memory/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47137140)

This article looks at how Java’s garbage collection (GC) uses both CPU and memory, and how this relationship has changed over time, especially with OpenJDK 26. It explains why just measuring pause time (when the app stops for GC) no longer tells the full story about performance or resource use.

Early garbage collectors stopped the whole application to reclaim memory, and developers focused on reducing these pause times. The article lists three GC costs: explicit (CPU cycles spent on GC threads), implicit (extra code like memory “barriers”), and microarchitectural effects (like CPU cache misses). In the past, you could just check pause time to understand how much GC was hurting your app, but now, with many cores and background GC work, this is not enough.

With single-threaded GC, more memory meant fewer pauses and better throughput. But as systems moved to many cores, GCs like Parallel GC could use all cores to cut pause times. However, this did not reduce total CPU work; it just spread it out. This sometimes left cores idle, wasting money in cloud setups.

Modern collectors like G1 and ZGC do much of their work while the app runs, in the background. G1 splits work between pause and background, so pause time only shows part of the GC’s true cost. ZGC does almost everything in the background, with tiny pauses, but it still uses lots of CPU—just not all at once. This means that using pause time as a measure of GC cost is now misleading.

To fix this, OpenJDK 26 adds a way to measure GC CPU time directly, both through logs and a new Java API. The article shows how to use `MemoryMXBean.getTotalGcCpuTime()` in code, letting developers see exactly how much CPU GC uses.

The author tested this on real apps (like xalan and Spring PetClinic) and showed that sometimes, G1 or ZGC uses less CPU for the same work, but sometimes much more, especially if memory is tight. Choosing the right GC and memory setup depends on your needs—whether you care more about speed, memory use, or cloud costs.

In the Hacker News comments, many people like the new API and think it will help both researchers and engineers tune their systems better. Some say this kind of metric should have been available much earlier, as it gives clear insight into where CPU time goes. Others mention that understanding the real cost of GC is important for cloud billing, since wasted CPU equals wasted money.

A few commenters point out that while the new tools are good, measuring only explicit GC time still misses the hidden costs of implicit barriers and changes in memory layout. Some share stories about moving to Go or Rust to avoid GC headaches, but others reply that for big Java systems, GC is still a necessary trade-off.

There’s debate about whether it’s better to have fewer, longer pauses or many short ones, and how user experience is affected. People also talk about tuning heap sizes, and some share tips about using G1 or ZGC in production. One commenter warns that tuning for lower pause times can actually raise total CPU costs, so it’s good to have more data.

Overall, readers agree that better GC metrics are a big step forward for Java performance work, especially in today’s multi-core, cloud-heavy world.

---

## Why isn't LA repaving streets?

- 原文链接: [Why isn't LA repaving streets?](https://lapublicpress.org/2026/02/why-isnt-la-repaving-streets/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47154076)

This story is about why Los Angeles is not fixing or repaving its city streets. Many people in LA complain about potholes, cracks, and rough roads, but the city does not seem to be fixing them fast enough.

The article explains that LA’s roads are old, and many need repairs. The city says it does not have enough money to fix all the roads. It costs a lot to repave even one street, and LA has thousands of miles of roads. City leaders must choose which streets to fix first, so some areas wait a long time. Sometimes, streets get fixed only after people complain for years. The city also has to pay for other things, like schools and parks, so the street budget is always small. Some streets are more important, like big main roads, so they get fixed first. Smaller streets in neighborhoods may wait a long time. Sometimes, the city does a quick fix by patching holes instead of repaving the whole street. This is faster but does not last as long. Also, weather and traffic make the roads break down faster, so it is hard to keep up.

In the comments, some people say the city should spend more money on roads. Others think LA is wasting money in other areas and needs better planning. A few commenters believe the city’s way of choosing which streets to fix is unfair. Some people say their street has been bad for years with no help from the city. Others say the problem is not just money, but also slow city workers and too much paperwork. A few people suggest using better materials or new technology for longer-lasting roads. Some think LA’s big size makes road repair very hard. Others point out that big cities everywhere have similar problems. One person says city leaders always promise to fix roads but never do enough. Another commenter says people should report bad streets to help the city know where to fix next. Some disagree, saying reports do not always help. In the end, people want smoother streets, but no one agrees on the best way to get there.

---

