# Hacker News 故事摘要 - 2025-10-12

## 今日概述

Today’s top Hacker News stories cover open hardware VPNs, people sharing their new tech projects, and a free course on running AI on small devices. There are also stories about using AI in Emacs, a rare programming bug with Turkish letters, making old computers work again, checking code for bugs, creative 3D insect scans, a bird photo contest, and ways to better understand code speed. Many stories focus on open tools, learning, and creative problem solving.

---

## Wireguard FPGA

- 原文链接: [Wireguard FPGA](https://github.com/chili-chips-ba/wireguard-fpga)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45559857)

This project is about building an open-source, hardware-accelerated WireGuard VPN using a cheap Artix7 FPGA board. The goal is to make fast, secure VPNs more accessible by moving WireGuard from slow software to fast, affordable hardware, and by using open tools so anyone can check or improve the code.

WireGuard is a modern VPN protocol known for being simple, secure, and easy to set up. Today, software versions of WireGuard are much slower than the physical network speed, and current hardware options are very expensive or closed-source. This project aims to fix those problems by creating a WireGuard implementation on a low-cost FPGA board, with all designs and tools open to everyone.

The team worked on another project called Blackwire, which was a very fast (100Gbps) WireGuard hardware switch, but it used expensive hardware and closed tools, so it was not practical for most people. Wireguard-FPGA instead uses a popular, low-cost Artix7 board with four Ethernet ports, and only open-source tools and standard design languages (Verilog/SystemVerilog).

The development plan is split into steps: first, they get the board running and make simple tests (like blinking LEDs and sending Ethernet test patterns), then build the basic hardware for WireGuard, and later add control software, management features, and more. The design splits work between a soft (programmable) CPU for control tasks (like setting up connections and keys) and custom hardware to encrypt, decrypt, and move packets at top speed.

For encryption and security, the project uses standard algorithms: ChaCha20 for encryption, Poly1305 for authentication, Curve25519 for key exchange, and BLAKE2 for hashing. Most of these will run in hardware, except for some parts like key exchange, which may stay in software at first.

Testing is a big part of the project. They use advanced simulation tools to check the design before running it on real hardware, and plan to make remote testing labs so more people can help. The team is careful to document each step, both to help new contributors and to keep the project open for outside review.

The project is still in early stages (“work in progress”). The first phase is a proof of concept, not a finished product. In the future, they hope to make the system more powerful, easier to manage, and ready for real-world use.

In the Hacker News comments, many people are excited about the open hardware and open toolchain approach. Some see this as a big step for transparent, trustworthy VPNs, since all the code is public and can be checked for backdoors. Others are glad that the project uses cheap hardware, making it more reachable for schools, researchers, and hobbyists.

A few commenters worry about the complexity of FPGAs and hardware debugging, saying this is much harder than software. Some point out that real-world testing will be tough, especially reaching true “wire speed” with full security. There are also questions about how easy it will be for others to replicate the setup, especially since FPGA boards are less common than regular computers.

Some users ask if this could help in areas where VPNs are heavily blocked or monitored, since a hardware VPN might be easier to hide or protect. Others wonder about power use and compare this FPGA approach to custom ASICs or modern CPUs with crypto extensions.

Finally, several people praise the team for sharing everything, including their challenges and failures, not just the finished product. Many hope that open hardware projects like this will become more common, to increase security and trust in network devices.

---

## Ask HN: What are you working on? (October 2025)

- 原文链接: [Ask HN: What are you working on? (October 2025)](item?id=45561428)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45561428)

This post is a monthly thread on Hacker News where people share what projects they are working on. It is a place for developers, makers, and tech fans to talk about their ideas and get feedback.

Many people talk about building new apps or tools. Some are making software to help with daily tasks, like calendar apps or note-taking tools. Others are working on websites that help people learn new skills, such as coding or language learning. A few are building games, both for fun and for learning. Some people are working on open-source projects, hoping others will join and help. There are also posts about small businesses and starting startups. Some makers are trying to solve problems they face at work, like making it easier to manage servers, emails, or databases. A few people are working on hardware, like smart devices or sensors.

Many share links to their projects, hoping for feedback or testers. Some explain the problems they faced and how they solved them. Others ask for advice on how to grow their user base or make money from their projects. Some mention using new technologies, like AI or blockchain, and share their experiences. A few talk about building projects just for fun or learning, not for profit.

In the comments, some people give helpful feedback or ideas to improve the projects. Others ask questions to learn more or point out possible problems. There are supportive comments, cheering on people for building and sharing. Some users share their own projects, hoping to connect or team up. A few people warn about common mistakes, like spending too much time on features that users may not need. Others remind makers to talk to their users and get feedback early. Some comment on how hard it is to balance building with marketing or making money.

Overall, the community is very positive and encouraging. Many enjoy seeing what others are creating and learning from their stories. There is a sense of excitement and support among people who like building new things.

---

## Edge AI for Beginners

- 原文链接: [Edge AI for Beginners](https://github.com/microsoft/edgeai-for-beginners)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45561700)

This GitHub project is a free course from Microsoft that helps beginners learn Edge AI—using artificial intelligence on local devices instead of the cloud. The course explains basic concepts, how small language models (SLMs) work on edge devices, and how to make and deploy AI apps that run locally for better privacy, speed, and cost.

The main lessons teach you how to run AI directly on hardware like phones, PCs, or IoT devices, which keeps data private and reduces delays. There are modules on understanding Edge AI versus Cloud AI, learning about SLMs (like Phi-4 and Mistral-7B), and how to optimize models so they run faster and use less memory. You get step-by-step guides for real-world projects, such as local chatbots, document search tools, and multi-agent systems. The course also covers production topics like monitoring, scaling, and compliance, helping you prepare for industry jobs in areas like healthcare, manufacturing, and smart devices. There are hands-on workshops, Jupyter notebooks, and code samples, and the course supports many languages. You can follow structured paths from beginner to expert, with practical projects and self-assessment tools.

From the comments, some people are happy to see more beginner-friendly AI education, especially for running models without the cloud. Others ask about real hardware support and whether examples work on things like Raspberry Pi or Android phones. A few users say the course is well-structured and like the focus on privacy and cost, but some want more real-life case studies or worry about Microsoft’s long-term support. One commenter points out that many edge devices have small resources, so it is good that the course covers model optimization. Some worry that AI on the edge is still limited compared to cloud AI, but others say local AI is important for privacy rules in some countries. There are also tips from people who tried the course, saying the hands-on parts are helpful, but beginners may need patience with setup. A few ask for more video or interactive lessons, not just text and code. Overall, most comments agree that courses like this can help more people start with Edge AI.

---

## Emacs agent-shell (powered by ACP)

- 原文链接: [Emacs agent-shell (powered by ACP)](https://xenodium.com/introducing-agent-shell)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45561672)

This article is about a new Emacs package called agent-shell, which lets you use AI agents in Emacs using the Agent Client Protocol (ACP). The author explains how agent-shell works as a native Emacs shell, so you can chat with different AI models right inside your editor.

The package uses ACP, a protocol made by Zed and Google, to connect with different AI agents through a single interface. This means you can switch between agents like Gemini and Claude Code by changing the configuration. The article gives code examples to show how to set up each agent. Agent-shell uses comint-mode, so it acts like a regular Emacs shell buffer, making it easy to use if you know Emacs.

The author talks about building extra tools, like a traffic buffer, to help see and debug the messages sent between Emacs and the agents. To save money and speed up testing, the author also created a way to replay traffic from fake agents, so they don’t have to keep paying for expensive API calls. This replay mode helps fix bugs faster.

There are still features missing, and the author wants to improve the user experience. They are experimenting with new features like a diff buffer for comparing changes. The article invites people to try the packages and give feedback or send code changes. The work is open source and available on GitHub, but the author asks for support to help fund the project.

In the comment section, some people are excited about using AI agents inside Emacs and think this tool can save time for developers. Others like that the package is agent-agnostic, so you’re not locked into one AI provider. A few users share their own experiences with similar Emacs tools and suggest ideas for making agent-shell even better, like adding support for more agents or improving the replay feature.

Some commenters ask about security and privacy, since using cloud AI agents means sending data outside your computer. Others worry that setting up agent-shell looks complex, especially for people new to Emacs or Lisp. There are also comments about the cost of using paid AI agents and how the fake agent tool helps save money.

Some people thank the author for making their work open source and encourage more funding for projects like this. A few suggest ways to make installation easier, like adding agent-shell to popular Emacs package managers. There are questions about the future of ACP and whether more editors will support it. Overall, commenters appreciate the clear documentation and the new possibilities this tool brings to Emacs.

---

## A years-long Turkish alphabet bug in the Kotlin compiler

- 原文链接: [A years-long Turkish alphabet bug in the Kotlin compiler](https://sam-cooper.medium.com/the-country-that-broke-kotlin-84bdd0afb237)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45559767)

This article talks about a hidden bug in the Kotlin compiler that only showed up for people using Turkish language settings on their computers. The problem started in 2016 and took about five years to fix, causing strange build errors for Turkish developers.

The root issue was with how computers handle upper and lower case letters in different languages. In Turkish, the letter ‘I’ and ‘i’ are not just simple uppercase and lowercase like in English. Turkish has two versions: ‘I’ (dotless) and ‘İ’ (dotted), and their lowercase forms are ‘ı’ (dotless) and ‘i’ (dotted). Kotlin’s code used a function to change words to lowercase or uppercase, but it didn’t say which language’s rules to use. Normally, “INFO”.toLowerCase() becomes “info” in English, but on Turkish systems, it became “ınfo” (with a dotless ‘ı’). This meant the compiler could not match important tags or function names, leading to errors.

At first, the bug caused build failures for Turkish developers. Later, after Kotlin added new features like coroutines, the bug became worse. For example, the compiler started inventing wrong function names like “boxİnt()” instead of “boxInt()”, which did not exist in the standard library. This caused programs to crash at runtime, not just at compile time. The issue was hard to spot because the difference was only a single dot on a letter, and it depended on the computer’s language settings.

Several Turkish developers found and reported the bug at different times. Sometimes the bug seemed to disappear, only to return in new places as Kotlin evolved. Each time, the root cause was the same: using locale-sensitive case conversion without specifying a language, so the compiler behaved differently in Turkish.

After many reports and investigations, the Kotlin team finally fixed the problem by always using the English (US) locale for these case changes in the compiler. They updated many parts of the code, changed how string case functions work, and even removed or replaced some confusing functions. Now, Kotlin’s newer versions are safe from this kind of bug.

In the Hacker News comments, many people said this is a classic example of why you should never use locale-sensitive string operations in programming language tools. Some users shared stories about similar bugs in other programming languages or platforms, especially with Turkish or other special alphabets. Others pointed out that the bug was tricky because it only affected a small group—Turkish developers—but caused big problems for them. Some commenters praised the Turkish developers for their detective work and for not giving up after being ignored at first.

A few people said this kind of bug shows why software should always set a default locale for important logic, instead of using the system’s language. Some developers joked about the “Turkish I” being a famous problem that every programmer should know about. Others wondered how many more bugs like this are hidden in other tools and libraries. A couple of users discussed how Unicode and language rules are much more complex than most programmers think, and that even big projects can forget about these details. Some also talked about how open source lets users help find and fix bugs like this. Finally, a few commenters said it’s important to listen to user reports, even if they seem “local” or rare, because they might reveal deeper problems.

---

## Completing a BASIC language interpreter in 2025

- 原文链接: [Completing a BASIC language interpreter in 2025](https://nanochess.org/ecs_basic_2.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45560974)

The article talks about making a new BASIC language interpreter for the 1983 Mattel ECS, an old add-on for the Intellivision game system. The author explains how they finished adding important features to their interpreter, like string handling and garbage collection.

First, the author wanted the interpreter to support text strings, just like the original ECS BASIC. They added ways to handle string variables (A$ to Z$), and updated the parser to know if something is a number or a string. Then, they made it possible to use string functions like ASC, CHR$, LEN, LEFT$, RIGHT$, MID$, INSTR, VAL, and STR$. They also added string concatenation with the plus sign.

A big problem was memory: temporary strings could fill up the stack and crash the interpreter. The author solved this by making two stacks, one for string variables and one for temporary strings, and using a value (0xCAFE) to mark empty spaces. This way, they could do simple garbage collection without making the program slow.

Next, the author added more math functions, like ATN, TAN, LOG, EXP, SQR, and the power operator. They fixed some rounding errors to make results more accurate. They also improved user features, like graphics support (PLOT, DRAW, CIRCLE), positioning (PRINT AT), timing (TIMER), and easier number input.

Saving and loading programs was hard because the old ECS uses cassette tapes at only 300 baud (very slow). The author had to fix problems with audio levels and delays to make data save and load correctly. They also added printer support, so users can print out their BASIC programs. 

Testing the interpreter with real games, like Reversi, helped find more bugs, especially with string handling and memory. The article ends with statistics: the project took about 7,370 lines of assembly code over a month, and the source code is open on GitHub.

In the comments, some people are impressed by the dedication to an old system and the technical tricks used for memory and speed. Others remember using BASIC in the past and enjoy seeing old machines get new life. Some ask why bother with old hardware, but fans reply that it’s fun, a challenge, and keeps history alive. A few discuss the string garbage collection method and suggest ideas for making it even more efficient. Some users are curious about the cassette and printer support, saying it brings back memories of their first computers. One person points out that making the interpreter smaller and faster than the original is a big achievement. Others talk about how hard it is to debug assembly code, and praise the clear explanations in the article. Some even say they want to try the interpreter themselves, while a few thank the author for releasing the source code.

---

## Three ways formally verified code can go wrong in practice

- 原文链接: [Three ways formally verified code can go wrong in practice](https://buttondown.com/hillelwayne/archive/three-ways-formally-verified-code-can-go-wrong-in/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45555727)

This article talks about how formally verified code—code that is “proven” correct—can still have bugs. The author uses the example of the “leftpad” function, which many people have tried to prove correct, but even those proofs can fail in real-world situations, like with tricky Unicode characters.

The main idea is that “correct” in formal methods means the code matches a written specification, not that it has no bugs at all. A specification is a rule or description of what the code should do. For example, the Haskell function `inc :: Int -> Int` has a spec saying it takes an integer and returns an integer. But it does not say that it always returns a bigger integer. Formal proofs check that the code matches its spec, but not that it works perfectly in every real situation.

The article explains three main ways formally verified code can still go wrong. First, the proof itself might be wrong. Sometimes, the tool or person checking the proof makes a mistake, or shortcuts are taken during the proof-writing process. Second, the specification might be wrong or incomplete. If the spec is too simple or misses important details, the code can be “proven correct” but still not do what people expect. For example, a leftpad function might be proven correct for string length but not for how text shows up on screen with different fonts or Unicode. Third, the assumptions might be wrong. Proofs often depend on things outside the code, like the system having enough memory, the input list being sorted, or other code not changing. If these things change or are wrong, the proof does not protect you anymore.

The article gives examples, like how binary search proofs can fail if you forget that computers use numbers with limits (which can overflow). It also points out that sometimes it is too hard to write a perfect specification, especially for things like visual alignment, which can change with fonts and systems.

In the Hacker News comments, some readers agree and share their own stories of formally verified code failing in practice. They point out that real-world systems are full of messy details and surprises, so even the best proofs can miss something important. Others say that formal verification is still very useful, especially for small, important parts of code, like cryptography or safety systems. A few people argue that most bugs come from weak or wrong specifications, not the proof tools themselves. Some comment that formal methods are hard to use because writing good specifications is difficult and time consuming. Others suggest that better education about what formal proofs really mean would help developers and users have more realistic expectations.

There are also comments discussing the trade-offs. Some say that formal verification should be one part of a bigger process, not a replacement for testing and code review. Others note that assumptions about the environment, like hardware or outside libraries, are always risky, and it’s impossible to prove everything. Some readers worry that people might trust “proven” code too much and stop checking for bugs in other ways. Finally, a few commenters share the hope that formal verification tools will improve and become easier to use, but agree that understanding what was actually proven is always important.

---

## Macro Splats 2025

- 原文链接: [Macro Splats 2025](https://danybittel.ch/macro.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45556952)

This article is about making detailed 3D models of insects using a method called “Macro Splats.” The author explains how to use many sharp photos taken from different angles to create 3D images you can move around and view on your computer.

The process starts with something called a Gaussian splat, which is like putting lots of soft, blurry shapes together to make a 3D photo. Normally, you take pictures of an object from all sides, then use a computer to build the model. But with tiny subjects like insects, close-up photos often have blurry spots because only a small part of the photo is in focus. To fix this, the author uses a method called focus stacking: taking many photos at the same angle, each with a different part in focus, and then combining them to make one sharp image.

Instead of using hundreds of photos for each angle, the author found a way to use just 16 photos per angle by carefully choosing camera settings. The insect was placed on a rotating disk, and the camera was moved up and down using a boom arm. A script helped rotate the disk and an automated device moved the camera for each focus step. This setup allowed the author to take photos from 111 different views, for a total of 1776 images. The camera used was a Nikon D810 with a special close-up lens, and the session took about four hours.

After all the photos were taken, the author used software to combine the images, fix colors, and remove the background. Then another program trained the 3D model so it could be viewed from any direction. The final result is a detailed, realistic 3D model of an insect, which you can see online or even download for free.

In the comments, some people are amazed by the quality and detail of the 3D models, calling them “incredible” and “beautiful.” Others discuss the technical challenges, like how hard it is to align images when the depth of field is so shallow, and how clever the focus stacking approach is. A few people ask about the hardware, wondering if faster cameras or new automation could speed up the process. Some suggest using different lenses or even trying this with other objects, not just insects.

One commenter points out that sharing the 3D model for free and allowing commercial use is very generous. Another mentions possible uses for education or science, saying these models could help students learn about insects without needing a microscope. Some people express interest in the software tools used, while others wish for even easier ways to make such models at home. A few raise privacy and copyright questions about sharing models, but most are very positive about the project. Overall, the community seems excited and inspired by the author’s creative and careful work.

---

## Bird Photographer of the Year Gives a Lesson in Planning and Patience

- 原文链接: [Bird Photographer of the Year Gives a Lesson in Planning and Patience](https://www.thisiscolossal.com/2025/09/2025-bird-photographer-of-the-year-contest/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45487232)

A Canadian photographer, Liron Gertsman, won the 2025 Bird Photographer of the Year award for a photo of a Magnificent frigatebird flying in front of a total solar eclipse. The article talks about how this photo took over a year of planning and a week of scouting in Sinaloa, Mexico. Gertsman’s picture shows the importance of patience and preparation in nature photography. The contest had more than 33,000 entries from many countries, including young photographers. It supports bird conservation by donating to the charity “Birds on the Brink.”

The contest has many categories, like Urban Birds, Best Portrait, and Birds in the Environment. Some winning photos include an Alpine chough in a snowstorm, a Southern giant petrel after a meal, barn owls in a church, and swallows flying over marigolds. The article invites readers to see the full winners’ gallery online and mentions a book of the best photos. It also says the 2026 competition is now open.

In the comments, some people are amazed by the effort behind Gertsman’s eclipse photo, saying it is a rare and lucky shot. Others talk about the skill needed for wildlife photography and how waiting for the right moment is just as important as camera gear. A few users share their own stories of trying to photograph birds and how hard it can be. Some point out the value of conservation and like that the contest supports bird protection. There are also questions about how much editing is allowed in such contests. A few people wish the contest would show more behind-the-scenes details so beginners could learn. Some comments praise young photographers in the contest, saying it’s good to see new talent. One user wonders if AI photos might be a problem in future contests, while another says nothing can replace real patience and time in nature.

---

## A whirlwind introduction to dataflow graphs (2018)

- 原文链接: [A whirlwind introduction to dataflow graphs (2018)](https://fgiesen.wordpress.com/2018/03/05/a-whirlwind-introduction-to-dataflow-graphs/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45552590)

This article explains what dataflow graphs are and why they’re useful for understanding how code runs on a computer. The author wants to show how thinking in dataflow helps you predict code performance, not just measure it after it runs.

Instead of just looking at which code is slow, the article suggests building a model of how your code works at a low level—thinking about each instruction, how they depend on each other, and how they move through the CPU. The author uses a simple machine model with 64-bit registers, basic arithmetic, loads and stores (memory access), and branches for control flow. Each instruction takes some time, and some can run in parallel if they don’t depend on each other. This is called instruction-level parallelism.

The author gives an example: looping over an array to sum numbers. Each loop loads a number, adds it to a sum, moves a pointer, and checks if it’s done. By drawing a dataflow graph, you can see which instructions depend on which, and how soon you can start each new loop cycle. The article shows that sometimes, the slowest step isn’t the one that takes longest (like memory load), but the one that blocks the next iteration (like advancing the pointer). This is called the critical path.

He then compares this to summing a linked list, where each step has to wait for the previous memory load. This makes the loop much slower, because you can’t start new work until the last load is done. The article also explains how memory latency (waiting for memory) can slow things down even more, and how some data structures make this worse.

The article talks about loop unrolling, where you process more than one element at a time to reduce overhead and better use the CPU. But this can shift the bottleneck from one spot to another, so you have to be careful. The key is to look at the data dependencies, not just the code itself.

Finally, the author says drawing these graphs is helpful even before you write code, unlike profiling which needs working code to measure. You can use dataflow ideas at any scale, from tight loops to big projects, to see what’s really blocking progress.

In the comment section, many readers liked the clear explanations and practical examples. Some said the diagrams helped them finally understand why linked lists can be slow. Others pointed out that real CPUs are even more complex, with more limits and surprises, but agreed that this model is a useful starting point.

A few commenters mentioned that sometimes, actual profiling is still needed because models can miss things, especially with modern hardware. Some readers discussed how compilers and CPUs are getting better at handling data dependencies, but knowing about dataflow still helps write better code.

There were questions about how to choose the right level of detail for your model—some people want more accuracy, others prefer simplicity. Some pointed out that the method works for understanding not just code, but also large systems, or even project planning.

Overall, most agreed that thinking about dataflow and critical paths is a smart way to write faster, more predictable code, and that practicing this skill can make you a better programmer.

---

