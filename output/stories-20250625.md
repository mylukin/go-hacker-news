# Hacker News 故事摘要 - 2025-06-25

## 今日概述

Today’s top Hacker News stories are about open source projects setting new rules for AI-generated code, a pyramid that always lands on the same face, why writing less code can be better, problems with online health companies, Richard Feynman’s advice on working on simple problems, groups helping people go offline, saving money on audio transcriptions, and the stress on unpaid open source maintainers. The main themes are tech quality, ethics, community, and the challenges of keeping software open and safe.

---

## QEMU: Define policy forbidding use of AI code generators

- 原文链接: [QEMU: Define policy forbidding use of AI code generators](https://github.com/qemu/qemu/commit/3d40db0efc22520fa6c399cf73960dced423b048)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44382752)

QEMU just made a new rule: they will not accept any code that was made by AI code generators, like ChatGPT, Copilot, Claude, or Llama. The reason is that the law around AI-generated code and software licenses is not clear yet, especially since AI models are trained on lots of code with different licenses and rules. QEMU wants to be sure that every part of its code has a clear legal status, so it can keep using open source licenses safely. If someone sends code made by AI, the team cannot be sure about the license or if it copies code from somewhere else. This is a risk for the project, so the team decided to be strict for now: no AI-generated code, unless there is a special exception and the contributor can prove the code’s legal status. This rule might change later, if the law gets clearer or tools get better.

People in the comments have mixed feelings about this. Some think it makes sense to be careful, because open source projects need clear legal rights to all their code. Others feel the rule may be too strict and could slow down new ideas or make it harder to get help from AI for simple tasks, like writing tests or setting up automation. A few people wonder if the real reason is not just legal, but also because AI code can be low quality and take a lot of time to review, wasting project resources. There are comments saying that humans can also write bad code, so banning AI alone won’t stop low-quality submissions. Some think this rule will help keep code safe and make sure people really own their work, not just copy-paste from AI. Others point out that the QEMU team left the door open for exceptions and might relax the rule in the future. There’s talk about how hard it can be to tell if code is written by AI, and about the risk of projects getting flooded with low-effort AI-generated contributions. Some people share stories about using AI for coding and not getting good results, saying current tools are not ready for big, complex projects like QEMU. Finally, a few think this is just a smart move to protect the project for now, since the legal and technical problems are not solved yet.

---

## A new pyramid-like shape always lands the same side up

- 原文链接: [A new pyramid-like shape always lands the same side up](https://www.quantamagazine.org/a-new-pyramid-like-shape-always-lands-the-same-side-up-20250625/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44381297)

A group of mathematicians has created a new kind of pyramid-shaped object—a tetrahedron—that always lands on the same face, thanks to a special weight distribution. This solves a math problem first asked over 50 years ago: can you make a pyramid with flat sides that only sits on one side?

The original question was about a regular tetrahedron with all sides and weight even, but that was proven impossible. The new twist is to move the weight around inside the shape. This idea is easy with round objects, like roly-poly toys, but very hard with sharp-edged polyhedra. Using computers, the team found a shape and weight setup that worked in theory, but building it was a huge challenge. They needed very light carbon fiber and a small, very heavy piece of tungsten carbide. Even a tiny bit of extra glue could ruin the balance. After months of careful work, they built a real model that always flips to one face, just as they hoped. This shows that experimenting and building things is important in math, not just solving equations. The work might help in designing self-righting robots or spacecraft.

Top comments on Hacker News share a mix of reactions. Some people joke about using this shape as a strange dice for games. Others ask why not just use a ball with a heavy side, which would also land the same way. Some point out that this pyramid needed special materials and extreme care to build—one commenter found it disappointing it can’t be made with just one material. There’s discussion about whether making a shape stable on exactly two faces would be useful for things like tamper detectors. Several users note that making the center of mass perfect is very tricky with flat-faced shapes. A few dive into the math, explaining why a regular, evenly weighted tetrahedron can’t do this trick. Others mention that this kind of breakthrough shows how sometimes simple ideas take a long time to build, needing better materials and computers. Finally, some dream of buying one of these “magic pyramids” as a fun toy at a gaming convention.

---

## -2000 Lines of code

- 原文链接: [-2000 Lines of code](https://www.folklore.org/Negative_2000_Lines_Of_Code.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44381252)

The article tells a story from early Apple history, where managers asked programmers to report lines of code written each week. Bill Atkinson, a key engineer for the Lisa project, thought this was a bad idea because he believed good code should be small and efficient, not big and bloated. He had just finished making Quickdraw’s region calculations much faster by rewriting and removing about 2,000 lines of code. When asked to report his code for the week, he wrote “-2000” to show he had removed, not added, code. After a few weeks, managers stopped asking him to fill out the forms.

Many readers agree with Atkinson’s point that less code can be better. Some shared their own stories, like removing tens of thousands of lines and replacing them with much smaller, faster code. Others worked on cleaning up code bases where bugs were hidden in copied and slightly changed functions, showing how counting lines can make things worse. A few comments joked about how these metrics encourage bad habits, like making useless changes just to boost numbers.

Some people remembered how management sometimes rewards fixing bugs or writing more code, often leading to silly or harmful results. Others pointed out that not everyone in management is fooled by big numbers, but using lines of code as a metric is still common and often unhelpful.

There were also discussions about new tools like AI code assistants. Some worry these tools create lots of extra code, which later needs to be cleaned up. Others say that it’s easy to accept bad code if it works, even if it’s not efficient. A few readers argued that the story might be a little exaggerated, but since Bill Atkinson was so important at Apple, it’s believable he could ignore silly rules. People also debated whether software quality will get better or worse in the AI era, and whether small, careful code will still matter when it’s so easy to generate lots of new code quickly. Overall, most agree that good code is about quality, not quantity.

---

## The Hollow Men of Hims

- 原文链接: [The Hollow Men of Hims](https://www.alexkesin.com/p/the-hollow-men-of-hims)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44382582)

This article looks at Hims, a telehealth company that sells treatments for things like weight loss, hair loss, and sexual health directly to customers online. The writer says that Hims takes advantage of legal loopholes to sell drugs in ways that may not be safe or honest, and uses clever marketing to make their business seem helpful and modern.

Hims claims to make healthcare easier and cheaper, but often just sells old, generic drugs at much higher prices. For example, they combine drugs like sildenafil and tadalafil (from Viagra and Cialis) into new pills, even though doctors say this is unsafe and not useful. They also sell “compounded” versions of expensive weight loss drugs like semaglutide by mixing in vitamins or changing doses, saying this makes them “personalized.” But really, these are just ways to get around drug patents and sell cheaper, copycat versions, sometimes from untested foreign suppliers. The company had a big marketing campaign saying they were fighting against Big Pharma’s high prices, but then quickly partnered with a big drug company (Novo Nordisk), only to be dropped when Hims kept selling their knockoff versions.

Hims also uses subscription models that lock people in and make it hard to cancel, with many customers complaining about surprise charges and poor customer service. The article notes that people pay Hims much more than regular pharmacies for the same drugs, mostly to avoid seeing a real doctor and for the “convenience” of online shopping. The company’s fast, automatic prescription process is more about making money than giving good medical care. The author compares Hims’ approach to other companies that also use loopholes to sell drugs not approved by the FDA, and says the whole system is built on tricking both the law and the customer.

In the comments, some people agree that what Hims is doing is risky, especially selling unapproved or poorly tested drugs from China. They worry about the safety and the lack of real medical checks. Others are confused by the article’s style, thinking some of the comparisons and jokes are hard to follow. A few point out that while the article is harsh, the real problem is that the law allows companies like Hims to operate this way. Some wonder why these actions are legal at all, and say the system seems broken if it lets companies profit from people’s desperation. There is also talk about how online healthcare can be good for some people who avoid doctors out of shame, but most agree that honest care and real safety checks are important. Overall, readers think the story is a warning about what can happen when tech companies move fast in health without enough rules or care for people’s health.

---

## What Problems to Solve (1966)

- 原文链接: [What Problems to Solve (1966)](http://genius.cat-v.org/richard-feynman/writtings/letters/problems)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44379606)

This article is a letter from Richard Feynman to a former student who felt his research was not important enough. Feynman tells him that the best problems to solve are the ones you can actually work on and make progress with, no matter how simple they seem.

Feynman says it's a mistake to only chase big, “grand” problems because it can make you feel sad or lost. He gives examples from his own life—he worked on many small or “humble” problems, like why friction works, how to make metal stick to plastic radio knobs, and even how to fold paper into toys called flexagons. Some of these problems were not world-changing, but they gave him joy and helped others. He feels that helping answer even a small question for a colleague is worthwhile. Feynman warns against thinking you’re only valuable if you solve the world’s biggest puzzles. He says people should not feel nameless or unimportant—your family, friends, and coworkers value what you do, even if it seems simple. He admits he made a mistake by giving his student a problem instead of letting him pick his own. He hopes the student will find happiness by working on things he can solve, rather than feeling pressure to chase only the biggest ideas.

In the comments, many people found the letter beautiful and wise. Some said Feynman’s writing helps them see that simple things matter and that he had a gift for making hard ideas easy to understand. Others liked his advice about feeling good when you solve any problem, even if it’s small. One commenter said this message helped them feel better about their own work, like answering colleagues’ questions or supporting their family. Some said it’s okay to just be “good enough” and that small, steady work is as important as big, flashy projects. Others pointed out that even “humble” problems, like the student’s research, can turn out to be very important later. 

A few comments were more critical, saying Feynman could be arrogant, but most focused on his kindness and honesty. Some people talked about how today’s tech world often pushes people to chase big ideas that may not be their own, warning against working on things just because they seem popular or profitable. Others talked about the pressure to find purpose, asking if it’s okay to change your mind about what matters. Some shared personal stories about how this letter helped them during hard times or when feeling stuck at work. One person suggested trying to make a flexagon, showing that even small, fun problems can be meaningful. Overall, most readers felt inspired, seeing value in solving any problem you care about, no matter how small.

---

## The Offline Club

- 原文链接: [The Offline Club](https://www.theoffline-club.com)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44381168)

The article talks about The Offline Club, a group that helps people take breaks from screens and spend time together in real life. It offers events like phone-free dinners, relaxed hangouts, and digital detox retreats in cities across Europe.

The main idea is to help people relax, meet others, and enjoy hobbies without using phones or computers. People can join events in cities like Amsterdam, London, Paris, and more. If there isn’t an event nearby, you can join a waitlist or even start your own local chapter. The club hosts many types of events—some for fun, some for quiet time, and some for businesses wanting team retreats. They also have a newsletter with tips for living more offline. Customers say the events are friendly and cozy, and reviews are very positive. The website shows stories from people who made friends, enjoyed reading, or just wanted a break from digital life. The club believes spending time offline can help people feel more connected and relaxed.

In the Hacker News comments, some people say this idea is like Meetup, but focused on being offline together. They point out common problems, like finding places to meet, making sure people actually show up, and keeping organizers interested. A few users share tips from running their own groups, like talking to coffee shop owners for space or sending personal messages to encourage attendance. Some warn that events can sometimes be used for things like sales or pyramid schemes, so it’s important to keep events honest and friendly.

Others discuss how many social events moved online during COVID and never returned to in-person, which they miss. Some say local game stores or dance events are already good places to meet people offline, but admit these aren’t for everyone. One person thinks paying for a welcoming, non-competitive event is helpful for people who feel shy or don’t want to join skill-based groups. People note that making new friends as adults is hard, and having scheduled events helps overcome the first barriers to meeting others. But a few feel that planned meetups can become too formal, which makes it harder to build real friendships. Some miss the old days of just dropping by a friend’s house, but others say this isn’t possible now—lives are busier and people often need to plan ahead. In the end, many agree that regular, friendly offline events are a good step for people who want more real-world connection.

---

## OpenAI charges by the minute, so speed up your audio

- 原文链接: [OpenAI charges by the minute, so speed up your audio](https://george.mand.is/2025/06/openai-charges-by-the-minute-so-make-the-minutes-shorter/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44376989)

OpenAI charges money for audio transcriptions based on how many minutes you upload. The article explains a simple trick: speed up your audio before sending it to OpenAI, so you pay less and get results faster.

The author shows how to use tools like ffmpeg to make audio play 2 or 3 times faster. This way, a 40-minute talk becomes 20 or 13 minutes long, saving money and time. The article shares a script to extract audio from YouTube, speed it up, and send it to OpenAI’s API. The writer found that speeding up audio does not hurt transcription quality much, at least at 2x or 3x speed. If you go up to 4x speed, the transcription gets really bad. The cost drops by about a third if you use 3x speed. The main cost is not just the audio minutes but also the number of tokens in the results. The process is like compressing images or text—humans (and AI) can understand even if some details are lost. The author also points out that using local tools like Whisper can be slow if your computer isn’t powerful, so offloading to OpenAI can be helpful. The article ends with simple advice: speed up your audio to save money, but don’t push it too far.

In the comments, many readers share tips to make this trick even better. Some suggest removing silence from the audio before uploading, which can cut minutes without losing any information. Others talk about Andrej Karpathy’s fast speaking style and wonder if there’s a way to measure talking speed and adjust the trick for each speaker. Some point out that listening at high speed works better with good audio quality. There are debates about whether watching or reading a summary is the best way to learn; a few say that slower, careful listening leads to deeper ideas. Multiple people mention that you can run transcription models like Whisper on your own computer for free, but note that it’s slow on older hardware. Others talk about using cheaper services like Groq or Deepgram. A few readers praise the article’s clear, up-front summary and wish more writers did the same. Some worry about privacy when sending audio to OpenAI, while others think the trick is useful for saving time and money. There is also talk about using YouTube’s built-in transcript tools or browser extensions to speed up playback. Finally, some commenters worry that always looking for shortcuts and summaries might make us less thoughtful, while others argue it’s just about giving people more choices.

---

## Libxml2's "no security embargoes" policy

- 原文链接: [Libxml2's "no security embargoes" policy](https://lwn.net/SubscriberLink/1025971/73f269ad3695186d/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44381093)

Libxml2 is a popular open-source XML parsing library used by many big companies and projects. The main maintainer, Nick Wellnhofer, recently announced he will no longer keep security bugs secret before fixing them, because he is an unpaid volunteer and can’t keep up with all the demands.

The article explains libxml2’s long history, from its beginning in the GNOME project to its wide use today. Over the years, the original creator, Daniel Veillard, handed over maintenance to Wellnhofer. Funding for the project has been very low, with only one big donation from Google. Wellnhofer has spent a lot of time fixing bugs, many reported by security researchers seeking credit or CVEs, but he gets little help or reward in return. He decided to treat security bugs like normal bugs—publicly report and fix them when he has time, instead of following strict “embargo” rules to keep problems secret until a patch is ready. He also stepped down from maintaining another related project, libxslt, saying the pressure from unpaid work is too high.

Wellnhofer argues that big companies use libxml2 but rarely give back, either with money or code. He thinks the secrecy around security is just a way for companies to push work onto open-source volunteers. Some people worry that making security bugs public right away could put users at risk, but Wellnhofer says the real problem is companies not supporting the software they rely on. Other open-source contributors have similar feelings, saying companies benefit from free software but don’t help maintain it. There are suggestions to write clear “maintenance terms” so everyone knows what support to expect.

In the Hacker News comments, many users discuss if bugs like denial-of-service (DoS) should really be called “security bugs.” Some say DoS is not the same as stealing money or data, but others point out that service outages can hurt banks, health care, or important systems. Some developers feel that reporting every crash as a security bug makes it hard to find real, serious issues. Others say context matters—what is a small problem for one app could be a big risk for another.

There’s debate about whether companies should do more to support open-source projects they use. Some say strict licenses like GPL could force companies to help, but others note that even with open licenses, companies don’t always contribute back. Many agree that unpaid maintainers shouldn’t feel pressured to fix every bug, especially for free. Some suggest companies should handle their own security fixes if they care so much. People also talk about the emotional side—maintainers often feel responsible, but it’s not fair for all the work to fall on one person.

A few commenters compare this situation to other open-source projects, like OpenSSL, which only got more support after public problems. Some think the solution is for governments or big companies to pay for core software, while others say maintainers should just set clear boundaries. In the end, most agree that the current way is not working well for volunteers or for the open-source ecosystem.

---

