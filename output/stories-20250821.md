# Hacker News 故事摘要 - 2025-08-21

## 今日概述

Today’s top Hacker News stories talk about US water use, new tricks and risks in Python pattern matching, open source AI rules, changes in building AI products, the new DeepSeek AI model, learning SVG paths, confusing AI job titles, a group chat AI startup, cave diving under Budapest, and using wearable data to predict health. Many stories focus on how AI is changing work, tools, and rules, while others look at hidden parts of the world and new ways to use data.

---

## How does the US use water?

- 原文链接: [How does the US use water?](https://www.construction-physics.com/p/how-does-the-us-use-water)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44971850)

The article looks at how the US uses water and why it often gets less attention than other types of infrastructure. It explains where water in the US comes from, how it moves through the environment, and how people and industries use it.

Most water in the US falls as rain or snow, but only 2% is used by people; the rest returns to the air or flows to the sea. US water infrastructure is similar to electricity systems, using large pipes and treatment plants to move water from sources to homes and businesses. In 2015, Americans used about 322 billion gallons of water per day. Most of this is fresh water, with 74% coming from surface sources (like lakes and rivers) and 26% from underground aquifers.

Water use can be “consumptive” (used up and not returned) or “non-consumptive” (returned after use). The biggest user is thermoelectric power plants (41% of all US water use), but almost all their water is non-consumptive—it’s returned to rivers or the sea, just warmer. Irrigation for crops is the next largest (37%), and most of this is consumptive, as water is lost to plants or soil. Crops like alfalfa, orchards, corn, and rice use the most irrigation water.

Golf courses use about 0.3% of US water. Homes and businesses use about 12%, with Americans using much more water per person than people in Germany or France. Industry uses 4.5%, mainly for things like making paper and steel, but most industrial water is also non-consumptive. Data centers use about 66 million gallons per day, mostly for cooling; this is important but small compared to farming or golf courses.

Aquaculture, mining, and livestock use the rest of the water. California, Texas, and Idaho use the most water—mostly because of their size and farming needs. Most irrigation happens in the west, where rainfall is low, and in some states, irrigation is a big part of total water use. Groundwater is being overused in some places, causing aquifers to shrink.

Over time, US water use peaked in 1980 and has dropped since, with less water used by power plants, farms, and industry, even as groundwater use has stayed steady. The article warns that water use numbers can be misleading—using a lot of water does not always mean it is “used up,” especially if it’s returned. But it also says we can’t ignore water limits, since some water, once used, is hard to get back.

Commenters had many views. Some pointed out that focusing on total water use can be confusing if most of it is returned to nature; they say we should care more about consumptive use. Others were surprised how much water power plants use, and discussed whether new energy sources could lower water needs. A few readers noted how much water goes into farming, especially for crops like alfalfa and rice, and wondered if food choices should change to save water.

People debated the impact of data centers. Some worried about their growth in dry areas, while others argued the value created per gallon at data centers is much higher than in farming. Several commenters shared stories of water shortages in their states and called for better water management. Others said the US is still lucky to have lots of water compared to many countries, but agreed that local shortages are serious.

A few users discussed the need for more investment in water infrastructure, saying it’s often ignored until there’s a crisis. Some talked about new technology for saving or cleaning water, while others were skeptical about high-tech solutions and said basic conservation is more effective. Many agreed that understanding the difference between consumptive and non-consumptive water use is key to making good decisions. Some were hopeful about trends showing less water use over time, but others felt new risks, like climate change and growing populations, mean the US can’t be complacent.

---

## Crimes with Python's Pattern Matching (2022)

- 原文链接: [Crimes with Python's Pattern Matching (2022)](https://www.hillelwayne.com/post/python-abc/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44977189)

This article looks at some strange things you can do in Python using pattern matching and Abstract Base Classes (ABCs). The author shows how Python’s new pattern matching uses isinstance checks, and how you can “trick” it with special ABCs and the __subclasshook__ method.

First, the article explains that __subclasshook__ lets you decide if a class is a “subclass” of your ABC, even if it doesn’t inherit from it. For example, you can make an ABC that matches all classes with palindromic names. When Python 3.10 added pattern matching, ABCs with custom subclass hooks could now control how matching works. The author demonstrates making a NotIterable ABC, so pattern matching can check if something is not iterable. Python does not block this, so you can do some odd things.

He goes further and shows how to match objects with certain attributes, like any object with a distance property. By using ABCs and the subclasshook, you can pattern match on features or fields, not just on type. The article also explores making combinators like Not and And using functions that build new ABCs at runtime, letting you create complex match rules.

The author tries to make stateful or one-time matches with ABCs, but Python caches subclasshook results, so this does not always work as expected. Still, some effects, like flipping behavior or asking the user for each match, are possible. At the end, the author warns not to use these tricks in real code, since they are confusing and unexpected.

In the comments, many readers say these tricks are clever but dangerous. Some think using __subclasshook__ this way breaks the idea of pattern matching and can make code much harder to read. Others point out that Python’s dynamic typing already has many foot-guns, and this just adds more. Some people are surprised that pattern matching relies so heavily on isinstance, which can be changed like this.

A few commenters wonder if there are safe ways to use these ideas, maybe for testing or special libraries. Others share that similar “hacks” exist in other languages, showing this is not just a Python problem. One person notes that overusing magic methods like __subclasshook__ can make it hard for new people to learn the codebase. Another person jokes that these tricks are fun to know, but “please never in code you want to maintain.”

Some users discuss if Python should block these patterns or at least warn when ABCs are used in pattern matching. There are also a couple of comments admiring the creativity and saying these “crimes” are entertaining, even if they are not practical. A few suggest the real lesson is to understand how pattern matching works under the hood so you don’t get surprised by strange bugs. Overall, most agree this is a neat exploration, but not something for production code.

---

## AI tooling must be disclosed for contributions

- 原文链接: [AI tooling must be disclosed for contributions](https://github.com/ghostty-org/ghostty/pull/8289)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44976568)

This article is about a new rule for the Ghostty open-source project: if you use AI tools to help write code, you must say so when you make a contribution. The main reason for this rule is that AI-generated code is not always as good as code written and checked by experienced people. The project maintainer explains that some people use AI tools without enough skill, so the code they submit often has mistakes or is not very good. If maintainers know AI was used, they can better judge how closely to check the code. The maintainer also says it is not fair to make reviewers spend a lot of time helping if it turns out the real author is just an AI tool. He is not against AI and uses it himself, but wants people to be honest and respectful. The pull request makes clear that none of its own content was written by AI. Some people suggest adding a checklist or template for pull requests to remind everyone to disclose AI use. This could also help track other things, like who really wrote the code. Another idea is for GitHub to make a standard way for AI tools to show they helped, maybe by adding their name to the commit message or another file. This would help maintainers and also give credit to the tools. Many people agree with the new rule, saying it is common sense and helps keep code quality high. Some commenters point out that even if AI helps, the human contributor must review and understand the code before sharing it. There is a question about small AI help, like tab completions, but the new rule’s documentation covers that too. A few users wonder if these requirements will spread to more projects. Some people joke about stopping “sloppy” code from AI. Most reactions are positive, with lots of thumbs up and heart emojis, but a few people do not like the rule. Overall, the discussion shows that many developers want more honesty about AI use, but there are different ideas on how best to do it.

---

## Building AI products in the probabilistic era

- 原文链接: [Building AI products in the probabilistic era](https://giansegato.com/essays/probabilistic-era)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44976468)

This article talks about how building AI products is now very different because AI does not work in a predictable way like old software. Before, when you made a digital product, you knew what would happen for each user action. For example, if you clicked a button, you got a set result every time. Teams could measure and control all the steps, and business success was about moving users through clear steps, or funnels.

With new AI models like ChatGPT, everything changes. The AI can take any kind of input, even things you never thought about, and give many possible answers. The same question might get different answers each time. The outputs are not always correct, and sometimes the AI just guesses or makes things up. There can be many ways to get to a result, and sometimes there is no perfect answer at all.

This makes it much harder to plan, test, and measure AI products. You cannot know all the things people will try with your product. You cannot be sure the AI will always work as you expect. The cost to run these models is also much higher than old software, but the results are not always reliable. This means old ways of building, testing, and growing products do not work well anymore.

Instead of acting like engineers, the article says teams should act more like scientists. You need to keep testing, watching real users, and learning from data. Every time a new AI model comes out, you might need to change your whole product, because the model will act in new and surprising ways. You cannot just add a few tests and hope things are fine. You have to use data to see what users are really doing, and what results they are getting.

Data is now very important, not just for training AI, but for seeing how people use your product after it launches. Teams need to track how users move through all the possible paths, not just clear funnels. This helps find out what works, what does not, and what new problems or costs might appear. All teams in a company need to work together, using the same data to understand users and make decisions.

In the Hacker News comments, some people agree that AI is a big change, and old playbooks do not fit anymore. They share stories about how hard it is to know what users will do with AI, and how outputs can surprise both builders and users. Some worry that not being able to explain or predict the AI is dangerous, and could lead to problems for businesses and users.

Others say that while the new AI is powerful, we have seen hype before. They think some old ways of building and testing are still useful, and that not everything has changed. A few point out that users really do not like it when AI acts randomly or makes mistakes, and that this could hurt trust in AI products. Some developers feel frustrated that the move from engineering to “science” means less control and more guesswork.

Finally, some commenters are hopeful. They like that AI opens new doors for products and creativity, and believe that companies who learn how to manage the uncertainty will be the winners. They say it is an exciting time, but agree it is also hard, and that everyone is still learning how to build in this new, probabilistic world.

---

## DeepSeek-v3.1 Release

- 原文链接: [DeepSeek-v3.1 Release](https://api-docs.deepseek.com/news/news250821)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44976764)

DeepSeek has released a new AI model called DeepSeek-V3.1, which aims to be better at acting as an agent and solving tasks. The update introduces a “hybrid inference” mode, letting users pick between “Think” and “Non-Think” modes for different needs. The “Think” mode is faster than before and better at handling multi-step tasks, while post-training has improved the model’s use of tools.

You can try out both modes using a button on their website. There are now two main API endpoints: one for fast, simple tasks and one for deeper reasoning. Both support longer input (up to 128,000 tokens), and the API now works with the Anthropic format and has stricter function-calling options in beta. The model also performs better on programming and terminal benchmarks, and is more efficient at reasoning through complex searches.

The V3.1 model has been further trained with 840 billion tokens to understand longer contexts. The tokenizer and chat template have also been updated, and both the base model and full weights are open source on Hugging Face. Pricing is changing soon—current discounts will end on September 5, 2025.

In the comments, some users are excited about the fast improvements and open-source release of the model weights. Others ask about real performance compared to other AI models, with a few people sharing benchmarks or their own tests. Some worry about the pricing changes, hoping it stays affordable for indie developers. Several users praise the long context window, saying it could help with big projects or documents. A few raise questions about the difference between “Think” and “Non-Think” modes and how to use them best. There are also suggestions for better documentation and more examples for the API. Some are curious about the strict function-calling feature and how it might help in building safer apps. Finally, a few comment on the model’s open approach, comparing it to more closed AI providers, and hope this continues in the future.

---

## An interactive guide to SVG paths

- 原文链接: [An interactive guide to SVG paths](https://www.joshwcomeau.com/svg/interactive-guide-to-paths/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44941605)

This article explains how to use SVG path elements, which are ways to draw lines and curves in SVG images. SVG paths can be hard to understand at first, but they let you draw many different shapes, including curves and arcs.

The article starts by showing how the SVG `<path>` element works like a pen in drawing software. You use commands like `M` to move the pen and `L` to draw lines. The path uses the end point from the last command as the starting point for the next one. This is different from what many people expect.

Next, it covers Bézier curves, both quadratic (`Q`) with one control point and cubic (`C`) with two. Bézier curves let you make smooth, flowing lines. The article explains the difference between the two curve types: cubic curves are better for more complex or precise shapes.

Then, it explains the arc command (`A`), which lets you draw parts of an ellipse between two points. This command has several parameters: the horizontal and vertical radius (`rx`, `ry`), rotation, large-arc-flag, sweep-flag, and the end point. The large-arc-flag decides if you want the longer or shorter arc, and the sweep-flag chooses between clockwise or counter-clockwise direction. The rotation parameter tilts the ellipse, but the author says it’s rarely needed.

The article also explains some extra features. You can close a shape with `Z`, use lowercase commands for relative movements, and chain curves smoothly with `T` and `S` commands. There are many code examples and interactive diagrams to help you see how each command works. The author also mentions a paid course about SVG animations.

In the Hacker News comments, many readers say this guide is very clear and helpful, especially for people who have trouble understanding SVG paths. Some say the interactive examples make it much easier to learn. Others share their own struggles with SVG path syntax and agree that the arc command is the hardest to understand. A few people mention using vector drawing programs to make paths, then copying the code, but some like to hand-write paths for more control.

Several users discuss tools and libraries that help with SVG paths, like Inkscape or online path editors. Some warn that browser support for complex SVG features can be tricky, especially for animations. Others say that after reading the article, they finally understand how arc parameters work. A few comment that understanding SVG paths is useful for making icons, data charts, or animations. One person suggests that the article could help even experienced developers who want a refresher. A few wish there were more details about animating paths or using them in web apps. Overall, readers think the article is a great resource for learning SVG paths.

---

## A Decoder Ring for AI Job Titles

- 原文链接: [A Decoder Ring for AI Job Titles](https://www.dbreunig.com/2025/08/21/a-guide-to-ai-titles.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44976929)

This article explains how AI job titles are confusing and always changing, making it hard to know what people really do. The writer tries to make sense of these titles by breaking them into parts: modifiers (like “Applied” or “Forward Deployed”), domains (like “AI,” “ML,” or “Gen AI”), and roles (like “Engineer,” “Researcher,” or “Architect”). 

“Forward Deployed” means working closely with customers, helping them use AI in their own companies. “Applied” means using AI to solve real-world problems but not building the core AI models. The domain words tell you the kind of AI work: “AI” is a general term, “ML” is about training models for tasks like recommendations, and “Gen AI” is for jobs using text, image, or video generation models. The role or suffix, such as “Engineer,” “Researcher,” or “Scientist,” describes the type of work—building things, researching, or advising.

The article gives job title examples. An “AI Researcher” tests new ideas and helps grow AI knowledge, often by doing experiments and sharing results. An “Applied AI Engineer” builds products using existing AI models, not making new models. An “Applied AI Solution Architect” helps customers plan and design how to use AI in their systems. An “AI Forward Deployed Engineer” creates AI-powered solutions for clients and works closely with them to get things running. The plain “AI Engineer” title is broad, sometimes covering everything from building apps to working on the basic AI systems.

The article also talks about how the word “Researcher” is used in different ways. Sometimes it means real research, but other times it just means working on products with business goals. “Scientist” is often used instead of “Researcher,” and they seem to mean the same thing. The “Gen AI” term became popular after ChatGPT, but now it is less clear because large language models do many types of tasks.

In the comments, some readers say the problem with AI job titles is the same in other fields, like software or data science—titles are often vague and change fast. Others think companies use fancy titles to attract talent or to make jobs sound more important. Some commenters say the “Applied” and “Forward Deployed” modifiers are helpful, but many agree that there’s still a lot of overlap and confusion. A few people point out that “Researcher” and “Scientist” can mean very different things from company to company, so job seekers need to look closely at the job description, not just the title. One reader jokes about how in a few years there will be even more confusing titles as AI keeps growing. Some people wish companies would use simpler, clearer names so everyone knows what the job really involves. Others enjoy the creativity in naming but agree that it makes hiring and job searching harder. A few mention that startups often give big titles for small roles, while big tech companies do the opposite. Overall, people like the cheat sheet but say the real answer is to read the job ad carefully—titles alone don’t tell the whole story.

---

## Text.ai (YC X25) Is Hiring Founding Full-Stack Engineer

- 原文链接: [Text.ai (YC X25) Is Hiring Founding Full-Stack Engineer](https://www.ycombinator.com/companies/text-ai/jobs/OJBr0v2-founding-full-stack-engineer)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44978073)

Text.ai is a new startup backed by Y Combinator, looking for a founding full-stack engineer to help build their AI-powered group chat app. The company wants to change how groups talk and work together by using AI not just to answer questions but to understand and help everyone in a group.

The main goal is to make group chats smarter and less chaotic. Text.ai’s AI will stay in the conversation, learn about the group, and help make decisions—like planning trips or picking restaurants—so everyone is happy. The company says this is different from other AI tools that only respond to one person at a time. Their vision is for AI to be a helpful presence in group chats, making things smooth and easy for lots of people at once.

They’re hiring someone who knows how to make mobile apps with React Native and can also handle backend work in Python. This engineer will build the app from scratch, create new ways for people to interact with AI, and help the company grow its technical team and culture. The job is hands-on and fast-paced; they want someone who ships high-quality work quickly and likes working in a startup with lots of change.

Text.ai claims their product already shows strong early growth, with high engagement and millions of messages sent. The company offers competitive pay, equity, and other benefits. They stress that this is not a typical big company job; it’s for someone who wants to invent new things and make a big impact.

In the Hacker News comments, some users are excited about the idea of AI making group chats easier, saying it could save time and reduce confusion. Others wonder if people really want AI in their personal conversations, raising privacy and trust concerns. A few users question if group decision-making can really be solved by AI, since people often have different needs and feelings. Some point out that making an AI that understands group dynamics is a very hard technical challenge, but also very interesting.

There are also comments about the job itself. Some developers like that the role is hands-on and offers a chance to shape the whole product. Others warn that startup jobs can be risky and stressful, even with good investors. A few people discuss the need for strong product instincts and fast shipping, noting that this can be both exciting and exhausting. Some commenters are curious about how the company will handle things like data privacy and user consent. Others share that they would wait to see if users really want AI in group chats before joining. Overall, the discussion is mixed but interested, with people recognizing both the potential and the challenges.

---

## Miles from the ocean, there's diving beneath the streets of Budapest

- 原文链接: [Miles from the ocean, there's diving beneath the streets of Budapest](https://www.cnn.com/2025/08/18/travel/budapest-diving-molnar-janos-cave)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44942627)

This article talks about scuba diving in a special cave system under the city of Budapest, far from the ocean. The cave, called Molnár János, is filled with warm, clear water and is hidden below the city’s busy streets.

The cave was found many years ago and has been explored by divers ever since. The water inside is heated by natural springs, making it warm even in winter. The cave tunnels are very big in some places, and the walls are white and smooth. Divers need special training and equipment to swim safely here, because cave diving is risky. The water is so clear that divers can see far ahead of them. Budapest is famous for its public baths, and the same warm water fills those baths and the cave. Not many cities in the world have places like this for diving. The cave is still being explored, and new tunnels are sometimes found. Scientists also study the water and rocks to learn about the history of the area. Even though the cave is under the city, most people walking above do not know it is there. The cave is protected to keep the water clean and safe for both people and nature. Some divers travel from other countries just to visit this special place.

In the comment section, many people are surprised that such a big cave system exists under Budapest. Some share stories about other secret places under cities, like tunnels and old bunkers. A few people talk about the dangers and strict rules of cave diving. Others are excited and want to visit the cave themselves. Some wonder if the city is at risk because of so many tunnels below. There are jokes about how city life goes on above, while divers swim below. A few commenters discuss the science, such as how the water stays so clear and warm. Some worry about pollution or safety for the cave system. Others talk about the beauty of the cave and share photos or videos they found. A few locals say they did not know about the cave, even though they live in Budapest. People also discuss how rare it is to have such a diving spot in a city.

---

## Beyond sensor data: Foundation models of behavioral data from wearables

- 原文链接: [Beyond sensor data: Foundation models of behavioral data from wearables](https://arxiv.org/abs/2507.00191)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44973375)

This article looks at how data from wearable devices, like step counts and sleep times, can help predict health better than just using raw sensor data. The authors built a big machine learning model using over 2.5 billion hours of data from 162,000 people. Instead of only looking at small sensor readings (like heart rate every second), they focus on higher-level behaviors, such as how much someone sleeps or moves over days and weeks. They designed new ways for the model to understand this kind of data, organizing it into pieces that make sense for health questions. The model was tested on 57 different health tasks, such as predicting if someone is sleeping or awake, and tracking health changes over time. It did very well, especially on tasks that need a long-term view, like understanding sleep patterns. When they combined the behavior data with raw sensor data, the predictions got even better. The results show that using behavior data gives a clearer picture for health models, and that wearable devices could support more useful health tools in the future.

In the comments, some people are excited about how this could make health care smarter, since wearables are common now. Others worry about privacy, asking who owns this huge amount of personal data and how it is kept safe. A few developers think the model size and data amount are impressive, but wonder if smaller teams could ever build something similar. Some users say that behavior data can be noisy or misleading, for example if a device is worn incorrectly. There are also concerns about bias, as the data comes from people who can afford wearables, which might not represent everyone. One person points out that combining different types of data (behavior and raw sensors) could help catch health problems earlier. Another commenter asks if these models could one day warn users about poor sleep or stress in real time. Finally, some say this research is promising but needs more testing in real-world health systems before it can be trusted fully.

---

