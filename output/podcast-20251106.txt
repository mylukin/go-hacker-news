Hello everyone, this is the 2025-11-06 episode of Hacker News Daily Podcast. Today, we have several important and interesting stories for software developers and tech fans.

First, a huge new data leak has come to light. About 2 billion email addresses and 1.3 billion passwords were added to Have I Been Pwned, the well-known breach-checking service. Most of the data comes from many old breaches and from malware that steals login info. The author checked the data and found many old and new passwords, some still in use, some forgotten, and some that did not belong to the email owner at all. Have I Been Pwned lets you check if your password was leaked, but does not link passwords and emails together, which keeps things safer. Many people thanked the service for this hard work, but the comments also showed how much password reuse is still a problem. Some praised password managers and two-factor authentication, while others worried about privacy or suggested websites should do more to protect users. The key message is: always use strong, unique passwords and check if your info was exposed.

Next, let’s talk about Kimi K2 Thinking, an open-source AI model for step-by-step reasoning, coding, and internet search. This model can do hundreds of actions in a row, planning, searching, thinking, and coding in cycles. It set new records on hard logic and coding benchmarks, like Humanity’s Last Exam and SWE-Bench. The report shows how Kimi K2 works as a “thinking agent,” using many tool calls and long prompts. It is especially strong at programming and web search, sometimes even beating humans. The Hacker News comments praised the technical work, the open-source promise, and the model’s agentic design. Some people raised questions about cost, safety, and if benchmarks are fair. Others want to see more real-world results, but most agree this is an exciting step for smarter software agents.

A big astronomy story is shaking up science this week. A new study says the universe’s expansion is not speeding up anymore—it is now slowing down. This goes against the old idea that “dark energy” is making space grow faster and faster. The problem was found by studying supernovae, which are not as standard as once thought. Supernovae from older stars are brighter, and from younger stars are dimmer, even after corrections. After making new corrections, the data fits a model where dark energy is getting weaker. Other data from the early universe supports this view. If true, this could change our understanding of space and time. The Hacker News discussion had excitement, doubt, and lots of questions about what this means for the future. Some want more data before believing, while others see it as a normal part of science changing when new facts come in.

Next, an article suggests everyone should try building an LLM agent, saying it is easier than it looks and helps you learn about AI. The author shows small Python examples using OpenAI’s API, including adding tools that the agent can use by itself. Many commenters agreed that building your own agent is a good way to learn. Others warn that simple agents are not ready for serious work and can have security or accuracy problems. Some liked the focus on “context engineering,” while others think this is just a trend. Still, most people felt trying it yourself is useful, even if you later decide not to use it.

Moving on, a new website gives book recommendations using machine learning, built by scraping three billion reviews from Goodreads. You enter books you have read, and the model suggests new ones based on real user reviews. Some people praised the effort and the scale of data. Others worried about the legal and ethical side of scraping so much from Goodreads. There were also questions about how well the recommendations work and if the model can help people find less popular books. Overall, users are curious and eager to try the tool, though some found CAPTCHAs on the site annoying.

Swift is now available as a preview on FreeBSD 14.3 and newer. Developers can try the Swift compiler and runtime on x86_64 machines, but there are known problems, like issues with the thread sanitizer, LLDB debugger, and package manager. The team asks for feedback and bug reports, and they hope to add support for more hardware and fix bugs soon. Hacker News users are happy to see more language support on FreeBSD, but agree this is just the first step. Some hope Apple will support this effort, while others think it will stay community-driven.

Hightouch, a company making AI tools for marketing, is hiring a software engineer focused on AI and large language models. The company works with modern data tools and counts big names like Domino’s and Spotify as customers. They want creative, product-minded people who are strong in backend work. The salary is high and the job is remote. The hiring process skips traditional coding interviews and focuses on system design and real problem solving. Some commenters liked this approach, while others wondered if skipping coding interviews is a good idea. Many agreed that understanding customer needs is just as important as technical skill.

The International Criminal Court is moving from Microsoft 365 to Open Desk, an open-source office suite from Europe. This is because of worries about digital independence after political problems led to Microsoft blocking a top ICC user’s email. Open Desk was built for the German government and is part of a bigger push for Europe to control its own software. While some commenters think this is smart, others are unsure if open source tools can fully replace big US products. Many agree that having control over key software is important, even if switching is hard.

A new research paper looks at how large language models understand the difficulty of problems like math or coding. The authors found that LLMs have a sense of human-rated difficulty inside their layers, and bigger models show this more clearly. When models are told to treat problems as “easy,” they make fewer mistakes. There is debate about how useful this is, and if models are just copying human errors. Some commenters hope this will make LLMs better for tutoring or auto-grading, while others warn about overfitting to benchmarks.

Next, OpenPCC is an open-source project for private AI inference, inspired by Apple’s Private Compute Cloud. It lets users run AI models while keeping their prompts and outputs private, using encrypted streaming, hardware attestation, and unlinkable requests. The project is open and governed by the community. Some users are excited to see a true open-source privacy effort, while others wonder how strong the privacy claims are and how easy it will be to run in real life. There are also questions about performance and how it compares to other privacy tech.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. We hope these stories help you stay updated and inspired. See you next time!