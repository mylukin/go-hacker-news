Hello everyone, this is the 2025-06-25 episode of Hacker News Daily Podcast. Today, we bring you seven stories from the world of tech, software, science, and community.

First, QEMU, the popular open source emulator, just announced a strict new rule: they will not accept any code made by AI code generators like ChatGPT, Copilot, Claude, or Llama. The QEMU team says the law around AI-generated code and software licenses is still unclear, because these AI models get trained on code with many different licenses and rules. QEMU wants to be sure every line in its codebase has a clear legal status, so it can keep using open source licenses safely. If someone sends code made by AI, the team cannot be sure about the license or if it copies code from somewhere else. This is a risk, so for now, the rule is: no AI-generated code, unless there is a special exception and the contributor can prove the code’s legal status. The team says the rule might change in the future if the law gets clearer or the tools improve.

In the comments, people have mixed feelings. Some think it’s smart to be careful, because open source projects need clear legal rights. Others feel the rule may be too strict and could slow down new ideas or make it harder to use AI for simple tasks, like writing tests or setting up automation. A few users wonder if the real reason is not just legal, but also because AI code can be low quality and waste time in code review. There are comments that say humans can also write bad code, so banning AI alone won’t stop low-quality submissions. Some think this rule will help keep code safe and make sure people really own their work, not just copy-paste from AI. Others point out that the QEMU team left the door open for exceptions and might relax the rule later. There’s talk about how hard it is to tell if code is written by AI, and about the risk of projects getting flooded with low-effort AI-generated code. Some share stories about using AI for coding and not getting good results, saying current tools are not ready for big, complex projects like QEMU. Finally, a few users say this is just a smart move to protect the project for now, while the legal and technical problems are not solved.

Next, a group of mathematicians has built a new kind of pyramid-shaped object—a tetrahedron—that always lands on the same face, thanks to a special weight inside. This solves a math problem first asked over 50 years ago: can you make a pyramid with flat sides that only sits on one side? For a regular tetrahedron with even weight, it’s impossible, but by moving the weight around inside the shape, they made it work. It sounds simple, like roly-poly toys, but it’s very hard with sharp-edged shapes. Using computers, the team found a shape and weight setup that worked in theory. Building it in real life was tough: they used very light carbon fiber and a tiny, heavy piece of tungsten carbide. Even a bit too much glue could ruin the balance. After months of careful work, they got it right—the pyramid always flips to one face. This shows that building things is important in math, not just solving equations, and the method could help design self-righting robots or spacecraft.

Hacker News comments range from jokes about using this as a weird dice, to questions about why not just use a ball with a heavy side. Some are disappointed it can’t be made with one material, and others discuss if you could make a shape that lands on exactly two faces for tamper detection. People dive into the math, explaining why a regular tetrahedron can’t do this trick. There’s talk about how this took a long time to make, needing better materials and computers. Some dream of buying one of these “magic pyramids” as a fun toy at a game convention.

Our third story is from Apple’s early days. Managers once asked programmers to report how many lines of code they wrote each week. Bill Atkinson, a key engineer, thought this was a bad idea. He believed good code should be small and efficient, not big and bloated. After making Quickdraw’s region calculations much faster by removing about 2,000 lines of code, he reported “-2000” lines written for the week. After a few weeks, managers stopped asking him to fill out the forms.

Many readers agree with Atkinson’s point: less code can be better. Some share their own stories, like removing many thousands of lines and making code faster or easier to fix. Others say counting lines can make things worse, hiding bugs and encouraging useless changes just to boost numbers. Some remember how management sometimes rewards fixing bugs or writing more code, leading to silly results. Others say not all managers are fooled by big numbers, but using lines of code as a metric is still common and not helpful.

There’s also discussion about new tools like AI code assistants. Some worry these tools create lots of extra code, which later needs to be cleaned up. Others say it’s easy to accept bad code if it works, even if it’s not efficient. Some argue that the story might be a little exaggerated, but since Atkinson was so important at Apple, it’s believable he could ignore silly rules. People also debate whether software quality will get better or worse in the AI era, and whether small, careful code will still matter when it’s so easy to generate lots of code. Most agree that good code is about quality, not quantity.

The next article looks at Hims, a telehealth company that sells treatments for weight loss, hair loss, and sexual health online. The writer says Hims uses legal loopholes to sell drugs in ways that may not be safe or honest, and uses clever marketing to look helpful and modern.

Hims claims to make healthcare easier and cheaper, but often just sells old, generic drugs at much higher prices. For example, they combine drugs like sildenafil and tadalafil into new pills, even though doctors say this is unsafe. They also sell “compounded” versions of expensive weight loss drugs by mixing in vitamins or changing doses, saying this makes them “personalized.” Really, these tricks help them get around drug patents and sell cheaper, copycat versions, sometimes from untested foreign suppliers. Hims had a big marketing campaign against high prices, but then quickly partnered with a big drug company, only to be dropped when Hims kept selling knockoff versions.

Hims uses subscription models that lock people in and make it hard to cancel, with many complaints about surprise charges and poor service. People pay Hims much more than regular pharmacies, mostly to avoid seeing a doctor and for the “convenience” of online shopping. The company’s fast, automatic prescription process is more about making money than giving good care. The author compares Hims to other companies that use loopholes to sell unapproved drugs, saying the system tricks both the law and the customer.

In the comments, some agree Hims is risky, especially selling unapproved or poorly tested drugs from China, and worry about safety and lack of real medical checks. Others are confused by the article’s style, saying some jokes are hard to follow. A few point out that the real problem is the law lets companies like Hims operate this way. Some wonder why these actions are legal at all, and say the system seems broken if companies can profit from people’s desperation. There is talk about how online healthcare can help people who avoid doctors out of shame, but most agree that honest care and real safety checks are important. Overall, readers see this as a warning about what can happen when tech companies move fast in health without enough rules or care for people’s health.

Our fifth story is a letter from Richard Feynman to a student who felt his research was not important enough. Feynman says the best problems to solve are the ones you can actually work on and make progress with, no matter how simple they seem.

He warns against only chasing big, “grand” problems, as that can make you feel lost or sad. Feynman gives examples from his own life—he worked on small problems, like why friction works, how to make metal stick to plastic radio knobs, and even how to fold paper into flexagons. Some were not world-changing, but they gave him joy and helped others. He says helping answer even a small question is worthwhile, and people should not feel nameless or unimportant—your family, friends, and coworkers value what you do, even if it seems simple. He admits he made a mistake by giving his student a problem instead of letting him pick his own, and hopes the student will find happiness by working on things he can solve.

In the comments, many people found the letter beautiful and wise. Some said Feynman’s writing helps them see that simple things matter, and he had a gift for making hard ideas easy to understand. Others liked his advice about feeling good when you solve any problem, even a small one. Some shared how this message helped them feel better about their own work, like answering colleagues’ questions or supporting family. Some said it’s okay to just be “good enough” and that small, steady work is as important as big, flashy projects. Others pointed out that even “humble” problems can turn out to be important later.

A few comments were more critical, saying Feynman could be arrogant, but most focused on his kindness and honesty. Some talked about how today’s tech world often pushes people to chase big ideas that may not be their own. Others talked about the pressure to find purpose, and if it’s okay to change your mind about what matters. Some shared personal stories about how this letter helped them during hard times or at work. One person suggested making a flexagon, showing even small, fun problems can be meaningful. Overall, most readers felt inspired, seeing value in solving any problem you care about, no matter how small.

Our next story is about The Offline Club, a group that helps people take breaks from screens and spend time together in real life. The club offers events like phone-free dinners, relaxed hangouts, and digital detox retreats in cities across Europe. The goal is to help people relax, meet others, and enjoy hobbies without using phones or computers. People can join events in cities like Amsterdam, London, and Paris. If there isn’t an event nearby, you can join a waitlist or start your own chapter. The club also has a newsletter with tips for living more offline. Customers say the events are friendly and cozy, and reviews are very positive. The club believes spending time offline can help people feel more connected and relaxed.

On Hacker News, some people say this is like Meetup, but focused on being offline together. They talk about common problems, like finding places to meet, making sure people show up, and keeping organizers interested. Some share tips from running their own groups, like talking to coffee shop owners or sending personal messages to encourage people to come. Some warn that events can sometimes be used for sales or pyramid schemes, so it’s important to keep things honest and friendly.

Others discuss how many social events moved online during COVID and never returned to in-person, which they miss. Some say local game stores or dance events are good places to meet people offline, but admit these aren’t for everyone. One person thinks paying for a welcoming, non-competitive event is helpful for shy people. People note that making new friends as adults is hard, and having scheduled events helps overcome the first barriers. But a few feel that planned meetups can become too formal, making it harder to build real friendships. Some miss the old days of just dropping by a friend’s house, but say this isn’t possible now—lives are busier and people need to plan ahead. Many agree that regular, friendly offline events are a good step for people wanting more real-world connection.

Our next story is about saving money on OpenAI audio transcriptions. OpenAI charges money for audio transcriptions by the minute. The article explains a simple trick: speed up your audio before sending it to OpenAI, so you pay less and get results faster.

The writer shows how to use tools like ffmpeg to make audio play 2 or 3 times faster, turning a 40-minute talk into 20 or 13 minutes. The quality of the transcription stays good at 2x or 3x speed, but gets worse at 4x. The cost drops by about a third at 3x speed. The main cost is not just audio minutes, but also the number of tokens in the results. The process is like compressing images or text—humans and AI can understand even if some details are lost. The article ends with simple advice: speed up your audio to save money, but don’t overdo it.

In the comments, many share tips to make this trick better, like removing silence from the audio before uploading. Some talk about Andrej Karpathy’s fast speaking style and wonder if you can adjust the trick for each speaker. Some point out that listening at high speed works better with good audio quality. There are debates about whether to read summaries or listen slowly for deeper ideas. Some mention you can run transcription models like Whisper on your own computer for free, but that can be slow. Others talk about using cheaper services like Groq or Deepgram. Some praise the article’s clear summary, while others worry about privacy when sending audio to OpenAI. Finally, there is talk about using YouTube’s transcript tools or browser extensions to speed up playback, and debate about whether shortcuts make us less thoughtful or just give more choices.

Our last story is about libxml2, a popular open-source XML parsing library used by many big companies. The main maintainer, Nick Wellnhofer, recently said he will no longer keep security bugs secret before fixing them, because he is an unpaid volunteer and can’t keep up with all the demands.

Libxml2 has a long history, starting in the GNOME project and now used everywhere. Funding for the project has been very low, with only one big donation from Google. Wellnhofer has spent a lot of time fixing bugs, many reported by security researchers seeking credit or CVEs, but gets little help in return. He has decided to treat security bugs like normal bugs—publicly report and fix them when he has time, instead of following strict rules to keep problems secret until a patch is ready. He also stepped down from maintaining another project, libxslt, saying the pressure from unpaid work is too high.

Wellnhofer argues that big companies use libxml2 but rarely give back, either with money or code. He thinks secrecy around security is just a way for companies to push work onto volunteers. Some people worry that making security bugs public right away could put users at risk, but Wellnhofer says the real problem is companies not supporting the software they rely on. Other open-source contributors have similar feelings, saying companies benefit from free software but don’t help maintain it. There are suggestions to write clear “maintenance terms” so everyone knows what to expect.

In the comments, many users discuss if bugs like denial-of-service should really be called “security bugs.” Some say DoS is not the same as stealing data, but others point out that service outages can hurt important systems. Some developers feel that reporting every crash as a security bug makes it hard to find real issues. Others say context matters—a small problem for one app could be a big risk for another. There’s debate about whether companies should do more to support open-source projects they use. Some say strict licenses like GPL could force companies to help, but others say even with open licenses, companies don’t always contribute. Many agree unpaid maintainers shouldn’t be pressured to fix every bug for free. Some say companies should handle their own security fixes if they care so much. People talk about the emotional side—maintainers often feel responsible, but it’s not fair for all the work to fall on one person. Some compare this to other projects, like OpenSSL, which only got more support after public problems. Some think the solution is for governments or big companies to pay for core software, while others say maintainers should just set clear limits. Most agree the current way is not working well for volunteers or open-source.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. We hope these stories gave you new ideas and things to think about. See you next time.