Hello everyone, this is the 2025-06-28 episode of Hacker News Daily Podcast. Today, we have a wide range of stories—from trademark battles in the software world, to new protocols for AI tools, to deep dives into computer science, music, and even ham radio. Let’s get started.

Our first story is about a legal fight over the “JavaScript” trademark, which is owned by Oracle. The creator of Node.js is upset because Oracle used a screenshot of the Node.js website as evidence, even though Node.js was never an Oracle product. The fraud claim against Oracle was dismissed, but the main question now is whether “JavaScript” is a generic term and if Oracle has given up their rights to it. The author points out that everyone uses “JavaScript” to mean the language, not any Oracle product, and there is huge support for making the name free for everyone. The next steps are for Oracle to answer every point in the case, then both sides will collect more evidence. The goal is to make “JavaScript” a public name so developers do not have to worry about legal issues when using it.

In the comments, many people wonder why Oracle wants to keep the trademark when it does not make them money. Some say Oracle should give up the name to win goodwill from developers, while others think Oracle is just acting like any big company—holding on to anything valuable, even if it does not help them. A few people remember that Sun Microsystems, before Oracle, also used legal tricks to protect their products, so this is not new. There are debates about whether Oracle’s reputation is really hurt by this, since their stock is doing well.

Some comments talk about trademark law, saying maybe “JavaScript” has become a generic word, like “Kleenex” for tissues. Others say the law is not clear, and winning such cases is hard. Some people did not even know JavaScript was a trademark, and find it strange that Oracle owns it. There are also side discussions about Oracle’s impact on open source, with mixed opinions. Some think Oracle helps open source, while others think they just buy and control projects. A few people suggest renaming JavaScript, but most agree the name is too important and widely used to change now. Finally, some think Oracle will never give up the trademark, while others hope this legal challenge will set the name free.

Our next story is about MCP, a protocol made for connecting AI models to tools and data, but which can also be a universal plugin system for many things. The article compares MCP to USB-C and car cigarette lighters—simple ports that allow you to connect anything, leading to unexpected uses. Even if you remove the AI, MCP lets any app connect to any tool or service easily. For example, if someone makes an MCP server for Spotify, any app could use it to play music without knowing Spotify’s code. The article gives fun examples, like a toaster with HDMI output, to show how open protocols lead to creative uses.

MCP is a protocol where every server lists what it can do, and any client can discover and use those functions. This “accidental” universality means that every MCP server made for one use can be used by many others, allowing for endless combinations and mashups. The article compares this to past protocols like HTTP and Bluetooth, which started small but now power much of the world. The author’s team is building an app called APM where all plugins are MCP servers, making it very flexible. The article ends by saying that every protocol ends up being used in ways its creators never planned, and maybe that is what makes them great.

In the comments, many agree that MCP makes interoperability popular again. Some say it is easy to connect tools now, but others are skeptical about how long this will last. Some think MCP is not really new—APIs, Unix pipes, and other plugin systems have done similar things. They say the only new thing is that MCP requires listing all available functions in a simple way, making it easy for AIs or people to use tools without special setup. Others worry that companies will soon lock down their APIs again, limiting the open ecosystem.

There are also technical details: MCP requires every server to have a “list-tools” endpoint, which is not always true for REST APIs or gRPC. People like that MCP includes both human-readable descriptions and JSON schemas for every function. Some say this informality makes MCP less reliable for strict machine-to-machine uses. There is debate about whether MCP is really different from REST, gRPC, or older systems like COM and SOAP, or if it is just better marketing. Some are excited that MCP can make apps more scriptable and open, while others are cautious, remembering past tech hype that ended with closed systems. Still, many developers are trying MCP and hope the attention will help solve problems quickly.

On a different note, this weekend was ARRL Field Day, a big event where ham radio operators in the US and Canada set up radios outdoors and try to talk to as many people as they can. Field Day mixes fun, learning, emergency practice, and a bit of friendly competition, drawing more than 31,000 people each year.

Clubs and individuals set up temporary stations in parks and public places. The goal is to make contacts using different bands and modes, often in tough conditions, to show how radio can help in emergencies. It is also a chance to show new people what ham radio is about, with many clubs inviting visitors. There are no prizes, but results are published and some people try for the best scores. Bonus points can be earned by making a contact through a satellite. Many clubs use this time to test skills, meet others, and have fun outdoors—sometimes even camping and cooking together.

In the comments, people share memories like helping a club reach top scores with satellite equipment, or enjoying late-night radio and group meals. Others find Field Day too busy or stressful, saying the airwaves get crowded and it is hard to have a friendly chat. Some with small radios avoid Field Day because big stations fill the air. Some dislike the contest-like rush and prefer more relaxed events. There are comments about clubs not being welcoming, making newcomers feel left out. Still, many say the event is great for learning, teamwork, and doing things you can’t do any other time. Even with mixed feelings, most agree Field Day is a special tradition for ham radio fans.

Now, let’s talk about vLLM, an open-source tool for running large language models quickly and at scale. The article explains what happens when you send a prompt to a vLLM server for AI text.

First, your prompt goes to an API server, which checks it and passes it to AsyncLLM. AsyncLLM changes your text into tokens and sends it to EngineCore, the heart of vLLM. EngineCore decides how to group requests (batching) and manages which tokens go where. The Scheduler inside EngineCore keeps track of all the requests and tries to use the GPU as much as possible by grouping tokens smartly.

vLLM uses a “continuous batching” system, meaning it can handle many requests together, filling up the GPU for better speed. There are two main steps: the prefill phase, where it processes all your input tokens at once, and the decode phase, where it generates new tokens one by one. Special memory blocks on the GPU, called KV caches, help the system remember important information for each request.

When it is time to run the model, vLLM groups all tokens from the batch into big tensors and sends them through all the model layers on the GPU. The model computes the next token for each request, and the results go back through AsyncLLM, are changed back into text, and streamed to you.

This process lets vLLM handle many users at once, making it good for big AI services. Each part of the system has a special job, and together they make serving LLMs much more efficient.

In the comments, the author says writing the article helped them understand vLLM better and is open to questions. One reader thanks the author but is confused about the prefill phase and why it is faster than generating new tokens. They ask if watching a long video on transformers would help. The author is friendly and encourages more discussion. Some readers find vLLM’s batching logic tricky, especially the prefill phase. There is interest in learning more about the technical side, but also a wish for clearer explanations. The comments are welcoming, and the author is ready to help readers learn more.

Next, we have a story about a student project where a group built their own CPU, created a C compiler, and got the Unix-like system Xv6 running on it. This was part of a course at the University of Tokyo, where students build everything from scratch, including CPU hardware on an FPGA and software tools.

The team first designed a CPU with a custom instruction set. They wrote the logic in a hardware description language and turned it into a chip using synthesis tools, which could take a long time. Instead of using GCC, they built their own C89 compiler, called Ucc, since one member already had a prototype.

Porting Xv6 to their CPU was hard. Xv6 is made for x86 and expects certain data sizes and stack behavior. The group had to figure out which CPU features were needed for an OS, like interrupts and virtual memory. They learned a lot by first porting Xv6 to MIPS, which helped them understand low-level OS needs.

As they worked, they improved their CPU and simulator, adding debugging and virtual memory. A major bug came from using virtual addresses for cache indexing, which caused problems when two addresses pointed to the same memory. They fixed this with "page coloring." After much debugging, and changing the compiler to match standard data sizes, they finally got Xv6 running on both the simulator and real hardware. They added games like Minesweeper and 2048, and even new system calls for better input.

The project ended with the team running a ray-tracing program on Xv6, on their own CPU. They shared their work online, and later groups kept improving it, running their own OS or even Linux on custom CPUs.

In the comments, many share similar stories. One person talked about porting MINIX3 to the Raspberry Pi, which was hard due to poor emulation and documentation. Others agreed that hardware work is tough, especially without good tools. Some remembered building simple CPUs but not running an OS and compiler. They recommended games and courses like Turing Complete or nand2tetris for learning about CPU and OS building. People pointed out that when you build everything from scratch, every bug is your own, and debugging is much harder. Still, most say these projects are fun and teach a lot, even if they are very challenging.

Our next story is about new discoveries in the Busy Beaver function, especially BB(6), which is the maximum steps a 6-state Turing machine can take before stopping. People thought BB(6) was already huge, but new results show it is much bigger—so big that even trying to imagine it is almost impossible.

The Busy Beaver function, BB(n), grows faster than any normal math function. For 5 states, BB(5) is about 47 million. For 6 states, the new lower bound is a number like 2 pentated to 5, or 2 tetrated to 2 tetrated to 2 tetrated to 9. These numbers are so big that you could never write them out, not even in all possible universes. The article explains how these numbers are found: by building clever Turing machines that use things like Collatz-like steps or exponentiation in their loops. Each new result comes from finding a machine that runs even longer before stopping. Some now think BB(7) could be even bigger, maybe bigger than Graham’s number.

The author also talks about the limits of math. At some point, the value of BB(n) becomes independent of normal set theory axioms (ZFC). That means math cannot prove what BB(n) is for some large n, even though there is a right answer. For BB(643), no proof inside ZFC can say exactly what number it is. Because of these new huge numbers for BB(6), people wonder if this limit happens much earlier.

In the comments, many are amazed at how fast BB(n) grows, and how these numbers go from something humans can imagine to something far beyond. Some debate if BB(7) is bigger than Graham’s number. A few think it probably is, since BB(n) quickly outgrows any number you can define with normal math. Others are surprised that a simple Turing machine with just a few states can lead to questions that math cannot answer. There is talk about how proving BB(n) for large n is not about the number itself, but about what math can show. Some comments explain that BB(n) is always a real number, but for large n, no proof system can say what it is. Others discuss philosophy—what counts as a number, and if these numbers really "exist" or are just ideas. Some say these huge numbers make them rethink what math and computation can do, and how simple rules lead to problems math cannot fully solve.

Now, let’s move to a story about social media. The article talks about how many social media apps start with good ideas but end up making people addicted. The writer tried to build a new social platform to help people connect in real life, but it failed. He realized the problem is not just one app—it’s how all social media is designed and funded. At first, these apps seem nice and focus on real connections. But after getting money from investors, they must grow fast, and growth becomes more important than people’s well-being.

To keep growing, companies use tricks to keep people on the app longer. They show things that create strong emotions, like anger or envy, to keep you scrolling. The more time you spend, the more money they make from ads. This makes people addicted, not by accident, but by design. Even creators with good intentions are pushed by the system to focus on engagement and profit. The article says it is very hard for people to fight this; the problem is too big for things like screen time limits or digital detox.

The writer suggests some solutions: fund social platforms like public services instead of with ads, make algorithms more open, or measure user happiness instead of just user numbers. He thinks maybe the answer is to make social media less important, and help people connect offline more. The real problem is the system that rewards addiction and attention.

In the comments, many people agree that outside investment is a big reason why social platforms change for the worse. Some say that once a company takes investor money, the real “product” is the company, not the users. Others argue that companies are forced to make decisions for investors, even if it’s not best for users. But a few push back, saying there is no law that companies must always put profit first—sometimes it’s just the culture or incentives.

Some think the problem is deeper than just funding. People often do not want to pay for social networks, so ads are the only way to make money. Others say human nature is the real problem—people want exciting, emotional content, so platforms become addictive. Some suggest small, paid, or non-profit networks could work, but building a big community is hard without lots of money. There are calls for more regulation, but others say it’s difficult to regulate something as complex as social media algorithms. Some share ideas for better models, like worker-owned companies or open-source networks, but admit these are hard to scale. Others think we should just spend more time offline and stop building so many social networks. There is debate about whether addiction is the right word, but overall, people want change, even if they do not agree on how to fix the problem.

Our next article is about a tool called “vet” that helps you run remote shell scripts more safely. Many people use commands like `curl ... | bash` to install software, but this can be risky.

Vet tries to make this safer. First, it downloads the script to a safe place instead of running it right away. It checks if the script has changed since you last ran it. Vet also uses ShellCheck to look for mistakes or signs of bad code. Before doing anything, it asks you if you really want to run the script. You can use vet by typing `vet https://example.com/install.sh` in your terminal. To install vet itself, you use a curl command, just like other tools.

In the comments, one person asks for a demo to show how vet works. They want to know if it uses a pager or editor, and how it shows problems found by ShellCheck. Another person says most remote scripts are installers, and asks how you can really know if the software you install is safe, since vet only checks the installer script, not the actual program it downloads. Someone else agrees and says vet is a good step, but not a full solution. Some like the idea. One person thinks it would be cool if vet could use AI to find more problems, but the creator of vet replies that using AI can send your code to outside servers, so vet uses ShellCheck, which runs offline. Another user says they sometimes trust install scripts just because everyone else does, and that vet helps make this safer. Overall, people think vet is useful, but it cannot solve all security problems alone.

Our last story is about music. Some never-heard pieces by French composer Erik Satie will be played for the first time, 100 years after he died. These new works give us a fresh look at Satie, who is best known for simple, dreamy piano music like the Gymnopédies.

The article explains how these pieces were found and why they matter. Satie wrote many strange and playful works. Some, like "Vexations," were meant to be played 840 times in a row, showing his odd sense of humor. Satie often poked fun at music rules and serious composers. His music is used in movies, ads, and games, even if many do not know his name. His style is simple, calm, and easy to remember, which is why his music is still popular. The new pieces are more traditional, but they help us see the bigger picture of his work. Fans say Satie’s tunes are great for relaxing or focusing. Others point out that different recordings can change how his music feels—a slow version might sound very different from a fast one.

In the comments, people talk about Satie’s personality and music. Some wonder if he is more famous for being odd or for his songs; most agree it’s the music that lasts. Many mention that Satie’s music is everywhere, even if people do not know it is his. Some say YouTube helped make him popular again, while others say his music was well-known long before the internet. Some share personal stories—how they first heard Satie in games, movies, or as children. There are also comments about how old music can still feel fresh and important. Some say only a few old pieces become very popular, and Satie is lucky to have several. One person recommends trying different versions of Satie’s music, since every performer adds their own style. There’s a mention of “furniture music,” a term Satie used for background music. Finally, people talk about how learning to play Satie’s music can be both easy and hard, but always rewarding.

That’s all for today. Thank you for listening to the Hacker News Daily Podcast, and see you next time.