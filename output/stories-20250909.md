# Hacker News 故事摘要 - 2025-09-09

## 今日概述

Today’s top Hacker News stories cover a new cancer drug showing promise, a judge stopping a big AI copyright deal, and Anthropic’s AI tool getting file editing skills. There’s news of a new fast e-paper display, an attack on popular software packages, and a new law for safer AI in California. Mistral AI raised a lot of money, and the Go programming language got a new JSON tool. Main themes are health breakthroughs, AI progress and rules, software safety, and new tech for developers.

---

## Immunotherapy drug eliminates aggressive cancers in clinical trial

- 原文链接: [Immunotherapy drug eliminates aggressive cancers in clinical trial](https://www.rockefeller.edu/news/38120-immunotherapy-drug-eliminates-aggressive-cancers-in-clinical-trial/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45188945)

A new immunotherapy drug called 2141-V11 was tested on people with aggressive cancers, and some patients saw their tumors shrink or disappear. This happened after earlier versions of similar drugs worked well in mice but failed in humans due to strong side effects and low success rates.

The drug works by targeting a part of the immune system called the CD40 receptor, which helps immune cells attack cancer. Earlier drugs caused problems because they spread through the whole body and harmed healthy cells, leading to serious side effects. The new version, 2141-V11, was made stronger and more precise, and doctors injected it straight into the tumors instead of using an IV drip. This change helped reduce side effects and made the treatment safer.

In the clinical trial, 12 patients with different kinds of advanced cancers got the new drug. Six of them had smaller tumors after treatment, and two patients had all their cancer disappear—one with melanoma and one with breast cancer. Even though only one tumor was injected, other tumors in the body also shrank or went away, showing that the drug can help the whole immune system fight cancer, not just in one spot.

Doctors found that the treated tumors filled up with new immune cells, replacing the cancer with healthy immune tissue. This effect was also seen in tumors that were not injected, which means the body’s immune system learned to fight the cancer everywhere. The study did not see the serious side effects that stopped earlier drugs.

Now, bigger trials are testing this new drug in more people and with different types of cancer. Researchers want to know why some people respond to the drug and others do not. The two patients who got full remission had a special type of immune cell before treatment, which might be a clue for future tests. Scientists hope to find ways to help more patients benefit from this kind of therapy.

In the comment section, some people are very excited about the results and hope this could be a big step forward in cancer treatment. Others warn that the trial was small, and more data is needed before saying the drug is a real breakthrough. There is talk about how cancer is different in every person, so it’s hard to find one treatment that works for everyone. Some users share personal stories about cancer and the need for better, safer treatments. A few are curious about the cost and how soon this therapy might be available to more patients. Others mention that new drugs often look promising in early trials but sometimes fail in bigger tests. There’s also interest in how this drug could combine with other cancer treatments. Some people ask about the science behind the drug, while a few express hope for loved ones fighting cancer. Overall, the comments show a mix of hope, caution, and questions about the future.

---

## Anthropic judge rejects $1.5B AI copyright settlement

- 原文链接: [Anthropic judge rejects $1.5B AI copyright settlement](https://news.bloomberglaw.com/ip-law/anthropic-judge-blasts-copyright-pact-as-nowhere-close-to-done)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45179304)

A judge has rejected a $1.5 billion copyright settlement between Anthropic, an AI company, and authors. The case is about Anthropic using millions of books to train its AI without permission, and the proposed deal was one of the largest ever for copyright and AI.

The judge, William Alsup, said the settlement is “nowhere close to complete.” He is worried the deal was made by lawyers without enough input from the authors whose work was used. He also said he needs to see more details about how authors will be told about the deal and how they can make a claim for money. The judge is concerned that some class action deals only help lawyers, not the people they are supposed to help. He wants to make sure every real author gets a chance to get paid, and that authors know they can choose to be in or out of the deal. If someone owns part of a book and does not want to join, that book is not covered by the deal.

The judge also does not want extra lawyers to take money from the settlement fund. He told the main lawyers to work out who really owns each book, since some books have many authors or publishers. The lawyers must make a full list of all books covered and submit it soon. The settlement is supposed to pay $3,000 for each book used, and could set an example for other big AI copyright cases. The president of the publishers’ group said the judge does not understand how book publishing works and is making things too hard. But the judge said he needs to be careful, so Anthropic cannot be sued again for the same thing later.

In the Hacker News comments, some people agree with the judge and think class action settlements often only help lawyers, not victims. Others think the judge is right to be careful, because AI copyright cases are new and important. Some worry there will be years of fights between authors and publishers over who owns what. A few say the $3,000 per book seems too low or too high, depending on the author. People talk about how hard it is to find and notify all the right authors. Some say the whole process shows copyright law is not ready for AI. Others wonder if AI companies should just stop using books without clear permission. There are also comments that praise Judge Alsup for asking hard questions and not approving a bad deal too quickly. Some think this case will affect future deals between authors and tech companies. Overall, the comments show people are divided but agree this is an important test for copyright and AI.

---

## Claude can now create and edit files

- 原文链接: [Claude can now create and edit files](https://www.anthropic.com/news/create-files)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45182381)

Claude, the AI from Anthropic, can now make and edit files like Excel spreadsheets, Word documents, PowerPoint slides, and PDFs. This means users can ask Claude to create files from data or ideas, not just answer questions with text.

Claude’s new feature is now available for some users (Max, Team, and Enterprise plans), and will soon come to Pro users. With this, you can give Claude data, and it will make reports with charts, clean up your data, and explain results. You can ask for things like a budget tracker in Excel, a project dashboard, or a financial model, and Claude will build these with correct formulas and more than one sheet if needed. If you upload a PDF report, Claude can turn it into a PowerPoint. If you upload invoices, it can make a spreadsheet with calculations. It can even turn meeting notes into a nicely formatted document.

Claude now works in a private computer environment. This means it can write code and run programs to create and analyze files. Instead of just giving advice, Claude does the technical part for you, helping turn your ideas into finished files quickly.

To use the feature, turn it on in the settings, upload your files or give instructions, chat with Claude to guide the work, and then download the finished files or save them to Google Drive. The article suggests starting with simple tasks and building up to more complex ones as you learn how Claude handles files. It also warns that because Claude uses the internet to make and analyze files, you should be careful with your data.

In the Hacker News comments, many users are excited about this new feature. Some say it feels like the future of work—AI doing boring parts of projects so people can focus on ideas. Others warn about privacy and security, noting that giving AI access to personal or company data could be risky. Some users talk about similar tools from competitors like ChatGPT, and wonder how Claude’s file skills compare. A few are worried about mistakes, like wrong calculations in spreadsheets, and suggest always checking Claude’s work. There’s talk about how this will change jobs—some think it will help people work faster, while others worry it could replace some tasks people do today. Some users like that Claude can handle different file types and hope more types come soon. Others share tips: start with simple tasks, and don’t trust the AI with sensitive data. Overall, most agree this is a big step for AI tools, but it’s important to use them carefully.

---

## E-paper display reaches the realm of LCD screens

- 原文链接: [E-paper display reaches the realm of LCD screens](https://spectrum.ieee.org/e-paper-display-modos)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45185756)

A small company called Modos has made a new e-paper display that can refresh at 75 times per second, almost as fast as normal LCD screens. This is a big step because e-paper screens are usually slow and are known for being used in e-readers, where speed does not matter much.

The new Modos Paper Monitor and Dev Kit uses standard e-paper panels but adds an open-source controller built with an FPGA. This controller, called Caster, lets the screen update much faster and controls each pixel on its own. Most e-paper screens refresh at only 10 Hz or less, but this new one can do 75 Hz, making things like scrolling and video smoother and less “laggy.” This could let people use e-paper not only for e-readers but also for computer monitors, tablets, or other devices where quick updates are important.

Modos is also making all their hardware and software open source. Developers can use their own e-paper panels, not just the ones Modos sells. The kit also comes with an adapter to connect different kinds of e-paper screens, even ones pulled from old e-readers. There’s also a C-language API, so programmers can control how the display works for different needs—like showing fast text, maps, or even video on the same screen.

The company tried to build a full e-paper laptop in the past but found it was too expensive because e-paper panels are not made in the right shape or size for laptops. Most e-paper panels are made for e-readers or signs, not computers. But new 13-inch panels are helping, and that’s what Modos uses now. The crowdfunding campaign is running now, and Modos hopes to ship the first kits in early 2026.

From the top Hacker News comments, people are excited about the improved refresh rate. Some say this could finally make e-paper good for daily use, like coding or reading websites, because it is easier on the eyes and uses less power. Others are happy that the project is open source and may help more people experiment with e-paper. Some worry that e-paper still does not have good color or video quality compared to LCD or OLED screens, so it may not replace those for all uses.

A few commenters mention that e-paper is great for people who want less eye strain and fewer distractions. Some think that using old e-reader panels is clever and good for the environment. Others point out that e-paper screens are still expensive and hard to buy in small numbers. There is also talk about how the open-source controller could help with other types of unusual displays, not just e-paper. Some people hope that big companies will notice this and start making better e-paper panels for new uses. Others still think LCD and OLED will be better for most things, but say this is still a cool step forward for tech fans and hobbyists.

---

## We all dodged a bullet

- 原文链接: [We all dodged a bullet](https://xeiaso.net/notes/2025/we-dodged-a-bullet/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45183029)

The article talks about a recent attack on popular NPM packages, which could have been much more dangerous. The attack only changed the destination of cryptocurrency payments, but the packages targeted are used everywhere in software.

The writer explains that these packages help with things like coloring text in terminals, listing color names, debugging, and checking if something is an array. Many projects depend on them without thinking they could be risky. If the attacker had done more, like stealing API keys or adding a botnet, it could have hurt many companies and users. The attack started with a very good phishing email that looked real and asked developers to change their security settings. The email used the real NPM username, created urgency, and only had a small clue (a different domain name) that it was fake. Even smart and careful people could have fallen for it, especially if they were busy. 

One person even avoided the attack only because they put off reading the email. The article says the attack focused on Web3 wallets like MetaMask, hoping to catch payments in browsers. But most people use these libraries in command line tools, so the malware did not reach many wallets. The writer finds it strange that the attacker wasted such a powerful opportunity just to steal crypto, instead of going after data or API keys.

The main lesson is that any software dependency could be dangerous. Developers should check all their dependencies, but there's rarely enough time. Shipping products quickly often wins over careful checking.

People in the comments have different views about what happened. Some agree that everyone is at risk and phishing emails are hard to spot. Others think the NPM ecosystem has too many small packages, which makes attacks like this easier and more dangerous. A few say companies should do more to protect against bad packages, like using better monitoring or restricting which people can publish updates. Some are surprised that the attack did not do greater harm, and a few think we were just lucky this time. There are people who feel open source needs stronger trust systems, while others warn that blaming users for falling for phishing is not helpful. Some recommend learning from this and building safer habits, like using two-factor authentication and not trusting emails too quickly. Overall, people agree the attack was serious, but things could have been much worse.

---

## Anthropic is endorsing SB 53

- 原文链接: [Anthropic is endorsing SB 53](https://www.anthropic.com/news/anthropic-is-endorsing-sb-53)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45189053)

Anthropic says it supports SB 53, a new California law for strong rules on big AI companies. The bill wants companies like Anthropic, OpenAI, and Google DeepMind to be open about how they keep powerful AI safe and what steps they take to stop big risks.

SB 53 makes companies create and publish safety plans, so everyone can see how they try to prevent harm. Companies must share reports about their risk checks before releasing new AI models. If something goes wrong, they must tell the state within 15 days, even for problems with models they use only inside the company. Whistleblowers get protection if they report dangers or rule-breaking. If a company makes promises in its safety plan and breaks them, it can get fined.

Anthropic says these rules match what they already do, like sharing their Responsible Scaling Policy and publishing “system cards” that explain what their models can and cannot do. Other big companies have similar rules too, but SB 53 makes these standards a legal requirement for everyone, not just something companies choose to do. Startups and smaller companies don’t have to follow these rules, so it won’t hurt new businesses.

Anthropic thinks SB 53 will stop companies from hiding safety problems just to compete. They say everyone will have to be honest about risks, which is good for public safety. But Anthropic also says this is just a start. The rules are based on how much computer power is used to train models, but that might miss some strong models. They want better detail in reports and the ability to update the rules as AI changes. Anthropic wants to work with lawmakers to make the law even stronger and keep up with new technology.

In the comments, some people agree with Anthropic and think the law is a good first step for AI safety. Others are worried that only big companies can handle the rules, so it may help them and hurt smaller ones in the future. Some say the government should focus on real risks, not just paperwork and reports. A few believe the FLOPS (computer power) rule is not enough, since strong AI can be built in new ways. Many want clear rules but are afraid too much regulation will slow down progress or get in the way of new ideas. There’s a lot of talk about balancing safety with not stopping small teams and new companies. Some commenters say the law should be at the federal level, not just in California, so companies don’t have to follow different rules in every state. Others worry the law will be hard to enforce and may not really stop bad things from happening. Overall, the discussion shows people want safe AI, but they don’t all agree on how to get there or if this bill is the best way.

---

## Mistral raises 1.7B€, partners with ASML

- 原文链接: [Mistral raises 1.7B€, partners with ASML](https://mistral.ai/news/mistral-ai-raises-1-7-b-to-accelerate-technological-progress-with-ai)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45178041)

Mistral AI just raised 1.7 billion euros in a new funding round, led by ASML, a big name in semiconductor equipment. This round puts Mistral’s value at 11.7 billion euros and marks a strong partnership between AI and the semiconductor industry.

Mistral says the money will help them keep doing advanced research in AI, focusing on hard problems in important industries. ASML, as the lead investor, wants to work together with Mistral to make new AI solutions for its customers and to team up on research projects. Many well-known investors joined this round, including heavyweights like NVIDIA and Andreessen Horowitz. Mistral has spent two years building advanced AI and forming partnerships with major companies. They want to keep making custom, decentralized AI tools to help businesses and public organizations solve big engineering problems. These AI tools are meant to give companies an edge by using powerful models and strong computing power. Mistral also says this funding helps them stay independent. The CEOs of both companies mention that this partnership brings together two leaders in their fields to help improve the whole semiconductor and AI industry.

In the Hacker News comments, many people are surprised at how quickly Mistral has grown and raised so much money. Some users wonder if this shows how important AI, especially European AI companies, is becoming. Others are interested in ASML’s involvement, noting that it’s unusual for a hardware company to lead an AI investment. A few people discuss what “decentralized AI” really means, with some skeptical about whether big funding can keep things truly independent or open. Some developers are excited about more competition for big US-based AI companies. Others ask if Mistral will keep their models open source or start closing them off as they grow. A few worry that so much money will push Mistral to focus only on large customers, leaving smaller developers behind. Some praise Mistral for focusing on hard industry problems instead of just chatbots. There’s also talk about how this might help Europe catch up in the global AI race. A couple of users point out that partnerships like this could help speed up progress in both chips and AI. Overall, the community sees this as a big move for both Mistral and European tech, with both excitement and some doubts about the direction things might go.

---

## A new experimental Go API for JSON

- 原文链接: [A new experimental Go API for JSON](https://go.dev/blog/jsonv2-exp)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45182770)

This article talks about a new experimental JSON API for the Go programming language. The Go team has made a new version called `encoding/json/v2` and a helper package called `encoding/json/jsontext` to fix old problems and make JSON handling better.

The old JSON package, `encoding/json` (now called `v1`), has been around for 15 years and is very popular. But it has some issues. For example, it lets invalid UTF-8 go through, accepts duplicate keys in objects (which can be a security risk), and sometimes shows confusing behavior with nil slices and maps. It also matches JSON keys to struct fields without caring about case, which can cause bugs. The API is hard to use for some tasks, like customizing how data is handled or rejecting unknown fields. Performance is also limited: the old version reads and writes everything in memory, which is slow and uses lots of memory for big data. Fixing these problems in the old package is hard because Go tries very hard not to break old code.

After years of planning and help from the Go community, the team built the new `v2` package. It is based on a lower-level package called `jsontext`, which handles the technical details of JSON syntax. This separation makes it easier to work with JSON as a stream, not always having to load everything into memory. The new API lets users set more options, both for how data is read and written and for customizing how types are handled. For example, now you can define better ways to marshal and unmarshal types, and even override this at the call site. The new version fixes the old problems: it rejects invalid UTF-8, doesn’t allow duplicate keys, treats nil slices and maps as empty arrays or objects, and matches field names by case. Performance is better, especially for unmarshaling (reading JSON into Go data), which can be up to 10 times faster. The old package will use the new code under the hood, so users can switch slowly and safely.

In the Hacker News comments, many people are happy Go is finally fixing old JSON problems. Some say they have struggled with the old package for years, especially with handling nil slices and duplicate keys. Others are excited about better performance and the new streaming features. A few users are worried about breaking changes, since lots of existing Go code depends on the old behavior, but the article explains that the switch will be gradual and safe. Some developers want even more features, like working with big JSON files without using much memory, and they hope these new packages will help. A few point out that other programming languages have faced similar JSON issues and had to make big changes too. Some users are glad the Go team took ideas from real-world problems and got feedback from the community. There are also questions about stability, since the new API is still experimental, but others remind everyone that testing is important and the Go team is careful. Some people praise the clear separation between syntax (jsontext) and semantics (v2), saying it will make code cleaner. Finally, many agree that having just one implementation for both the old and new APIs will help with maintenance and reduce bugs in the future.

---

