Hello everyone, this is the 2025-09-09 episode of Hacker News Daily Podcast. Today, we have several big stories for developers and tech fans.

First, there’s exciting news in cancer research. A new immunotherapy drug called 2141-V11 was tested on people with aggressive cancers. Some patients saw their tumors shrink or even disappear. Earlier drugs of this type worked in mice but failed in humans because of strong side effects and low success. The new drug targets a part of the immune system called the CD40 receptor. Doctors made it stronger and more precise, then injected it straight into tumors. This made the treatment safer and reduced side effects.

In the trial, 12 patients with advanced cancers got the drug. Six had smaller tumors, and two had all their cancer disappear—one with melanoma and one with breast cancer. Even tumors that were not injected also shrank, showing the immune system was fighting cancer everywhere in the body. Treated tumors filled up with healthy immune cells, and this effect spread to other tumors too. Serious side effects seen with earlier drugs did not happen this time.

Now, bigger trials are starting. Researchers want to know why some people respond and others do not. The two patients who recovered fully had a special type of immune cell, which may be a clue for future treatment. In the comments, many people are hopeful and see this as a big step forward. Some warn the trial was small and more data is needed. Others discuss how cancer is different for every person, so finding one cure is hard. There are stories from people touched by cancer, as well as questions about cost and access. Some users remember other drugs that looked good early but failed later. There’s also talk about combining this drug with other treatments. Most comments show a mix of hope, caution, and curiosity about the future.

Next, a judge rejected a $1.5 billion copyright settlement between Anthropic, an AI company, and authors. Anthropic used millions of books without permission to train its AI, and the proposed deal was one of the biggest ever in copyright and AI. Judge William Alsup said the settlement is not complete and worries it was made by lawyers without enough input from the authors. He wants to make sure every real author knows about the deal and can choose to join or not. He also wants a full list of books covered, and warns that lawyers should not take too much from the fund. The deal would pay $3,000 per book, and could set an example for other AI copyright cases.

People in the comments agree this is a big test for copyright and AI. Some support the judge, saying class action settlements often help lawyers more than victims. Others think it’s right to be careful, since AI copyright is new. There are worries about fights between authors and publishers, and debates over whether $3,000 per book is fair. Some say copyright law is not ready for AI, while others ask if AI companies should stop using books without clear permission. Judge Alsup gets praise for asking hard questions. Most agree this case will shape future deals between authors and tech companies.

Moving on, Anthropic’s AI assistant Claude now has new skills. It can create and edit files like Excel, Word, PowerPoint, and PDFs. Users can ask Claude to build reports, clean up data, make charts, or turn meeting notes into formatted documents. These new features work for some users now, with more coming soon. Claude runs in a private computer space, so it can write code and process files, not just give advice.

To use the feature, turn it on, upload files or give instructions, chat with Claude, then download the finished files or save to Google Drive. The article advises starting simple, and warns to be careful with private data since files are handled online.

Hacker News users are excited and call this the future of work, letting AI handle boring tasks. Some warn about privacy risks, and say you should always check AI-created files. There’s talk about similar tools from competitors, and questions about how Claude compares. Some worry AI could replace jobs, while others think it will help people work faster. Many want more file types supported, and share tips about using the tool safely. Most agree it’s a big step for AI, but users should still be careful.

Next, a small company called Modos has made a new e-paper display that refreshes at 75 Hz, almost as fast as normal LCD screens. This is a big change, since e-paper is usually slow and used only for e-readers. The Modos Paper Monitor and Dev Kit use standard e-paper panels and a new open-source controller built with an FPGA. This lets the screen update much faster, making scrolling and even video smoother.

All hardware and software are open source, and developers can use their own panels. There’s also a C-language API for programmers. Modos tried to build a full e-paper laptop before but found it too expensive. Now, thanks to new 13-inch panels, they hope to ship the first kits in early 2026.

Comments are excited about the faster refresh rate. Some think e-paper could now be good for coding or browsing, since it’s easier on the eyes and saves power. Others like the open-source approach and using old e-reader panels. Some worry e-paper still lacks color and video quality compared to LCD or OLED. There’s hope that big companies will notice and make better panels. Most see this as a cool step forward, even if e-paper won’t replace other screens for everything.

Now, there’s news about a recent attack on popular NPM packages. The attack changed where cryptocurrency payments went, but the packages targeted are used widely in software. These packages help with things like coloring text, listing colors, debugging, and checking arrays. The attack started with a very convincing phishing email that tricked developers into changing settings. Even careful people could have fallen for it.

The attacker mainly targeted Web3 wallets like MetaMask, but most people use these libraries in command line tools, so the attack did not reach as many wallets as planned. The main lesson is that any software dependency can be risky, but developers rarely have time to check them all.

In the comments, people say that phishing is hard to avoid and the NPM ecosystem has too many small packages, making attacks easier. Some think companies should monitor dependencies better. Others are surprised the attack did not do more harm, and feel we were lucky. There’s talk about open source needing stronger trust systems, and advice to use two-factor authentication and be careful with emails. Most agree this was serious, but it could have been much worse.

In other news, Anthropic says it supports SB 53, a new California law for strong rules on big AI companies. The law asks companies to publish safety plans, share risk reports before releasing new AI models, and tell the state quickly if something goes wrong. Whistleblowers get protection, and companies can be fined if they break their own safety promises. These rules are for big companies, not startups.

Anthropic says the law matches what they already do, and will stop companies from hiding AI risks. But they also say the rules are just a start and should change as AI develops. In the comments, some agree the law is a good first step. Others worry it will only help big companies and hurt smaller ones. Some say the government should focus on real risks, not just reports. Many want clear rules, but fear too much regulation will slow progress. There’s talk about balancing safety with not stopping small teams. Some want a federal law, so rules are the same everywhere. Overall, people want safe AI but don’t fully agree on how to get there.

Now to Mistral AI, which just raised 1.7 billion euros, led by ASML, a big name in semiconductors. This puts Mistral’s value at 11.7 billion euros, and shows a strong link between AI and the chip industry. The money will help Mistral do advanced AI research and work with ASML on new solutions. Many famous investors joined this round, including NVIDIA and Andreessen Horowitz. Mistral wants to keep making custom, decentralized AI tools for businesses and public groups.

People on Hacker News are surprised by Mistral’s fast growth and wonder what “decentralized AI” really means. Some like more competition for US-based AI companies. Others ask if Mistral will keep their models open source, or focus only on big customers. Many praise the focus on hard industry problems, not just chatbots. There’s hope this will help Europe catch up in the AI race, and that partnerships like this will speed up progress in both chips and AI. But there are also doubts about the direction things might go.

Finally, the Go programming language team has released a new experimental JSON API called encoding/json/v2, with a helper package encoding/json/jsontext. The old JSON package has been around for 15 years but has problems—like letting invalid UTF-8 through, allowing duplicate keys, and confusing behavior with nil slices and maps. It’s also slow for big data.

The new v2 package fixes these problems. It’s based on a lower-level package for handling JSON syntax, so now you can work with JSON as a stream, not just in memory. There are better options for customizing how data is read and written, and performance is much better, especially when reading JSON. The old API will slowly use the new code underneath, so users can move over safely.

People are happy the Go team is fixing old JSON problems. Some are excited about better performance and streaming. A few worry about breaking changes, but the switch will be slow and safe. Developers like the new clean separation between syntax and meaning, and many agree this will help keep Go code clean and reliable in the future.

That’s all for today’s episode. Thanks for listening to the Hacker News Daily Podcast. We’ll be back tomorrow with more news and insights from the world of software and technology.