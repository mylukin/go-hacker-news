# Hacker News 故事摘要 - 2026-01-29

## 今日概述

Today’s top stories on Hacker News cover new AI tools and updates, creative software for building digital worlds, big steps in cancer research, and open source favorites like Flameshot. There’s also news about running old PlayStation 2 games natively on PC and Europe’s new weather satellite. Many stories focus on progress, but also raise questions about trust, privacy, and keeping user choice. If you like AI, gaming, health, or space tech, there is something interesting to read today.

---

## Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT

- 原文链接: [Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT](https://openai.com/index/retiring-gpt-4o-and-older-models/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46816539)

OpenAI says it will stop offering GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini models in ChatGPT starting February 13, 2026. This change follows the earlier plan to retire GPT-5 Instant and Thinking models too, but for now, API users are not affected.

OpenAI explains that after first removing GPT-4o, they brought it back because some users said they needed more time to switch and liked GPT-4o's friendly and warm style. The feedback helped improve new models, like GPT-5.1 and GPT-5.2, making them better at creative tasks and more customizable. Now, users can choose different styles, tones, and control how ChatGPT responds—like making it more friendly or enthusiastic. OpenAI says most people now use GPT-5.2, and only a tiny number (0.1%) still pick GPT-4o each day. They also mention work to make ChatGPT less strict and more creative, plus features like age prediction to keep younger users safe. OpenAI promises to be clear about changes and says retiring old models is hard, but it helps them focus on the most popular ones.

In the Hacker News comments, some users are frustrated about losing access to models they prefer, especially GPT-4o’s style. Others think it makes sense for OpenAI to focus on newer, better models instead of supporting many versions. A few worry that removing choices limits user freedom and hurts specific workflows. Some users question if new models are really better at creativity and warmth, or if they just sound different. There are also concerns about trust, with people asking for more transparency on why models are retired and how user feedback shapes changes. A few point out that switching models can break existing tools or integrations, which is a headache for developers. Others feel OpenAI moves too fast and doesn’t give enough time for users to adjust. Some are happy with the new customization options and think OpenAI is listening to feedback. Overall, the community is split—some see the change as progress, while others wish for more stability and choice.

---

## Project Genie: Experimenting with infinite, interactive worlds

- 原文链接: [Project Genie: Experimenting with infinite, interactive worlds](https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46812933)

Google has launched Project Genie, a tool for making and exploring interactive worlds, now open to AI Ultra subscribers in the U.S. The project is an early research prototype from Google DeepMind, aiming to let users build, explore, and remix digital environments using AI.

Project Genie works by letting you sketch worlds with text prompts or images. You can create your own character and set how you want to explore, like walking or flying. The tool uses Genie 3, Google’s world model, which can generate the path ahead in real time as you move through the world. This means the environment changes and grows as you interact with it, not just showing static scenes. You can also remix other people’s worlds, exploring what others have made and building on top of their ideas. The app lets you download videos of your worlds and explorations. For more control, there is a “World Sketching” feature using Nano Banana Pro, where you can adjust the look and camera perspective before starting. The experience is meant to be fun, but also helps Google learn how people might use world models for games, education, or other creative projects. Project Genie is still early and has some limits: the worlds are not always realistic, character control can be slow, and some features are missing. Google says it will add more features and improve realism over time, and hopes to make the tool available to more users in the future.

In the Hacker News comments, some users are excited about the possibilities for game development and creative storytelling. They think tools like this could help small teams or even solo creators make rich games or interactive stories without big budgets. Others are more skeptical, pointing out that the worlds created now are still simple and not very realistic. Some worry about Google keeping the tool behind a paywall, making it hard for indie developers to try. There are concerns about AI-generated content, including who owns the new worlds and how much control users really have. A few commenters compare Project Genie to older “world builder” tools, wondering if this will last or just be another tech demo. Others ask about privacy and what Google might do with data from users’ creations. Finally, some people hope Google will open up the technology for outside developers, while others worry it will stay locked inside Google’s ecosystem.

---

## PlayStation 2 Recompilation Project Is Absolutely Incredible

- 原文链接: [PlayStation 2 Recompilation Project Is Absolutely Incredible](https://redgamingtech.com/playstation-2-recompilation-project-is-absolutely-incredible/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46814743)

A new project is making it possible to run PlayStation 2 games natively on modern PCs, instead of using emulators. This tool, called PS2Recomp, recompiles PS2 games so they can work directly on Windows or Linux computers.

The PS2 had special hardware like its unique “Emotion Engine” CPU and custom graphics chip. Most emulators try to copy this hardware, but they need strong computers and sometimes have problems with speed or game bugs. PS2Recomp takes a different approach: it converts the PS2 game’s code into something your PC can run, meaning better performance and fewer issues. 

This tool is not simple to use yet. You can’t just click and run any game; each game needs to be processed with the tool first. But once a game is recompiled, you can enjoy higher resolutions, better frame rates, and even HD texture packs. It also opens the door for fans to make remasters, add new features, or fix old problems. 

Other consoles have had similar projects. The Nintendo 64 community made native PC versions of games like Mario 64 and Zelda, even adding ray tracing and new controls. If this PS2 project succeeds, we could see classic games like Metal Gear Solid 2, Gran Turismo, or God of War running natively on PCs with modern features.

The article explains that the PS2 was powerful for its time, even though its hardware was slower compared to competitors. Its architecture is tricky to copy, so this recompilation project is exciting for game preservation and fans who want to play old favorites easily.

In the comments, many people are amazed by the technical challenge. Some think this could be the best way to keep old games alive, since original hardware is getting rare and emulators are not perfect. Others point out that recompiling every game is a big task, and wonder how long it will take before many games are supported.

A few users worry about legal issues, especially if people share recompiled game files. Some are excited about the chance for mods and upgrades, like adding new graphics or fixing bugs that were never fixed on the original PS2. 

One person remembers the struggles of emulating PS2 games in the past and hopes this will make things much easier. Another user mentions that similar projects with N64 games have really improved the experience, so they are hopeful here too.

Some commenters discuss the technical side, like how hard it is to translate code made for the PS2’s strange hardware into something a PC can use. Others are just happy to see more attention given to preserving video game history.

Overall, people are excited but know this is still early work. They look forward to seeing which games get support first and hope more projects like this happen for other old consoles.

---

## Claude Code daily benchmarks for degradation tracking

- 原文链接: [Claude Code daily benchmarks for degradation tracking](https://marginlab.ai/trackers/claude-code/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46810282)

This article shares daily benchmark results for Claude Code Opus 4.5, a tool that helps with software engineering tasks. The main goal is to notice if Claude’s performance gets worse over time, using clear numbers and statistics.

Each day, the team checks how well Claude solves 50 real programming problems. They use a trusted set of tasks and always test the latest version of Claude Code, just like normal users would. The team does not use any special tricks or custom setups, so results are fair and realistic.

They measure the percent of tasks Claude solves each day, and compare this to a “baseline” average of 58%. If the daily score drops a lot below this number, it could mean something is wrong. For one day, Claude passed 50% of tasks out of 50 tries. Over the last 7 days, the pass rate was 53%. Over the last 30 days, it was 54%. The tracker uses statistics to decide if these drops are just normal ups and downs, or if they show a real problem.

The article also explains that small drops might not matter, but bigger drops that are “statistically significant” are important. Over the last month, the tracker found a real drop of about 4% that is big enough to matter. The team says they are independent and want to help users notice problems early, especially after past issues with Claude’s quality.

The comment section has many different views. Some users are happy to see someone checking AI tool quality in a clear, open way. Others ask if 50 daily tests are enough to spot real changes, or if more samples would make results more stable. Some people worry about “degradation,” saying they have seen AI tools get worse after updates, so they value outside tracking. A few users want to know if other models, like Codex, are also tracked for fairness.

There are technical comments about the statistics, with some saying the confidence intervals and significance tests look solid, while others think the bar for “significant” change is too low or too high. Some users want automatic alerts or better ways to see long-term trends. A few ask for more details about the test set, to make sure it is hard enough and not repeated too often. Overall, the feedback is mixed but most agree that regular, public benchmarks are very useful for the AI community.

---

## Drug trio found to block tumour resistance in pancreatic cancer

- 原文链接: [Drug trio found to block tumour resistance in pancreatic cancer](https://www.drugtargetreview.com/news/192714/drug-trio-found-to-block-tumour-resistance-in-pancreatic-cancer/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46812159)

A new study found that using three drugs together can stop pancreatic cancer tumors from growing and stop the cancer from coming back, at least in mice. Pancreatic cancer is very hard to treat, and most treatments do not work well for long.

The scientists targeted three important pathways that help cancer cells grow and survive. These are called RAF1, EGFR family receptors, and STAT3. The three drugs used are RMC-6236 (which targets KRAS), Afatinib (which blocks EGFR), and SD36 (which destroys STAT3). They tried this on mice with pancreatic tumors that are like the ones found in humans.

In the study, the tumors shrank and did not come back for over 200 days. The mice did not show strong side effects from this treatment. The team also tested the drug combo on human cancer tissue grown in mice. The results were similar: the tumors got smaller, and resistance did not appear.

One big problem with cancer drugs is that tumors often become resistant and start to grow again. This new combo treatment seems to stop that from happening, at least so far in mice. The researchers say this could lead to new clinical trials for people in the future.

Several commenters were excited about the news, saying that new treatments for pancreatic cancer are badly needed. Some people pointed out that results in mice do not always happen the same way in humans, so they want to see more testing. Others asked about the cost and possible side effects if these drugs were used together in people. A few commenters discussed how blocking several pathways at once could also harm healthy cells, so safety will be important.

Some users shared personal stories about family or friends lost to pancreatic cancer, and they hope for faster progress. Others explained how cancer cells can be tricky and find new ways to survive, so even multi-drug treatments may only work for a while. There was also talk about how getting drugs approved for people takes a lot of time and money, and not all promising ideas make it through.

A few users wondered if the same approach could help other tough cancers. Others stressed the importance of open data, so more researchers can try these ideas. Some were hopeful but cautious, saying it is a good step but not a cure yet.

---

## Compressed Agents.md > Agent Skills

- 原文链接: [Compressed Agents.md > Agent Skills](https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46809708)

This article talks about making AI coding agents smarter with up-to-date Next.js docs. The team at Vercel tried two ways to help AI agents use new Next.js 16 APIs that the models did not know about.

First, they used "skills," which are special tools that agents can call when they need extra help. Skills include prompts, tools, and docs, and the agent is supposed to call a skill when it needs framework knowledge. Second, they tried putting a small, compressed docs index in a file called AGENTS.md, which always stays in the agent’s context.

When they tested both methods, skills did not work well by default. The agent often did not use the skill unless told directly. Even adding clear instructions only made the agent use the skill about 95% of the time and reach a 79% pass rate on their tests. But the AGENTS.md approach, with just an 8KB compressed docs index, got a perfect 100% pass rate. This happened because the agent always saw the docs index and did not need to decide when to look for help.

The team noticed that skill instructions were very fragile—small changes in the wording led to big changes in agent behavior. Sometimes, the agent missed important project context if told to check the docs too soon. By contrast, the AGENTS.md file meant the agent always had the docs nearby and could use them at any time.

They solved the problem of “context bloat” (too much info in the agent’s memory) by compressing the docs index. The agent could then look up which file it needed, instead of having all docs at once. To make this easy, they made a tool that adds the AGENTS.md file and downloads matching docs for any Next.js project.

For framework authors, the article suggests using AGENTS.md for general knowledge, since it works better than skills right now. Skills are still useful for special, action-based tasks.

In the comment section, many people are surprised that the simpler AGENTS.md approach works better than the fancy skill system. Some say this fits their experience with AI not using tools unless told to. Others worry about context limits and wonder if this method will work for even bigger projects. A few think skills can improve as AI models get better at following instructions, but agree that today’s results matter more than future hopes.

Some users like the idea of compressing information to fit more into the agent’s memory. Others point out that this only helps if the agent is able to fetch the right file when it needs details. There are also comments about how important it is to test with APIs the model does not already know, since that’s where up-to-date docs really help.

A few commenters mention that mixing both methods (passive docs and skills) could be the best way for now. Some hope future agents will be smarter with tools, but agree that AGENTS.md is a good fix today. Many appreciate the clear, data-driven approach and like that Vercel shared their test results and tools with the public.

---

## Launch HN: AgentMail (YC S25) – An API that gives agents their own email inboxes

- 原文链接: [Launch HN: AgentMail (YC S25) – An API that gives agents their own email inboxes](item?id=46812608)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46812608)

AgentMail is a new tool that lets software agents have their own email inboxes, like real people. The company launched on Hacker News and is part of the Y Combinator Summer 2025 group.

The main idea is to help AI agents or bots use email like a human would. For example, an agent can read, send, and reply to emails. AgentMail gives each agent a real email address. Developers can use AgentMail’s API to connect these inboxes to their own software. This means an AI could answer customer support questions or work with other services through email. The system handles spam, security, and privacy. It supports IMAP and SMTP, which are standard email protocols. AgentMail also has tools to help with email parsing and sending attachments. The goal is to make it easy for agents to join human email conversations. The founders believe this can help automate many tasks that still happen over email. They think it will speed up workflows in areas like sales, support, and business operations.

In the comments, some people are excited about letting agents join email threads. They see many uses in customer service and automation. Others worry about trust and security. They ask how AgentMail stops agents from sending spam or making mistakes. A few developers want more details about pricing and scaling. Some users point out that handling email is hard, with lots of edge cases. Others ask if this could help with boring or repetitive email tasks. There are questions about how AgentMail works with existing email clients. A few people warn about privacy risks if agents read sensitive emails. Some are interested in the technical side, like API limits and latency. One person thinks this could lead to more email noise, but others believe it could free up human time for better work. Overall, the discussion is a mix of excitement, technical questions, and caution about possible problems.

---

## OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)

- 原文链接: [OTelBench: AI struggles with simple SRE tasks (Opus 4.5 scores only 29%)](https://quesma.com/blog/introducing-otel-bench/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46811588)

This article talks about a new benchmark called OTelBench, which tests if AI models can add OpenTelemetry tracing to code, a basic task for SREs (Site Reliability Engineers). The team tried 14 top AI models on small, real-world tasks across 11 programming languages, asking them to instrument microservices for distributed tracing.

They found that even the best AI model, Claude Opus 4.5, only got 29% of tasks right, while others like GPT 5.2 and Gemini 3 Pro were close behind. Many models failed to understand the business context: instead of making separate traces for different user actions, they often mixed them up into one. The models could write code that compiled, but often the traces were wrong, missing key details or breaking the trace chain.

C++ tasks had the highest success, but that was likely because the tasks were simpler. Go was tested more and had a lower pass rate. Other languages like Java, Swift, and Ruby saw very poor results. The cost and speed to run these models varied a lot, with cheaper models sometimes matching or beating more expensive ones in some areas.

The article says that OpenTelemetry is hard for AI because it isn’t just about writing code—it needs understanding of many languages, real business flows, and build systems. Also, there’s not much public training data for these tasks; most real-world examples are in private company code.

The key takeaway is that AI is far from being able to replace human SREs for even simple tracing jobs. Many models do well at writing code, but not at handling complex, real-world debugging. Still, there is hope: on some tasks, models did much better, so progress is possible.

In the Hacker News comments, some users were not surprised by the low scores. They pointed out that distributed tracing is hard, even for humans, and often requires understanding messy legacy systems. Others said the benchmark is useful and shows where AI tools need to improve before they can help in SRE or DevOps work. A few commenters suggested that the lack of training data for tracing code is a big reason why models struggle. Some people thought the results were a good reminder not to trust AI with critical debugging tasks just yet. Others questioned if the benchmark tasks were really as “simple” as claimed, since real-world SRE work is always tricky. There were also comments about the cost: some felt the expense of running these models for little gain is a problem for companies. Finally, a few users were hopeful, saying that with better data and feedback, AI might get much better at this kind of work in the next few years.

---

## Flameshot

- 原文链接: [Flameshot](https://github.com/flameshot-org/flameshot)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46815297)

Flameshot is a free and open source screenshot tool for Linux, Windows, and Mac. It lets you take screenshots, edit them right away, and even upload them to Imgur.

The tool is easy to use and has many features. You can change the look, draw shapes, add arrows, blur parts of the image, and write text. Flameshot can be started from the system tray, the terminal, or with keyboard shortcuts. There are many commands—like taking a screenshot after a delay, saving to a special folder, copying to the clipboard, or capturing one monitor only. On Windows, there’s a special “cli” version for better command-line output. You can set up shortcuts in most desktops, like KDE, Gnome, XFCE, and Fluxbox, to use Flameshot instead of the default screenshot tool. There are guides for each desktop about how to do this. 

Flameshot works best with desktop environments that support D-Bus and have a system tray. Sometimes you need to install extra extensions to see the tray icon, especially on Gnome. You can change settings in a config file, and even copy your settings between Linux and Windows if you update the save path. Installation is simple, with packages for many Linux distributions, Mac (with brew or MacPorts), and Windows (with Chocolatey). For people who want to build from source, the instructions and dependencies are clear.

In the Hacker News comments, many people say they love Flameshot for its simple editing tools and quick sharing. Some say it’s their favorite screenshot tool, especially on Linux. Others like that it does not collect data or show ads. A few users had trouble with the tool on Wayland or with the system tray icon not showing up. Some think the interface could be simpler, or hope for better support for HiDPI screens. There are people who still prefer other tools, like Shutter or the built-in ones on Mac and Windows, but they admit Flameshot is strong for quick edits. One person pointed out that Flameshot’s upload to Imgur is very useful for sharing. Another user liked that the tool works well with scripts. Some users wish for more features, while others are happy it stays lightweight. Many are glad the tool is open source and supports many platforms. Finally, a few gave tips on setting up keyboard shortcuts, or shared how they use Flameshot in their workflow.

---

## Europe’s next-generation weather satellite sends back first images

- 原文链接: [Europe’s next-generation weather satellite sends back first images](https://www.esa.int/Applications/Observing_the_Earth/Meteorological_missions/meteosat_third_generation/Europe_s_next-generation_weather_satellite_sends_back_first_images)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46806773)

Europe’s new weather satellite, Meteosat Third Generation-Sounder (MTG-S), has sent back its first pictures from space. These images show how the satellite will help give better weather forecasts for Europe and northern Africa.

MTG-S sits high above Earth in a fixed spot, 36,000 kilometers away. It uses an Infrared Sounder to measure temperature and humidity. The first images show warm and cold areas on Earth. Dark red shows high temperatures, mostly over Africa and South America, while blue areas are cooler, usually the tops of clouds. Another image shows humidity in the air: blue means more water vapor, red means dry air. You can see very dry air over the Sahara and the Middle East, and wetter air in eastern Africa.

The satellite can also track big events, like volcano eruptions. For example, it followed an eruption in Ethiopia and showed how the ash cloud moved over time. MTG-S gives new data every 30 minutes, so weather experts can watch storms and other changes as they happen. It works with another satellite, MTG-Imager, to give even more details, like cloud shapes and lightning.

What makes MTG-S special is its hyperspectral instrument. This tool looks at light in many tiny slices, so it can make very detailed maps of the air. It can help measure temperature, humidity, wind, and even trace gases, building a 3D picture of the atmosphere. Scientists say this will help predict storms and dangerous weather faster and better. MTG-S is the first European satellite to have this technology in geostationary orbit.

The mission took 15 years to build and is a big project involving ESA, Eumetsat, and many companies. The satellite also carries the Sentinel-4 mission, which looks for air pollution.

In the comments, many people are excited about the new technology and the clear images. Some say it is great that Europe now has its own advanced weather satellite. Others talk about how this will help with warning people about storms and floods earlier. A few users compare MTG-S to US and Japanese satellites, noting the differences and similarities. Some commenters are interested in the technical side, asking about the satellite’s sensors and how data is shared with the public. One person hopes the data will be open for researchers. Another mentions the long wait for this technology, saying it is good to see it finally working. There are also worries about space junk, but most agree the benefits for weather and safety are worth it. Many thank the teams for their hard work, saying this is a proud moment for European science.

---

