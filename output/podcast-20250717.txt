Hello everyone, this is the 2025-07-17 episode of Hacker News Daily Podcast. Today, we have a full lineup of stories from the world of AI, coding tools, robot hands, digital independence, and even the strange world of artistic perfume.

Let’s start with Mistral’s big update to their AI assistant, Le Chat. The new features are aimed at making Le Chat a better partner for deep research, voice chats, and organizing your work. One of the key additions is Deep Research mode. This tool helps you get fast, structured reports, almost like working with a research partner. For example, you can ask about upcoming NYSE IPOs, and Deep Research will build a full summary with facts, dates, numbers, and sources. The answer goes beyond simple search results, showing which companies are going public, their values, dates, and what they do. The report also explains why IPO activity is climbing in 2025, uses tables, and highlights key companies in tech, health, and crypto.

Another new feature is Voxtral, the voice chat system. Now, you can talk to Le Chat instead of typing, which is handy for brainstorming or getting quick answers on the go. The voice recognition is designed to be fast and natural. For those working in different languages, Le Chat now supports mixed-language conversations, even switching between languages mid-sentence, powered by their Magistral model. You can get clear answers in English, Spanish, Japanese, Arabic, and more.

Projects is a new way to keep your chats, files, and ideas together. It’s useful for managing long-term work or team projects. Image editing has also improved: you just type what you want to change in a picture, and Le Chat will edit it for you.

Hacker News commenters are excited about these updates, especially Deep Research and Projects. Some say Le Chat is starting to feel like a real research assistant. Others like the voice mode, saying it could help busy people or those on the move. A few developers tested Deep Research and found it gives good references, though sometimes it still makes mistakes or includes fake links.

There are some concerns, too. People worry about privacy, especially if Le Chat collects lots of data in company settings. Others ask if voice mode works well with different accents, and if multilingual support is truly strong. Some are interested in how the image editing compares to tools like Midjourney or DALL-E. There are also questions about the business model—will all these features stay free? Still, most users are curious and positive, eager to try the updates but looking out for any problems.

Next up, Apple’s new technical report gives a look at two big language models behind Apple Intelligence. One model is small and runs directly on your device, with about 3 billion parts. It’s designed to work fast with Apple’s chips, using tricks like shared memory and low-precision numbers to save space and power. The server model is even bigger, using a Mixture-of-Experts design for good answers and lower costs. Both can understand many languages, look at pictures, and use different tools to help users. Apple trained the models with data from the web, books, and synthetic data, and says all was collected safely and legally.

Apple improved the models with extra lessons from humans and special feedback loops. The models did as well as, or better than, similar open-source models in tests. Developers can use these models in their apps with a simple Swift API. Privacy is a key focus, with features like Private Cloud Compute and strong safety checks for bad content, plus tests for different countries.

Hacker News users praise Apple for running strong models on devices, saying this could help privacy and speed. Some are curious about the server model, but wonder how private Apple’s cloud really is. Developers like the easy Swift tools, while others warn that Apple’s track record with developer tools is mixed. There’s debate about how “responsible” Apple’s AI is, with doubts about perfect filtering. Some trust Apple more than other big tech companies, but most agree that this is a big step. People want to see how well it works in practice.

Moving to something very different, one article explores the world of weird and artistic perfumes. The writer, who never cared about perfume before, became curious after reading about strange scents online. The world of indie and experimental perfumes is much bigger than the usual sweet or flowery types found in malls. Some perfumes are designed to smell like burning leaves, cold towns, the ocean, or even horror movie scenes. Many are not expensive to try, since you can buy small samples.

The writer tried 39 different scents, like “Room 237” (creepy), “Asphalt Rainbow” (city and food), “Lampblack” (ink and old books), and “Acqua di Sale” (the ocean). Some brought back strong memories, like fishing with family, while others were just interesting or strange. Perfume reviews online were very divided—some people loved a scent, others hated it. The writer found that some perfumes really felt like art, especially those that changed over time or told a story. In the end, they bought two bottles: Acqua di Sale for work, and Kyoto for personal use, expecting them to last for years.

On Hacker News, commenters were surprised that perfumes could be so different and artistic. Some shared their own favorites, like scents of old books or wood smoke. Many found it funny that people’s perfume reviews are so different, like with wine or coffee. Some like the idea of cheap samples to explore, and a few warned it’s easy to buy too many. There was agreement that smells can trigger strong memories, and overall, the world of weird perfumes sparked excitement, curiosity, and some amusement.

Now, let’s talk about robots. The Amazing Hand is an open-source robot hand you can build yourself. It’s low-cost, 3D printable, and designed to be expressive and useful for real robots like Reachy2. The hand has four fingers, each with two moving parts, and eight small motors inside—no cables or outside parts needed. The design uses flexible plastic so the fingers move like a real hand. All files and guides are free online, and you can control the hand using Python scripts or an Arduino. The hand weighs about 400 grams and costs under 200 euros to build.

The project includes guides to calibrate the fingers, make left or right hands, and connect two hands to a robot. The motors can sense torque, position, and temperature, but the hand is not fully tested for safe gripping yet. There are plans to add more features like fingertip sensors.

Hacker News users are excited that this project is affordable and easy to build. Students and hobbyists can now try robotics more easily. The all-in-one design with no cables is seen as smart and simple. Some ask about the hand’s strength and if it can be used for real tasks, while others suggest adding a thumb or more sensors. There’s talk about using the hand for prosthetics, but others note that real prosthetic hands need more testing and safety. The open-source spirit is widely liked, and many look forward to future updates.

Next, there’s an article about how many AI models may actually learn the same things, even if they look different. The idea is explained with a guessing game called “Mussolini or Bread”—people and AI can narrow down ideas because they share a common world model. As AI models get bigger, they get better at compressing data and generalizing, which makes them smarter and more efficient. The Platonic Representation Hypothesis says that large models start using the same features and seeing the world in similar ways.

The author worked on a project called vec2vec, using CycleGAN to translate between different models’ internal representations. The results show it’s possible to move between models’ “embedding spaces.” Other research finds that different models often have similar inner parts. This could help us build better tools for understanding and translating between models, and maybe even help us decode lost languages or animal communication in the future.

Hacker News commenters liked the idea and shared similar experiences with different models. Some warn that focusing too much on similarities could hide real risks, like if all models make the same mistakes. There’s excitement for practical uses, such as moving data between models or opening black box systems. Others question if this will work for things like translating whale speech, since we might not have enough data. Some note that the ideas are not new, and there’s debate about whether compression alone can measure intelligence. There’s also interest in how this could help with security, privacy, and open-source models, but many open questions remain.

Turning to the AI coding world, Anthropic, the maker of Claude, changed how much code people can run with Claude Code, but did not warn anyone. Users suddenly found they hit usage limits much faster, making work difficult or impossible. The company did not update their website or send any messages about the change. Many users are upset, especially those who pay for the service. The article points out that clear communication is important, and that quiet changes can hurt trust. Some users now plan to try other tools or go back to old ways of coding.

Hacker News comments show a lot of frustration. Some say it feels unfair and sneaky, while others note that this is a common problem with new tech companies. A few defend Anthropic, saying maybe the change was needed to save money or keep the service running. Many agree that trust is lost when companies make surprise changes, and that clear limits should always be explained.

Related to this, another article shares a user’s two-week experience with Claude Code after switching from Cursor. The writer finds Claude Code helpful for coding tasks, reviewing code, and managing large projects. The tool offers models like Sonnet 4 and Opus 4; Sonnet is fast and good for most tasks, while Opus is better for tough bugs. Features like subagents help search large codebases. The writer gives tips for using Claude Code well, like managing context, using custom commands, and learning keyboard shortcuts. They note that Claude Code’s command line encourages curiosity, but the UI is less friendly than Cursor’s, and copy-pasting could be better.

In the comments, many readers share their own experiences. Some agree that Claude Code is great for large projects, but find the learning curve steep and the UI lacking. There’s debate about the high cost, with some saying it’s only worth it for professional work. People compare Claude Code to Copilot and Cursor, and discuss ideas for better search, more models, and easier session management. There are warnings about relying too much on AI tools, which can make it easy to miss bugs. The article’s practical tips are appreciated, and overall, there’s strong interest in how AI is changing coding.

Now, we have a story about someone setting up their own autonomous system (AS) on the Internet, just for fun and to learn. The Internet is made up of many networks, each managed by different groups, but most people never need to think about this. Usually, your ISP handles everything, but if you want to run your own part of the Internet, you need your own public IP addresses, an ASN, and a router that can talk BGP. This is not easy—public IPv4 addresses are hard to get, and you need to set up peering with other networks. The author got some IPv6 space from a friend, applied for an ASN, and set up a big Cisco router in a data center. It was a complicated and unnecessary project, but a great technical challenge.

Hacker News users are impressed by the effort and see it as fun and educational. Some say it’s much harder now because IPv4 space is running out and rules are stricter. There are stories from people who have run small ISPs or networks, and talk about the challenges of routing tables, paperwork, and security. Some say most people don’t need this level of control, and that cloud providers make things easier. There are debates about whether having your own AS gives you real independence, since you still depend on bigger networks for connections. The social side is also important—making friends and trading favors helps with peering. Overall, people think it’s a cool project, but only for those who really want to dive deep into how the Internet works.

Our last story is about the risks of using AI to write stories or make art. The article lists nine reasons why writers should not use AI for creative work. It says AI doesn’t really understand stories or emotions, and its writing is often flat and confusing. AI-generated content is built on work stolen from real artists, who are not paid. Readers do not want to buy AI-made books and may feel tricked. Using AI can cause scandals and hurt your reputation. If too many indie writers use AI, people might stop trusting all indie books. You may even lose copyright protection for AI-generated work. Overuse of AI can make your own writing skills weaker, and AI causes harm by spreading lies, using lots of resources, and taking jobs. Finally, only you can write with your own voice—AI cannot replace real personal stories.

In the comments, most people agree that using AI is a shortcut that takes away real skill. Some share funny examples of bad AI writing. A few use AI for brainstorming or to help with writer’s block, but still prefer to write their own stories. Some think AI can help people with disabilities. There’s debate about whether AI can ever be used ethically, but most agree that it depends on copying human work. Some warn that using AI too much is like cheating yourself, and that it is unfair to readers and writers. There are calls for better laws and rules, but some think regulation is hard. A few are not fully against AI, but say we must be careful and always remember the value of real human creativity.

That’s all for today’s episode. We covered advances in AI assistants, Apple’s language models, the world of artistic perfumes, open-source robotics, how AI models may learn in similar ways, the changing landscape of AI coding tools, running your own Internet network, and the debate over AI in creative work. Thank you for listening to Hacker News Daily Podcast. See you next time!