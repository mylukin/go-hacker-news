Hello everyone, this is the 2026-02-25 episode of Hacker News Daily Podcast. Today, we have a wide range of tech news and community stories, from legendary music engineering to new programming languages, AI privacy, software upgrades, and city infrastructure. Let’s get started.

First, we look at Jimi Hendrix and his groundbreaking use of technology and engineering to create new sounds on the electric guitar. Hendrix worked with sound engineers and used special pedals and amplifiers to produce effects never heard before in his time. For his famous song “Purple Haze” in 1967, Hendrix used the Octavia pedal built by Roger Mayer. This pedal, plus the Fuzz Face and wah-wah, changed the sound of the guitar. When the song was sent to the US for remastering, engineers had to be told that the strange sounds were on purpose, not errors. Hendrix showed that the electric guitar could act like a wave synthesizer, making many different sounds beyond just strings.

Each pedal in Hendrix’s setup had a clear job. The Fuzz Face made the sound rough and fuzzy. The Octavia doubled the frequency, making notes one octave higher. The wah-wah made the guitar sound like it was talking. The Uni-Vibe gave a moving, airy sound. Hendrix also used the amplifier and even the room itself as part of his system, moving his guitar to control feedback and create long, singing notes.

The article’s author, who works with computers, used circuit simulations and open-source tools to model Hendrix’s signal chain. They found that Hendrix’s genius was in how he connected everything and used his body to control the system, not just in playing notes. Hendrix did not use technical terms, but worked closely with engineers and experimented like a systems engineer.

On Hacker News, readers loved the idea of Hendrix as an engineer, showing how musicians use technology in creative ways. Some pointed out that artists and engineers think differently; Hendrix may not have used technical language, but he understood systems in his own way. Others tried to copy Hendrix’s sound with digital tools, finding it hard to match the feeling of old analog gear. There were also discussions about the importance of physical movement and feedback, which is hard to recreate in software. Some commenters said that focusing too much on the engineering can take away from the magic of art, but most agreed that Hendrix’s teamwork with people like Roger Mayer was key to his success. Many simply celebrated how exciting and groundbreaking his music still feels today.

Next, we introduce the Om programming language, a new, simple language for writing programs and algorithms. Om is concatenative, which means you build programs by joining smaller parts together, but it uses prefix notation—functions come before their inputs. This helps avoid stack errors, makes code easier to read, and lets computers run code faster. Om uses “panmorphic typing,” meaning there are no data types—every value is just an operand, and any operation can work with any operand. The language is “homoiconic,” so code and data have the same structure, like Lisp.

Om is built as a C++ library, so you can use it in C++ or Objective-C++ projects, or as a stand-alone interpreter. The project is on GitHub under the Eclipse Public License. To build Om, you need CMake, Boost, and ICU4C.

Om has only three elements: operators, separators, and operands. Programs are built by combining these. Functions can be identity (do nothing), constant (add something), or operations (do work). If an operation lacks input, it stays for later. Om has basic operations like “drop,” “copy,” “choose,” “quote,” and “dequote.” You can define new operators on the fly. The language supports full Unicode and efficient recursion. To contribute, you can add new operations or help fund the project.

In the comments, people found prefix concatenative languages interesting, since most use postfix notation. Some thought prefix was easier to read, but others worried about confusion in complex programs. Some liked Om’s simple treatment of all data, like in Lisp, and its potential for metaprogramming. Others said Om is missing many basic operations and is not ready for real use, but praised the clear documentation and creativity. Many see Om as an experiment with interesting ideas, and some plan to check back when it matures.

Moving on to AI tools, one article shares how using a CLI method with one command made using MCP—a tool for AI agents—much cheaper. Normally, MCP sends a long list of all tool details to the AI at the start, using a lot of tokens and money. With CLI, only tool names and locations are sent, saving around 94% of token costs. The agent looks up tool details only when needed, which uses more tokens only on demand. The author built CLIHub to help people make CLIs from MCPs easily.

Commenters think this is a smart way to save money, especially for big projects. Some wonder if the extra work of building CLIs is worth it for small teams, or if it might slow agents down. Others worry about tool discovery and possible security risks. Most like that CLIHub is open source and model-agnostic, and agree that saving tokens is important as AI use grows. One person jokes that everything old—like CLI—becomes new again.

Now, a story about bus stop balancing in US cities. The article says US buses stop too often—sometimes every 200 meters—making them slow and costly. In Europe, stops are farther apart, making service faster and more reliable. By removing some stops, US cities can speed up buses, save money, and make each stop better. Riders might walk a bit farther, but overall service improves.

In the comments, many agree, saying their cities improved bus service by removing stops and making the rest nicer. Some worry about people who have trouble walking, and say agencies should be careful about which stops to close. A few say that in some places, stops are already too far apart. Others note that people do not like change, but that bus stop balancing is a simple, effective way to improve transit.

Next, Microsoft is updating Notepad and Paint for Windows 11. Notepad now supports more Markdown, like strikethrough text and nested lists. There’s a new welcome screen and faster streaming results for AI-powered Write, Rewrite, and Summarize features, though you need a Microsoft account to use them. Paint gets an AI-powered “Coloring book” feature, which works only on Copilot+ PCs, and a fill tolerance slider for better color control.

Many users are happy about Markdown in Notepad, but some wish for even more features. Others want Notepad to stay simple. Some dislike needing a Microsoft account for AI tools. For Paint, people are excited about the coloring book, but sad that some features require special hardware. Most users are glad to see updates, but hope the apps do not become too complex or force everyone online.

On privacy, a recent article shows that large language models (LLMs) can identify people from anonymous posts with high accuracy. Researchers tested this on sites like Hacker News, Reddit, and LinkedIn, and found that LLMs can connect anonymous accounts to real people using just a few comments. LLMs can guess where you live, your job, and hobbies, and then search the web to find your identity. This makes privacy online much harder, as even using fake names may not help.

Commenters were surprised and worried about how powerful these AI tools are. Some say this problem is not new, but LLMs make it much easier. There are concerns about government or company surveillance, and about open-source AI making the problem worse. Some suggest sharing less personal information, choosing platforms that care about privacy, or hoping for new laws or tech solutions. Most agree users need to be careful about what they share online, as AI can now connect the dots far better than before.

In other software news, there is now a pure Go version of the tree-sitter runtime, which means you can use tree-sitter in Go without needing any C code or CGo. It works on any platform, helps with cross-compiling, and is much faster for small code changes. It supports 205 languages, and you do not need to recompile grammars. The library is useful for code editors, language servers, or static analysis tools.

People are excited about the pure Go version, especially for WASM or cloud builds. Many had problems with CGo in CI or deployment, and think this will help a lot. Some worry about increased memory use, but most agree the trade-off is worth it for easier builds. The maintainer says only one language is not fully supported right now. Many users thank the author and want to try it in their own projects.

Turning to energy, solar power in the US grew by 35% last year and produced more electricity than hydropower for the first time. US energy use also went up, with more heat pumps and electric cars. Solar and wind covered much of the extra demand, but coal use also rose by 13% because of higher gas prices and slow new plant building. Renewables are now close to a quarter of all US electricity, and more solar, wind, and battery storage are coming. Even so, more coal use could offset some environmental gains.

Commenters are excited about solar’s growth, but concerned about rising coal use. Some discuss cheap solar panels and how hydropower is limited, while solar can keep growing. Others ask about grid stability and the role of batteries. Some share their own solar experiences, and some say the US needs to use less energy overall to really help the planet.

Now, a look at Java’s garbage collection in OpenJDK 26. The article explains that older garbage collectors stopped the whole app to reclaim memory, so people focused on reducing pause times. With modern multi-core systems and new GCs like G1 and ZGC, most GC work runs in the background, and pause time is no longer enough to measure performance. OpenJDK 26 adds a new way to measure GC CPU time directly, both through logs and a Java API, so developers can see exactly how much CPU GC uses.

Commenters like the new API, saying it helps tune systems and understand real costs, especially in cloud setups. Some say only measuring explicit GC time misses hidden costs, and share stories about switching to Go or Rust to avoid GC issues. There’s debate about pause times versus total CPU use, and tips on tuning heap sizes. Most agree better GC metrics are a big step forward for Java performance.

Finally, a story about why Los Angeles is not fixing city streets fast enough. Many roads are old and need repairs, but the city says it lacks enough money. Repaving is costly, and leaders must choose which streets to fix first, often leaving smaller roads waiting for years. Sometimes, only quick patches are done, which do not last. Weather and heavy traffic make things worse.

Commenters say the city should spend more on roads, while others blame waste and poor planning. Some feel the way streets are chosen for repair is unfair. Others suggest better materials or new technology, but agree that big cities everywhere face the same problems. Some say people should report bad streets, while others think reports do not always help. In the end, everyone wants smoother streets, but there is no easy answer.

That’s all for today’s episode. Thank you for listening to the Hacker News Daily Podcast. See you next time!