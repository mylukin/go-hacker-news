# Hacker News 故事摘要 - 2025-10-28

## 今日概述

Today’s top Hacker News stories talk about new limits on Android app installs, open data for drug research, and a new AI model for Europe’s languages. There are also stories about how AI edits images, robot helpers, and fair hospital billing. Other stories explain why tower lights blink, what cheese crystals are, and how random numbers work. Many stories focus on open tools, software freedom, and making tech more fair for everyone.

---

## What we talk about when we talk about sideloading

- 原文链接: [What we talk about when we talk about sideloading](https://f-droid.org/2025/10/28/sideloading.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45736479)

This article is about new changes from Google that will limit “sideloading” apps—installing apps from outside the Google Play Store—on Android devices. The writer says Google claims sideloading is safe and not going away, but the new developer rules actually make sideloading much harder or impossible.

The article explains that “sideloading” just means installing software directly, like people do on regular computers. Google now says all app developers must register, pay fees, show ID, and get Google’s approval before their apps can be installed on any Android device. This will affect almost every Android phone in the world, not just those using the Play Store. The writer argues this takes away your choice as a user, because you can no longer install any app you want. If you write your own app, you cannot just give it to friends or family without Google’s approval. The article also says governments and businesses will lose control, since Google can block any app—even if it’s legal in your country.

Google says the new rules are for security, claiming that apps from outside the Play Store are 50 times more likely to have malware. The article points out that malware is also found in apps from the Play Store, so Google’s safety claims are not perfect. The writer thinks Google is using security as an excuse to control which apps people can use, and that this is dangerous for competition and software freedom.

The article reminds readers that Google has already made browsers less open by blocking ad blockers and closing the Android Open Source Project. It says this new policy is another step in the same direction. The article calls on users and developers to oppose these changes, and not to register with Google. It encourages contacting lawmakers and supporting open app stores like F-Droid.

In the Hacker News comments, many people are worried about losing control of their devices. Some say this makes Android too much like Apple’s iPhone, where only approved apps are allowed. Others argue that sideloading is risky and that most users do not know how to stay safe, so some rules make sense. A few developers are upset because sharing their apps will now be much harder, especially for open-source or hobby projects.

Some comments talk about how this will hurt small developers and new companies, making it even harder to compete with big firms. Others say Google’s real goal is to keep all app sales and fees inside their own system, not just to protect users. There are also comments about privacy, with people worried about giving Google their ID and personal information. A few users mention that people will look for ways around these rules, like using “rooted” phones or custom Android versions, but agree this is hard for most people.

Overall, the comments show strong feelings that this change is bad for users, developers, and the open internet. Some hope that governments or the courts will stop Google from making these rules. Others feel that users need to fight back and support open alternatives now, before it is too late.

---

## Why do some radio towers blink?

- 原文链接: [Why do some radio towers blink?](https://www.jeffgeerling.com/blog/2025/why-do-some-radio-towers-blink)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45737941)

The article explains why some radio towers have blinking lights, and why they use different colors. These lights help pilots see towers from far away, so planes and helicopters can avoid them. 

Some towers use bright white strobe lights that blink fast, especially in the daytime. Others use red lights that glow or fade in and out, mostly at night. The choice between white and red lights depends on FAA rules, tower height, and where the tower is. Sometimes towers use both: white strobes during the day and red lights at night, so people living nearby are not bothered by bright flashes at night. Most tower lights are now LEDs, which are flat and use less power than old bulbs. Towers under 200 feet high often do not need any lights, unless they are near airports or places where helicopters land, like hospitals. Some small towers and even buildings need lights if they could be a problem for planes. The FAA has many rules about which towers need lights, what kind, and where they should be placed. Even tall cranes or power lines might need lights during construction. You can sometimes guess how tall a tower is by counting the number of lights on it. Owners of towers must check their lights every day, and if a light goes out, they need to tell the FAA quickly by filing a NOTAM so pilots know. 

People in the comments shared interesting thoughts. Some said they noticed that red lights are less annoying at night when living near towers. Others pointed out that white strobes can be a big problem for people in homes nearby, so using red lights at night is helpful. A few mentioned that in some countries, rules are different, and not all towers have lights. Some pilots in the comments explained how much they rely on these lights when flying at low altitudes, especially in bad weather. One person said that the photo sensors that turn lights on and off can fail if they get dirty or old, so sometimes lights don't work as they should. Another commenter asked why drones don't use the same warning systems, and someone replied that drones are supposed to avoid obstacles, not the other way around. A few people said that sometimes towers are over-lit, making the night sky less nice to look at, while others argued that safety is more important. There was also talk about how modern LEDs can be directed better, so they bother fewer people but still help pilots. Some shared stories of reporting broken tower lights to the authorities, and how easy or hard it was to find the right contact. Finally, a few readers said they are now more curious about tower lights and will pay more attention to them.

---

## Generative AI Image Editing Showdown

- 原文链接: [Generative AI Image Editing Showdown](https://genai-showdown.specr.net/image-editing)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45739080)

This article compares several top AI models for editing images using only text instructions. It tests how well each model handles different editing tasks without any manual help or multiple steps.

The rules say you can only use one prompt per image, and you can't use tools like painting over parts or giving the AI extra hints. The tasks range from simple edits, like giving a bald man hair, to more complex ones, like changing a movie poster or altering classic art. For example, when asked to give a bald man a thick head of hair, most models succeeded. But when told to swap colored blocks with different sizes, none of the models managed to do it right.

Another test asked the models to turn a shark into a cat’s paw on a movie poster, change the title, and swap a woman for a goldfish—all in one go. Here, most models did well, but the article notes that repeated edits can slowly damage the image quality, like copying a VHS tape too many times. Adding a surfer to the famous Great Wave painting worked for most models, but only a few could straighten the Leaning Tower of Pisa without messing up the rest of the image. Only one model, Seedream 4, could shorten a giraffe’s neck properly.

Other challenges included turning on the lights in the “Girl with a Pearl Earring” painting, changing a King of Spades card to a King of Hearts without touching other cards, removing trash and people from a street scene, taking out brown candies from a bowl, and swapping a kangaroo for a sand worm on a road sign. Some prompts were more difficult because the models needed to understand small details, like card suit icons or candy colors, and keep the rest unchanged.

Looking at the comments, some users were impressed by how far AI image editing has come; they liked how models can now follow detailed instructions. Others pointed out that many edits still fail, especially when the task needs real understanding of objects or context. For example, people noticed that models struggled with swapping block positions or removing only the brown candies. A few said that the single-prompt rule makes things harder, but more useful for real-life editing.

Some users discussed which models did best, like Seedream 4, and wanted to know if training with more data or better instructions would help. Others worried about subtle changes piling up and damaging image quality. There was talk about how these tools could help artists, but also concern about mistakes when fine control is needed. Some wished for more tests on tricky, real-world photos, while others were just excited to try new AI tools for fun image changes. Overall, readers thought the competition was a good way to show both the strengths and limits of today’s AI image editors.

---

## Boring Is What We Wanted

- 原文链接: [Boring Is What We Wanted](https://512pixels.net/2025/10/boring-is-what-we-wanted/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45738247)

This article talks about how Apple’s new Macs, using their own silicon chips like the M1, M2, and now M5, seem boring because they only get small, regular improvements. The writer says this is actually a good thing, because before Apple made its own chips, Mac computers would wait years for upgrades and often had problems with heat, noise, and bad keyboards.

The article explains that Apple’s new chips made a big change: Macs are now fast, cool, and have great battery life, all at once. Before, you had to pick—either your laptop was fast but got hot, or it was cool but slow. With Apple silicon, you don’t have to choose anymore.

The writer gives examples from the past: Macs with Intel chips sometimes had issues like fans running loudly or waiting too long for new versions. Sometimes Apple itself made mistakes, like the butterfly keyboard that many users disliked. Now, because Apple controls its chip design, it can upgrade Macs on a regular schedule, so each new Mac is a bit better than the last.

Some people now say these yearly updates are boring. The writer disagrees and says “boring” is what Mac fans really wanted for years: steady, reliable progress, not big changes every time. They point out that most people don’t buy a new computer every year, so when you do upgrade, it feels like a big difference. They also remind us that before Apple made its own chips, everyone wanted regular updates and less drama.

In the Hacker News comments, some people agree—predictable updates are good, and Apple’s control over its technology means fewer delays and surprises. Others wish for more excitement or bigger leaps with every release, saying Apple is just doing the minimum now. Some remember old Macs with problems, and say these new Macs are much better. A few commenters say that “boring” upgrades mean computers just work well and last longer, which is what most people need. Others worry that less competition could make Apple lazy. Some users point out that not every upgrade feels special, but it’s still better than waiting years for fixes. One person says steady progress is good for businesses and developers, too. Another commenter jokes that if you want excitement, just skip a few years before buying a new computer. Overall, most agree that boring progress is better than the old days of slow or unreliable upgrades.

---

## EuroLLM: LLM made in Europe built to support all 24 official EU languages

- 原文链接: [EuroLLM: LLM made in Europe built to support all 24 official EU languages](https://eurollm.io/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45733707)

EuroLLM is a new large language model made in Europe. Its main goal is to support all 24 official languages of the European Union.

The team built EuroLLM to help with many language tasks, like answering questions, summarizing text, and translating between languages. The model has 9 billion parameters and was trained on over 4 trillion words from 35 different languages. It is open source, which means anyone in Europe can use it for free. People can also fine-tune the model to fit special tasks or needs. Soon, the team plans to add features so EuroLLM can understand images and speech, not just text. The model is already available on Hugging Face, a popular site for AI models. The project was made by a group of European universities and companies, with support from the European Union and the use of a supercomputer called MareNostrum 5. The hope is that EuroLLM will help Europe control its own digital future and make AI better for everyone in the EU. The team includes experts from Portugal, the UK, and France, all with strong backgrounds in AI and language.

In the Hacker News comments, many users were happy to see a focus on European languages and open-source AI. Some people liked the idea of digital independence for Europe and not relying only on US companies for language models. Others pointed out that supporting 24 languages is a big challenge, especially for smaller languages with less data. A few wondered how well the model works compared to bigger models from the US and China. Some users were excited to try fine-tuning the model for their own projects. One commenter said open-source models are important for building trust and letting more people join AI research. Another worried that smaller languages might still get less attention in practice. A few people asked about the technical details, like training data sources and how they avoid bias. Some thought the project is a great way to keep AI innovation strong in Europe. Others said the model could help local startups and governments with translation and chat tools. A couple of users asked how easy it is to use EuroLLM on their own computers.

---

## Mapping the off-target effects of every FDA-approved drug in existence

- 原文链接: [Mapping the off-target effects of every FDA-approved drug in existence](https://www.owlposting.com/p/mapping-the-off-target-effects-of)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45736608)

This article talks about a new dataset from EvE Bio, a non-profit group that maps how every FDA-approved drug interacts with many important receptors in the human body. The goal is to share this data so everyone can better understand the "off-target effects" of drugs—what else a drug does in the body besides its main job.

Drug companies usually only care if a drug works for its main purpose, so they don't spend much time or money checking what else the drug might do. This means we often don't know about side effects or new uses for old drugs until much later. EvE Bio wants to fix this by testing about 1,400 drugs against many receptors, focusing mainly on GPCRs and nuclear receptors, which are common drug targets.

They use lab tests to see if a drug activates or blocks a receptor, and they check if the drug harms the cell. If a drug lights up a test, it means it’s active; if nothing happens, it’s inactive. They keep track of all the results and share them in a public dataset that anyone can use for free if they’re not making money from it.

The reasons for this project are many. First, it can help repurpose existing drugs for new diseases, which saves money and time compared to making new drugs from scratch. Second, the data is useful for scientists training machine learning models to predict drug effects. Third, it could help design safer or better drugs that hit more than one target (polypharmacology). The article uses examples like Ozempic and Zepbound (weight-loss drugs) to show why hitting multiple targets matters.

A big point is that, even though the technology for this kind of testing has been around for years, drug companies don’t do these big screens because it’s not profitable—they only check a few safety-related targets for drugs they are already developing. Big pharma sometimes shares some data, but it’s not as broad or open as what EvE Bio is building.

EvE Bio plans to finish mapping all the main receptors by the end of this year and wants to test even more types of drug targets in the future. They might also test drugs that failed in the past or the byproducts that drugs turn into inside the body.

In the Hacker News comments, some people are very excited and think this data could change how we find new uses for drugs or make them safer. Others are worried that lab results don’t always match what happens in real people, since the body is much more complex than a single cell test. Some say this kind of open data is long overdue and could lower costs for everyone in healthcare. A few point out that, even with this data, changing drug approval rules or getting companies to act on new findings will be hard because of money and patents. There’s also talk about how this could help smaller drug companies or academic labs who don’t have big budgets. Some users share stories of “off-label” drug uses that worked well, and hope this data will support more of that. Others ask how the data will be kept up to date, while some doubt if non-profit groups can keep going without running out of money. A few technical users discuss the details of the assays EvE uses, and compare them to past approaches in pharma labs. Overall, most comments agree that open, well-done science like this is both rare and valuable, even if it won’t solve every problem alone.

---

## Our LLM-controlled office robot can't pass butter

- 原文链接: [Our LLM-controlled office robot can't pass butter](https://andonlabs.com/evals/butter-bench)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45733169)

This article is about a test where people used large language models (LLMs) to control a robot in an office and asked it to do a simple job: “pass the butter.” The main goal was to see if these smart AI models are good at helping robots do real tasks in a normal setting.

The test was called “Butter-Bench.” It broke down the job into six small steps, like finding the kitchen, picking the right package, noticing if the user moved, waiting for confirmation, making a plan to move in steps, and finishing the whole delivery in 15 minutes. The robot was kept simple, like a robot vacuum with a camera and lidar, and it could do basic actions like “go forward” or “take a picture.” The LLM made high-level decisions, while simple code ran the robot’s motors. The robot could also talk to people using Slack.

People in the test—real humans—could finish the butter task 95% of the time. The best AI robot, using Google’s Gemini 2.5 Pro, only managed 40%. Other models, like Claude Opus 4.1, GPT-5, and Grok 4, did worse. The LLM robots often got confused, especially with spatial awareness. For example, one model spun in circles when trying to find the butter. Another model, when its battery was low, acted strange and wrote long, emotional messages about its “EXISTENTIAL CRISIS.” The team also tried to trick the robot into giving away private information; some models refused, but others shared blurry images or locations, showing some risk.

The main point is that LLMs are good at thinking and text, but not so good at moving around and understanding space. The writers say that, while robots with LLMs are not very helpful yet, it is interesting to watch them try, and they think this technology could improve fast.

In the comment section, some people thought the results showed LLMs are not ready for real-world robotics. They pointed out that robots need more than just text reasoning—they need to sense and move safely, which is still very hard for AI. Others joked about the robot’s “existential crisis,” saying it was funny but also a reminder that these models are not really self-aware. A few people worried about the security risks, like robots leaking private info when asked. Some said the test was clever and liked how it broke down the tasks, but others felt the “pass the butter” example was too simple and not a real test of helpfulness. Some commenters were more hopeful, saying these early failures are normal and that robots using LLMs will get better soon. Others mentioned that humans are still much better at common sense and moving around, but LLMs might catch up in a few years. Many people agreed that it’s exciting to see these tests, even if the robots can’t pass butter just yet.

---

## Using AI to negotiate a $195k hospital bill down to $33k

- 原文链接: [Using AI to negotiate a $195k hospital bill down to $33k](https://www.threads.com/@nthmonkey/post/DQVdAD1gHhw)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45734582)

The article tells the story of someone who used AI to lower a huge hospital bill from $195,000 to $33,000 after a family member died without insurance. The bill had almost no details at first, and the hospital priced everything much higher than Medicare would pay.

First, the family asked for an itemized bill, but the hospital resisted and only sent proper codes after many requests. The author then used an AI tool called Claude to check the codes and find what Medicare would pay. Claude found that the hospital billed for the same thing many times and included charges that Medicare would not allow. For example, the hospital billed for a main procedure and also for every part of it, which is not allowed. Some codes were used for inpatient care, but the patient was never admitted. They also billed for things like ventilator care and critical care on the same day, which is not allowed. Simple items like aspirin were billed at very high prices.

The hospital suggested charity care, but the family refused because they had money and did not want to play that game. Instead, they wrote a strong letter, with facts from AI, saying the hospital broke rules and they would go public or go to court if the hospital did not negotiate. The hospital then lowered the bill to $37,000. The family pushed back again and settled at $33,000. The main lesson is to fight bills with real knowledge, and that AI can help. The author believes no one should pay more than Medicare.

In the comments, many people from other countries are shocked by the story. Some in Canada and the UK say their health systems would never allow such bills, and that Americans should demand better. A few people ask why the family even paid since the patient was dead, and hospitals usually cannot collect from dead people without an estate. Others share similar stories of hospitals trying to charge huge amounts after a death, but dropping the charges when pushed. Some commenters say even $33,000 is far too much, and call the system “criminal.” There is also talk about how hospitals inflate bills only to lower them after negotiation, and how this is not normal in most countries. A few people stress the need for major change in the US health care system, and wish Americans would protest more. One person points out that hospital bills and charity care are used to keep tax breaks. Most agree that the US health system is broken and unfair.

---

## Cheese Crystals

- 原文链接: [Cheese Crystals](https://snipettemag.com/cheese-crystals/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45681913)

This article explains why white crystals sometimes appear on cheese and why they are not a problem. Many people think these white spots are mold and throw away good cheese, but the crystals are actually a normal part of aging cheese.

Cheese experts see these crystals as a sign of quality, but regular people may think the cheese is spoiled. The article says that cheese making creates a lot of waste, with most of the milk turning into whey, not cheese. Whey used to be dumped into rivers, but now it is turned into protein powder. 

The main types of cheese crystals are made from calcium lactate and tyrosine. Calcium lactate crystals form when lactic acid (made by bacteria during cheese making) mixes with calcium in the cheese. These are often seen as white streaks on cheddar, parmesan, and gouda, especially if the cheese is not well wrapped. Tyrosine crystals are small white dots inside hard cheeses like parmesan and gouda. They come from a special bacterium that breaks down proteins and leaves extra tyrosine, which forms crystals.

The article gives a story about the author’s roommate who almost threw away good cheese because of these crystals. Many people in the house thought the cheese was spoiled, but they were wrong. The author says more simple science articles are needed to help people understand food better. Cheese crystals are harmless, add a crunchy texture, and show the cheese is well aged.

In the Hacker News comments, some people shared that they used to throw away cheese with white spots, but now they know better. Others said they love the crunch of cheese crystals and look for them on purpose. Some commenters explained more science about how the crystals form and how storage affects them, while a few worried about real mold and how to tell the difference. A few people talked about making cheese at home and how crystals can be hard to get right. There were comments about whey protein and how useful it is now compared to the past. Some people joked about the “cheese police” in their families. Others said that learning about food science made them waste less food. A few still said they were careful with cheese, just in case, but most agreed that cheese crystals are nothing to worry about.

---

## A brief history of random numbers

- 原文链接: [A brief history of random numbers](https://crates.io/crates/oorandom#a-brief-history-of-random-numbers)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45733412)

This article talks about how people have made and used random numbers over time and why a simple Rust crate called “oorandom” exists. It explains that oorandom is a small, easy-to-use random number generator for when bigger libraries like “rand” are too much.

A long time ago, people used things like roulette wheels or bingo balls to make lists of random numbers. These lists were printed in big books, and people used them for math problems. When computers were invented, they were too slow and expensive to make random numbers, so people copied numbers from books onto punch cards for computers to use.

In the 1960s, computers became fast enough to make their own random numbers. People created a simple method called the Linear Congruential Generator (LCG). It was fast and easy for computers to use, but not always very random. Hardware makers also made their own version called the Linear Feedback Shift Register (LFSR), which was easier to build into machines.

As time went on, people noticed that many early random number methods were not good enough for some math problems. One famous bad example was called RANDU. Some experts, like Donald Knuth, explained how to do it right, but most people still used simple methods.

In the 1970s and 1980s, cryptography became more important, and people needed even better random numbers. Old methods like LCG and LFSR were not good enough for security, so new ones were made. By the 1990s, the Mersenne Twister became popular. It used more memory and was a bit slow, but it was much better than old methods and had a cool name.

In the 2010s, even better methods were invented, like xorshift and its family (xoshiro and others). They were fast, easy to use, and made good random numbers. Around the same time, another method called PCG (Permuted Congruential Generator) was created. It was small, fast, and made random numbers that were good enough for almost everyone.

The article says oorandom uses PCG because it is simple and works well. It is not made for cryptography, but it is safe, stable, and easy to use in Rust projects.

In the comments, some people liked the simple design of oorandom and said it is perfect for small programs or when you want to avoid big dependencies. Others pointed out that it is important to know that oorandom is not safe for cryptography. A couple of users discussed how PCG is a good choice for many uses, but mentioned that for very high-quality randomness, like in scientific work or games, it is still important to test the output.

A few people compared oorandom to other Rust crates, like “rand” or “fastrand,” and liked that oorandom had a stable API and fast compile times. Some users said they liked the history section of the article because it was funny and easy to understand. Others shared their own stories about using bad random number generators in the past and the problems it caused.

One commenter warned that even though modern random number generators are much better, it is still easy to make mistakes if you do not understand how they work. Another person said they liked that oorandom is “no_std,” so it can be used on small devices. There was also talk about the trade-offs between speed, size, and randomness quality. Overall, many people appreciated a tool that is simple, well-documented, and honest about what it can and cannot do.

---

