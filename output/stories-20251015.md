# Hacker News 故事摘要 - 2025-10-15

## 今日概述

Today’s top Hacker News stories focus on new AI hardware from Apple, a faster and cheaper coding AI from Anthropic, and major security warnings for developers and companies. There are also stories about open-source software, hard drive reliability, and new ideas in physics. Some stories discuss risks in developer tools and open source workflows. If you’re interested in AI, security, or programming ideas, today’s stories have a lot to offer.

---

## Apple M5 chip

- 原文链接: [Apple M5 chip](https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45591799)

Apple just announced the M5 chip, which is their newest processor for MacBook Pro, iPad Pro, and Vision Pro devices. The main focus is much better AI performance and faster graphics. The M5 is built using new 3-nanometer technology, making it more efficient and powerful. It has a 10-core GPU, and each core now includes a special Neural Accelerator for running AI tasks much faster—over 4 times faster than the M4 chip. The graphics also get a big boost, with up to 45% better performance and new features like third-generation ray tracing for more realistic visuals in games and 3D apps.

The CPU has up to 10 cores, split between performance and efficiency, and is now the fastest Apple has made, with up to 15% better speed for multitasking. The Neural Engine (used for AI tasks) is now 16 cores and is both faster and more energy efficient. The new memory system is also improved, with unified memory bandwidth up to 153GB/s, almost 30% more than before, letting the chip handle bigger AI models locally. This means users can run advanced AI apps (like image generators and language models) directly on their devices, without needing to use the cloud.

Apple says these improvements help with creative work, gaming, and even everyday tasks, thanks to better AI in things like photo editing and writing tools. They also talk about how the M5 chip uses less energy, which supports their goal to be carbon neutral by 2030.

Hacker News commenters have mixed opinions. Some are impressed by the technical leap, especially the AI accelerators built into the GPU, saying this could help Apple stay ahead in AI features. Others point out that Apple’s benchmarks always compare to their older chips, not to other brands, so it’s hard to tell how the M5 really stacks up against Intel, AMD, or Nvidia for things like gaming or machine learning. A few worry that these hardware upgrades may not help if software doesn’t keep up, noting that many AI and developer tools still don’t work well on Apple’s platform.

Some developers are happy about the faster on-device AI, as it could mean more privacy and better performance for users. But others are cautious, wanting to see real-world tests before getting excited. There are also comments about the price of new Apple devices and how each year’s chip upgrade can feel minor for most users. A few people also ask if the improved AI features will actually make a difference in daily use, or if it’s more of a marketing push. Overall, the M5 is seen as a strong update, but many want to see if the software and real-world use will match Apple’s promises.

---

## Claude Haiku 4.5

- 原文链接: [Claude Haiku 4.5](https://www.anthropic.com/news/claude-haiku-4-5)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45595403)

Claude Haiku 4.5 is a new AI model from Anthropic, focused on fast and cheap performance for coding and real-time chat tasks. The model gives almost the same quality as their top model, Sonnet 4.5, but at one-third the cost and more than double the speed.

Haiku 4.5 is even better than Sonnet 4 in some areas, like using computers and working with other AI agents. This makes it very useful for things like chatbots, coding helpers, and customer service bots. Developers can use it for rapid prototyping and big coding projects, and it responds quickly, which is important for pair programming. The model is now available through the Claude API, Amazon Bedrock, and Google Cloud, and it costs $1 for a million input tokens and $5 for a million output tokens.

Performance benchmarks show Haiku 4.5 reaches about 90% of Sonnet 4.5’s coding ability. It’s also much faster—up to five times quicker than Sonnet 4.5 in some tests. The model does well in tasks like following instructions for slide text and generating code for tools like GitHub Copilot. Claude Haiku 4.5 is also safer than earlier models. Safety tests found it had fewer risky behaviors and lower chances of harmful outputs, so it is rated at a less strict safety level (ASL-2) than some other models.

The article explains the test methods used, like running the model many times on real coding and language tasks, and comparing it to OpenAI’s GPT-5 and Google’s Gemini. Developers don’t need to change much in their code to start using Haiku 4.5, making it easy to upgrade from older models.

In the comment section, many people are excited about the speed and low price. Some say this will help more developers use strong AI in their projects, especially those with limited budgets. Others warn that while benchmarks look good, real-world results might differ, especially for bigger and more complex jobs. A few users are happy about the improved safety, while some ask what “safety” really means and if the tests are enough.

Some commenters compare Haiku 4.5 to OpenAI and Gemini models, wondering if Anthropic can keep up. There are worries about possible job loss if coding AIs keep getting better and cheaper. A few developers share that switching to Haiku 4.5 was easy and made their apps faster, but others wish the API had more features. One user points out that using several smaller, faster AIs in parallel could open new ways to build software. Finally, a few skeptics say that AI hype is high, but only time will tell if Haiku 4.5 changes real developer workflows.

---

## I almost got hacked by a 'job interview'

- 原文链接: [I almost got hacked by a 'job interview'](https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45591707)

A developer was almost hacked after a fake job interview from a company that seemed real on LinkedIn. The attacker used a professional company profile, a legit-looking coding challenge, and a test project sent before the meeting.

The developer, usually careful, got a coding assignment that looked normal—a React/Node.js codebase from Bitbucket with clean documentation and a company logo. In a rush to prepare, he checked the code but did not run it right away. Before starting the app, he asked his AI assistant to scan for anything weird. The AI found hidden, obfuscated code in the user controller file. This code, when run, would fetch and execute malware from an outside server. The malware could steal files, passwords, crypto wallets, and more. The attacker’s server went offline after 24 hours, making it hard to trace. VirusTotal confirmed the payload was very bad.

The scam was detailed and smart: a fake LinkedIn profile matched to a real company, professional language, a reasonable coding test, and good scheduling tools. Everything looked normal and trustworthy. The attack worked by using pressure (finish the test quickly), authority (professional profiles), and familiarity (a common coding test).

The main lesson: always sandbox unknown code, use AI to scan for malware, and double-check everything even if it looks real. Developers are easy targets because they often run code from strangers and have access to valuable data.

In the comments, some people were shocked at how advanced and believable the scam was. Others said this type of attack is becoming more common, especially for developers working with crypto. A few said it’s easy to get tricked when you trust LinkedIn or Bitbucket. Some developers shared their own stories of fake interviews or test projects with hidden malware. Others reminded everyone to always use containers or virtual machines for unknown code. A few argued that even advanced users can make mistakes when they feel rushed or pressured. Some people suggested that companies and platforms like LinkedIn should do more to stop fake profiles and scams. Others felt that developers must always be extra careful, saying this story is a good warning. Many agreed that using AI to scan code for threats is a smart new trick. Some worried that these scams could hit big companies if just one developer makes a mistake. A few also questioned if the company or Bitbucket could have done more to prevent this. Overall, the Hacker News crowd agreed: be paranoid, check everything, and never trust code from strangers.

---

## Gravity Can Explain the Collapse of the Wavefunction (Sabine Hossenfelder)

- 原文链接: [Gravity Can Explain the Collapse of the Wavefunction (Sabine Hossenfelder)](https://arxiv.org/abs/2510.11037)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45598309)

This article is about a new idea from Sabine Hossenfelder on how gravity might explain why the wavefunction in quantum physics seems to “collapse” when we make a measurement. The wavefunction collapse is a big mystery in quantum mechanics because it looks like the act of measuring changes reality in a strange way.

Hossenfelder suggests that if we bring gravity into quantum theory, we can explain this collapse without adding extra rules. In her model, gravity and matter are connected at a basic level. When a quantum system gets big enough, gravity acts on it in a way that “selects” one possible outcome, making the wavefunction collapse. This happens locally, so the effect is not “spooky” or faster than light. Her idea does not need any new parameters or special numbers to work; it uses only what we already know about gravity and quantum physics. The model also gives predictions that scientists can test in experiments, which is important for any new idea in physics. If the model is right, we should be able to see certain effects in future experiments with very sensitive devices.

People in the Hacker News comments have mixed feelings. Some are excited and think it’s great to see a simple idea that connects gravity and quantum mechanics. Others are more skeptical, saying this kind of model has been tried before, and it is hard to get real proof. A few mention that testing gravity at the quantum level is very difficult because the effects are so small. Some users wonder if this idea could fit with other theories, like string theory or loop quantum gravity. One commenter says it’s nice that the model is local and does not break special relativity. Others ask if the predictions are clear enough to be tested soon, or if they are still too vague. A few users worry that adding gravity does not really solve the mystery, just moves it to a new place. Some hope this idea will make more physicists think about the problem in new ways. Others remind everyone that physics needs experiments, not just clever ideas. Overall, the discussion shows both hope for progress and the usual caution that comes with big new theories.

---

## Pwning the Nix ecosystem

- 原文链接: [Pwning the Nix ecosystem](https://ptrpa.ws/nixpkgs-actions-abuse)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45592401)

This article explains how the authors found a security problem in the Nix ecosystem, using GitHub Actions. They show how some workflows could let attackers run bad code or steal tokens, which could have put the whole Nix project at risk.

The main issue comes from using GitHub Actions, a tool that runs code when people push changes or make pull requests. Some actions use a trigger called `pull_request_target`, which gives more power to workflows, such as access to secrets and the ability to write to the repository—even from forks. If the workflow is not careful, attackers could use this power to do bad things.

The authors found two dangerous examples. In the first, a workflow checked changed files using `xargs` and `editorconfig-checker`. If someone named a file in a tricky way, they could inject commands or arguments, because `xargs` is not safe with untrusted input. In the second example, a workflow checked a file called OWNERS. Attackers could replace this file with a link to another file on the server, such as a credentials file. When the workflow ran, it would print out information from the secret file, letting attackers steal tokens with write access to the Nix repository.

Once the authors found these problems, they told the maintainers, who quickly fixed them by disabling dangerous workflows and changing how they handle untrusted data. They also made sure permissions were set more safely and renamed the workflows to avoid more problems.

The main lessons: never mix untrusted data with secrets, only give workflows the permissions they need, and always read the documentation about GitHub Actions security. If you think your organization is at risk, you can quickly disable all actions in the settings.

In the comments, some people were surprised such simple mistakes were present in a big project like Nixpkgs. Others said these problems are common, because GitHub Actions is flexible but easy to misuse. A few users argued that YAML and the way Actions are designed make it easy to make mistakes, and think GitHub should do more to help users avoid them. Some developers shared their own stories of similar bugs in their projects, while others pointed out that even with warnings, many people do not fully understand how powerful `pull_request_target` is. A few praised the authors and maintainers for acting fast and sharing what they learned, saying this helps everyone be more careful. One comment suggested better tooling to scan for risky workflows. Another person said the real answer is to limit permissions by default and require reviews for all changes to workflows. Some users discussed whether it's possible to make CI systems truly safe, or if the risks will always be there. Lastly, a few thanked the authors for their clear write-up and links to more resources, saying this is a good lesson for the whole open source community.

---

## Are hard drives getting better?

- 原文链接: [Are hard drives getting better?](https://www.backblaze.com/blog/are-hard-drives-getting-better-lets-revisit-the-bathtub-curve/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45595724)

This article looks at whether hard drives are getting better by using data from Backblaze’s data centers over the last 13 years. The main question is if the old “bathtub curve” idea—where hard drives fail a lot at the start, then work well for years, then fail again near the end—is still true.

The article explains that the classic bathtub curve shows many early drive failures, steady performance in the middle, and rising failures at the end. But Backblaze’s real-world data does not match this simple pattern. Instead, their drives today last much longer and fail less often, especially at the beginning and middle of their lives. For example, in 2013, failure rates peaked at about 13-14% after around 3-7 years. In 2025, the peak failure rate dropped to just over 4% and happened after more than 10 years. This is a big improvement.

The article also describes how Backblaze’s drive pool has changed. In early years, they used mostly consumer drives and had fewer drives, which made small changes in data seem bigger. Now, they use more drives (over 300,000 in 2025), better decommission drives, and buy in bulk. This makes their data more stable and reliable.

The article shares technical details about how they tracked drive “age” and failure rates using SQL queries. It also explains that drives are often retired before they actually fail, which lowers the failure rates shown in the data.

The piece argues that the bathtub curve is not wrong, but it is too simple. It ignores things like workload, manufacturing changes, and how drives are managed. Data center environments are more controlled than home use, but there are still surprises that affect failure rates.

Backblaze says that, overall, hard drives in their data centers are getting better and lasting longer. They encourage readers to look at their open dataset and follow future reports for more updates.

In the Hacker News comments, many people agree that hard drives are getting better and say they have also seen drives lasting longer at work and at home. Some users point out that Backblaze’s data comes from data centers, which use drives differently than home users. They warn that people at home might not get the same results.

Others discuss if Backblaze’s method of retiring drives early makes the numbers look better than real-world results. Some note that modern drives have better error correction and smart features, which help them last longer. A few users miss the days when drives were cheaper and easier to repair.

There is debate about whether Backblaze’s situation is special. Several people say that buying in bulk and good drive management make a big difference. Others worry about rare, sudden failures that can still happen no matter what.

Some commentors share stories of using old drives for over a decade without problems. Others mention new problems, like higher costs for bigger drives or firmware bugs. A few ask for more open data so they can check the results themselves.

Overall, most agree that hard drives today are more reliable than before, but some warn that statistics can hide certain risks. Many like that Backblaze shares real data and hope to see more updates in the future.

---

## Show HN: Halloy – Modern IRC client

- 原文链接: [Show HN: Halloy – Modern IRC client](https://github.com/squidowl/halloy)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45590949)

Halloy is a new open-source IRC client built in Rust, made to work on Mac, Windows, and Linux. It aims to be simple, fast, and easy to use, with a modern interface using the Iced GUI library. The client supports many new IRCv3.2 features like account notifications, chat history, message tags, and SASL authentication. Users can join multiple servers and channels at once, use keyboard shortcuts, and get notifications. Halloy has auto-complete for nicknames, commands, and channels, plus a command bar for quick actions. It also supports custom themes and a portable mode. You can install Halloy from Flathub, Snap Store, or build it from source, and there is clear documentation online. The project is released under the GPL-3.0 license and has a growing number of contributors.

In the comment section, some people are excited to see a modern IRC client, especially one written in Rust. They mention that IRC still has a loyal user base, and new tools can help keep it alive. A few users like that Halloy is cross-platform and open-source. Others ask about features like DCC file transfers and bouncer support, and some are happy to see SASL and IRCv3.2 support. A few developers share their own stories of making IRC clients or talk about how hard GUI programming can be. Some users wish for mobile versions, while others think desktop clients are better for IRC. There are comments about the look and speed of the app, and some people wonder if it will be easy for beginners. A few are concerned about missing features or bugs, but most agree that it is a good project with lots of promise. Others discuss how much they miss the old days of IRC and hope this client will make it easier for new users to join. Overall, people like the idea and are happy to see fresh work on classic chat tools.

---

## Princeton Engineering Anomalies Research

- 原文链接: [Princeton Engineering Anomalies Research](https://pearlab.icrl.org/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45509713)

The article talks about the Princeton Engineering Anomalies Research (PEAR) program, which studied how human minds might affect machines and physical systems. PEAR was part of Princeton University for almost 30 years, and now its work continues with other groups and companies.

PEAR's main idea was to test if human thoughts or intentions could change the results of experiments with random machines, like Random Event Generators (REGs). The team did many experiments where people tried to influence these devices just by focusing their thoughts. They also made theoretical models to explain any strange results they found. Over time, PEAR published many articles and essays about their work. Some research looked at things like remote viewing or how people might sense information at a distance. PEAR also explored what their findings could mean for science, engineering, and even spiritual ideas.

Now, PEAR works with the International Consciousness Research Laboratories (ICRL) to archive old research and share it with more people. They also helped start a company, Psyleron, that sells REG devices, so anyone can try these experiments. PEAR wants to keep working on education, outreach, and new projects, while being serious about good science. They offer lots of material online and even a DVD with lectures and a virtual tour of their lab.

People on Hacker News have many opinions about PEAR. Some are very skeptical and think the results are more about wishful thinking than real science. They point out that other scientists have not been able to repeat PEAR’s findings, and that the effects are very small and could just be chance. Others find the research interesting, even if they are not sure it is true, and say it is good to question what we know about consciousness. A few commenters mention that testing ideas like this is important, because sometimes strange things lead to new discoveries. Some people are excited that the data and methods are open, and want to try the experiments themselves. But many users still worry that the research is not solid enough, and that it mixes science with spiritual beliefs too much. Overall, the comments show a mix of curiosity, doubt, and a little hope that we might learn something new about the mind and reality.

---

## Monads are too powerful: The expressiveness spectrum

- 原文链接: [Monads are too powerful: The expressiveness spectrum](https://chrispenner.ca/posts/expressiveness-spectrum)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45555426)

This article talks about monads in functional programming and asks if they might be too powerful for most needs. The writer explains that monads let you build programs where each step can depend on the result of the last step, which is great for making flexible programs in languages like Haskell.

But, the writer says, this flexibility comes with a cost. When your programs can do anything at any time, it's hard to know what they might do before running them. That makes static analysis—where you check your code for problems before running it—much harder. Monads are so expressive that you can't always predict what effects (like reading a file or deleting data) will happen just by looking at the code.

The article introduces a spectrum: on one side, you have strong static analysis and less expressive code; on the other, you have very expressive code that’s hard to analyze. Monads are on the expressive side, but sometimes that's more power than you really need. For example, if you create a "ReadWriteDelete" effect, you can't easily tell if a program will call "deleteMyHardDrive" without actually running it.

The writer shows that using less powerful tools—like applicatives—can help. Applicatives are limited compared to monads: you can't use the result of one effect to decide the next. But because of this, it's easy to analyze what a program will do before running it. You can even list all the effects a program will perform.

There's also something called selective applicatives, which are between monads and applicatives. They let you branch into different paths, but you still have to list all the possible branches up front. This means you get a bit more power than applicatives, but you still have some ability to analyze programs before running them.

However, selective applicatives are harder to write and read. You can't do everything you can with monads, like loops or using results from effects in future steps. The writer says there's no perfect tool yet, but it's good to keep looking for the right balance between power and safety.

People in the comments had many thoughts. Some agreed that monads are often used when something simpler would work just as well, and that more static analysis is useful for safety and understanding. Others said that while applicatives and selective applicatives are interesting, monads are still important for real-world programs where you need a lot of flexibility.

A few commenters pointed out that it’s up to the developer to choose the right tool for the job—sometimes safety is more important, and sometimes you need more power. Some mentioned that other effect systems or new research might bring better solutions in the future. There were also people who felt the examples in the article made the trade-offs clear and helpful, while others said the syntax for selective applicatives is too hard to use in practice.

A number of readers discussed how this problem is similar to issues in other languages, not just Haskell. They said that understanding the trade-off between power and safety is something all programmers face. Some shared their own experiences using these tools in big projects, saying that simpler systems are easier to maintain.

Finally, a few commenters liked the idea of finding a "sweet spot" between too much and too little power, and that the search for better abstractions is important for programming as a whole.

---

## F5 says hackers stole undisclosed BIG-IP flaws, source code

- 原文链接: [F5 says hackers stole undisclosed BIG-IP flaws, source code](https://www.bleepingcomputer.com/news/security/f5-says-hackers-stole-undisclosed-big-ip-flaws-source-code/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45592271)

F5, a big U.S. cybersecurity company, said hackers broke into their systems and stole secret flaws and source code for their main product, BIG-IP. The attack was discovered in August 2025 and lasted long enough for hackers to get into product development tools and engineering documents. BIG-IP is used by many top companies to manage web traffic and keep applications secure. F5 says that, even though the hackers took some sensitive files, there is no sign they used these secrets to attack anyone yet.

The company says the hackers did not change the software supply chain or put any bad code into their products. Customer data, like financial or support information, was not touched. Other products, such as NGINX and Silverline, were not affected either. After the hack, F5 made its systems more secure: they changed passwords, improved access controls, and added better threat monitoring tools. They also worked with security experts from NCC Group and IOActive to review their code and check for problems.

F5 has released updates and patches for BIG-IP and other products to fix the stolen flaws. Customers are being told to update their systems as soon as possible and follow new security best practices, such as using special diagnostic tools and not exposing management interfaces to the public internet. The company delayed telling the public about the hack because the U.S. government asked them to wait, likely to give time to fix important systems first. F5 says all services are still safe and running.

In the Hacker News comments, some users say this shows how risky it is to trust closed-source security products. Others point out that many companies depend on F5, so even a small leak is a big deal. Some are surprised that F5 did not notice the breach for so long, while others say these kinds of attacks are hard to spot, especially from skilled hackers. A few people worry that the stolen flaws might be sold or used later, even if there is no attack yet.

One commenter thinks F5 did the right thing by working with outside experts and sharing updates quickly. Another says customers must take their own steps to secure systems, not just trust vendors. Some users question if F5 is telling the full truth, since companies sometimes hide the worst parts in early reports. Others are glad that F5’s supply chain was not affected, since that could have caused even bigger problems. There are also suggestions for companies to use open-source tools when possible, so more people can review and spot issues. Finally, some users remind everyone that no system is perfect—attacks like this are a warning to stay alert and keep software up to date.

---

