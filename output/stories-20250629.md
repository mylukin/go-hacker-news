# Hacker News 故事摘要 - 2025-06-29

## 今日概述

Today’s top Hacker News stories talk about new tools for Rust error handling, funny tricks to fool malware in virtual machines, and a fast Go pub/sub library. There are also stories about Bloom filters, networking tools like Octelium, and a trick to avoid ransomware. People share their projects in the “what are you working on” thread. Other stories cover bringing back old software, IPv6 problems at home, and the real meaning of the “premature optimization” quote. Lots of new ideas and helpful tips for developers today.

---

## Error handling in Rust

- 原文链接: [Error handling in Rust](https://felix-knorr.net/posts/2025-06-29-rust-error-handling.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44416157)

This article talks about how Rust developers usually handle errors by making one big error enum for a module or crate, even if some errors in that enum don’t apply to every function. This can make code harder to read and work with, since you see error types that don’t really belong to your function.

The author points out that one of Rust’s strengths is its strict type system, but using huge error enums goes against this. These enums often include errors that a function can’t actually create, just to avoid the pain of making new error types and conversions for every function. Some developers use a different approach: they make each error its own struct and group related errors into sets, but this can be a lot of work and make code more verbose.

The article introduces the `error_set` crate, which uses macros to help define error sets quickly and generate conversions between them. With `error_set!`, you can build error enums from both variants and unions of other error sets. The `?` operator in Rust will also work if the function’s error set includes the error set from a called function, making error handling simpler.

There are code examples showing how these error sets work together. The author admits it’s still a bit verbose when you want errors with more data, but sees this as a fair trade-off. The article also mentions other crates, like `terrors` and `SmartErr`, that try different ways to make error handling nicer in Rust. The author wishes there was a crate that could auto-generate error enums just by looking at the function body.

In the comments, one user says they’re tired of seeing more macros in Rust and prefer simple error enums, since they are easy to understand and don’t add “magic” code. This person thinks error enums are good enough, and making them more complex just adds mental work. Another commenter likes the idea of error sets, especially for libraries that need clear and specific error types. They think good error types help developers know what can go wrong and are useful for documentation. A third commenter questions if it’s really helpful to have a different error type for every function. For them, if a file can’t be read, they don’t care which function failed, just that the read didn’t work.

Overall, some people like the new ideas for error handling, while others prefer to keep things simple with regular enums. The main debate is between having more detailed but complex error types, or using easy and familiar patterns.

---

## I made my VM think it has a CPU fan

- 原文链接: [I made my VM think it has a CPU fan](https://wbenny.github.io/2025/06/29/i-made-my-vm-think-it-has-a-cpu-fan.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44413185)

This article explains how some malware checks for a CPU fan to see if it is running inside a virtual machine (VM). The author wanted to trick a VM into showing that it has a CPU fan, so malware would not detect it as a VM. Many malware use Windows tools to look for hardware parts like the CPU fan, which is usually missing in VMs.

The author found out that Windows checks the SMBIOS data to see if a CPU fan exists. SMBIOS is a system that stores hardware information. The “Win32_Fan” class in Windows gets its data from SMBIOS, specifically type 27, which is for cooling devices like fans. The author used tools to see this data and learned how to add a fake fan entry.

To add fake SMBIOS data in Xen, the author followed old guides and set up a special file with the right bytes. This file described a fan and was linked to the VM’s settings. However, it did not work at first—Windows still did not show a fan in the VM.

After more research, the author found that a temperature probe (SMBIOS type 28) also needed to be faked, since the fan entry points to a temperature sensor. By creating both a fake fan and a fake temperature probe in SMBIOS, and adding them to the VM, Windows finally showed that a CPU fan was present.

For QEMU/KVM users, the process is easier. You can add SMBIOS data with a command-line option, and you do not need to patch the system or add special headers. You can even use your host’s SMBIOS data directly if you like.

In the comments, some people thought the project was clever and funny. Others pointed out that malware uses many tricks to detect VMs, so adding a CPU fan might not be enough. A few users explained that SMBIOS editing can help with other hardware checks as well. Some said this kind of tinkering is fun and teaches a lot about how computers and virtualization work.

A few commenters warned that copying SMBIOS data from real computers could cause problems or be used for cheating in games or software licensing. Others noted that anti-malware researchers often need to patch or fake hardware data to study malware safely. Some users shared tips about using QEMU, saying it is easier than Xen for this trick. One commenter asked if malware will soon check for even stranger hardware, making it a cat-and-mouse game.

Overall, people enjoyed the write-up and the step-by-step guide. Some said they learned new things about SMBIOS and virtual machines. Others joked about how malware keeps finding new ways to spot VMs, meaning there will always be more tricks to try.

---

## Ask HN: What Are You Working On? (June 2025)

- 原文链接: [Ask HN: What Are You Working On? (June 2025)](item?id=44416093)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44416093)

This post is a monthly thread where people on Hacker News share what projects they are working on. Many users talk about their startups, software tools, or side projects. Some are building new apps, others are improving old ones, and a few are just learning new skills.

One person is making a tool to help writers check their grammar. Another is building a service for tracking personal finances. Someone else is working on a simple website to teach people how to code. There are also projects about machine learning, home automation, and personal blogs.

Some users share updates on their open-source projects. Others mention they are writing books or creating online courses. A few people are starting newsletters or podcasts. Many talk about the problems they face, like finding users or staying motivated. Some ask for feedback or invite others to try their work.

In the comment section, people are supportive and offer advice. Some give tips on marketing or building a community. Others ask questions to learn more about the projects. There are also discussions about the tools and languages people use, like Python, JavaScript, or Rust.

Some users say it is hard to find time after work, but they keep trying. Others share how they balance a full-time job with building something on the side. A few mention making money from their projects, while some just build for fun. Many enjoy seeing what others are working on and feel inspired. Some wish there was an easier way to meet people with similar interests. Overall, the thread is full of encouragement, sharing, and advice.

---

## 4-10x faster in-process pub/sub for Go

- 原文链接: [4-10x faster in-process pub/sub for Go](https://github.com/kelindar/event)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44413809)

This article talks about a new pub/sub (publish/subscribe) library for Go that is much faster than older options. The author explains how this library works inside the same process, so it does not need to send data over the network.

The library is easy to use for Go programmers. It lets you send messages from one part of your program to another. Because everything happens in memory, it is very quick—4 to 10 times faster than using Redis or NATS for the same job. The author shows benchmarks comparing the new library with other tools. The results show lower latency and higher message rates.

The code uses Go channels and careful memory management to avoid slowdowns. There are examples in the article showing how to set up publishers and subscribers. You can use this library for things like logging, events, or simple task queues inside one application. It is not made for sharing messages between different computers.

The author also talks about when you should not use this tool. If you need messages to go to other machines, you still need Redis or NATS. But for fast communication inside one program, this is a better choice. The article gives tips for using the library with many subscribers or lots of messages.

In the comments, some people are excited about the speed and want to try it in their own projects. Others say networked tools like Redis are still needed for bigger systems. A few readers ask about thread safety and memory use when there are many subscribers. Someone points out that this library will not help if you need to restart your program and keep messages.

Some users say that for simple jobs, this library is a great fit, but for more complex needs, you still need bigger tools. Others ask about real-world examples and if it works well under heavy load. A few people share similar tools they have used or built. There is a discussion about when to use in-process tools versus networked ones, and some warn not to replace proven systems too quickly. Overall, the comments show interest but also careful thinking about the best way to use such a tool.

---

## Show HN: Octelium – FOSS Alternative to Teleport, Cloudflare, Tailscale, Ngrok

- 原文链接: [Show HN: Octelium – FOSS Alternative to Teleport, Cloudflare, Tailscale, Ngrok](https://github.com/octelium/octelium)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44412207)

Octelium is a new open-source tool that helps you connect computers and services over the internet, similar to Teleport, Cloudflare, Tailscale, and Ngrok. The project wants to give you more control over your network without depending on big companies.

Octelium lets you set up secure connections between your devices, even if they are behind firewalls or on different networks. It uses modern encryption to keep your data safe. You can create private networks, share files, or expose local web servers to the internet. The software is free and open-source, so anyone can look at the code or help improve it. Octelium works on Linux, Windows, and Mac, and there is a simple command-line interface. The tool tries to be easy to set up, with clear documentation and examples.

One special thing about Octelium is that you can run your own relay servers, instead of using a company’s cloud. This means you control where your data goes. Octelium supports peer-to-peer connections, but can also use relays if direct connection isn’t possible. The project’s goal is to let small teams or solo developers have the same networking tools as big companies, without giving up privacy or control.

People on Hacker News had a lot to say. Some users were happy to see a free and open-source alternative to popular services, because they worry about trusting their data to cloud companies. Others asked about setup difficulty, wanting to know if non-experts could use Octelium easily. A few commenters compared it to other tools like WireGuard and ZeroTier, asking what makes Octelium different or better. Some users liked the idea of self-hosting relay servers, but wondered about the security risks and maintenance work. There were questions about performance, such as how fast Octelium is for remote desktop or file sharing. A few people offered tips or suggested features, like mobile app support or better user interfaces. Others pointed out that open-source projects can be hard to keep alive, and hoped Octelium will get enough support. Some said they would try the tool for side projects or home labs. Overall, the community was interested but wanted to see how Octelium works in real situations.

---

## Many ransomware strains will abort if they detect a Russian keyboard installed (2021)

- 原文链接: [Many ransomware strains will abort if they detect a Russian keyboard installed (2021)](https://krebsonsecurity.com/2021/05/try-this-one-weird-trick-russian-hackers-hate/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44415233)

Many ransomware programs skip attacking computers if they see a Russian or similar keyboard installed. The article explains that this is a common trick used by cybercriminals from Russia and Eastern Europe to avoid trouble with local law enforcement. These criminals make sure their malware does not infect people in their own countries, so they don’t get the government’s attention.

The article talks about the DarkSide ransomware group, which was behind the big Colonial Pipeline attack. Like other groups, DarkSide’s software checks your computer for languages like Russian, Ukrainian, or others from the Commonwealth of Independent States (CIS). If it finds one, the malware stops and does nothing. This “do-not-install” list is hard-coded in many ransomware strains from that region.

The reason for this is simple: In Russia, police usually only investigate cybercrimes if someone inside the country complains. By not infecting local computers, hackers keep themselves safe from being hunted by their own government. Some security experts say that changing your Windows settings to add a Russian keyboard or language might “trick” some ransomware into thinking you’re a local and leave you alone. There are even scripts you can run to add these language settings easily, though this won’t stop all types of malware. The article warns that this is not a full solution—many threats do not care what language your computer uses. Still, it’s a free and easy step that might help against some attacks.

Experts also note that malware authors could update their software to look for more clues, like which language is active, how long it has been installed, or even your timezone and IP address. But making it harder for hackers could force them to choose between making less money or risking legal trouble at home.

In the comments, some people joke about the trick, while others share worries or extra ideas. A few think installing all language packs would protect them from all malware, but others reply that this won’t really help—malware can use many other tricks to find out where you are. Some say that switching to Linux or Macs is a better way to avoid ransomware, but others argue that no system is perfect and Mac malware is growing as well.

Some commenters talk about technical issues, like what happens if you install too many languages, or how malware could check which keyboard is actually in use, not just installed. Others think hackers might start using IP addresses or timezones instead, but people point out that these can be faked or are often not clear enough. There’s also debate about whether this trick just makes defenders look weak, and if hackers will soon adapt.

A few warn about problems from running unknown scripts to change your registry, and some share that their systems got messed up doing this. People also argue about the cost of using Macs versus Windows and whether security is really better. Finally, there are jokes about installing Klingon keyboards and comments about the never-ending fight between attackers and defenders. Overall, most agree it’s a clever trick, but not a magic bullet for security.

---

## Bloom Filters by Example

- 原文链接: [Bloom Filters by Example](https://llimllib.github.io/bloomfilter-tutorial/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44412370)

This article explains what a Bloom filter is and how it works. Bloom filters help you quickly check if something is in a set, using little memory, but they may give false positives.

A Bloom filter uses a long row of bits, called a bit vector. When you add something, like a word, you run it through a few hash functions. Each hash function gives you a number, which tells you which bits to turn on (set to 1) in the bit vector. When checking if a word is present, you use the same hash functions and see if all those bits are on. If any bit is off, the item is not in the set. If all are on, the item might be in the set, but there is a chance it’s not—this is called a false positive. Bloom filters never give false negatives, so if it says “no,” it’s always correct.

The article also talks about choosing hash functions. The best hash functions are fast and spread bits evenly, but they don’t need to be secure like cryptographic hashes (e.g., SHA-1). Many popular programs use fast hash functions such as Murmur, FNV, or xxHash. For example, Chromium, RedisBloom, and Apache Spark use Murmur, while InfluxDB and RocksDB use xxHash. The choice of hash function can make Bloom filters much faster.

The size of your Bloom filter matters. A bigger filter means fewer false positives, but uses more memory. You also need to pick how many hash functions (_k_) you use. More hash functions make the filter slower and can fill it up faster, but too few means more false positives. There’s a math formula—(m/n)ln(2)—to find the best number of hash functions for your filter size (_m_) and expected items (_n_). You should also check the false positive rate for your choices.

Bloom filters are used when you can’t store everything, but need to check quickly if an item is probably in your set. Examples include web browsers, databases, and big data tools. However, if you don’t know how many items will be added, or if your set is very small, a different data structure may be better.

In the comments, many people say Bloom filters are great for saving memory and making checks fast. Some share where they use Bloom filters, like in caching, databases, or blocking spam. A few warn that Bloom filters can be tricky when you need to remove items, as basic Bloom filters don’t support deletion. Others bring up that false positives can be a problem if your application needs perfect answers. Some suggest looking at other tools, like Cuckoo filters, if you need to delete items or handle more advanced cases. A few people discuss the math behind tuning a Bloom filter, saying it’s important to set the size and number of hash functions right for your needs. Finally, some mention that if your set is tiny, a simple list or set may be easier and just as fast.

---

## Using the Internet without IPv4 connectivity

- 原文链接: [Using the Internet without IPv4 connectivity](https://jamesmcm.github.io/blog/no-ipv4/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44411273)

This article is about losing IPv4 internet at home after a power cut, but still having IPv6, and how the author fixed it using Linux, WireGuard, and a VPS. The main problem was that many websites do not work with only IPv6, so normal browsing and work tasks broke.

The author explains that IPv4 addresses are running out because there are too many devices and not enough numbers. To handle this, most people use NAT, which lets many devices share one public IP. ISPs use something called Carrier Grade NAT to share addresses even more, but this can break things, like in the author’s case. IPv6 has many more addresses, so you don’t need NAT, and every device can have its own address. But a big problem is that many websites (like GitHub) do not accept IPv6 connections yet.

To fix the problem, the author used a VPS from Hetzner that has both IPv4 and IPv6. He set up a WireGuard VPN tunnel from his home to the VPS, using IPv6 as the connection. Then, all his internet traffic went through the tunnel, and the VPS could reach IPv4 sites for him. The article goes into detail about how to set up WireGuard for both IPv4 and IPv6, including sharing the configs for the server and the client.

He also explains how to use network namespaces in Linux to run another VPN (for work) inside the WireGuard tunnel, and even how to get Docker running inside this setup. There were some technical problems, like needing to set the right MTU (packet size) on the tunnel, otherwise some websites would not load. The author shares how he debugged this by testing with different packet sizes.

In the end, the author says that having Linux skills and tools like WireGuard really helped. He recommends having a VPS ready for emergencies, and thinks about using an open-source router for more control next time.

In the Hacker News comments, some people say they have had similar problems with CG-NAT and ISPs breaking IPv4. Others agree that IPv6 should be used more, but complain that too many websites still do not support it. A few users warn that using VPNs or tunnels can be confusing, especially with things like DNS leaks or routing issues. Some like the technical details and thank the author for sharing the configs and tips, especially the troubleshooting about MTU. A few people point out that setting up WireGuard and namespaces is not easy for non-experts, and wish ISPs would just fix their networks better.

One commenter says running your own router with OpenWRT is very helpful—others agree, sharing their own stories. Some people suggest using commercial VPNs as a backup instead of setting up your own VPS, while others say having your own server is more flexible and private. There’s some debate about how long it will take before most of the web truly supports IPv6, and if that will ever happen. A few users mention that macOS and Windows are still behind Linux for advanced networking, and thank the author for highlighting the power of Linux. Overall, most readers found the article useful and practical, and some saved it for future emergencies.

---

## The Medley Interlisp Project: Reviving a Historical Software System [pdf]

- 原文链接: [The Medley Interlisp Project: Reviving a Historical Software System [pdf]](https://interlisp.org/documentation/young-ccece2025.pdf)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44413574)

The article talks about the Medley Interlisp Project, which is a group effort to bring an old software system called Medley Interlisp back to life and make it work on today’s computers. Medley Interlisp was a special programming environment, first made at Xerox PARC in the 1970s and 1980s, and is known for being part of the early history of the LISP language.

The main goal of the project is not just to get Medley running, but also to keep its historical value and make it easier to use with modern hardware and software. The team wants Medley to run on Windows, macOS, and Linux, and to work with new things like Unicode, the system clipboard, and modern mice and keyboards. They’re also fixing bugs, finishing old unfinished features, and making Medley more like the official Common Lisp standard.

Medley Interlisp was important because it allowed rapid prototyping and had features that even today’s systems do not have. Some of its unique features were DWIM (Do What I Mean), which tried to fix simple programming mistakes for you, and the very first UNDO function, which let you undo actions even out of order. The whole environment, including the operating system, was written in Interlisp, and could be changed by users at any time.

The project’s journey has not been easy. The software is very old, and even the original developers had to relearn how it worked after 30 years away. The documentation was scattered and out of date, and the code had many bugs, including some related to the Y2K problem. Also, the team had to merge different old versions of Medley to get a working system. Some technical challenges included moving from big-endian to little-endian computer systems and making the old virtual machine, called Maiko, work on new hardware.

Progress has been made: Medley now runs on modern systems, and you can even try it in your web browser or using Docker. New tools let Medley integrate with Git, and a clipboard function lets users copy and paste text in and out. The team is also updating the documentation, called the Medley Primer, to help new users understand and enjoy the system, while keeping some charming old explanations for historical flavor.

They are also building a big bibliography of Interlisp materials, making it useful for researchers and programmers interested in computer history. External help has come from university students, who worked on documentation, videos, and organizing materials, and from freelancers, though the freelancers were less effective because they didn’t know the project well.

In the Hacker News comments, many people express excitement about seeing Medley revived, calling it a piece of computing history worth saving. Some praise the team for their hard work and for keeping old ideas alive, saying that modern programming could learn a lot from Medley’s features, like the DWIM system and the deep integration of tools. Others are curious if Medley could inspire new kinds of programming environments today. A few commenters remember using Interlisp or similar systems and share stories about how much they liked the flexibility and the “living” feel of those environments.

Some users point out the challenges of preserving old software, especially when hardware and documentation are lost. They worry that many valuable ideas from the past might disappear forever if projects like this stop. Others ask about how to contribute or try Medley themselves, and the project’s open-source nature is seen as a big plus. There are also discussions about the learning curve, with some warning that Medley is complex but rewarding for those who stick with it. A few suggest that the project could help teach new generations about software history and design. Many agree that even if old systems like Medley are not used widely again, bringing them back teaches us important lessons about creativity and software development.

---

## Revisiting Knuth's "Premature Optimization" Paper

- 原文链接: [Revisiting Knuth's "Premature Optimization" Paper](https://probablydance.com/2025/06/19/revisiting-knuths-premature-optimization-paper/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44386236)

This article looks at the famous quote by Donald Knuth: “premature optimization is the root of all evil,” and explains what Knuth really meant. The writer says people often use this quote to say small optimizations are always bad, but Knuth did not mean that.

The article reviews the original context. Knuth’s paper was about whether using “goto” statements is needed for speed. He gave code examples for a multiset (a collection that lets you count how many times each item appears). One version uses arrays and a “goto” to handle two different ways to finish the search and insert. Another, more modern version, uses a map, which is usually slower for small sets but faster for big ones.

Knuth showed different ways to write the insert function. One version uses optimistic insertion to avoid extra checks. Another unrolls the loop to make it faster. These changes give small speed boosts, like 10–12%. Knuth says that, in real engineering, even small improvements can matter if they are easy and in critical code.

Knuth warns not to waste time optimizing code that does not matter; you should measure and see what is really slow first. But if you know a part of the code is important, or it's a library used everywhere, small optimizations can be worth it. He also says that compilers don’t always make these changes for you, so it may help to do them by hand.

The author runs benchmarks and shows that, for very small sets, all versions are about the same speed, and sometimes the “clever” version is not faster. For bigger sets, the faster code or a better data structure (like a hash map) is much better. The article suggests just using well-made library functions, because their writers already did the important optimizations. Compilers still don’t always do the best job, even 50 years after Knuth’s paper.

Now, looking at the top Hacker News comments, people have many views. Some agree that Knuth is often misquoted and that small optimizations matter in the right place. Others say that in modern times, hardware and compilers make some old tricks less useful, and you should focus on clear code first. Some point out that guessing which code is slow rarely works—you have to measure.

A few users talk about times when “premature optimization” was actually helpful, like in low-level or “hot path” code. Others remind that most code is not performance-critical, so you should not overthink small speed gains everywhere. Some share that they’ve seen bad code written in the name of optimization, which then became hard to maintain.

There is also debate about how much you can trust compilers to optimize loops and branches. Some think compilers are smart enough now, others say they still miss easy wins. A few people mention that in library code, even tiny improvements can add up because the code is used so much.

Many agree that the main lesson is to measure first, optimize only if needed, and use good libraries. The biggest mistake is to optimize blindly or too early, but it’s also wrong to ignore easy wins in important code. Overall, most think the article gives a good reminder not to take Knuth’s quote out of context.

---

