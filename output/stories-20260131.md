# Hacker News 故事摘要 - 2026-01-31

## 今日概述

Today’s top Hacker News stories cover programming language debates, new privacy risks from phones, and the effect of AI on Wikipedia. There is news about faster math libraries, safer container images, and a simple guide to Wikipedia’s sandbox. People also remember a public health hero, enjoy a funny post about computer bugs, and read about a link between Ferrari imports and the stock market. If you like tech, privacy, AI, security, or just a good story, there’s something for you today.

---

## Swift is a more convenient Rust

- 原文链接: [Swift is a more convenient Rust](https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46841374)

This article compares Rust and Swift, saying Swift is like a more convenient version of Rust. The writer explains how both languages have similar features: strong type systems, enums, pattern matching, and compiling to native code or WASM. Rust is made for low-level system work and gives tools to work higher-level if needed, while Swift starts as a high-level language but lets you go lower when you want.

In Rust, the memory model is strict: you must manage ownership and borrowing, and use wrappers like `Cow` or `Box` when you want copy-on-write or recursive types. Swift uses value types and copy-on-write by default, making it simpler but sometimes less fast. Swift hides some complex ideas behind easy, C-like syntax; for example, its `switch` statement works much like Rust’s `match`, but looks more familiar.

Both languages avoid nulls: Rust uses `Option`, Swift uses `T?` (optionals). Error handling is also similar—Rust uses `Result`, Swift uses `throws` and `do-catch`, but Swift wraps these ideas in syntax that feels more like older languages. When you need recursive data types, Rust makes you use `Box`, but Swift only needs an `indirect` keyword and handles the rest.

Swift has more features, like classes, async/await, actors, property wrappers, and result builders. This makes it bigger and less “pure” than Rust, but easier for new users. The trade-off is that Rust is faster by default, while Swift is easier to use but needs more care for maximum speed.

The article points out that Swift is now cross-platform: it runs on Windows, Linux, and even on small devices, and recent updates make it easier to use outside Apple’s ecosystem. The Swift community is working on better tools and package support, but it still lags behind Rust’s ecosystem and has some problems like slow compile times and a large language size.

In the Hacker News comments, some people agree that Swift is more convenient for many tasks, especially UI and server work. Others say Rust’s strictness is better for catching bugs early, and that Swift’s “magic” can hide important details. A few think Swift is still too tied to Apple, despite recent progress on other platforms. Some users point out that Swift’s package manager and libraries aren’t as mature as Rust’s, making cross-platform work harder.

A number of commenters like how Swift handles optionals and errors, saying it’s less clunky than Rust. Others prefer Rust’s explicitness, even if it’s more work. Some mention that Swift’s syntax feels more welcoming, while Rust’s learning curve is steeper but worth it for control and speed. There are also discussions about compile times, with both languages getting criticism for being slow to build.

Finally, a few people share their own experiences using both languages, saying the choice depends on the project: Rust for systems and performance-critical code, Swift for apps and fast prototyping. Both communities are seen as friendly and helpful, and many are excited to see where each language goes in the future.

---

## Mobile carriers can get your GPS location

- 原文链接: [Mobile carriers can get your GPS location](https://an.dywa.ng/carrier-gnss.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46838597)

This article explains that mobile carriers can get your exact GPS location from your phone, not just a rough estimate from cell towers. Apple’s new privacy feature in iOS 26.3 tries to limit this, but only on newer iPhones with Apple’s own modem. The article says cell towers can already give an idea of where you are, but not very precisely—maybe within tens or hundreds of meters. However, there are hidden protocols in mobile networks (like RRLP for 2G/3G and LPP for 4G/5G) that let carriers ask your phone directly for its real GPS coordinates, which can be accurate to a few meters. Your phone usually does this without you knowing, and it is built into the way mobile networks work. The article mentions that this ability has been used for years by groups like the DEA in the US and Shin Bet in Israel to track people. For example, Israel used this data for COVID-19 contact tracing, showing how precise and powerful this tracking can be. The author warns that these protocols are not well-known and might be open to abuse, maybe even by foreign actors or hackers. Apple’s update helps, but the author says users should also be allowed to turn off these location-sharing features completely and get alerts when their location is requested.

In the comments, many people were surprised that phones can send GPS data directly to carriers, not just use tower data. Some said this is worrying for privacy and shows why we need stronger controls. Others pointed out that these features are required for emergency services, so turning them off could cause problems in real-life emergencies. A few commenters remembered news stories about police or governments using this tech for both good and bad reasons, like catching criminals or tracking everyone during COVID. Some people argued that the real issue is how easy it is for governments or companies to request this data, often without a strong legal process. Others doubted how often carriers use these protocols outside of emergencies, but some with telecom experience confirmed it is possible and not rare. There was also talk about whether using a different phone or software could help, but experts replied that almost all phones follow these rules because they are part of the network standard. A few commenters praised Apple for trying to protect users, while others said Apple should go further and give users more power. Lastly, some people worried about hacking or foreign use, while others said the main threat is still from local governments and carriers who have easy access to this data.

---

## Generative AI and Wikipedia editing: What we learned in 2025

- 原文链接: [Generative AI and Wikipedia editing: What we learned in 2025](https://wikiedu.org/blog/2026/01/29/generative-ai-and-wikipedia-editing-what-we-learned-in-2025/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46840924)

This article looks at how generative AI, like ChatGPT, affected Wikipedia editing in 2025. Wiki Education, a group that helps bring new editors to Wikipedia, studied how people used AI tools when adding or changing articles.

The main point is clear: editors should never copy and paste AI-generated text into Wikipedia. The group found that while only a small percentage of articles had fake sources, most AI-written articles failed a key test—when you check the source, the information is not actually there. This means the facts may sound real, but you cannot prove them. The group used a tool called Pangram to detect AI-generated text in articles. Before ChatGPT, there was almost no AI-written text; after its launch, the amount grew. They spent a lot of time checking flagged articles and had to clean up many that failed verification.

To help, Wiki Education created training for new editors, telling them where AI tools can be helpful (like finding sources or gaps in articles) and where they should not be used (never for writing article text). They also improved their systems to catch and address AI-drafted content quickly. Most new editors followed these rules, and fewer than expected tried to add AI-written text to live articles. When someone did, the content was reverted by staff, instructors, or even by the students themselves after being notified.

The article says AI can help with research steps, like finding sources or checking grammar, but should not write final text. Most students found AI tools helpful for ideas or finding information, but did not trust them to write for Wikipedia. The group believes that, right now, AI chatbots cannot create verifiable and accurate Wikipedia text.

In the comment section, some people agree and say Wikipedia must stay careful, because even small errors can spread widely. Others think the focus should be on improving AI tools so they can give better, more reliable output in the future. A few commenters are worried about over-relying on detection tools like Pangram, saying false positives could hurt good editors or create extra work. There are also voices who believe AI can be a good helper if used carefully, especially for brainstorming or organizing information, but they agree human editors must check everything. Some mention that teaching AI literacy is important for new editors, so they know both the risks and the benefits. A few point out that Wikipedia’s policies will need to keep changing as AI gets better. Lastly, some users stress that the real problem is not AI itself, but people misusing it or not checking facts well enough.

---

## Outsourcing Thinking

- 原文链接: [Outsourcing Thinking](https://erikjohannes.no/posts/20260130-outsourcing-thinking/index.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46840865)

This article talks about the risks and problems of letting AI, like language models, do our thinking and writing for us. The writer looks at when using chatbots can be harmful and when it might be okay.

The main idea is that using AI for simple tasks can make us weaker at thinking for ourselves. The writer agrees with another blogger, Andy Masley, that it is bad to let chatbots handle things that help us learn or build important knowledge for the future, times when we need to show care for others, or when honesty matters. The writer explains that writing and talking to other people is not just about sending information—it is also about showing who we are. If we let AI change our words, we lose our real voice and trust with others. Some people think AI helps people who have trouble with writing or use another language, but the writer worries that using AI too much stops us from learning and makes our writing less true.

The article also says that using AI for things like vacation planning or writing personal messages takes away from life’s valuable experiences. Even boring tasks can help us learn and connect with others. The writer shares a story about learning to play jazz piano, showing that practice and repeating tasks build real skill and knowledge. If we let machines do everything, we might lose these chances to grow.

There is also a discussion about the idea that our minds can be “extended” by technology, like phones or computers. The writer strongly disagrees, saying that thinking and feeling are more than just information processing. Remembering a friend’s birthday, for example, is not the same as having a machine do it for us.

In the end, the writer says that we need to think carefully about what we let machines do for us. Automating “boring” cognitive tasks can change us, and not always for the better. It’s not just about being more efficient; it’s about what kind of people and society we want to be.

Many commenters on Hacker News agree that using AI for everything can make us lazy or less skilled. Some share stories about students letting chatbots do their homework, which means they don’t really learn. Others point out that AI is very helpful for people who struggle with writing or have to work in a second language. A few argue that technology always changes how we work, and people complained about calculators and spellcheckers too, but we still learned math and writing.

Some say that being honest about using AI is important, especially in personal messages or public writing. Others wonder if we are just being too nostalgic and that new tools always feel strange at first. One commenter notes that not all writing needs to be personal—sometimes it is just about getting a task done. But many agree with the article that if we let AI do all our thinking, we risk losing important skills and our own voices.

There are also practical worries, like what happens when everyone uses chatbots to write job applications or answer emails—will everything start to sound the same? Several people mention that AI is not very good with some languages, so it can actually make things harder for some users. A few think that the real problem is not the tool itself, but how we choose to use it. In the end, most agree that we need to use AI carefully and remember what makes human thinking and communication special.

---

## Demystifying ARM SME to Optimize General Matrix Multiplications

- 原文链接: [Demystifying ARM SME to Optimize General Matrix Multiplications](https://arxiv.org/abs/2512.21473)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46840252)

This article talks about how to make matrix math faster on computers with ARM’s new SME hardware. The main idea is that general matrix multiplication (GEMM) is very important for things like deep learning and science, but most software does not use the full power of the new SME hardware from ARM, especially for big matrices. The authors built a new library called MpGEMM that is open-source and uses special tricks to get the most out of SME.

They studied the SME hardware to learn how it works. They found that using the cache well is very important, so they split up the data in a smart way (this is called cache-aware partitioning). They also move and change the data as needed, right when it is being used (on-the-fly transposition). The library uses small blocks of code (micro-kernels) that can load many data vectors at once and use all the special registers in the hardware. They tested their library on an Apple M4 Pro chip using real workloads from big AI models like DeepSeek and LLaMA. MpGEMM was about 23% faster than Apple’s own Accelerate library and much faster than other open-source libraries.

In the Hacker News comments, some people are happy to see more open-source libraries that help get the most out of new hardware. A few users ask if this will help on older ARM chips, or if you need the latest hardware to see the speed-up. Others wonder if these tricks could be used on other types of chips, like x86 or GPUs. Some developers worry that optimizing for very new hardware makes the code hard to maintain or less portable. One commenter points out that most big companies have their own super-optimized math libraries already, so this might help small companies or open-source projects more. Another person says it’s exciting to see academic papers with real code that anyone can try. There is also a discussion about how important matrix multiplication is for AI and why hardware keeps adding more features for it. A few users share their own stories of trying to hand-tune math code and say it can be tricky but rewarding. Some people ask for benchmarks on other chips and workloads. One user notes that Apple’s Accelerate library is closed-source, so open alternatives are needed. Finally, there’s talk about how these kinds of improvements can save power as well as time, which matters for laptops and phones.

---

## Show HN: Minimal – Open-Source Community driven Hardened Container Images

- 原文链接: [Show HN: Minimal – Open-Source Community driven Hardened Container Images](https://github.com/rtvkiz/minimal)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46840178)

This article is about Minimal, a set of open-source, hardened container images with very few known security problems (CVEs). These images are meant for running popular software like Python, Node.js, Go, Nginx, and databases in a safer way.

The main idea is that most container images (like the ones from Debian or Ubuntu) come with a lot of built-in packages, which means more possible security holes. Minimal images only include what is needed to run your app, which keeps the attack surface small and makes it easier to patch any problems quickly. These images are rebuilt every day using modern tools (apko and Wolfi packages), so any new security issues are fixed in less than two days, while normal images might take weeks. Most images are “shell-less,” meaning you can’t open a shell inside them, which further protects against attacks.

Each image runs as a non-root user by default, another security best practice. All images are cryptographically signed, and come with a full list of included software and licenses (SBOM), so you can check exactly what’s inside. The images support many use cases: web apps, databases, CI/CD, and more. The project provides simple commands for running or testing the images using Docker.

The build process uses a pipeline: it starts with trusted package sources, assembles the image, checks for vulnerabilities, and signs the result. If any serious problems are found, the build fails. The images update daily, but you can also trigger builds manually or when making changes. Developers can build and test images locally with easy commands, and the project structure is simple and clear.

Now, let’s see what people on Hacker News think. Some developers like that these images are “minimal” and have fewer security risks than big, standard images. People also like the fast patching—having fixes in 24-48 hours instead of weeks makes them feel safer. A few users worry that removing the shell makes debugging harder if something goes wrong inside the container. Some point out that very small images may leave out tools you sometimes need, so you have to plan ahead. Others mention that using non-root users is good, but it can break apps that expect root access. Several people compare this project to other distroless or minimal image projects, and wonder how it stands out. A few are concerned about depending on newer tools (like Wolfi) that might not have the same history as Debian or Ubuntu. Some users appreciate the open-source, community-driven approach and say they would like to contribute. Others ask about support for other languages or extra features. Overall, many see Minimal as a strong option for teams who care about security and want smaller, safer containers, but some think you need to balance minimalism with practical needs.

---

## Wikipedia: Sandbox

- 原文链接: [Wikipedia: Sandbox](https://en.wikipedia.org/wiki/Wikipedia:Sandbox)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46829965)

Wikipedia:Sandbox is a special page on Wikipedia where anyone can try editing or adding text without worrying about making mistakes. This page is for testing how editing works, learning the tools, and seeing your changes before you try them on real articles.

You can use either the source editor or the VisualEditor to make changes. After editing, you can click “Show preview” to see what your text looks like or “Show changes” to compare to the old content. When you’re done, you can click “Publish changes,” but remember, the sandbox is cleared often, so your work will not stay forever. There is a link to reset the sandbox quickly if you want to start fresh. If you create a Wikipedia account, you also get your own private sandbox to use any time. The page warns not to put copyrighted, illegal, or offensive text in the sandbox. There are links to more help pages and tutorials for new editors. The sandbox is available in over 200 languages, and many other Wikimedia projects have their own sandboxes too.

You can also find different types of sandboxes: for user pages, files, categories, templates, and more. There are shortcuts to get to the sandbox quickly, like WP:SB or WP:SANDBOX. The page is open to all, and editing is not limited to registered users. The sandbox page is under a Creative Commons license, like all of Wikipedia.

In the Hacker News comments, many people say the sandbox is a great place to learn how Wikipedia works without risk. Some users share memories of first trying out wiki markup here before making real edits. Others like that you don’t need an account to experiment, making Wikipedia more open to everyone. A few people say they wish more websites had a “sandbox” to practice safely. Some developers point out that the sandbox is a good way to teach HTML, links, and formatting. There are questions about how often the page is reset and if there’s a history of past sandbox edits. Others mention that sometimes the sandbox is misused for spam or jokes, but it’s usually cleaned up fast. Some suggest adding more features, like better guidance for first-time users. A few worry that newcomers do not always read the rules and might post personal or private info by mistake. Others note the sandbox is a good example of how open editing can be managed with simple rules and community help. Overall, the comment section agrees that the sandbox is a simple but important part of what makes Wikipedia work for everyone.

---

## Scientist who helped eradicate smallpox dies at age 89

- 原文链接: [Scientist who helped eradicate smallpox dies at age 89](https://www.scientificamerican.com/article/smallpox-eradication-champion-william-foege-dies-at-89/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46793313)

William Foege, a key scientist in the fight to end smallpox, has died at age 89. He led the U.S. Centers for Disease Control and Prevention’s Smallpox Eradication Program in the 1970s and helped make smallpox the first disease to be wiped out worldwide. Smallpox was very deadly, killing about one in three people who caught it, but since 1977 there have been no new cases. Foege’s work is said to have saved hundreds of millions of lives. He later led the CDC and worked as an adviser at the Gates Foundation. In 2012, he received the Presidential Medal of Freedom from President Obama. Foege strongly supported vaccines and wrote about ending diseases like polio. He also spoke out about problems in U.S. public health policy, especially in recent years. Many people in public health saw him as an inspiration and a source of hope.

In the Hacker News comments, people shared respect for Foege’s achievements and the global effort to stop smallpox. Some users pointed out how rare it is to truly wipe out a disease, and how hard the smallpox campaign was. Others talked about how Foege’s “ring vaccination” strategy was smart and effective, even in poor or remote places. A few users mentioned that Foege’s approach could be a model for fighting other diseases, like polio and even COVID-19. Some comments discussed the importance of vaccines and strong public health leadership. Others wondered why polio and some other diseases are still around, and what lessons can be learned from smallpox. There were also personal stories—some commenters remembered getting the smallpox vaccine as kids, or knew people who worked in public health. A few users debated the future of vaccine science and global health, while some warned that new problems could bring old diseases back if we are not careful. Overall, the thread showed great respect for Foege and the huge impact one person can have on world health.

---

## The Saddest Moment (2013) [pdf]

- 原文链接: [The Saddest Moment (2013) [pdf]](https://www.usenix.org/system/files/login-logout_1305_mickens.pdf)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46840219)

This article is a funny take on the topic of Byzantine fault tolerance in computer science. The writer, James Mickens, talks about how sad and complicated it feels to listen to talks or read papers about making computer systems reliable when everything can go wrong.

He compares presentations on Byzantine fault tolerance to sad foreign films, where everything is hopeless and confusing. The article jokes that every research paper has a confusing diagram with millions of messages flying around, pretending to make things secure. No matter how clever the protocol, the reality is that real-world problems—like a datacenter worker spilling coffee or making a silly mistake—will break the system anyway.

Mickens makes fun of how researchers invent new, strange names for their ideas, like “leap year triple-writer dirty-mirror asynchronous semi-consistency.” He says these ideas are not intuitive at all. To show how weird these protocols are, he imagines a group of friends trying to decide on lunch, but everyone has to keep confirming and denying each other’s choices, just like a Byzantine protocol. In the end, someone just leaves for the cafeteria alone because it’s all too much trouble.

The article ends by saying that people should maybe stop writing new papers about Byzantine fault tolerance, because it’s like an addiction that leads to more confusion and long, unreadable reports. No amount of clever math or security tricks can solve basic human mistakes or make things truly reliable.

In the Hacker News comments, some people really enjoyed the humor and said Mickens is one of their favorite technical writers. Others pointed out that Byzantine fault tolerance is not hopeless—there are real systems that use it, like blockchains and some databases. A few readers agreed that these papers are often too complex and hard to understand, and that simple explanations are rare.

Some commenters shared stories about real-world system failures that had nothing to do with fancy protocols, just human errors or hardware problems. Others defended the importance of research in this area, saying that even if it seems hard, it’s important for things like banking or critical infrastructure.

One person joked that the lunch example was too real and reminded them of meetings at work. Another said that the real enemy is not technology, but people making mistakes. Some felt that the field is too focused on academic ideas and not enough on practical problems. A few readers wished there were better ways to explain these topics to newcomers.

Overall, the comments showed a mix of laughter, agreement with the article’s skepticism, and some respect for the difficult work of making computers reliable—even if it sometimes feels impossible.

---

## Ferrari vs. Markets

- 原文链接: [Ferrari vs. Markets](https://ferrari-imports.enigmatechnologies.dev/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46815209)

This article looks at how many Ferraris are imported into the U.S. each month and how that number matches changes in the stock market and Bitcoin. It explains that, from 2020 to 2026, about 8,818 Ferraris came into the country—about 121 cars each month. The number of Ferraris imported goes up and down in a way that is very similar to the price movements of Bitcoin, the S&P 500, and the NASDAQ. The data comes from U.S. customs records, which are collected for every shipment entering the country. These records list what is shipped, who is shipping it, and what value they claim it has. The article shows different Ferrari models that were imported and explains how Enigma, a data company, uses this information.

The article then shifts to talk about fraud and crime in shipping and customs. It gives several real cases: 
- A Wisconsin company lowered invoice prices to cheat on customs taxes, leading to a $10M fine.
- A freight company in Los Angeles worked with a Mexican cartel to smuggle goods, resulting in billions of dollars in illegal trade and the arrest of top executives.
- A tech company sold Chinese cameras as “Made in USA” to the government, hiding security risks, and made over $112M before getting caught.
- A fragrance and chemical company mislabeled dangerous chemicals to avoid fees, resulting in a $3.1M settlement.
- A Chinese auto parts company lied about what it shipped to skip anti-dumping duties, leading to a $53M settlement after years in court.
- A plastic resin distributor faked the country of origin for its products, but avoided prosecution by admitting the fraud and paying $6.8M.

For each case, the article describes how better use of customs data can help catch fraud—by checking values, origins, and shipping paths.

In the comments, some readers are surprised at how closely Ferrari imports match the stock market and Bitcoin, joking that Ferraris are a “rich people’s index.” Others think the data is interesting but want to see more details or a chart. Some people discuss the fraud cases, saying they show how easy it is for companies to cheat if no one checks the data. A few commenters say the high settlements show that U.S. customs takes fraud seriously, while others worry that only big cases get caught and most fraud goes unnoticed. There is debate about whether technology can really stop all fraud or if people will always find ways to cheat. Some readers focus on the “Made in USA” scam, saying it is a big national security problem, while others talk about how customs paperwork is very complex and confusing for honest businesses. A few point out that whistleblowers play a key role in catching fraud. Overall, people agree that trade data can tell interesting stories about the economy, fraud, and even luxury trends.

---

