Hello everyone, this is the 2025-07-19 episode of Hacker News Daily Podcast. Today, we have a wide range of stories, from strong backup systems and offline AI, to new chip factories, fast travel, and deep dives into both hardware and software security. Let’s start.

First, we look at how to build a truly reliable backup system for your data. The article reminds us that planning is more important than writing backup scripts. Many people only realize their mistakes when it’s too late—just copying files is not enough, especially for live databases, because these backups often cannot be restored. The author shares hard-learned lessons from losing servers to fire, flood, and ransomware, but always being able to recover quickly thanks to good backups.

Before you start, you need to ask what data needs to be protected, how much risk you can accept, and how much downtime is okay. Where you keep your backup matters. Backups on the same machine are risky, but ones stored far away may be hard to use in an emergency. There are mainly two backup types: full disk and file-based. Full disk backups help with fast recovery and work well with virtual machines, but they use more space and may need you to stop the machine. File backups are more flexible and can run live, but need careful planning.

For reliable backups, the article suggests using snapshots before copying data, to freeze the system and keep everything consistent. Tools like ZFS, BTRFS, and LVM can help, though some have their own problems. Another point: should backups be “pushed” from clients or “pulled” by servers? The author prefers pull backups with a secure server, so if the client is hacked, backups are still safe. Using snapshots on the backup server itself adds more protection.

A good backup system should allow quick recovery, use off-site storage, be secure, manage space well, and be easy to use. In the comments, many agree: the biggest mistake is not testing your backups. Some share stories of loss because they trusted simple file copies. Others praise snapshot tools for saving them. Some argue that the cloud is not a backup by itself, and there’s debate about push vs pull methods. Most agree: have a real backup plan, test it, and make sure you can restore your data when you need it.

Next, we discuss using local large language models, or LLMs, and offline Wikipedia in places without internet, like during disasters. The article compares different LLMs from the Ollama library with Wikipedia downloads from Kiwix. For example, the “Best of Wikipedia” with 50,000 articles is 356 MB, while a small LLM is about 523 MB. Full Simple English Wikipedia is about 915 MB, and bigger models like Llama 3.2 3B are around 2 GB. The biggest Wikipedia download is over 57 GB, while the largest LLMs are about 20 GB.

The author explains that LLMs and encyclopedias work differently—LLMs generate answers but may not always be accurate, while Wikipedia is a set of facts you have to search. LLMs need more computer power, but Wikipedia can work on old devices. There’s no clear winner. In the comments, people say Wikipedia is more reliable for facts, while LLMs are flexible for searching and explaining. Some think having both is smart: Wikipedia for facts, LLMs for explanations. Others worry about trusting LLM answers, and most agree that in an emergency, simple tools that work everywhere are best.

For our next story, we turn to deep system security. The article describes how a kernel exploit, Trigon, was improved to work on more Apple devices by targeting special hardware called coprocessors. The original exploit worked on A10 chips using a security feature called KTRR. For older and newer devices, the author found different ways to locate and control protected memory. On older chips, the author and a friend attacked the Always-On Processor (AOP), which controls special tasks and is easier to reach. By overwriting the AOP’s code, they gained full memory access.

The article goes into technical detail, including tricks like AXI remapping, and how these methods differ from past jailbreaks. In the comments, many are impressed with the level of skill and knowledge. Some discuss how Apple’s hardware security has changed over time, making exploits harder. There are questions about the details of memory mapping, and some worry about the risks if this knowledge is misused. But most agree that public research helps everyone stay safer, and thank the author for sharing.

Switching gears, TSMC is building four new chip factories in Taiwan to make 1.4-nanometer chips, some of the smallest ever. These factories, called Fab 25, will be in the Central Taiwan Science Park, with production starting in 2028. The first factory aims to produce 50,000 wafers per month and may help the area earn over 1.2 trillion NT dollars each year. TSMC is also investing in new factories in Arizona, and soon, about 30% of their advanced chip production will be in the US.

Hacker News commenters are impressed by the speed of chip progress, but some worry about the huge costs and whether such small chips are needed for most products. There’s debate about the environmental impact, especially water use, and if there will be enough workers. Some see this as keeping Taiwan important in tech, while others think the US is catching up.

Now, let’s talk about the future of fast passenger travel. The article covers new attempts to build planes and even rockets that travel faster than the speed of sound. The Concorde was the last supersonic jet for passengers, but it stopped in 2003 due to high costs, fuel use, and noise rules. New ideas use better materials and engines, but fast planes always use more fuel and are worse for the environment. For example, rockets and hypersonic jets can use over 30 kg of fuel per passenger per 100 km.

Because of these limits, such travel will likely be for business, luxury tourists, or the military, not for most people. For example, Boom Supersonic’s tickets are expected to cost as much as business class or more. Some hope new technology and better fuels can help, but many doubt that supersonic travel will become common soon. In the comments, people debate if the time saved is worth the cost and climate impact, and whether noise rules will change.

Turning to computer history, we have a story about UNIX workstations from the 1990s. The author owns several old machines like the SGI Indigo², HP 9000, and DEC Alphastation, and noticed their internal layouts look a lot like cheap PCs from the same time, especially those using the LPX design. The move to flat cases, standard memory, and ports made UNIX workstations more like PCs inside.

In the comments, some say this is just a natural result of companies trying to save money and use standard parts. Others share memories of working on these machines and say the changes made repairs and upgrades easier. Some miss the unique designs, while others joke that “everything becomes a crab”—meaning different things often end up looking the same.

Next, science news: doctors have helped some babies be born without mitochondrial disease by using DNA from three people. This new method is called mitochondrial replacement therapy. The process uses the mother’s nucleus, a donor egg with healthy mitochondria, and the father’s sperm. The baby’s DNA is mostly from the parents, but a small part is from the donor, helping prevent serious diseases.

This technique is very new, first allowed in the UK, and only a few babies have been born this way. In the comments, people are both hopeful and cautious. Some see it as a big step for medicine, while others worry about unknown risks or ethical questions. There’s discussion about fairness and the need for good laws, and most agree more research is needed.

Now, a warning about security in AI protocols: the article examines MCP, a protocol for connecting AI models to tools, and finds many security problems. Tool descriptions are just text, so a hacker could add hidden instructions to trick the AI. Most MCP servers do not properly check these descriptions, and authentication is weak. Supply chain attacks are also possible, since tools can be shared as packages with too many permissions.

The author suggests fixes like cleaning tool descriptions, using structured data, and stronger authentication with OAuth. The newest MCP spec does require OAuth, but some risks remain. In the comments, many agree that boring security steps are easy to skip, but very important—especially when AIs can act quickly and at scale. Some call for more strict rules and better defaults in the protocol itself.

Finally, we have a project that helps you detect if your code is running in an AI-powered coding environment, like Copilot, Claude, or Cursor. This open source library works in Node.js and the terminal, and can help your app change its behavior depending on whether a human or an AI agent is running it. It provides simple APIs and a CLI with lots of output options.

In the comments, some are excited about using this for debugging or adapting apps for AI use. Others worry about privacy and false positives. There’s talk about improving detection and even using this for analytics. Some joke about making code more friendly to AI agents. The response is a mix of technical ideas, concerns, and curiosity.

That’s all for today’s episode. We covered backup planning, offline AI and Wikipedia, deep system exploits, the future of chips and fast travel, UNIX hardware history, new medical science, AI security, and tools for the age of AI coding. Thank you for listening to Hacker News Daily Podcast. See you next time.