# Hacker News 故事摘要 - 2026-02-03

## 今日概述

Today’s top Hacker News stories focus on new AI tools for coding and data, better ways to run untrusted code safely, and updates to old software. There are big discussions about open-source AI models, safer cloud sandboxes, new features in databases, and Apple adding AI to Xcode. Other stories talk about email quirks and problems with web-crawling bots. Readers are excited about new tech, but also careful about safety, privacy, and real-world results.

---

## Qwen3-Coder-Next

- 原文链接: [Qwen3-Coder-Next](https://qwen.ai/blog?id=qwen3-coder-next)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46872706)

Qwen3-Coder-Next is a new AI model made for writing computer code. The article comes from the Qwen team and explains what is special about this model.

Qwen3-Coder-Next is built to help people write and understand code in many languages, like Python, JavaScript, and C++. It is trained on a large set of code and has been tested against other code-writing AI models. The article says it beats models like GPT-4 on some programming tasks. Qwen3-Coder-Next can read code, fix mistakes, and even explain what a piece of code does. The team shares that it works well with many tools used by developers, such as code editors. The model is open-source, so anyone can download and use it for free. They also talk about safety: Qwen3-Coder-Next tries to avoid writing harmful code or leaking private data. The article shows test results and some examples where the model solves real coding problems. It can understand both short commands and long, complex requests. Qwen3-Coder-Next is meant for both beginners and experts. The team says they will keep making it better and want feedback from users.

In the comment section, many people are excited about another open-source coding model. Some think it can help small teams and indie hackers who cannot pay for big commercial tools. Others ask how it compares to models like GPT-4 and Code Llama. A few users worry about the size of the model and if it will run well on normal computers. There are questions about how safe the tool is, and if it can be tricked into making dangerous code. Some developers are happy about the model’s support for many programming languages. Others hope the team will share more details about how the model was trained. Some users point out bugs in the demo and suggest ways to improve it. A few people share that they tried the model and found it good for simple tasks, but less strong at very complex problems. There is also talk about using Qwen3-Coder-Next in education to help students learn programming. Overall, the community is interested and hopeful but wants to see more real-world results.

---

## Deno Sandbox

- 原文链接: [Deno Sandbox](https://deno.com/blog/introducing-deno-sandbox)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46874097)

Deno Sandbox is a new service from Deno that lets you run untrusted code inside secure Linux micro virtual machines (microVMs) in the cloud. The article explains how this tool is built for people and platforms that need to run code created by users or AI (like code from large language models) safely, especially when that code needs access to APIs and secrets.

Deno Sandbox creates small, fast-booting virtual machines to keep dangerous code away from your main systems. You can start and manage these sandboxes using JavaScript or Python SDKs. The sandboxes can be controlled with SSH, HTTP, or even through VS Code. One key feature is that secrets (like API keys) are never actually put inside the sandbox. Instead, a placeholder is shown, and the real secret only appears if the code tries to connect to an approved API host. This stops bad code from stealing secrets and sending them somewhere else.

Another big feature is network control. You can list which websites or APIs the sandbox can talk to. If the code tries to reach an unapproved site, the request is blocked. This is done using an outbound proxy, giving Deno a single place to enforce rules about secrets and connections. You can also use Deno’s own runtime permissions for extra safety.

When your code is ready, Deno Sandbox lets you deploy it straight to Deno Deploy with a single command—no extra setup needed. For storage, sandboxes are usually temporary, but you can use volumes for data, and snapshots to save installed tools or starting states. The technical specs show the sandboxes have 2 vCPUs, up to 4 GB memory, and can live for up to 30 minutes, booting in less than a second. Pricing is by compute time and storage, with some free usage included in the Pro plan.

In the Hacker News comments, many users liked the idea of running untrusted code in a strong sandbox, especially as AI-generated code becomes more common. Some praised the approach to protecting secrets, saying it solves a real problem with plugin systems and user scripts. Others asked about performance, pricing, and how Deno Sandbox compares to similar products like Firecracker microVMs or Google’s Cloud Run.

A few commenters worried about lock-in, since deploying is easy if you use Deno, but harder with other tools. Some said it’s great for short-lived, safe code runs, but might not work for every use case, especially if you need longer runtimes or lots of storage. People liked the API and SDK options, but wondered if it’s mature enough for production.

There were questions about the security model, such as whether the outbound proxy can be bypassed, or if side-channels could leak data. Some users asked about support for other languages besides JavaScript and Python. A few were excited to try it for AI agents and plugin sandboxes, while others just wanted to see more benchmarks and real-world examples. Overall, the community was interested and optimistic, but cautious about pricing, security, and long-term support.

---

## AliSQL: Alibaba's open-source MySQL with vector and DuckDB engines

- 原文链接: [AliSQL: Alibaba's open-source MySQL with vector and DuckDB engines](https://github.com/alibaba/AliSQL)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46875228)

AliSQL is a special version of MySQL made by Alibaba, now open source, and it adds some new features like a vector engine and support for DuckDB as a storage engine. The project is based on MySQL 8.0.44, but with many changes to help big companies handle lots of data and special workloads. One main feature is that you can use DuckDB inside MySQL, so you can run fast analytical queries without leaving the MySQL world. Another big feature is vector storage and search: AliSQL lets you store high-dimension vectors (up to 16,383 dimensions) and search them quickly using the HNSW algorithm, which is good for AI and search use cases. This means you could build things like recommendation systems or semantic search with standard SQL. Some other improvements are planned, like making DDL (schema changes) faster and safer, speeding up crash recovery, and making replication better for large databases. Building AliSQL is much like building MySQL: you need CMake, Python 3, a modern C++ compiler, and you use a shell script to build and install. The license is GPL-2.0, the same as MySQL, and the DuckDB features also follow this license.

In the comments, some people are excited to see vector search added right inside a SQL database, saying it helps bridge the gap between AI and normal data work. Others wonder how well the DuckDB integration will work in practice, since DuckDB is usually used alone, not as a MySQL engine. A few users ask about performance: will the vector search and DuckDB be fast enough for real business use, or just for simple demos? Some mention that AliSQL is not the first fork of MySQL, but it might be the first to focus on AI features like this. There are concerns about long-term support, since Alibaba’s needs may change, and not all features may get back to the main MySQL project. Others are happy that it is open source and invite more community help. Some say they want better English documentation, as much is still in Chinese. A few compare AliSQL to other projects like MariaDB or Percona, thinking about which is best for their needs. Others point out that using DuckDB under MySQL could make debugging harder, but it also adds a lot of power. Overall, people seem interested, but want to see more real-world tests and details.

---

## FlashAttention-T: Towards Tensorized Attention

- 原文链接: [FlashAttention-T: Towards Tensorized Attention](https://dl.acm.org/doi/10.1145/3774934.3786425)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46877403)

The article talks about FlashAttention-T, a new way to make the attention part of AI models faster and better. Attention is very important in models like ChatGPT, but it uses a lot of memory and time, especially with big data.

FlashAttention-T tries to solve these problems by using something called "tensorized attention." This method changes how the computer does the math for attention, so it can do more work at once. The new method uses the GPU in a smarter way, letting it work with bigger pieces of data and keep more information in fast memory. This helps because computers can get slow when they have to move data in and out of memory all the time. FlashAttention-T also cuts down on the number of times the computer has to read and write data, which saves time.

The paper shows that models using FlashAttention-T can train faster and use less memory. This is good for people training big AI models because it saves money and energy. The authors say their method works well with many types of models, not just one kind. They also say you can use FlashAttention-T with other new AI tricks, so it does not limit what you can build. The paper gives numbers to show how much faster FlashAttention-T is compared to older methods. For example, it can be much faster than normal attention, especially when working with long text.

In the Hacker News comments, some people are excited about the speed improvements. They say that making attention faster is very important for building bigger and better AI models. Some users ask about how hard it is to use FlashAttention-T in real projects and if it works with popular AI libraries. Others want to know if it only helps with big data or if it is also good for small models.

A few commenters talk about the technical details, saying they like how the method uses GPU memory more efficiently. Some people compare FlashAttention-T to other new attention methods and ask which one is best. One person brings up the point that even if models are faster, they are still expensive to train. Another commenter wonders if these improvements will help make AI cheaper for everyone, not just big companies. Some users talk about the open-source code and ask when it will be available so they can try it out. Others are just happy to see progress in making AI models more efficient. Overall, the comments show both excitement and some questions about how easy it will be to use FlashAttention-T in real life.

---

## Agent Skills

- 原文链接: [Agent Skills](https://agentskills.io/home)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46871173)

Agent Skills are folders full of instructions and resources to help AI agents do their jobs better. These skills give agents extra information and steps they can use for different tasks.

The main idea is that while AI agents are smart, they often don't know enough about specific jobs or company rules. Agent Skills fix this by giving them clear guides, scripts, and context, which they can load when needed. This helps agents be more reliable and accurate in their work. If you create a skill, you only need to make it once, and then many agents can use it. Agents that support the skills standard can get new abilities right away, just by adding the skill. For teams, Agent Skills let you save your company’s know-how in organized, shared packages that are easy to update.

With Agent Skills, you can give agents special knowledge for things like legal reviews or data analysis. You can also add new powers, such as making presentations or handling complex server tasks. Skills make it easy to turn complicated jobs into clear, step-by-step plans, so the results are always the same and easy to check. Plus, the same skill can be used by different agents if they all support the standard.

The format for Agent Skills was started by Anthropic and is now open for anyone to use and improve. Many popular AI tools already support it, and the project is growing with help from the community.

In the Hacker News comments, some people think Agent Skills are a smart way to share knowledge across teams and make AI agents more useful at work. Others say it reminds them of old ideas, like plugins or macros, but for AI. A few worry that skills might not always work well if the agent doesn’t understand the context enough. There are questions about how easy it is to write a good skill, and if most companies will have the time to make them. Some users are excited about open standards and sharing skills across different tools, while others think it could lead to security or privacy problems if skills are not managed well. A few are hopeful that Agent Skills will help agents handle more real-world tasks, but some doubt if agents are reliable enough yet for important jobs. Overall, the discussion is mixed but interested, with people wanting to see how the idea develops.

---

## Xcode 26.3 unlocks the power of agentic coding

- 原文链接: [Xcode 26.3 unlocks the power of agentic coding](https://www.apple.com/newsroom/2026/02/xcode-26-point-3-unlocks-the-power-of-agentic-coding/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46874619)

Apple has released Xcode 26.3, adding “agentic coding” to help developers build apps faster and smarter. Now, developers can use AI agents like Anthropic’s Claude Agent and OpenAI’s Codex right inside Xcode to do complex coding tasks for them.

With this update, Xcode can break down projects into smaller steps, make coding decisions, and use built-in tools without much help from the user. These AI agents can search documentation, explore project files, change settings, and even run builds and fixes, checking the results with Xcode Previews. Before, Xcode 26 added a smart assistant for writing Swift code, but now, the agents can do even more and help at every stage, from planning to testing. The agents can work together with Xcode’s own features, making it easier for developers to try ideas, fix mistakes, and finish apps quickly. Apple says this should boost creativity and let developers focus on what makes their apps special. With the new Model Context Protocol, developers can also connect any other compatible agent, not just the built-in ones.

The update is first available as a release candidate for Apple Developer Program members, and will soon be in the App Store.

On Hacker News, people have a mix of feelings. Some are excited, saying this could save time and let them focus on important parts of coding. Others worry that too much automation might hide what’s going on, making it hard to understand or debug code in the future. A few users say using big AI models inside Xcode might slow things down or need more computer power. Some wonder about privacy—will agents send code to cloud servers? There are questions about how well these agents know Apple’s own libraries and best practices. Others mention that letting agents make important decisions could lead to mistakes if the AI misunderstands the project. Some developers like the open protocol idea, since it lets them choose different agents. A few are worried new developers might not learn the basics if an AI does everything for them. Some users want to see how well these features work in real life before trusting them. A few think this move is Apple just keeping up with other tools, while others see it as a big step forward for developer tools.

---

## What's up with all those equals signs anyway?

- 原文链接: [What's up with all those equals signs anyway?](https://lars.ingebrigtsen.no/2026/02/02/whats-up-with-all-those-equals-signs-anyway/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46868759)

This article looks at why you sometimes see lots of equals signs (“=”) in old emails posted online. The author explains that these signs come from the way emails were encoded, not from secret codes or scanning errors.

Emails used to be just plain text, but as people wanted to send longer lines and special characters, mail software started using something called “quoted-printable” encoding. In this system, if a line is too long, the software adds an equals sign at the end to show the line continues. When the email is read, the program should remove the equals sign and join the lines back together, but sometimes this doesn’t work right.

The equals sign can also mean a special character is coming. For example, “=C2=A0” means a non-breaking space, which is used for things like indenting text. If the software decoding the email isn’t careful, it can leave these equals signs and extra letters in the message, making the text look strange.

The main problem happens when someone converts the email’s line endings (the way lines break) from Windows (CRLF) to Unix (NL), but doesn’t update the software that reads the quoted-printable format. The decoder expects to see three characters (“=CRLF”) but only finds two (“=NL”), so it gets confused and leaves equals signs or removes the wrong letters. This often happens when people use scripts meant for servers (that expect Windows endings) on Unix files.

The author says this is mostly a technical issue—bad software or scripts that don’t handle email formats properly. He also notes that quoted-printable was meant to be used just for sending emails, and the encoded parts should be cleaned up when the mail arrives, but that often doesn’t happen.

In the comments, some people enjoyed the little jokes mixed into the article. One person shared a story about bacon and kosher food, which made others smile. Another commenter suggested the equals signs might come from scanning paper documents (OCR errors) or from “watermarking” to catch leaks, but another reader pointed out that the article already explained it’s not about scanning or secret tracking.

One reader made a joke about email commands, showing the audience is technical and enjoys playful references. There were also links to the article shared on Reddit and other sites, which shows people found the topic interesting or useful. Overall, readers appreciated the clear explanation and some even learned something new about email encoding. Some debate still happens about why these errors show up, but most agree it’s about technical details and not secret codes.

---

## OpenClaw (a.k.a. Moltbot) Is Everywhere All at Once, and a Disaster

- 原文链接: [OpenClaw (a.k.a. Moltbot) Is Everywhere All at Once, and a Disaster](https://cacm.acm.org/blogcacm/openclaw-a-k-a-moltbot-is-everywhere-all-at-once-and-a-disaster-waiting-to-happen/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46875952)

This article talks about OpenClaw, also called Moltbot, a bot that is running on many computers and servers. The author says OpenClaw is spreading fast and is causing problems online. OpenClaw is made to crawl websites and collect data, but it does not respect rules from web servers. It ignores robots.txt files, which sites use to control which bots can enter. Because of this, OpenClaw uses up a lot of server resources and can slow down or even break websites. Some sites try to block it, but OpenClaw keeps changing its behavior to get around these blocks. The article also says OpenClaw does not tell website owners who is running it or what it is collecting. This makes it hard for website owners to protect their sites. The author warns that if OpenClaw keeps spreading, it could cause more damage and make the web less safe or stable. The article asks for better ways to stop bots like OpenClaw.

Many people in the comments agree that OpenClaw is a problem. Some say they have seen their own websites get hit by this bot and had to spend time and money to block it. Others think bots like OpenClaw are not new and that website owners should use tools like firewalls or CAPTCHAs to stop them. A few people point out that good bots, like Google or Bing, follow the rules and identify themselves, while bots like OpenClaw try to hide. Some worry that if too many bad bots exist, website owners might block all bots, even the good ones. A few think this is part of a bigger problem with how easy it is for anyone to make and run bots on the internet. Some commenters ask if there should be new laws or rules for bots. Others say that the internet has always had this problem and it is hard to fix. Overall, people agree that OpenClaw is making things worse for everyone online.

---

