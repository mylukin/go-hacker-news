Hello everyone, this is the 2025-07-14 episode of Hacker News Daily Podcast. Today, we bring you a mix of science, open source, AI, games, and a few surprises from the tech world.

First, let’s talk about one of the biggest events in space science this year. LIGO and its partner observatories have detected the largest black hole merger ever seen. In November 2023, two giant black holes—one about 100 times the mass of our Sun and the other 140—crashed together and formed a new black hole that is 225 times more massive than the Sun. This event, named GW231123, was spotted during LIGO’s fourth big observing period, with help from Virgo in Italy and KAGRA in Japan. Before this, the biggest known merger made a black hole of 140 solar masses, so this new discovery sets a new record.

What’s more interesting is that these black holes were spinning very fast, making the signals hard to study. Scientists believe that black holes this big cannot form in the usual way. It’s possible they were made from smaller black holes merging together over time. This finding is pushing the limits of both technology and theory. The rapid spinning almost breaks the rules set by Einstein’s theory, and it took special models just to read the signal. The team says it will take years to fully understand what happened.

The LIGO-Virgo-KAGRA team includes thousands of scientists worldwide, using very sensitive machines to detect tiny space changes. More data will be shared soon for other researchers to study.

In the comments, people are amazed by the size of these black holes and the power of the technology. Many are surprised such massive black holes can exist, since old theories say stars cannot create them. Some think maybe black holes grow by eating other black holes. Commenters are also curious about the accuracy of the measurements and wonder if even larger events will be found. There’s a lot of praise for international teamwork and open science, as well as questions about what this means for our understanding of the universe. Some even joke about black holes as “cosmic Pac-Men,” always eating more and getting bigger. The overall feeling is one of wonder and curiosity about the strange nature of space.

Moving on to software news, Apple’s MLX machine learning library is getting support for CUDA, which means it will soon run on NVIDIA GPUs, not just Apple devices. This early work is already running some examples, and Apple is sponsoring the project. CUDA support is important because NVIDIA GPUs are widely used in research and big computing jobs. The developer, zcbenz, explains how to build and try the new backend. Early tests work on Ubuntu with CUDA 11.6, and more updates are coming.

The team is working on performance improvements, fixing slow parts of the code, and making changes that increased training speed from 500 steps per second to 2100. Some optimizations use more memory, but the developer plans to make this easy to adjust. There are also plans to support special devices like NVIDIA Jetson in the future. Other improvements include faster build processes and ideas for just-in-time compiling.

In the comments, the community is excited and thankful. Some want to add support for AMD GPUs, and there’s discussion about the best way to merge the new code—big updates or small steps. Users are testing the new code and giving feedback on errors and fixes. There’s also debate about memory use: keeping data longer makes training faster but could be a problem for big models. Most people are happy with the progress, sharing advice and showing support for CUDA in MLX.

Next, let’s talk about PHP. The project is planning to switch to the well-known Modified BSD License, starting with PHP 9.0. Right now, PHP and its Zend Engine use their own special licenses, which are confusing and sometimes not compatible with other open source licenses. The BSD license is popular, clear, and approved by important open source groups. This change should make it easier to use, share, and distribute PHP, and avoid legal problems.

The RFC explains that past license confusion caused trouble for users and for package maintainers, like Debian, who sometimes had to rename or avoid PHP packages. The new license removes special rules and makes things simpler for everyone. All PHP contributors will keep their rights, and both the PHP Group and Perforce, who have special rights under the old license, have already given informal approval. There will be a public discussion before voting.

In the comments, most users welcome the change, saying it is long overdue. Some explain how the old license caused problems for Linux distributions and companies. Others like that the BSD license is short, clear, and helps PHP adoption. A few worry about losing trademark protection for the PHP name, but most agree the new license is better overall. Some hope other projects will also move to simpler, well-known licenses in the future.

Now, let’s take a look at history and technology. The Distant Early Warning Line, or DEW Line, was a huge radar system built during the Cold War to watch for enemy planes coming over the Arctic from the USSR. The DEW Line had 33 stations across 3,600 miles, from Alaska to Greenland, running 24 hours a day for 36 years. It was built very quickly—just 32 months—even though the conditions were extreme.

Keeping these stations running was hard work, and after the DEW Line closed, it left behind a lot of waste and even dangerous chemicals, raising questions about environmental cleanup. Inuit people were part of the project, both helping with construction and being affected by it. Most of the artifacts are gone, but a virtual museum keeps the history alive, with photos, videos, and stories from those who worked there.

In the comments, people are surprised at how big and fast the project was. Some remember seeing these radar domes as kids or had family members who worked there. Others talk about the bad effects, like environmental damage and changes to Inuit life. There is a mix of respect for the effort and concern about the cost to people and nature.

Next, let’s talk about a new AI-powered IDE called Kiro. Kiro helps developers by making specs and automation part of the coding process. Most AI tools can make prototypes quickly, but it’s hard to turn those into real, production-ready apps. Kiro uses “specs”—clear written plans for each feature. You can give it a prompt like “add a review system,” and it will break this down into user stories and edge cases using EARS notation.

Kiro then creates technical designs, diagrams, data tables, and API endpoints, all before coding starts. After that, it turns everything into tasks, links them to requirements, and adds tests and checks for things like mobile and accessibility. Kiro also uses “hooks”—small automations that run when you save or change files, helping keep code standards and catch mistakes early. It works with VS Code settings and plugins, and supports all major platforms.

Comments are mixed but interested. Some users like the focus on specs and automation, hoping it will solve problems like unclear requirements and missing documentation. Others wonder if teams will keep specs up-to-date or if Kiro might get in the way of their workflow. There are questions about how well Kiro handles real-world projects and changes over time. Many agree that tools like Kiro are moving the industry forward, but want to see real examples before deciding.

Switching to AI research, there’s a new project called NeuralOS. It shows how an operating system can be simulated using neural networks, not regular code. In the demo, users can move the mouse, click, or type, and the neural network creates and controls what you see on screen. You can choose between RNNs or diffusion models, and adjust quality settings.

The main idea is to see if neural networks can learn to act like an OS, not by programming them step by step, but by training them on data. NeuralOS is open source, and the demo is open to everyone. It’s not meant to replace real OSes yet—this is more of an experiment.

Comments are a mix of excitement, doubt, and curiosity. Some are amazed that a neural network can simulate an OS at all, while others say it’s more of an art project for now. There are questions about speed, training, and reliability—neural networks can make strange mistakes that normal code wouldn’t. Some users suggest combining neural networks with regular code to get the best results. Overall, people are interested to see where this kind of research might lead.

Let’s talk about games for a moment. Blender Studio has released a new free game called DOGWALK, where you play as a big dog helping a child build a snowman in a winter forest. The game is short, open-world, and uses cute art made from real paper models scanned into the computer. You can explore, play, and choose how you want to help—the game has no way to lose, just different moments based on your choices.

DOGWALK is open-source: the code is under the GPL license, and the art is Creative Commons. It runs on Windows, macOS, and Linux, and you can download everything from their website. Most people finish in about 30 minutes, and the game has a high rating.

Comments praise the cute art, fun gameplay, and sweet story. Some ask for a browser version, and there’s a debate about open-source licenses. Blender Studio staff say they will make the license clearer and add direct links to the source code. Players like the relaxing style and creative use of paper models, calling it a great example of open-source games.

Now for some AI research. An article looks at how large language models like GPT, Claude, Gemini, and Qwen handle long input texts. Many models now support millions of tokens, but simple tests don’t show if they can really understand or reason about big inputs. The authors run deeper tests, changing the similarity of questions and answers, the number of distractors, and how well the answer blends in. They also try more complex tasks and a test where the model must repeat a long sequence exactly.

The main findings: as the input gets longer, model performance drops, especially if the question and answer are less similar or if there are more distractors. Strangely, models do worse with well-ordered text than with random sentences. In the repeat test, models struggle to copy long sequences.

In the comments, users say this shows that benchmarks don’t match real-world tasks, and better tests are needed. Some note that humans also struggle with lots of information. Others are puzzled by models doing worse with logical text, and guess that maybe the attention system in LLMs works differently than we think. There are questions about how to break up long documents, use retrieval tools, and design prompts that help models focus. Some are hopeful that bigger or newer models will fix these problems, while others worry that hype about big context windows is ahead of reality.

For those who love retro tech, there’s Bedrock, a tiny 8-bit computer system you can use to write programs that run almost anywhere. Bedrock is just a set of rules for a simple computer. Anyone can make a Bedrock emulator for any device—even on the web or Nintendo DS. There are only 32 instructions and 12 devices, so it’s quick to learn. The website has live demos and guides, and the focus is on making programs that last and are easy to move.

Comments are positive, with people saying Bedrock is great for learning how computers work, and could help teach beginners. Some compare it to other systems like Uxn and CHIP-8. Others hope more tools and games will be made, and like the idea of running the same program everywhere, even on old or odd devices.

Finally, we have Replicube, a 3D puzzle game that runs right in your browser. You move cubes around a 3D space, trying to match a target shape. The controls use your mouse or keyboard to move and rotate cubes, and the graphics are smooth and modern thanks to WebGL and custom shaders. The game starts easy but gets tricky, and there’s instant feedback when you solve a level. No install is needed; just play in your browser.

In the comments, people like the smooth gameplay and smart use of shaders. Some found the controls confusing at first but easy after some practice. There’s talk about browser compatibility and ideas for mobile versions. Developers are interested in the tech stack and shader code. Overall, the feedback is positive, with players hoping for more levels and features.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. We hope you enjoyed these stories and insights from the community. See you next time!