# Hacker News 故事摘要 - 2025-06-27

## 今日概述

Today’s top Hacker News stories highlight creative uses of coding, new ways to make and edit images with AI, and unusual history like mailing children. There are also tools for safer programming, mixing logic with AI, and learning languages like OCaml. Other topics include fun tech demos, open data projects, and jobs in clean energy. If you like stories about tech, history, or new tools, there is something interesting to read today.

---

## Show HN: I'm an airline pilot – I built interactive graphs/globes of my flights

- 原文链接: [Show HN: I'm an airline pilot – I built interactive graphs/globes of my flights](https://jameshard.ing/pilot)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44396518)

This article is about an airline pilot who made interactive graphs and a globe to show all the flights in his career. He tracked things like total distance flown, time in the air, landings, and different roles in the cockpit.

The pilot, James Harding, flew almost 1.9 million nautical miles—about nine trips to the Moon or nearly 87 laps of the Earth. He spent over 5,800 hours in the air across more than 2,100 flights and 1,400 landings. His last flight was from Denver to London and took nine hours. The dashboard presents data like day versus night landings, annual flight hours, and even the difference in time for westbound versus eastbound flights due to winds. He explains pilot roles (like Pilot in Command and relief pilot) and how British Airways shares the flying between Captains and First Officers. The graphs also show how different routes and airspace restrictions (like avoiding Russian airspace) affect flight times and paths. For example, some flights to Asia take longer now because they have to fly around closed airspace. The visualization includes a destination matrix showing flights between countries, and notes special flights, like a diversion from Portugal to Spain. The pilot logs his own data using a logbook app and exports it to make these charts.

In the comments, many people praise the visuals and the idea of applying coding skills to a pilot’s career. Some ask technical questions about the data source (it’s a SQLite file from logbook software) and suggest new features, like tracking radiation exposure or altitude. There are discussions about how pilots split their time between flying and resting, and whether pilots have time to code during flights (most work on side projects between flights, not while flying). Some suggest turning this project into a product for other pilots. People share similar projects, tools like GCMap, and ideas for better map projections. The conversation also covers the overlap between software engineers and pilots, career changes, and how pilot training can be very expensive unless supported by company programs. Others discuss pilot health (like ear pressure), logging rules, and what happens when flights don’t return as roundtrips. There are a few jokes, encouragements, and even debates about the carbon footprint of flying. Some point out technical quirks in the graphs, and others ask about the pilot’s favorite planes or most memorable sights in the sky. The overall mood is supportive, curious, and full of new ideas for combining aviation with tech.

---

## Normalizing Flows Are Capable Generative Models

- 原文链接: [Normalizing Flows Are Capable Generative Models](https://machinelearning.apple.com/research/normalizing-flows)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44400105)

This article talks about a new way to make computer models that create images, using a method called Normalizing Flows (NFs). The team at Apple built a new model called TarFlow, which uses NFs with some extra tricks to make better images.

Normalizing Flows are a kind of model that learns how to change simple data (like random noise) into real images, and you can also go back the other way. In the past, people thought NFs were not as good as other models for making images. But this team shows that, if you build them the right way, they can work very well.

TarFlow is a special version of NFs that uses Transformer blocks, which are popular in language models, and it looks at small parts of images (patches) one at a time. The model changes the order it looks at these patches in each layer, which helps it learn better. TarFlow is simple to train and can create images directly, pixel by pixel.

To make the images even better, the team uses three new ideas: they add a little bit of random noise during training (Gaussian noise), they clean up the images after training (denoising), and they use a guidance trick to control how the images look, for both labeled and unlabeled data. With these steps, TarFlow beats other models at measuring how well it fits images (likelihood estimation), and the images it makes look as good as those from top diffusion models, which are very popular now.

The article also links to more work on similar models, like STARFlow, and talks about how these ideas might help with other tasks, like making text.

In the Hacker News comments, some people are surprised that Normalizing Flows can work so well, since they thought this method was old or not as strong as diffusion models or GANs. One person points out that using Transformers in image models is becoming more common, and it’s interesting to see them used here. Others are interested in the tricks used to improve image quality, like noise and denoising, and wonder how much they help. 

Some commenters ask about the speed and cost of using TarFlow compared to diffusion models, since those can be slow. There are also questions about how easy it is to train and use this model in real-world problems, and whether it can be used for things besides images. A few people think this work might bring Normalizing Flows back into focus and start more research in this area. Overall, the comments show a mix of excitement, curiosity, and healthy skepticism about how well TarFlow will do outside of tests.

---

## A Brief History of Children Sent Through the Mail

- 原文链接: [A Brief History of Children Sent Through the Mail](https://www.smithsonianmag.com/smart-news/brief-history-children-sent-through-mail-180959372/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44399854)

The article talks about a time in the early 1900s when some parents in the United States sent their children through the mail. When parcel post started, people realized it was sometimes cheaper to mail a child by train than to buy a train ticket. In these cases, children were “mailed” by being handed over to postal workers, who would make sure the child reached their destination safely. The post office treated the children as packages, charging by weight, and the kids would travel with a label pinned to their clothes. This practice was rare but real, and often happened in rural areas where families knew their mailmen personally. After a few years, the post office made new rules to stop people from mailing children. The article uses stories and old photos to show how different life was at that time.

One top comment jokes about a photo of a child in a tote bag alongside an ad for a free tote from the magazine, saying “the child is not included.” Another commenter wonders if adults could be mailed, and someone else points out that an adult named Henry Box Brown actually mailed himself in a box to freedom. But another person says the post office has a rule now: packages can’t weigh more than 70 pounds, so most adults are too heavy to mail. Some people feel amazed at how much trust people had in society back then, letting strangers take care of their kids. Others say it’s a sign of how people sometimes made questionable choices in the past. The comments show a mix of surprise, humor, and reflection on how things have changed. Some laugh at the odd idea, while others think about safety and how we see trust and rules today.

---

## Structuring Arrays with Algebraic Shapes

- 原文链接: [Structuring Arrays with Algebraic Shapes](https://dl.acm.org/doi/abs/10.1145/3736112.3736141)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44399757)

This article looks at better ways to work with arrays in programming, using a new type system called Star. Today, most programming languages for arrays either have very simple types—just the element type or number of dimensions—or very complex types called dependent types, which are hard to use and slow to check. The authors say this is a problem for people who use arrays a lot, like in data science or machine learning, because mistakes with shapes and indices are common and can break programs.

They introduce the Star calculus, which gives arrays richer types using records (like named fields in a struct) and variants (like choices in an enum), and supports subtyping. This system lets you describe the structure of an array more clearly, so you can catch shape mistakes early, before running code. Instead of solving complex math at compile time, it checks if your array shapes match using these richer types. The system is built to avoid the problems of dependent types—it’s simpler and more practical. The authors also suggest that with algebraic subtyping, you can get very good type inference, like in the ML family of languages, but without losing speed or safety.

One commenter finds this approach very exciting. They want a language that is both type-safe and easy to use for math, arrays, and vectors, but without the heavy complexity of dependent types. They like that the system balances deep mathematical ideas (like connections to lambda calculus and tuples) with real-world needs, and hope for a working version to try.

Another commenter points out a possible problem. They say that naming axes (for example, calling an axis “time”) gives meaning to array shapes, but in real code, array shapes often change quickly—reshaping, squeezing, or permuting axes just to match another function. Adding names can make things harder, because you have to manage all these labels and keep them correct as shapes change. Once you label an axis, every change to the array must keep track of the label, even if the axis gets merged or split later. They see this as a tradeoff between clarity and extra work.

Overall, some people are excited to see more math-friendly, type-safe tools for arrays, while others worry that adding structure could make code harder to manage when arrays change shape often. The balance between safety, clarity, and ease of use is still a big topic for array programming.

---

## SymbolicAI: A neuro-symbolic perspective on LLMs

- 原文链接: [SymbolicAI: A neuro-symbolic perspective on LLMs](https://github.com/ExtensityAI/symbolicai)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44399234)

SymbolicAI is a Python library that mixes traditional programming with large language models (LLMs) to help you write more powerful and flexible code. It lets you use both simple logic and AI-powered reasoning together, so you can build programs that understand meaning and context, not just rules.

SymbolicAI’s main ideas are “primitives” and “contracts.” Primitives are basic building blocks called Symbols. These can act like normal Python values (strings, lists, numbers) or, when you switch modes, they use AI to understand meaning. For example, you can check if “feline” is in a sentence about cats, and in semantic mode, the AI knows the words are related, even if they’re not the same. There are many operators (like ==, +, &, etc.) that work in both normal and semantic ways. You can mix and chain these operations to create complex logic that blends code and AI.

Contracts are rules that help you avoid mistakes when using LLMs. They work like “Design by Contract” in programming, making sure your program checks its inputs and outputs, fixes errors, and only accepts correct results. You can add these checks to your data models and LLM-powered agents, so your code is safer and doesn’t rely only on testing after things go wrong.

The library supports many AI engines, including OpenAI and Anthropic, and can also work with local models like llama.cpp. It lets you use extra features for things like speech, images, or web search, by installing optional packages. Setting up SymbolicAI needs some API keys, and it has a flexible system for managing configuration files, so you can control settings for global, project, or testing use. There are tools to help you see which configuration is active and to keep things organized.

For testing, SymbolicAI uses pytest, and you can run coverage checks. The library is open source under BSD-3 license and is looking for users and contributors. There is more documentation on DeepWiki, and you can find video tutorials and a research paper if you want to dig deeper.

In the Hacker News comments, people are interested in how SymbolicAI combines symbolic and neural approaches. Some think it’s a much-needed way to make LLMs more reliable by adding structure and rules. Others wonder if it’s too complex or if most developers will use just the basic LLM features instead. A few users mention that mixing semantic and traditional logic can get confusing, but they like the idea of having contracts to catch errors before they happen. Some compare SymbolicAI to other tools like LangChain, but note that SymbolicAI seems more focused on the programming side, not just chaining prompts.

There is also some discussion about the need for more examples and better documentation, especially for people new to neuro-symbolic programming. One commenter asks if it’s possible to use SymbolicAI with fully local models, and another says they like the open-source license and modular design. A few users think that, while the tool is powerful, it might be overkill for small projects. Others are excited to see more “neuro-symbolic” ideas making their way into real software libraries, and hope this makes LLMs safer and more useful in real code. Some users mention they will follow the project to see how it grows, and a few suggest improvements to make the setup process easier.

---

## Qwen VLo: From "Understanding" the World to "Depicting" It

- 原文链接: [Qwen VLo: From "Understanding" the World to "Depicting" It](https://qwenlm.github.io/blog/qwen-vlo/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44397124)

Qwen VLo is a new AI model that can both understand images and create or edit them based on instructions. The article explains how this model builds images step by step, letting users generate pictures, change styles, or edit objects just by telling it what to do, even in different languages like English and Chinese. Qwen VLo is better than older models at keeping the meaning and details of what you want, like changing a car’s color without changing the car itself, or making a painting look like it was made by Van Gogh. You can ask it to do many things at once, such as changing backgrounds, editing text, or adding objects, all in one request. The model can also handle different image sizes and formats, making it useful for posters, banners, or comics. It uses a special way of building images from top to bottom and left to right, which makes editing easier and lets you see changes as they happen. Qwen VLo is in an early stage, so sometimes it makes mistakes or doesn’t follow instructions perfectly. The team says they will keep working to make it better and more stable.

In the comments, many people are disappointed that the model’s weights (the data needed to run or train the model yourself) are not open to everyone. Some users say Qwen was known for sharing its models before, and they wish this one was also open, so researchers could study it or use it freely. Others point out that if a company gives away the model, other people can run it too, making it hard for the original team to earn money after spending a lot to build it. Some commenters argue about what “open source” or “open weights” really mean, with some saying that real open source means you can use the model for anything, not just for research or personal projects. A few users mention that some other Chinese models are still open, and the situation might not be as closed as it seems. Some technical comments discuss how the model sometimes changes parts of an image you didn’t ask to change, which is partly because of how these AI models work. There are also remarks about the model’s image quality, with some people noticing a yellow tint like in other AI models, and others saying that details often get lost or altered. One user, a researcher, warns against saying these models “understand” images, since they often make strange mistakes, like drawing keyboards with the wrong number of keys. A few people defend the use of simple words like “understand” or “depict” to explain what the model does, saying it helps regular users. Lastly, some commenters feel the model’s outputs are not useful beyond research right now, while others are curious about the technical details behind how the model works.

---

## Transmitting data via ultrasound without any special equipment

- 原文链接: [Transmitting data via ultrasound without any special equipment](https://halcy.de/blog/2025/06/27/transmitting-data-via-ultrasound-without-any-special-equipment/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44398390)

This article talks about sending data between devices using ultrasound, and you do not need any special hardware—just normal computer speakers and microphones. The author explains that while most data is sent using radio waves (like WiFi), sound can also be used, especially high-frequency sounds (ultrasound) which people usually cannot hear.

First, the article explains what ultrasound is: sound above 20,000 Hz, which most humans cannot hear. Most computers, phones, and laptops can play and record sounds a bit above what people can hear. So, you can use these high sounds to send secret data between devices. The author tried two ways to send data: Morse code (which did not work well), and a better method called frequency shift keying (FSK), where bits are sent by changing the pitch of a beep. The code to do this is shared in the article.

To send data, the sender changes the sound’s frequency for each bit (0 or 1). The receiver listens and checks which frequency is loudest to read back the data. The message is sent as ASCII characters, with special bits added before and after each letter to help the receiver know where the message starts and ends. The author says the system works, but it is slow, not very reliable, and can easily break if there is too much noise or interference.

There is room for improvement, like adding error correction or making the system stronger against noise. The author mentions that similar ultrasound data signals are used by some meeting apps to detect nearby devices, so this idea is not just a toy.

In the comments, people remember older products that used ultrasound to send simple commands to phones at events, making light shows by syncing many phones at once. Someone who worked at Google says Google tested this for devices like Chromecast, but the main problem was that dogs could hear the high sounds and got upset. Another user says the method used is not new and is similar to how old tape recorders stored computer data, using frequency changes for bits.

Some people discuss the limits of “ultrasound” with normal devices. They note that 18-20 kHz is not true ultrasound, because some young people can still hear it and find it annoying. Medical ultrasound uses much higher frequencies, but regular speakers and microphones cannot make or hear those. Others talk about sound equipment limits—most consumer gear cannot play much above 20 kHz, so staying in the high-audio range makes sense for this trick.

A few users talk about technical details, like sample rates and bitrates, and how higher sampling allows higher frequencies, but the hardware may not support it. One person tried the web tool and was surprised it worked even with loud background noise, but admits high-frequency noise might still cause problems. There is also mention of other tools like GGWave, used in fitness apps for syncing recordings, and comments about meeting apps using ultrasound to know which room a device is in. Finally, some people bring up small issues, like confusion about how music apps show sound and complaints about website design.

---

## Spark AI (YC W24) is hiring a full-stack engineer in SF (founding team)

- 原文链接: [Spark AI (YC W24) is hiring a full-stack engineer in SF (founding team)](https://www.ycombinator.com/companies/spark/jobs/kDeJlPK-software-engineer-full-stack-founding-team)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44400190)

Spark AI is a new startup in San Francisco, building AI tools to help companies create large clean energy projects like solar farms and battery storage. They are hiring a founding full-stack engineer, offering a salary of $150K–$200K, equity, and visa sponsorship.

The company’s mission is to speed up the move to renewable energy using software. Their tools help big energy developers and firms find and use important information about rules and local conditions, which can be very complex. Spark already works with well-known industry customers who build projects worth billions of dollars and provide clean power to millions of homes.

The team is small and in-person, made up of people with backgrounds at big tech companies and in energy. They use modern technologies like TypeScript, NextJS, NodeJS, and Postgres. The job means working closely with founders and customers, quickly building and testing new features, and taking ideas from start to finish. Candidates should have at least three years of experience building web apps and be eager to learn about AI and the energy field. Extra points if you have experience with large data systems, LLMs, or have worked at startups.

Spark wants people who want to make a real impact, enjoy talking to users, and can balance quick work with building solid systems. They value ownership, urgency, curiosity, and building for a big mission. The interview process includes calls, coding, team meetings, and a system design session.

In the comments, there is little discussion so far, but some users note the strong focus on in-person work and the generous offers for early team members. Others point out that working on clean energy tech is exciting and meaningful, and the mix of AI and energy is a growing field. Some people mention San Francisco’s high cost of living but say the role's equity and mission could make it worth it for the right person. A few users wonder about the company's long-term plans and how much impact it can have, but most see joining as a rare chance to help shape a company from the start. Overall, the job is seen as a good fit for someone who wants to grow quickly, learn new things, and help the world move to green energy.

---

## 10 Years of Pomological Watercolors

- 原文链接: [10 Years of Pomological Watercolors](https://parkerhiggins.net/2025/04/10-years-of-pomological-watercolors/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44397168)

This article is about how, ten years ago, the author worked to get the US government to release a big set of fruit paintings called the Pomological Watercolor Collection. The collection has over 7,000 pictures of fruits, painted between the 1880s and 1940s, and was locked behind a paywall even though few people were buying them.

The author made Freedom of Information Act requests and wrote a blog post asking for the images to be freely available. After some months, the US National Agricultural Library put the high-quality scans online for everyone to access and download. Instead of stopping there, the author helped put the images on Wikimedia Commons, which meant learning Python and making a bot to upload the files. This was the author’s first programming project and helped start a new career in coding.

Later, the author made a Twitter bot (which now runs on Mastodon and Bluesky) to share these fruit pictures online. The paintings have also been used in talks, music videos, datasets, and even in making small buttons as keepsakes. Over the years, the collection has inspired books, postcards, art prints, and has been shown in the media and even on TV shows. The author found the collection while working to support the public domain, and says that following this curiosity led to ten years of surprises and happiness, making life better in unexpected ways.

In the Hacker News comments, people thank the author for making the images free and share how they have used them in their own projects. Some used the pictures for art, research, or even made prints for their offices. One person said the collection inspired them to ask other museums to open up old art collections. Another commenter went down a “rabbit hole” of image compression because of these scans.

There is some talk about licensing: a few users note the images are public domain, so attribution is not required, although the official site asks for it. Some think the attribution request is just old boilerplate and not legally binding. Others share tips for downloading the whole collection and finding the metadata. A few people mention how learning to code for this kind of project changed their lives. There is also a light joke about the word “pomological” and some friendly banter. Overall, the comments are positive, with people feeling inspired, grateful, and happy about the public access to these unique fruit paintings.

---

## Learn OCaml – Exercises

- 原文链接: [Learn OCaml – Exercises](https://ocaml-sf.org/learn-ocaml-public/#activity=exercises)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44400025)

The article talks about “Learn OCaml,” a web tool for learning the OCaml programming language through exercises. It lets users sign up with a nickname and secret token, then solve coding activities directly in the browser.

The main idea is to help people learn OCaml by practicing. You can start as a new user or return with your token to pick up where you left off. The platform offers different exercises and activities. After logging in, you can sync your progress, export your work, or download source files. Everything runs online, so you don’t need to install anything. It is simple for both beginners and teachers to use. Teachers can see feedback and help students. The goal is to make OCaml learning easier and more interactive.

In the Hacker News comments, some users are happy to see tools that help people learn functional programming. They think that OCaml is a powerful language, but not many good resources exist for beginners. Some users say that interactive tools like this make learning less scary. One commenter wonders if the tool covers advanced topics or just basics. Another user mentions that having exercises is important for learning any language well. Some people wish there were similar tools for other programming languages. A few users talk about using OCaml in real projects and how learning platforms could help new programmers join the OCaml community. Others discuss how easy it is to start with this tool compared to setting up OCaml on your own computer. Overall, most comments are positive and hope for more resources like this in the future.

---

