# Hacker News 故事摘要 - 2025-07-08

## 今日概述

Today’s top Hacker News stories cover new security bugs in AI and Git, a personal finance app’s slow path to success, and a creative open-source music editor. There is also science news about the Moon’s origins and how plants heal themselves, plus tips for better GitHub demos and a new open-source language model. Main themes are security, AI, science, and useful tools.

---

## Supabase MCP can leak your entire SQL database

- 原文链接: [Supabase MCP can leak your entire SQL database](https://www.generalanalysis.com/blog/supabase-mcp-blog)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44502318)

This article explains a new security problem with Supabase’s Model Context Protocol (MCP) when used with large language models (LLMs). It shows how attackers can make the AI assistant leak private SQL database data by tricking it with special messages.

The issue is that LLMs do not know which text is data and which is a command. If a user puts a command inside their message—like telling the assistant to dump secret data—the LLM may just do it. In the example, an attacker uses a normal support ticket to send a message that looks like a real support request but also includes hidden instructions for the AI. The AI assistant, running with high-level database access, reads this message. It then runs SQL commands that pull secret tokens from the database and posts them back in the support ticket, where the attacker can see them.

The attack works because the AI agent has a special “service_role” in Supabase. This role can access everything in the database, even things normal users and support agents cannot see. The agent is supposed to help developers by summarizing tickets, but it cannot tell the difference between a real message and a trick. As a result, if the agent is not filtered or restricted, it can be forced to leak data.

The article suggests two quick ways to reduce the risk. First, use a read-only mode for the AI agent so it cannot write or change anything in the database. Second, add a filter to check for dangerous commands or SQL code in messages before giving them to the AI. These fixes help, but the article warns that the problem is deeper and needs careful attention.

Hacker News readers had many thoughts. Some were shocked that such a basic security mistake was possible. They said giving the AI assistant full database access was a bad idea from the start. A few pointed out that LLM prompt injection is a known risk and that tools should not process user data as instructions. Others suggested that using more strict roles or context separation could help. One commenter said this shows why AI assistants should never get full admin access, even for convenience. Some thought better input filtering would stop most attacks, while others warned that clever attackers can always find ways to sneak past filters. A few readers wondered if other platforms have the same problem, and some shared their own stories about prompt injection risks. Many agreed that the mix of LLMs and critical systems like databases needs new safety tools and better design.

---

## Breaking Git with a carriage return and cloning RCE

- 原文链接: [Breaking Git with a carriage return and cloning RCE](https://dgl.cx/2025/07/git-clone-submodule-cve-2025-48384)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44502330)

This article is about a new security bug in Git (CVE-2025-48384) that lets attackers run code on your computer if you use `git clone --recursive` on a bad repository. The bug is caused by how Git handles carriage return characters (the old “return” from typewriters, or `\r` in code) in config files.

Git uses config files to track submodules. These files can have special characters like carriage returns. When Git reads these files, it strips out any `\r` at the end of a line. But when Git writes these values back, it sometimes doesn’t put them in quotes unless they have certain characters. This means someone can trick Git by putting a carriage return at the end of a submodule path.

On Unix systems, filenames can include control characters like `\r`. So, a bad repository can set a submodule path to include a carriage return. When Git reads and writes this path, it changes the meaning—one place sees the path with `\r`, and another without it. This confusion can be used to make Git put files in unwanted places, which could let an attacker run code when you just clone a repository.

Windows is not affected because it does not allow control characters in filenames, but macOS and Linux are at risk. The bug only happens if you use `git clone --recursive`, which most people do not use by default on the command line. But GitHub Desktop uses this option automatically, making it more dangerous for those users.

The fix is simple: when Git writes a config value that has a carriage return, it always puts it in quotes. There is already a patch and new versions of Git that fix this.

In the comments, some people are surprised that such an old character (carriage return from typewriters) can still cause big problems in modern software. Others note that similar bugs have happened before in Git and other software, often because of how different systems handle line endings. Some say that the way Git tries to handle many old formats (like DOS and Unix line endings) makes these bugs more likely.

A few users argue that it’s too easy to make mistakes when reading and writing config files, especially with all the edge cases. Some think that using a more strict format, or always quoting values, would help make things safer. Others point out that the "robustness principle" (accepting many formats) was good in theory, but now often causes security issues like this.

People also talk about how GitHub Desktop’s use of `--recursive` by default is risky, since many users may not know the dangers. Some advise always checking `.gitmodules` before running submodules, but admit most people will not do this. Finally, some commenters thank the person who found the bug and stress how important it is to keep software like Git under review for these tricky problems.

---

## Bootstrapping a side project into a profitable seven-figure business

- 原文链接: [Bootstrapping a side project into a profitable seven-figure business](https://projectionlab.com/blog/we-reached-1m-arr-with-zero-funding)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44495428)

This article tells the story of how ProjectionLab, a personal finance planning tool, grew from a side project into a business making over $1 million every year, all without outside funding. The creator started building the tool in 2021 because he wanted something better for his own financial planning and couldn't find it elsewhere.

He began working on ProjectionLab after his regular job, putting in hours at night and on weekends. The business grew slowly at first. He made his first sale in May 2021, then hit key milestones: $1,000 monthly revenue by the end of 2021, $10,000 per month by mid-2023, and finally $83,000 per month by June 2025. There were many hard times, like months with no growth, dips in earnings, and lots of canceled subscriptions. He worried often about whether to give up and focus on his normal job instead.

A big part of the journey was learning not to quit. The author says that just showing up every day is more important than being the smartest person in the room. After working alone for two years, he realized he needed help to keep growing. He looked for someone with marketing skills and found a partner who proved himself by helping before asking for anything in return. They also brought on contractors from their user community to help with customer questions and support. The team chose to hire people from their community instead of outsourcing support cheaply, because they wanted users to have the best experience.

ProjectionLab now has a strong community, with over 8,500 people in their Discord. The author says that the real secret was making a good product, staying focused, and not chasing every new trend. They plan to keep building slowly and carefully, without taking outside money or trying to grow too fast.

In the comment section, many people were impressed by the steady growth and consistency. Some praised the author for sharing real numbers and showing the hard parts, not just the wins. Others pointed out that building a business alone is tough, and hiring the right partner was a smart move. A few users said that the founder’s story matched their own experiences with side projects—lots of slow growth and doubts, but big changes over time. Some commenters asked technical questions about how the product works and how support is handled. Others wondered about the risks of not taking funding and the balance between slow, steady growth and moving faster with more resources. Finally, several people said this story gave them hope and encouragement for their own projects, showing that patience and showing up every day can lead to big results.

---

## Radium Music Editor

- 原文链接: [Radium Music Editor](http://users.notam02.no/~kjetism/radium/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44502298)

Radium is a music editor and digital audio workstation (DAW) that uses a special interface to make editing music faster and to show more musical data on the screen. It mixes ideas from piano roll and tracker interfaces, letting you edit notes and effects both graphically and by text.

Radium started in 1999 and was first released in 2000. It works on Linux, Windows, and Mac, and has grown into one of the most advanced tracker-like music editors. You can use Radium to record, edit, and mix audio, work with MIDI, and use many audio plugins like VST and LADSPA. There are lots of built-in effects and instruments, plus you can do things like granular synthesis, automate effects, zoom in and out, and script with Python or Scheme. It supports microtonal music, has unlimited undo/redo, and lets you synchronize with other DAWs. Radium is open source, easy to build, and has regular updates. To get started, you load a demo song, press space to play, and add notes with your keyboard.

In the comments, some people say they really like Radium’s unique interface and the mix of tracker and piano roll features. Others think the look is confusing at first, especially for users used to classic trackers or DAWs. A few users say Radium is powerful, but the learning curve can be high if you are new to these kinds of programs. There are comments about how open source and cross-platform support are big advantages. Some users wish more DAWs tried new ideas like Radium does. Others mention that while Radium is feature-rich, it can be hard to set up on certain systems. A few say they appreciate the fast development and regular updates. There are also people who ask about plugin support and scripting, and they like that Radium lets them use Python or Scheme. Some say the documentation is helpful, while others want more tutorials or videos. Overall, users respect Radium for trying something different and for giving musicians many creative tools.

---

## Dynamical origin of Theia, the last giant impactor on Earth

- 原文链接: [Dynamical origin of Theia, the last giant impactor on Earth](https://arxiv.org/abs/2507.01826)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44502527)

This article looks at where Theia, the giant object that hit Earth and helped form the Moon, might have come from. The authors use computer models to test how Theia could have formed and moved in the early Solar System.

In their study, they start with a mix of small planets (called embryos) and even smaller rocks (called planetesimals) between the orbits of Venus and Earth. They also add in some carbon-rich objects that Jupiter pushed closer to the Sun. Their model matches many things we see today: the size and orbits of Earth and Mars, the amount of carbon-rich material inside Earth, and the fact that Mars has much less of this material. Their model shows that Mars gets its carbon-rich parts only from small rocks, not from big embryos. The timing of the Moon-forming impact also fits, happening late in Earth’s growth. After this impact, most new material added to Earth is not carbon-rich.

The model says that, long ago, there were about 0.2 to 0.3 Earth masses of these carbon-rich objects in the inner Solar System. Most of this mass was in large embryos, not in small rocks. These embryos were about 1% to 5% the mass of Earth. The model gives about a 50-50 chance that Theia was carbon-rich—either completely or because it swallowed another carbon-rich body before hitting Earth. This supports older chemical studies that guessed Earth got a lot of its carbon from Theia.

In the top comments, many people were amazed by how much detail these models can now show. Some users talked about how hard it is to know the exact path and make-up of objects from billions of years ago. Others asked how these findings might change our ideas about how planets form, or about the chances of life on other planets. A few users pointed out that these results help explain why Earth and Mars are so different, even though they are close in space. Some were curious if this could help us study exoplanets and their moons. One person wondered if new data from Moon rocks could help test these ideas even more. Another commenter said it’s exciting to see computer models and chemistry studies agree. Some users said it's still hard to be 100% sure because we can’t see the past, but they like how these models give us better guesses. Finally, several users enjoyed learning how planet building is a mix of chaos, luck, and many random crashes.

---

## The Tradeoffs of SSMs and Transformers

- 原文链接: [The Tradeoffs of SSMs and Transformers](https://goombalab.github.io/blog/2025/tradeoffs/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44503056)

This article compares two types of AI models for handling sequences: State Space Models (SSMs) and Transformers. It explains how both are used for tasks like language modeling, but they have very different strengths and weaknesses.

SSMs work by using a hidden state to compress all past information, like how a brain remembers things—always updating, but with limited memory size. The article highlights three main parts that make SSMs strong: they use a big hidden state, have flexible ways to update this state, and use tricks to train faster and with less memory. The new SSMs, like Mamba, combine these ideas and now perform almost as well as Transformers for language tasks.

Transformers, on the other hand, store every token they've seen in a big "cache," like a database that can look back at any specific detail. This makes them very good at remembering exactly what happened and working with fine details, but it also means they use lots of memory and compute, especially for long sequences. Their main trick, called "attention," compares every part of a sequence to every other, which is powerful but slow for long data.

The article uses analogies: Transformers are like a database (storing everything exactly), while SSMs are like a brain (summarizing history but maybe forgetting details). SSMs can't perfectly recall a random phone number from a long list, but neither can people. Transformers hit a hard wall if their cache is too small, while SSMs can remember much longer, though fuzzier, sequences.

The author also says that attention works best on "pre-compressed" data—like language that has already been split into meaningful tokens (words or subwords). Transformers struggle when each input token is not meaningful, for example at the character or byte level. In these cases, SSMs do better, as shown in experiments with raw text and DNA data. The article argues that tokenization (breaking data into tokens) is an ugly but practical hack, and hopes for future models that can skip it.

Another key point is that mixing both types—using mostly SSM layers with a few attention layers—can give even better results, similar to how humans use both memory and notes. Big labs are now building hybrid models like this, which are both faster and more accurate.

From the comment section, some readers agree that SSMs are promising, especially for tasks with long or noisy sequences. Others point out that Transformers are still king for tasks needing exact recall and manipulation. Some question whether SSMs can really compete at larger scales or if they have hidden limits. A few note that attention is a strong and flexible tool, and that many "efficient" attention variants blur the line with SSMs. There’s debate over whether getting rid of tokenization is worth the effort, with some saying the practical benefits are not clear yet. People also discuss the analogies: some like the brain/database idea, while others think it oversimplifies the technical details. Overall, most agree that both models have a place, and that hybrid systems may be the future, but there’s still much to learn about their real trade-offs.

---

## Plants monitor the integrity of their barrier by sensing gas diffusion

- 原文链接: [Plants monitor the integrity of their barrier by sensing gas diffusion](https://www.nature.com/articles/s41586-025-09223-4)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44472613)

This article is about how plants keep their protective barrier strong by sensing how gases move in and out. Scientists studied a plant called Arabidopsis and looked at how its outer tissue, called the periderm, heals after being hurt. The periderm protects the plant from things like bugs and dryness. When the periderm is cut or damaged, the plant quickly starts to rebuild it. Special cells and chemicals work together to make new barrier layers. Two gases, ethylene and oxygen, are key in this process. Normally, the periderm keeps these gases from moving freely. When the barrier breaks, ethylene leaves the tissue and oxygen comes in. The loss of ethylene and the gain of oxygen act like a signal, telling the plant to start making new barrier cells. If the wound is covered so gases can’t move, the barrier does not repair well. The researchers also found that these gases work together: both need to change for the best healing. The same idea was tested in other plant parts, like stems, and they found gas movement helped healing there too, but the details were different. In the end, the study shows that plants use gas diffusion to check if their barrier is hurt and to guide repairs.

In the comments, some readers are impressed by how plants use such a simple method—gas movement—to sense damage. Others point out that this research might help in farming, like making crops that heal faster after injury. Some wonder if this idea can be used for making better cork or other plant-based materials. A few people discuss how this compares to animal healing, noticing that plants and animals use very different systems. Another group is interested in the idea that plants use both physical and chemical signals to control growth and repair. Some users ask if this could be a way to design new sensors or bio-inspired tech. A few are surprised at how little we know about plant self-repair, even after many years of study. There are also comments about the technical parts of the experiments, like how the scientists measured gases and marked different cells. Some readers wish for more studies in other plants, or in real soil, not just in lab settings. Others think this finding could help us understand how climate change or pollution affects plant health. Finally, some just express excitement at learning more about the hidden “intelligence” of plants.

---

## TIL you can make "GIFs" with SVGs for GitHub README.md files

- 原文链接: [TIL you can make "GIFs" with SVGs for GitHub README.md files](https://koaning.io/posts/svg-gifs/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44498133)

This article talks about how you can use animated SVGs to make images that look like GIFs in your GitHub README files. The author explains that these SVGs are smaller and sharper than normal GIFs, and GitHub supports them out of the box.

To make these SVGs, you first record a terminal session with a tool called asciinema. Then, you use another tool, svg-term-cli, to turn that session into an animated SVG file. You can then drag and drop this SVG file directly into your README file, and it will show the animation. The author uses this trick in their own project called "bespoken."

The article explains that SVG files can have built-in animations. This works because the SVG format supports elements like `<animate>`, `<animateTransform>`, and `<animateMotion>`. These elements let you change parts of an SVG image over time, or move things around, which is how the animation works. The svg-term-cli tool uses these features to make terminal recordings look animated, just like a GIF, but with better quality and smaller file sizes.

In the comment section, many people are surprised that SVGs can do animations at all. Some think this is a cool trick and want to try it on their own projects. Others point out that SVGs load faster and look better than GIFs, so it is a smart choice for code demos. A few users say they worry about browser support, but most agree that modern browsers handle animated SVGs well. Some people share tips about customizing the SVGs or using them for other things, like flowcharts or diagrams. There are also questions about security, but others reply that GitHub safely shows SVGs. A few mention that SVGs can sometimes be blocked by email clients, but that is not a problem for GitHub. One user says this is a great way to show terminal output without big files. Overall, the comments are positive and excited about using animated SVGs.

---

## Smollm3: Smol, multilingual, long-context reasoner LLM

- 原文链接: [Smollm3: Smol, multilingual, long-context reasoner LLM](https://huggingface.co/blog/smollm3)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44501413)

SmolLM3 is a new, small language model with 3 billion parameters. It is made to be efficient, support six languages, reason well, and handle very long text (up to 128,000 tokens). The article explains how SmolLM3 beats other models of similar size and even matches some bigger ones, all while being fully open and easy to use.

The team built SmolLM3 by changing the usual Transformer architecture. They used grouped query attention to save memory, NoPE to handle long text better, and intra-document masking for stable training. They trained the model on 11 trillion tokens in three stages: starting with mostly web data, then adding more math and code, and finally focusing even more on high-quality math and code examples.

After main training, they did special “mid-training” steps. First, they made SmolLM3 better at handling long texts by slowly increasing the amount of text it could read and remember. Next, they trained it to reason, using both real and synthetic data with reasoning steps included. For final polishing, they used a method called Anchored Preference Optimization (APO) to make the model’s answers better by comparing good and bad responses.

To solve some performance issues, the team merged different model checkpoints. This let them keep both strong reasoning and long-context abilities. SmolLM3 supports two modes: quick answers (“no_think”) and detailed reasoning (“think”)—users can switch modes with special commands in the prompt. It also supports tool use, so you can connect it to other software.

Tests show SmolLM3 is the best or second-best on many benchmarks for its size, including knowledge, reasoning, math, and code. Its multilingual support is strong across English, French, Spanish, German, Italian, and Portuguese. It is easy to run on your own machine, and the article gives code examples for using it in both reasoning and non-reasoning modes.

In the Hacker News comments, some people are excited about having a small, open model that is easy to use and fast. They like that the full training process and data are shared, making it possible for others to build on this work. Others ask if the model can run on older hardware or on devices like laptops and phones. Some users are interested in the tool-calling feature, wondering how well it works in practice.

A few commenters are cautious, asking about real-world accuracy and if the benchmarks used are fair. Some worry that focusing on reasoning might hurt performance on very long texts, and they note the trade-offs involved when merging models. There are positive remarks about the clear instructions and open data, with people saying it helps smaller groups and hobbyists. A few users also ask how SmolLM3 compares to popular models like Llama and Qwen in daily tasks, not just benchmarks.

Overall, the main feeling is that SmolLM3 is an important and helpful open-source model. Many are happy to see a model that is small, powerful, and shared with clear training details, but some want to see more real-world tests and comparisons.

---

