# Hacker News 故事摘要 - 2026-02-24

## 今日概述

Today’s top Hacker News stories talk about Apple moving Mac mini production to the US, AI writing more research papers, and fun projects like teaching a dog to code games. There are new tools for privacy and coding with AI, plus clever device hacks. People also discuss inspiring childhood stories, website outages, and a new web framework made almost fully by AI. The main themes are AI’s fast growth, creative tech experiments, and changes in how we work and build things.

---

## Mac mini will be made at a new facility in Houston

- 原文链接: [Mac mini will be made at a new facility in Houston](https://www.apple.com/newsroom/2026/02/apple-accelerates-us-manufacturing-with-mac-mini-production/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47143152)

Apple is moving Mac mini production to a new factory in Houston, Texas, starting later this year. The company will also make advanced AI servers in the same facility and open a center to train people in new manufacturing skills.

The new Houston site will double the size of Apple’s campus there and create thousands of jobs. Workers in the Houston factory will build Mac minis and assemble servers, including making logic boards on-site. These servers are used in Apple’s data centers across the U.S. Apple says the Mac mini, known for its small size and power, is an important tool for many people, from students to business owners. The company wants to show it is serious about building more products in America.

Apple is also opening a 20,000-square-foot training center in Houston this year. This center will teach students, suppliers, and other U.S. businesses how to use new manufacturing methods, with Apple experts leading classes. The goal is to help more American companies make high-tech products.

Apple shared updates on its other U.S. investments too. The company has bought more than 20 billion U.S.-made chips in the last year, working with partners like TSMC and Texas Instruments. New factories in Texas, Arizona, and Kentucky are making silicon wafers and glass for Apple devices. Apple is also training small U.S. manufacturers in Detroit and online, focusing on AI and automation.

In the Hacker News comments, some people are happy to see Apple building products in the U.S. again, saying it will help local jobs and skills. Others wonder if this move is only for public relations or to respond to government pressure. A few ask if all parts of the Mac mini, like the chips, will truly be made in the U.S., or just assembled there. Some commenters point out that building in the U.S. may raise costs, possibly making the Mac mini more expensive. Others say it is good for national security to have tech made locally, especially for servers and key hardware. There is also talk about how much of the supply chain, like chips and glass, is still global, even if final assembly is in the U.S. A few people share worries about whether enough workers will have the right technical skills, but they like the idea of Apple’s new training center. Some see this as a small but important step for U.S. manufacturing, while others doubt it will change the bigger trend of making electronics overseas. Overall, the news brings out both hope and skepticism from the community.

---

## Looks like it is happening

- 原文链接: [Looks like it is happening](https://www.math.columbia.edu/~woit/wordpress/?p=15500)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47143211)

This article talks about a big increase in the number of new physics papers on the arXiv, especially in the field called hep-th (high-energy physics theory). The writer thinks this jump is because AI can now write papers as well as, or better than, many humans in this area.

The author gives numbers from arXiv to show the change. For example, in December, there were 634 papers in 2022, 684 in 2023, 780 in 2024, but a huge jump to 1,192 in 2025. The early months of 2026 are even higher, with more than double the usual number. The author thinks this is because AI can make papers much faster than before. He also says that before, professors used students and helpers to write many average papers, but now AI can do this work, so more people can try, and there will be even more papers.

The writer jokes that maybe an AI could do a better job of studying this trend, or even moderating the comments, since it is now hard to tell if a comment is from a person or an AI. He asks readers not to leave empty or off-topic comments, unless they have a strong reason why the numbers might not mean what they seem.

In the Hacker News comments, some people agree that AI is now changing academic publishing in a big way. They worry that it will be harder to find good, real research because there will be so many low-quality, AI-generated papers. Others say that there have always been too many bad papers, and AI just makes it more visible. Some readers ask if arXiv will start blocking or labeling AI papers, but others point out that it is very hard to check if a paper is written by AI or a person.

One commenter says that more papers do not always mean more progress, especially if most are not useful. Another person thinks that AI will be a good thing, making it easier for people without strong connections to publish ideas. Some people are hopeful that new tools will appear to help scientists find the best work, even in a sea of AI papers. Others are not so sure, and think that trust in science may fall if too much fake or careless work is published. A few say that, in the end, only important ideas will last, no matter who or what writes them. Some even wonder if AI will be able to do real discovery, not just repeat old patterns. Finally, a few readers just joke that AI will soon be the only one reading these papers, too.

---

## I'm helping my dog vibe code games

- 原文链接: [I'm helping my dog vibe code games](https://www.calebleak.com/posts/dog-game/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47139675)

A software engineer lost his job and decided to teach his small dog, Momo, to “vibe code” video games using AI. He set up a system where Momo presses keys on a keyboard, and those random keystrokes are sent through a Raspberry Pi to an AI called Claude Code, which is told to treat the input as secret, creative commands from a genius game designer.

The system works like this: Momo’s keystrokes go to a Rust app called DogKeyboard, which filters them and forwards them to Claude. When Momo types enough, the system triggers a smart feeder to give her treats, and a chime lets her know when to type again. The games are made in Godot using C#. The AI is prompted to turn any input—even total nonsense—into meaningful game ideas and code. The prompt was improved over time, adding rules so every game must have things like sound, a player character, and controls. When Momo smashed the keyboard, Claude would “decode” her input into game ideas, like a frog catching bugs, and then build a playable game.

To make things smoother, the author built tools to help Claude test and fix its own games. These include screenshot scripts, fake input testers, and code linters that check for errors in the Godot files. The whole setup was made reliable by picking a tough keyboard and an easy-to-control treat dispenser for Momo. Training Momo took a couple of weeks, using treats and chimes to teach her to press keys for food.

Some of the games Momo “made” are real and playable, like a rhythm game with an octopus, a game about herding sheep, and a cosmic music adventure. The author found that the real key to making fun games from nonsense input was not the input itself, but the feedback tools and systems around the AI. The better the automated testing and feedback, the better the final games became. He encourages others to try this with their own pets or keyboard smashing, since all the tools are open source.

In the Hacker News comments, many people found the project funny and creative, calling it a clever mix of humor and engineering. Some readers praised the author’s use of prompt engineering and feedback loops, saying it showed the power of good systems over perfect input. Others pointed out that the AI is really doing all the work, and the dog is just randomly pressing buttons, but they still liked the playful idea. A few people wondered if this could be done with other animals or even just random human input. Some were impressed by the open source tools, and others shared stories of pets causing computer mischief. There were also comments discussing the future of AI-assisted coding, with some saying this project shows how much the “quality of feedback” matters for AI tools. A few readers joked about their own pets becoming programmers, while others questioned the ethics of using animals in tech experiments, though most agreed Momo seemed happy and well-treated. Overall, people enjoyed the story and saw it as both a fun experiment and a lesson about building better tools for working with AI.

---

## Hacking an old Kindle to display bus arrival times

- 原文链接: [Hacking an old Kindle to display bus arrival times](https://www.mariannefeng.com/portfolio/kindle/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47141797)

This article shows how someone turned an old Kindle into a live display for bus arrival times. The writer wanted to reuse a Kindle to show New Jersey Transit bus times, similar to a product called TRMNL, but much cheaper.

First, the writer jailbroke the Kindle to allow running custom code. They installed special software, KUAL and MRPI, to add and launch new apps. They set up SSH so they could connect to the Kindle like a server and control it from a computer. Then, they built a server that takes bus data from NJ Transit using a GraphQL query, turns it into HTML, and makes a PNG image that fits the Kindle’s screen. The server uses a tool called wkhtmltoimage to make the image every few minutes. The image is rotated and moved so it looks right on the Kindle’s screen. 

Next, they created a custom app for the Kindle’s launcher (KUAL). This app starts the dashboard showing bus times and lets the user exit by pressing the menu button. The script that runs the dashboard fetches the latest image, clears the screen, and shows the bus info. It also shows the date, battery, and wifi status. The script listens for the menu button so the user can stop the dashboard easily. If the dashboard stops, the script clears the screen and restarts the Kindle’s normal user interface. 

The writer mentions two main issues: First, the screen sometimes shows leftover marks (color bleeding) after running for days. They think flashing the screen black and white at night might help. Second, the battery lasts about 5 days; they hope to reach 2 weeks but want to keep live minute updates. Turning off the device at night helps save some battery.

In the comments, many people praised the project and shared excitement about reusing old devices. Some said it’s a clever and practical way to give new life to Kindles. Others mentioned they had trouble setting up similar projects, especially with jailbreaking and installing custom software, saying the instructions online can be confusing. A few users worried about battery drain and suggested updating the display less often or turning off wifi. Some liked the idea of showing other info, like weather or calendars, on the Kindle screen. One commenter asked if e-ink screens are good for quick updates; others replied that e-ink is best for slow updates, not for fast-changing data. People also talked about the challenge of getting the right screen size and rotation. A few mentioned that using open public data, like transit info, is a great use of technology. Some shared links to their own Kindle hacks for dashboards or smart home displays. Overall, readers enjoyed the project and found it inspiring, though some warned it takes patience and some technical skill to copy.

---

## Nearby Glasses

- 原文链接: [Nearby Glasses](https://github.com/yjeanrenaud/yj_nearbyglasses)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47140042)

This project is about an Android app called "Nearby Glasses," which tries to detect smart glasses near you and give you a warning. The app uses Bluetooth signals to find devices made by companies like Meta, Snap, or Luxottica, which produce smart glasses with cameras.

The app works by scanning for Bluetooth Low Energy (BLE) signals. Every device that uses BLE has a company ID in its signal. The app looks for these IDs for known smart glasses makers. It checks the strength of the signal (RSSI) to guess how close the device is. For example, a stronger signal means the smart glasses are likely closer to you. The app shows a notification if it finds a matching device nearby. You can change some settings, like which company IDs to watch for, how close the device should be before warning you, and how often you want to get notifications. There is also a log you can export, but the app does not collect or share your personal data.

The creator made this app because they think smart glasses are a big privacy problem. They worry about hidden cameras and facial recognition in public. The project is open source, so anyone can look at the code or help improve it. The app is not perfect—it can make mistakes, like warning you about a VR headset instead of smart glasses. The developer says to use the app carefully and not to act without thinking.

In the comments, some people think this app is a good idea for privacy. They like that it is open source and does not track users. Others point out that it is hard to tell smart glasses from other devices, so there will be many false alarms. Some suggest that more work is needed to filter out unrelated devices, or that the app should use more data to improve accuracy. A few people say that smart glasses are not yet common, so this app may not be needed everywhere. Others think it is better to have some warning, even if not perfect. Some ask if an iOS version is coming, while a few share worries about apps like this being blocked by phone makers in the future. There is also talk about the balance between privacy, security, and not making people scared in public. Overall, commenters are interested, but see both technical and social challenges.

---

## Show HN: Emdash – Open-source agentic development environment

- 原文链接: [Show HN: Emdash – Open-source agentic development environment](https://github.com/generalaction/emdash)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47140322)

Emdash is an open-source tool that lets you use many AI coding agents at the same time, in parallel, for software development. It works on macOS, Windows, and Linux, and supports over 20 different coding agents like Claude, Copilot, and Codex, letting you pick whichever suits you.

The main idea is to speed up coding by running several “agents” (AI helpers) together, each in its own safe Git workspace. This means you can test or develop many features at once without mixing up the code. Emdash also connects with project tracking tools like GitHub, Jira, and Linear, so you can hand off tickets directly to an agent and review their code changes side-by-side. It works both on your computer and with remote servers over SSH, which is useful if your code lives elsewhere. Emdash keeps your data local (in a small SQLite database) and does not send code or private info to its own servers. Telemetry (usage stats) is collected, but you can turn this off in settings. You do not need to use GitHub features if you do not want to, and adding a new provider just means following a simple guide and making a pull request.

In the comments, some people are excited about being able to run many agents in parallel and like that it is open-source. A few users ask how easy it is to add new agents or if they can use it with their favorite tools. Some are curious about privacy, but are happy to see that their code stays local unless sent to the AI provider they choose. Others compare Emdash to existing IDEs and wonder if it can replace tools like VS Code, or if it is more for specific workflows. A few mention that the SSH remote support is helpful for working on servers. There are concerns about the need to install many different agent CLIs, but others think the flexibility is worth it. Some users report that the setup is smooth on Linux and macOS, while a few Windows users wish for easier installation. Several people discuss possible security risks with running untrusted agent code, but the use of separate Git worktrees is seen as a good safety step. Overall, most agree Emdash is an interesting step for coding with AI agents and are happy to see so many integrations in one place.

---

## HuggingFace Agent Skills

- 原文链接: [HuggingFace Agent Skills](https://github.com/huggingface/skills)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47139902)

Hugging Face has released a collection called "Skills" for AI and machine learning tasks, letting coding agents easily do things like model training, dataset creation, and evaluation. These Skills work with different agent tools, such as OpenAI Codex, Claude Code, Google Gemini, and Cursor, by sharing a common format and structure.

Each Skill is a folder with instructions, scripts, and resources for a specific task, and includes a `SKILL.md` file describing what it does. While not all agent tools use the same term ("Skill"), Hugging Face made their repo work with each tool’s own system, so you can use them almost anywhere. For example, Claude uses the term "skills," Codex uses `AGENTS.md`, and Gemini uses "extensions" with a JSON file. If your tool doesn’t support Skills directly, you can still use the instructions from the repo.

Installing a Skill is simple and depends on which agent you use. For Claude, you add the repo as a plugin marketplace and install with a command. For Codex, the agent reads instructions from `AGENTS.md`. Gemini users can use extension commands, and Cursor users install through its plugin system.

Some example Skills include: running Hugging Face CLI commands, managing datasets, evaluating models, running compute jobs, training models, publishing research papers, building API tools, and tracking ML experiments. After you install a Skill, you just mention it in your instructions to your coding agent, and it will load the needed scripts.

If you want to make your own Skill, you copy an existing folder, update the description, add your scripts, and run a script to check everything. There’s also a marketplace file that lists available Skills with descriptions for people browsing.

In Hacker News comments, some users like how this project makes coding agents more useful and helps standardize agent instructions. Others think it’s a good move for Hugging Face to support many tools, not just their own. Some people are excited to create and share new Skills, and see potential for automation in ML workflows. A few wonder if there will be problems with versioning or Skill quality as the marketplace grows. Some wish there was better documentation or more ready-to-use Skills. Others are curious about security, since Skills can run code, and suggest reviews or sandboxes. There’s also debate about whether this standard could become popular outside of Hugging Face, or if tools will keep using their own formats. Overall, many see it as a positive step, but note it’s early days.

---

## I pitched a roller coaster to Disneyland at age 10 in 1978

- 原文链接: [I pitched a roller coaster to Disneyland at age 10 in 1978](https://wordglyph.xyz/one-piece-at-a-time)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47136604)

A man remembers when he was 10 years old in 1978 and built a model of a roller coaster with four loops, then sent his idea to Disneyland, hoping they would use it. He loved roller coasters, especially Space Mountain, and wanted to make one that went upside down, which was rare at the time.

He made blueprints for his dream ride, calling it the “Quadrupuler,” and built a model using balsa wood and melted plastic for the loops. He took Polaroid photos of the finished model and wrote a letter to Disneyland, asking them to build his roller coaster. After weeks of waiting and checking the mailbox every day, he finally got a letter back from WED Enterprises, Disney’s design and engineering division. The letter thanked him for his idea, explained they were working on a new ride called Big Thunder Mountain Railroad, and said his model looked like quite an adventure.

Instead of feeling sad or rejected, he felt proud and inspired by Disney’s response. Years later, he tried inventing other things, like a new kind of Rubik’s Cube, but companies turned him down. However, the letter from Disney gave him confidence to keep inventing and not let rejection stop him. He grew up to become an actor and inventor, and he still feels that being creative and pushing through rejection is important. His story ends with the lesson: keep going, one piece at a time.

In the comments, many people say this story is heartwarming and inspiring. Some share their own stories of sending ideas to big companies as kids and getting nice replies, even when their ideas were not used. Others talk about how important it is to encourage children’s creativity and not crush their dreams. A few readers remember when roller coasters with loops were new and exciting, and they talk about how fast theme park rides changed in the 1970s and 80s. Some users discuss how getting a reply from a company, even just a form letter, can have a huge impact on a child’s confidence. There are also comments about the joy of making things by hand and how childhood projects can lead to lifelong passion and careers. A few people say they wish companies today would answer letters from kids more often. Some wonder if Disney ever used any ideas from letters like this, while others note that just being heard and recognized was enough. The main feeling is that stories like this show how small moments can shape a person’s life.

---

## Manjaro website off-line again due to lapsed certificate

- 原文链接: [Manjaro website off-line again due to lapsed certificate](https://distrowatch.com/dwres.php?resource=showheadline&story=20140)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47141385)

The Manjaro Linux website went offline because its security certificate expired. This is not the first time it has happened; the same problem occurred in 2015 and 2022. The website’s HTTPS certificate is important because it keeps user connections safe and private. Normally, these certificates renew automatically every few months. But sometimes, technical issues or mistakes in the renewal process can cause the certificate to lapse without anyone noticing right away. When this happens, most browsers block the website, and users see a warning or can’t open the page at all. For open-source projects like Manjaro, this can be frustrating for users who need to download updates or find information. The article explains that renewing certificates is usually easy but needs someone to check if it fails. It also points out that this is a common problem, not just for Manjaro, but for many websites that use automatic certificate renewal.

In the comments, some people say that letting certificates expire is a small but embarrassing mistake, especially for a tech-focused group. Others understand that small teams might miss renewal emails or have scripts that break, so it’s an easy error to make. A few commenters share stories of their own sites going down for the same reason. Some suggest that better monitoring tools or alert systems could help catch this before it becomes a problem. Others think this shows why bigger companies have whole teams just for site reliability. There’s also talk about how important HTTPS is today, and that users have learned to trust sites with valid certificates. A few people say that, while annoying, this kind of outage is better than a security issue or hack. Some ask if open-source projects should get more help to avoid problems like this. Lastly, a few joke that “at least it wasn’t DNS this time,” showing that web issues are common and sometimes funny to those who work with them.

---

## How we rebuilt Next.js with AI in one week

- 原文链接: [How we rebuilt Next.js with AI in one week](https://blog.cloudflare.com/vinext/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47142156)

Cloudflare rebuilt the popular Next.js framework using AI in just one week, creating a new tool called vinext. Vinext is a drop-in replacement for Next.js, built on top of Vite, and it can deploy apps to Cloudflare Workers faster and with smaller client bundles.

The main problem with Next.js is that it’s hard to deploy to different serverless platforms because its build output is custom and needs a lot of work to adapt. OpenNext tries to solve this, but it’s complicated and easily breaks when Next.js changes. Cloudflare decided to make a clean reimplementation of the Next.js API on Vite instead of trying to adapt the existing Next.js output. You can use vinext by just swapping it in your project, and most of your code and configs will work the same.

Vinext offers fast development and production builds. In tests, vinext built apps 1.6 to 4.4 times faster than Next.js and created bundles that were over 50% smaller. Deploying to Cloudflare Workers is simple: one command builds and deploys your app. You also get advanced caching out of the box, and the caching can be changed to fit your needs.

Vinext is open-source and mostly platform-independent, so it can work on other hosting providers too. However, it's still experimental and not fully tested at large scale yet. The team says they have 94% coverage of the Next.js API, and some early real-world users have seen good results.

One thing vinext does differently is how it handles pre-rendering. Instead of building every possible page ahead of time, it uses traffic data to only pre-render pages that people actually visit, saving a lot of build time. Everything else is rendered on-demand and cached after the first visit.

The real surprise is that almost all code for vinext was written by an AI model, directed by one engineer. The AI handled most tasks, but the human managed project direction and fixed mistakes. Tests and quality checks ensured the code was solid. This shows how AI can quickly build complex software when the APIs and tests are well-defined.

In the Hacker News comments, many people were amazed by the speed of development and wondered about the quality and maintainability of AI-generated code. Some users worried that using AI might introduce hidden bugs or make it harder to understand the code later. A few developers questioned if vinext could really handle all the corner cases and big production workloads like Next.js does. Others liked the idea of using Vite as the base, since it’s already popular and fast. Some saw this as proof that AI is changing how software is built, letting small teams move faster, while others thought it might not work as well for less-documented or messier projects. Several commenters were excited about the traffic-aware pre-rendering idea, saying it solves a real pain point for big sites. A few pointed out that this project depends on both Next.js and Vite being open and well-documented, and this might not work for all frameworks. Some people also discussed how this could make it easier to deploy React apps to more platforms, not just Vercel. Overall, most commenters were impressed but said they would wait and see how vinext does in real-world, large-scale use before switching.

---

