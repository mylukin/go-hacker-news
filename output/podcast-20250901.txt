Hello everyone, this is the 2025-09-01 episode of Hacker News Daily Podcast. Today, we bring you a mix of stories covering software, hardware, AI, and some unique ideas from the world of tech. Let’s get started.

We begin at MIT with a talk from Professor Patrick Winston, who shares tips on how to speak well in public. He believes your speaking skills can be more important than writing or even your ideas alone. Instead of starting with a joke, he suggests you should promise your audience what they will learn by the end of your talk. Winston explains four main techniques: repeat your key idea several times—he calls this cycling; make your idea stand out from others—this is fencing; use pauses and summaries as verbal punctuation to help listeners refocus; and ask questions to keep people engaged. Timing and the place matter too—he says 11 a.m. is best, and the room should be bright and lively.

For teaching, Winston likes using chalkboards or whiteboards because drawing helps people understand and gives your hands something to do. Props can make ideas memorable. If you use slides, keep them simple—few words, big text, and avoid laser pointers so you keep eye contact. To inspire, show your passion, give strong examples, and teach people how to think with stories and good questions. For job talks, explain your vision, list clear steps, and show your achievements quickly. To make your ideas stick, try the “5 S” method: use a symbol, a short slogan, a surprise, highlight your main point, and tell a story. When ending, don’t just say “thank you”—summarize your message, give a call to action, or finish with a light joke.

People in the comments thank Winston for his clear advice and kind teaching style. Some share stories of seeing him practice early each morning, showing his care for students. Many say these tips helped them stay focused through a whole talk for the first time. There’s some debate about not saying “thank you” at the end, but most agree it’s better to end with a strong message or a story. Overall, people feel inspired and grateful for Winston’s wisdom.

Next, we look at Amazon’s approach to hiring AI experts. Unlike Google, Microsoft, or OpenAI, Amazon is moving slowly and not making big hires or deals in AI. Their main AI project, called Bedrock, helps businesses use AI models, and they’re adding AI to Alexa and AWS, but these are not as flashy as the competition. Some say Amazon is being careful and saving money, or waiting to see what works. Company leaders believe their slow and steady way will win in the long run, using their strong cloud business to help customers use AI.

The comments are split. Some think Amazon is smart for not joining the expensive AI race, saying Amazon has always waited to see what works before spending big. Others worry Amazon might fall behind and miss out on top AI talent. Some point out that Amazon has lots of data and cloud power and could catch up later. Others say Amazon’s culture is more about selling and logistics, not research. A few believe Amazon is quietly working behind the scenes and might surprise everyone later. The debate continues: is Amazon being wise, or are they taking a risk?

Now to a technical article about choosing the best large language model, or LLM, for each task without spending too much. Big LLMs are expensive, but not every job needs the most powerful model. The authors suggest a “contextual bandit” method—they call their system PILOT. It tries different LLMs for each request, learns from feedback, and uses a math problem called the “multi-choice knapsack problem” to manage costs across many requests. The system can change its choices as user needs and budgets change.

In the comments, developers like the idea of making LLM use more efficient, since costs are a real worry. Some ask if the method works with open-source models and how it adapts when new LLMs appear. People talk about the challenges: getting good feedback, privacy issues, and whether the same idea could be used for other decisions, like picking the best database or translation tool. Some hope the code will be open-sourced soon.

Moving to graphics, there’s a guide on making a foil sticker effect in Three.js using custom shaders. This effect shows shiny, rainbow colors that shift with the viewing angle and includes sparkling foil flakes. The shader changes the color based on the angle to create iridescence, and adds random bright spots for the foil effect. The article explains both the vertex and fragment shaders and offers a live demo to play with settings. The code is free for non-commercial use, but you need a license for business use.

Commenters are impressed with the realism and performance, and like the clear explanations. There’s talk about possible uses for games, digital trading cards, or fun UI elements. Some discuss browser support and how to integrate the effect with other materials. There’s also interest in porting the shader to other engines like Unity or Godot.

On the hardware side, OpenBSD now supports the Raspberry Pi 5 Model B. You can run OpenBSD on this new board, but some things still do not work: you can’t boot from PCIe storage, WiFi is not working on some boards, and the cooling fan does not work yet. The developers are fixing these issues. The update passed review, and users are happy to see progress. Some wish for better hardware support, while others say OpenBSD’s focus on safety and simple code means support comes slowly. There’s also a comparison to Linux, which usually supports new hardware sooner, but OpenBSD brings unique safety features.

Now to the Linux kernel and the future of 32-bit support. Most new hardware is 64-bit, and support for 32-bit systems is being reduced. Some old Arm boards and other processors are still supported, but many are being dropped. Keeping 32-bit support creates problems, especially in memory management. Soon, the kernel will not support 32-bit systems with more than 4GB of memory. There’s also the year-2038 bug, which breaks time on 32-bit systems. Kernel and library fixes exist, but many programs are not fixed, so most 32-bit desktops will stop working in 2038. The kernel team plans to remove complex memory support by 2027 and nommu support by 2028.

People in the comments agree that it’s time to remove 32-bit support to make the kernel simpler. Others worry this will hurt users with old hardware, especially in poorer countries or for hobby projects. Some say the kernel team is handling the change with care, and ask for clear warnings before support is dropped. There’s also some sadness about saying goodbye to old systems.

We return to Amazon to look at their Leadership Principles. The article, written by an AWS customer, explores how these principles work in real life. “Customer Obsession” means working backwards from customer needs, but the writer thinks Amazon sometimes just builds what customers ask for, instead of what they really need. “Ownership” is about thinking long-term, but the writer sees too much secret work inside Amazon, causing wasted effort. “Bias for Action” is about moving fast, but moving too fast can hurt trust. The writer suggests more senior engineers should be able to stop bad projects before launch.

In the comments, people share mixed views. Some say the principles are good but not always followed. Others say they are just buzzwords, or that silos inside Amazon are a real problem. Some defend Amazon, saying a big company can’t avoid silos, and fast action is needed to beat rivals. Many agree the principles need better use and real leadership.

Next, we have a new idea for designing computer memory: split RAM into two types—long-term and short-term. Long-term RAM would store data that doesn’t change much but needs to be read often, like models or reference data. Short-term RAM would hold data that changes often and doesn’t last long. The authors believe this could make computers faster and cheaper. The operating system would help manage which type of memory to use.

Commenters compare this idea to storage, where we have SSDs and hard drives for different needs. Some worry it could make programming more complex, while others think it will help with power saving and data center performance. There’s debate about whether software or hardware should pick the memory type, and if this will help normal users or just big cloud companies. Some are excited, others are cautious, and many want to see if this idea will catch on.

Cloudflare Radar’s new AI Insights report shows how AI bots visit and scan websites. The top five bots—GPTBot, ClaudeBot, Meta-ExternalAgent, Amazonbot, and Bytespider—make up most AI-related traffic. Most scanning is for training new AI models, with less for search or real user actions. Bots crawl many pages but send back little user traffic. Cloudflare recommends using robots.txt to control access, but some bots do not respect these rules.

Commenters worry about AI bots scraping too much data without giving back value. Others like seeing this level of detail to help block unwanted bots. Some point out that robots.txt is not always followed, and that blocking all bots could hurt website discovery. There are ethical debates about using public data, and some people want better bot identification or new standards. Overall, people want tools to balance AI growth with fair use and website control.

Finally, there’s a fun project building a Minecraft-like world as a round planet instead of flat land. The author made a demo called Blocky Planet using Unity, where you can build and destroy blocks on a sphere. The main challenge is making blocks work on a curved surface with gravity pointing to the center. The author solves this by using a “quad sphere” method, splitting the world into six sectors and layers called shells. He uses 3D noise for smooth terrain and has two biomes—forest and arctic—based on how close you are to the poles.

Commenters love the project and talk about the technical challenges, like mapping grids to spheres and handling block neighbors. Some worry about performance as the planet grows, others see it as a tool for learning math and geometry. There’s interest in gameplay ideas like digging to the core or flying around the planet, and some hope for multiplayer or more features in the future.

That’s all for today’s episode. We covered speaking tips, AI hiring, LLM routing, shiny graphics, new hardware support, the future of 32-bit, Amazon’s leadership, memory ideas, web bot traffic, and a round Minecraft world. Thank you for listening, and see you next time on Hacker News Daily Podcast.