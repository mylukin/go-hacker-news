# Hacker News 故事摘要 - 2025-09-13

## 今日概述

Today’s top Hacker News stories cover open-source projects and why maintainers must say “no,” how big systems grow from small ones, creative uses of AI, tricky bugs in old and new code, running retro PCs on new hardware, why time feels faster as we age, changes in C++ safety plans, how Ruby speeds up code, a new PHP tool, and learning a new programming language. Many stories focus on building, learning, and the balance between safety, speed, and creativity.

---

## An Open-Source Maintainer's Guide to Saying No

- 原文链接: [An Open-Source Maintainer's Guide to Saying No](https://www.jlowin.dev/blog/oss-maintainers-guide-to-saying-no)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45234593)

This article talks about why open-source maintainers often need to say “no” to new feature requests, even if the ideas are good. The writer explains that it’s not enough for a feature to work well—it also has to fit with the project’s main vision and philosophy.

Maintainers have to protect the “soul” of the project. They do this by making sure every change matches the mental model or goal of the software. Clear documentation about why the project exists helps a lot. It attracts contributors who agree with the purpose and keeps the project focused. The writer notes that with tools like LLMs (large language models), it’s now much easier to create and submit code, so people often send full pull requests (PRs) without asking if the change is needed. This leads to more work for maintainers, who must now review more code that may not fit the project.

To manage this, the writer tried requiring an issue before every PR. But some users just wrote quick, low-effort issues right before submitting their code, which didn’t help much. A better way is to clearly say that only changes matching the project’s purpose will be accepted, and it’s up to the contributor to prove this. The article also shows that maintainers worry about long-term support for new features. If a new feature causes problems, maintainers are responsible, even if they didn’t ask for it. To help with this, the writer made a “contrib” section in their project for extra features that are not fully part of the main project and are maintained by the original contributor.

The writer feels sad that, over time, they have become less responsive to users who don’t make an effort to engage or explain their needs. They prefer simple, clear questions over walls of AI-generated text. Even though AI can help with some tasks, the writer believes that careful, thoughtful stewardship leads to better software and stronger communities. They give an example from a recent meeting about an AI protocol, where the group carefully debated each new idea, always asking if it truly fit the protocol’s main goal.

In the comments, many people agree that saying “no” is important to keep projects healthy and maintainable. Some say that too many features can make software harder to use and support. Others mention that contributors may feel hurt when their ideas are rejected, so it’s important to explain the “why” behind a “no.” A few say that requiring issues before PRs doesn’t always work, since people can find ways around rules. Some suggest having clear contribution guidelines and a public roadmap can help set expectations. Others worry that AI-generated PRs will only make things harder for maintainers. But there are also people who think new contributors should still be encouraged, as they bring fresh ideas and energy. Some maintainers share that they use “contrib” sections or plugins, like the article suggests, to separate extra features from the main code. A few note that open-source maintainers often get tired and burned out from dealing with too many requests. Some wish there was more respect for the time and care that maintainers give to their projects.

---

## Magical systems thinking

- 原文链接: [Magical systems thinking](https://worksinprogress.co/issue/magical-systems-thinking/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45233266)

This article talks about how big, complex systems—like electric grids or health care—usually start as small, simple systems that work first. The story that these huge systems are built by one smart plan is not true; instead, they grow slowly, step by step, and many clever people fix and change things along the way.

The article gives examples of failed “systems thinking” in government. For instance, HealthCare.gov crashed at launch, Australia’s disability reforms got too expensive, and the UK’s new energy plan made the grid worse. Even with new tools and better analysis, these systems are hard to control, and problems still happen.

The article explains that modeling the world as a system (like Jay Forrester did) can fail because real life is too complex. Forrester’s model said the world would run out of resources by now, but actually, things are better—more forests, less pollution, and more wealth. His models worked in simple cases, like helping a fridge factory fix its supply chain, but not with whole countries or the world.

The writer introduces Le Chatelier’s Principle from chemistry: when you change a system, it pushes back. John Gall, a doctor, said the same thing happens with human systems—if you try to fix them, new problems appear. Gall’s Law says, “A complex system that works always starts as a simple system that works.” The article uses the game Factorio as an example: players build factories by starting simple, learning, and then making things more complex step by step.

For big systems, the article says we can’t just turn them off and start over, but we can build new, simple systems next to old ones. The US missile program, Covid vaccine rollout, and rebuilding Notre-Dame all worked by creating new, focused teams outside the usual, slow bureaucracy. Estonia’s digital government started small and grew over time.

In summary, the article warns that trying to plan and fix big systems all at once usually fails. Instead, we should start small, be humble, and grow working systems step by step.

In the comments, many people agree with the article’s focus on starting small. Some share stories where simple solutions worked better than big plans. Others point out that sometimes, old systems get so messy that change is impossible without starting fresh. A few users warn that “simple” is not always easy—sometimes tiny systems still hide big problems, or get complicated fast.

Some commenters say that governments and big companies are slow to change because of politics or fear of risk, even when they know the simple way is better. Others talk about the role of AI, agreeing with the article that more tech will not always fix complexity; in fact, it may make things harder to understand. Several users bring up open-source projects, noting they often follow the “start simple and grow” rule, which is why many succeed.

There is also discussion about the limits of models and predictions—many users agree that models often miss important details, especially when people are involved. Some are hopeful about the “simple system first” approach but say it needs leaders who are willing to let go of control and trust small teams. Finally, a few remind everyone that every fix can create new problems, so it’s important to stay careful and expect surprises.

---

## Show HN: A store that generates products from anything you type in search

- 原文链接: [Show HN: A store that generates products from anything you type in search](https://anycrap.shop/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45231378)

This article talks about a new website called Anycrap, which lets you type anything into a search box, and then it makes up a product based on what you wrote. The site acts like a store where you can “buy” products from other universes or parallel worlds.

The main idea is that you can invent your own product just by typing it in. For example, you can write “banana-powered phone charger,” and the site will create a fake product based on your idea. Every product is a made-up concept, created instantly for you. You do not get a real product—just a fun concept or description. The website describes itself as a “conceptual marketplace,” which means it’s a store for ideas, not real items. You can search for anything, and the site promises to “find” it for you, even if it doesn’t exist yet. The site encourages people to be creative and come up with strange, funny, or impossible products. It highlights categories like “weird tech stuff” and “snacks from outer space.” There’s no real shopping, payment, or delivery. You just get an instant description or image of your custom product. The site wants to make shopping fun by letting your imagination run wild.

People in the Hacker News comments had mixed reactions. Some thought the idea was funny and enjoyed typing in silly requests to see what the site would create. Others said this is a clever use of AI for entertainment, and they liked seeing how creative the results could be. A few users asked if this could be useful for real businesses, like helping inventors brainstorm new products. Some were confused at first, thinking they could buy real items, but then realized it’s just for fun. Some worried that fake stores like this might confuse people or could be misused for scams, but most agreed this site is clearly a joke. One person said it reminded them of old joke websites or random product generators. Another user wondered if this kind of tool could help with marketing by inspiring new product ideas. A few people pointed out that the site doesn’t save your ideas or share them, so it’s just a quick, playful experience. Some liked the simple design, while others thought it could be improved. Overall, most comments thought it was a lighthearted, creative project that shows the power of imagination and AI.

---

## RIP pthread_cancel

- 原文链接: [RIP pthread_cancel](https://eissing.org/icing/posts/rip_pthread_cancel/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45233713)

This article talks about a problem the curl project had when they tried to use pthread_cancel to stop threads doing DNS lookups. Curl wanted to use threads for getaddrinfo(), a function that looks up network addresses but can take a long time and block the main program.

They started a new thread for each getaddrinfo() call, so curl could keep working while it waited. But after finishing, they had to clean up these threads. They could either join the thread, which waits and blocks again, or detach the thread, which lets it run on its own—both were not good for many network transfers.

So, curl tried using pthread_cancel to stop the thread as soon as it wasn’t needed. This seemed to work at first. But after releasing this feature in curl 8.16.0, people noticed it was causing memory leaks. The leaks happened because of how the GNU C Library (glibc) handles getaddrinfo(). When getaddrinfo() is cancelled while reading the /etc/gai.conf file (which decides how to sort addresses), memory that was already allocated is not cleaned up. This is because reading this file can be cancelled at just the wrong time, leaving things unfinished.

The author looked at the glibc code and saw there were probably more places where cancelling could cause leaks. This made it unsafe to keep using pthread_cancel in curl, since leaking memory over and over is not acceptable.

In the end, curl decided to remove pthread_cancel. Now, they have to accept waiting for slow getaddrinfo() calls sometimes. If programs really need fast, non-blocking DNS, they can use another library called c-ares, but it cannot do everything glibc’s getaddrinfo() does. DNS is still a hard problem.

Commenters had lots of opinions. Some said pthread_cancel is almost always dangerous—many libraries aren’t written to handle threads being stopped in the middle. Others pointed out that glibc’s use of cancelation points is confusing, and canceling threads is rarely safe or portable. Several people suggested using c-ares or even writing their own DNS code to avoid these issues. Some felt disappointed that POSIX threads can’t solve this cleanly, while others thought it was just a fact of life in C programming.

A few commenters shared that they had similar problems with memory leaks when cancelling threads in other programs. Some said it’s better to design code so threads exit by themselves, instead of being forced to stop. Others warned that even if pthread_cancel seems to work at first, it can break in new environments or library updates. There were also some who wished glibc would fix the leaks, but most agreed that’s hard to do. Several people respected curl’s decision to remove this feature, even if it means slower DNS sometimes. Overall, most agreed that DNS and threads are both tricky topics and there’s often no perfect answer.

---

## 486Tang – 486 on a credit-card-sized FPGA board

- 原文链接: [486Tang – 486 on a credit-card-sized FPGA board](https://nand2mario.github.io/posts/2025/486tang_486_on_a_credit_card_size_fpga_board/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45232565)

This article talks about running a 486 PC (an old Intel CPU) on a small FPGA board called the Tang Console 138K. The author ported an open-source 486 CPU core (ao486) from another FPGA system (MiSTer) to this new board.

The main changes were using SDRAM for memory instead of DDR3, since SDRAM fits better with the old 486 hardware. The author used DDR3 only for graphics. Because the Tang board doesn’t have a fast chip to talk to the FPGA, the author made the FPGA read disk data directly from an SD card. To boot the system, a small program loads BIOS and other settings from the SD card into memory before starting the CPU.

Debugging was hard because the 486 is complex, and testing on hardware was slow. To make it easier, the author used simulation software called Verilator. This let him run the whole system, see what was happening, and catch bugs faster. He added ways to print debug messages and trace what parts like sound or disk were doing. Some bugs came from differences in how the software tools worked on this new hardware.

The first version was slow—like an old 80386 PC. The main problem was some parts of the logic took too long to process in one clock cycle. The author fixed this by changing how some signals were wired and by optimizing how instructions and memory addresses were handled. One fix was to make the memory buffer logic simpler, which made the CPU run faster. He also changed the way the TLB (a cache for memory addresses) worked, which helped a bit.

With all these tweaks, the system could run about 35% faster and reach the speed of a real 486SX-20. The author reflects that increasing the clock speed was the best way to improve things, but past a point, memory speed is the limit. He also found that x86 CPUs like the 486 are much more complex than ARM CPUs, making this project much harder than his last one.

In the comments, some people are impressed that so much old PC power fits on a small, cheap board. Others like how the project brings old DOS software back to life and makes retrocomputing easier. A few discuss how hard x86 is to implement compared to other CPUs, and praise the author for choosing simulation tools to speed up debugging. Some are curious about how games run, and ask if sound and graphics are good enough for classics like Doom. Others debate if these FPGA projects can ever match real hardware speed, or if software emulators are sometimes fast enough. A few suggest more optimization tricks, while others just want to see videos or demos of the system running. Overall, many are excited and hope more open, easy-to-use FPGA computers like this will appear.

---

## Perceived Age

- 原文链接: [Perceived Age](https://sdan.io/blog/perceived-age)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45189963)

This article talks about why time feels slower when you are a child but speeds up as you get older. The author shares memories of long summers as a kid and explains how, by age 22, years seem to pass much faster.

A study found that young people can estimate two minutes more accurately than older people; older people think less time has passed than really has. This is linked to the brain’s dopamine—the chemical that helps us feel excitement and notice new things. When we are young, everything is new, so there is more dopamine, and time feels longer. As we do the same things over and over, our brains release less dopamine, so time feels shorter. 

The article says our brains have an “internal clock” that works with memory. New experiences stretch our sense of time, but boring routines make time shrink. The author shares a concept called the “reminiscence bump”—big, new life events (like first love or travel) stick in our memories and help us feel like time is full. Adults usually have fewer new experiences, so years seem to race by.

The author uses math to show that, at age 6, a year is a big part of your life, but at age 18, a year is much smaller. This is called “perceived age”—it is how old you feel, not just how many years you have lived. The message is: if you want time to feel slower and life to feel richer, you should keep trying new things, learn new skills, and break up your routines. The author says that habits and discipline help, but it is important to keep your life dynamic and not just do the same thing every year. Money is important, but not as important as using your time well, especially when you are young.

The writer ends by saying that even after hard times, like losing a year of school to Covid, it is possible to feel young and excited about life again by staying open to new experiences.

In the comments, many people agree that time feels faster as they get older and share their own stories about how childhood seemed to last forever. Some readers talk about how starting new hobbies or traveling has helped them slow down their sense of time. Others point out that having children or big life changes can also make time feel slower again. A few say that routines, like working the same job for years, make time disappear quickly, while others feel that routines give comfort and stability even if years pass faster. Some users discuss the brain science behind dopamine and time, and a few question if it is just about chemicals, or if culture and stress also matter. One commenter wonders if technology and always being busy make time feel even shorter today than in the past. Some people feel sad about time passing quickly, but others see it as a reason to live more fully and try new things, no matter their age.

---

## Safe C++ proposal is not being continued

- 原文链接: [Safe C++ proposal is not being continued](https://sibellavia.lol/posts/2025/09/safe-c-proposal-is-not-being-continued/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45234460)

The article talks about the end of the Safe C++ proposal. This proposal aimed to add a “safe” part to C++ that works like Rust, helping to avoid common bugs without breaking old code.

Safe C++ would let programmers mark sections of their code as “safe.” Inside these sections, the code would follow strict rules for things like memory and types, similar to Rust. The rest of the code would work as usual, so existing C++ projects would not break. This plan tried to make it easy to move slowly from “unsafe” to “safe.” The proposal included ideas like a “borrow checker” to stop memory errors and ways to mix safe and unsafe code. Some problems were still unsolved, like how errors would be shown and how this would work with templates. Still, many people thought it was a good idea.

Now, the proposal is not moving forward. One of the main authors, Sean Baxter, said the C++ committee decided to focus on “Profiles” instead. Profiles are a way to add safety by limiting how you can use C++ features. If you turn on a profile, your code must follow certain safe rules. If not, your code stays as before. Profiles do not add new language parts; they limit the unsafe ways you can use old ones. This is easier to add and less risky for existing code.

The author thinks that Safe C++ was more ambitious but harder for the community to accept. Profiles are less strict but are more likely to be used in real projects. The article says Profiles are not perfect but still a step forward for safer C++.

In the comments, some people are sad that Safe C++ is gone. They liked the idea of making C++ much safer, like Rust. Others say C++ should not try to copy Rust too much. If you want Rust’s safety, just use Rust. Some are happy with Profiles, saying they are more practical and will help more people. There is worry that Profiles are too weak and will not stop enough bugs. Some users think no safety plan will work until the C++ community really wants change. Others say C++ must stay flexible and can never be as safe as Rust. A few people point out that C++ already has safe coding styles, even if they are not standard. Some are hopeful that Profiles will at least start a move to better safety. Others still wish for a bigger change in the future. Overall, the comments show a split: some want strong safety, others want to keep C++ as it is, and many see Profiles as a small but welcome step.

---

## How Ruby executes JIT code

- 原文链接: [How Ruby executes JIT code](https://railsatscale.com/2025-09-08-how-ruby-executes-jit-code-the-hidden-mechanics-behind-the-magic/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45189058)

This article explains how Ruby runs code using JIT (Just-In-Time) compilation, focusing on newer tools like YJIT and ZJIT. It looks at where the JIT-compiled code lives, how Ruby switches from running bytecode to running machine code, how Ruby chooses what to compile, and why sometimes Ruby must stop using JIT code.

When you write Ruby code, Ruby turns each method into something called an Instruction Sequence (ISEQ). This holds the bytecode, which Ruby’s virtual machine can understand. When a method is used a lot, Ruby may JIT-compile it, creating machine code that the computer can run much faster than bytecode. But Ruby does not throw away the bytecode; it keeps both the original bytecode and the new machine code for each method. This is important for safety, because sometimes Ruby has to stop using the machine code and go back to the bytecode if things change.

Ruby decides which methods to JIT-compile by counting how many times each method is called. At first, Ruby just runs the bytecode. Once a method is called enough times (for example, 30 times), Ruby profiles the method and then compiles it to machine code. The next time you call the method, Ruby checks if there’s JIT code ready. If there is, it jumps straight to the fast machine code.

However, JIT code makes guesses to run faster. For example, if a method always adds two numbers, the compiler will speed things up by assuming both are integers. If you suddenly give it something else, like a float, the JIT code notices the change, stops, and sends control back to the normal interpreter to make sure the result is still correct. Other things can also make Ruby stop using JIT code, like turning on debugging tools (TracePoint), changing how core methods work, or using Ruby’s multi-threading features (ractors).

The article also answers why Ruby doesn’t just JIT-compile everything: compiling uses memory and time, and many methods are not called often enough to make it worthwhile.

In the comments, some people praised the clear explanation, saying it helped them finally understand how Ruby’s JIT works. Others noted that keeping both bytecode and machine code is common in many language runtimes, not just Ruby. A few developers wished for even faster JIT compilation and asked if Ruby could tune the thresholds for different programs. Some commenters warned that JIT can bring new bugs or make debugging harder, because code can change behavior at runtime. There were questions about how JIT interacts with gems or larger Rails apps, and a few shared their own experiences with performance improvements or problems using JIT in production. One person pointed out that JIT can be less effective for short-lived scripts. Another liked that the article linked to resources for learning about YARV and ZJIT internals. Some were curious how Ruby’s JIT compares to Python’s new plans for JIT, and a few discussed the trade-offs between memory use, speed, and safety when using any JIT compiler.

---

## Mago: A fast PHP toolchain written in Rust

- 原文链接: [Mago: A fast PHP toolchain written in Rust](https://github.com/carthage-software/mago)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45232275)

Mago is a new toolchain for PHP, built in Rust, that helps developers write better and faster PHP code. It works as a linter, formatter, and static analyzer, and aims to be much quicker than current PHP tools.

Mago lets you check your PHP code for mistakes, style problems, and bugs, all in one place. It uses Rust to make these checks run very fast. You can use Mago to lint your code with custom rules, do deep static analysis to catch type errors, and even fix some problems automatically. Mago can also format your PHP code to follow best practices and style guides. There is a way to see your code's structure using its AST (Abstract Syntax Tree) feature. Mago takes ideas from popular Rust tools like Clippy and OXC, as well as PHP tools like Psalm, PHPStan, PHP-CS-Fixer, and PHP_CodeSniffer. You can install it with a simple shell command, and there is support for Homebrew, Composer, and Cargo. The project is open source and welcomes contributions from the community. Mago is released under both the MIT and Apache-2.0 licenses. Its goal is to give developers a unified, modern, and very fast way to check and improve their PHP code.

In the Hacker News comments, some people are excited about Mago's speed and like that it is written in Rust, which is known for high performance. Others say PHP already has good tools, but they are interested to see if Mago can be better or easier to use. A few users point out that having one tool that does linting, formatting, and static analysis together is helpful, especially for teams. There are questions about how Mago will work with big codebases and if it can fully replace older tools. Some think using Rust for a PHP tool is a smart move, but there are worries about installation or compatibility on Windows. Others want to know how Mago’s analysis compares to Psalm or PHPStan in finding real bugs. A couple of users hope Mago will be easy to set up in CI/CD pipelines. Some are happy to see fresh energy in the PHP world, while a few are waiting for more real-world reviews before switching. In general, the community feels positive, but they want to see how Mago does in practice.

---

## My First Impressions of Gleam

- 原文链接: [My First Impressions of Gleam](https://mtlynch.io/notes/gleam-first-impressions/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45231852)

This article is about someone trying the Gleam programming language for the first time, using it to write a parser for old AOL Instant Messenger (AIM) chat logs. The writer shares step-by-step thoughts and struggles as they learn Gleam, which is a statically-typed, functional language inspired by Elixir.

First, the writer explains their project: parsing AIM logs that come in different formats, with the simplest being plain text. They think Gleam might be a good fit for this task, especially because functional languages are said to be good for parsing. The author is an experienced programmer but is new to functional languages—most familiar with Go and Python.

When starting, they find that Gleam doesn’t have built-in support for parsing command-line arguments, but they discover a simple third-party library called "argv" that does the job. Next, they are confused by the "gleam build" command, which doesn’t produce a binary executable like Go or Zig. Instead, it compiles to BEAM bytecode for the Erlang VM, which is less straightforward to run directly.

As they implement a simple parser, the writer struggles with the lack of features they expect: no if statements, loops, or list index access. Instead, they learn to use functions like list.map and pattern matching, which are new to them. They show how to split strings into lines, map over those lines, and use pattern matching to process only the relevant chat message lines. To extract the message content, they use string.split and string.split_once, and handle the results with pattern matching and Result types, which is different from their usual way of coding.

They also describe filtering out empty strings using list.filter, and later refactor their code to use Result types for clearer error handling. The author enjoys Gleam’s pipeline syntax for chaining functions, finds the example-heavy documentation helpful, likes warnings for unused variables, and appreciates the todo keyword for marking unfinished code.

However, they find error handling with Result types a bit awkward, especially in pipelines. They feel the core language and standard library are small, missing many built-in features found in larger languages, and relying a lot on third-party packages. They end by sharing the source code and reflecting that Gleam is fun and helps them learn new ways of thinking, even if it’s sometimes uncomfortable.

The Hacker News comments bring up several points. Some readers agree that using Gleam is a good way to learn functional programming, and say that the author’s struggles are normal for people moving from imperative to functional languages. Others note that pattern matching, pipelines, and immutable data are important ideas that take time to get used to, but are rewarding.

A few commenters mention that the small standard library and young ecosystem are common problems for new languages, but they hope Gleam will grow over time. Some readers wish that Gleam made it easier to create standalone executables, since relying on the Erlang VM can be awkward for simple tools. Others argue that the focus on functional purity and strict types can make some things harder, but also prevent bugs.

There are also tips from people with more experience in functional languages. They recommend thinking less about loops and variables, and more about chaining transformations and using pattern matching for control flow. Some like that Gleam feels approachable compared to other functional languages, while others hope for more documentation and libraries to make it easier for beginners.

In summary, the article and discussion show that Gleam is an interesting new language for people who want to try functional programming, but it can be challenging for those used to other languages. The community is friendly and helpful, and many hope the ecosystem will improve as more people use Gleam.

---

