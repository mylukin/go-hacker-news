Hello everyone, this is the 2025-09-13 episode of Hacker News Daily Podcast. Today, we bring you stories about open-source challenges, complex systems, creative AI, tricky C code, retrocomputing on FPGA, the feeling of time, the end of Safe C++, how Ruby’s JIT works, a new PHP toolchain, and learning the Gleam language. Let’s get started.

We begin with a story about open-source maintainers and why they often have to say “no” to new feature requests, even when the ideas are good. The writer says that every change must fit with the project’s main vision, not just work well. Maintainers protect the “soul” of the project by making sure changes follow the project’s mental model and goal. Good documentation helps attract contributors who really understand the purpose. With tools like LLMs, it’s now easier for people to send full pull requests, but this means maintainers must review more code that might not fit. The writer tried to require an issue before every PR, but some users just wrote quick, unhelpful issues. A better way is to clearly say only changes matching the project’s vision will be accepted, and contributors must show how their code fits. There’s also a worry about long-term support, because maintainers are responsible if a new feature causes problems, even if they didn’t ask for it. To help with this, the writer made a “contrib” section for extra features maintained by the original contributor. Over time, the writer became less responsive to users who don’t explain their needs. They prefer simple, clear questions and not long AI-generated texts. Even with AI, careful stewardship is important for good software and strong communities. In a recent AI protocol meeting, the team debated each new idea, always asking if it matched the main goal.

In the comments, many agree that saying “no” is key to keeping projects healthy. Some say too many features make software hard to use and support. Others note that contributors can feel hurt if their ideas are rejected, so it’s important to explain why. Some point out that requiring issues before PRs doesn’t always work. Clear contribution guidelines and a public roadmap can help set expectations. People worry AI-generated PRs will make things harder for maintainers, but new contributors should still be encouraged. Some maintainers use “contrib” sections or plugins to keep extra features out of the main code. Many mention burnout and wish for more respect for the time and care maintainers give.

Next, we look at a story about big, complex systems. The article explains that large systems like electric grids or health care always start as small, simple systems that work. The idea that big systems are built with one smart plan is not true; instead, they grow step by step, with many people fixing and changing things along the way. The article gives examples of failed “systems thinking” in government projects, like HealthCare.gov’s crash and Australia’s costly disability reforms. Even with better tools, these systems are hard to control. Modeling the world as a simple system, as Jay Forrester did, often fails because real life is too complex. Forrester’s global models predicted resource collapse, but the world improved instead. His models worked for simple cases but not for countries or the world.

The writer shares Le Chatelier’s Principle from chemistry: change a system, and it pushes back. John Gall, a doctor, saw the same for human systems—if you try to fix them, new problems appear. “Gall’s Law” says a complex system that works always starts as a simple system that works. The game Factorio is used as an example: you start simple, learn, and build up. For big systems, we can’t just turn them off and start over, but we can build simple new systems next to old ones, as seen in the US missile program, Covid vaccine rollout, Notre-Dame’s rebuild, and Estonia’s digital government.

In summary, trying to plan and fix big systems all at once usually fails. It’s better to start small, be humble, and grow working systems step by step. In the comments, people agree with starting simple and share stories where simple solutions beat big plans. Some say old systems can get too messy and need to be replaced. Others warn that “simple” is not always easy—small systems can hide big problems. Some discuss the slow pace of change in big organizations, while others agree that more technology does not always fix complexity, and can make things harder. There is also talk about open-source projects, which often succeed by starting simple and growing. Many agree that models can miss important details and that every fix can create new problems, so leaders need to trust small teams and expect surprises.

Our next story is about a fun new website called Anycrap. This site lets you type anything into a search box, and it makes up a product based on your words. It acts like a store, where you can “buy” products from other universes, but they are all fake ideas. For example, if you type “banana-powered phone charger,” the site instantly creates a fake product based on that idea. The site calls itself a “conceptual marketplace”—a store for ideas, not real things. There’s no real shopping or delivery, just creative, sometimes funny, or impossible product descriptions. The site wants people to be playful and let their imagination run wild.

In the comments, people had mixed reactions. Some thought it was funny and enjoyed making up silly products. Others said it was a clever use of AI for entertainment. A few asked if this could help real businesses brainstorm new ideas. Some were confused at first, thinking it was a real shop, but most understood it was just for fun. A few worried about fake stores confusing people, but most saw that this site is a clear joke. Others mentioned it could help with marketing ideas, and some liked the simple design, though others thought it could be better. Overall, most people thought it was a lighthearted, creative project that shows the power of imagination and AI.

Moving on, we have a technical story about the curl project and the problems they faced with threads and DNS lookups. Curl wanted to use threads to run getaddrinfo(), which can block the main program. They started a new thread for each lookup, but cleaning up these threads was hard. Joining the thread blocks again, and detaching it is not good for many transfers. Curl tried using pthread_cancel to stop threads early, but after releasing this in version 8.16.0, users found memory leaks. The leaks happened because glibc does not free memory if getaddrinfo() is cancelled at the wrong time. The author saw more places in glibc where cancelling could cause leaks, so it was unsafe to keep this feature. In the end, curl removed pthread_cancel. Now, they have to accept waiting for slow DNS sometimes. For fast DNS, users can use c-ares, but it can’t do everything getaddrinfo() does. DNS remains a hard problem.

In the comments, some say pthread_cancel is almost always dangerous, and many libraries can’t handle threads being stopped suddenly. Others point out that glibc’s cancelation points are confusing. Some suggest using c-ares or writing custom DNS code. A few share similar problems with memory leaks in other programs. Some say it’s better to design code so threads exit by themselves. Others warn that even if pthread_cancel seems to work at first, it can break later. Many respect curl’s decision, even if it means slower DNS. Overall, people agree that DNS and threads are both tricky, and there’s often no perfect answer.

Now let’s talk about retrocomputing. One article describes running a 486 PC on a small FPGA board called the Tang Console 138K. The author ported an open-source 486 CPU core from the MiSTer project to this new board. They used SDRAM for memory, which fits better with old 486 hardware, and DDR3 for graphics. The FPGA reads disk data directly from an SD card. Booting the system involves loading BIOS and settings from the SD card into memory.

Debugging was hard, so the author used Verilator simulation software to catch bugs faster. The first version was slow, like an old 386 PC. The author sped things up by changing how signals were wired and optimizing memory logic. With these fixes, the system became 35% faster, matching a real 486SX-20. The author says that raising the clock speed helps, but memory speed is the real limit. They also found that x86 CPUs are much more complex than ARM CPUs.

Comments are positive. People are impressed that old PC power fits on a small, cheap board. Others like how the project brings old DOS software back to life. Some discuss how hard x86 is to implement and praise using simulation tools for debugging. People ask about running games and if sound and graphics are good enough for classics like Doom. There’s debate about whether FPGA projects can match real hardware speed, or if software emulators are enough. Some suggest more optimization tricks, and many hope to see videos or demos. Overall, there’s excitement for more open, easy-to-use FPGA computers.

Our next article explores why time feels slower as a child but speeds up as we get older. The author remembers long summers as a kid, but by age 22, years seem to pass quickly. A study found that young people estimate two minutes more accurately than older people, who think less time has passed than really has. This is linked to dopamine, the brain chemical that helps us notice new things. When we’re young, everything is new, so time feels long. As we repeat the same things, less dopamine is released, so time feels shorter. Our brains have an “internal clock” that works with memory. New experiences stretch our sense of time, but routines make time shrink. The “reminiscence bump” means big, new life events stick with us and make time feel longer. The author shows that at age 6, a year is a big part of your life, but at age 18, it’s much smaller. The message: if you want time to feel slower, keep trying new things and break up your routines. The writer says that even after hard times, like losing a year to Covid, it’s possible to feel young again by staying open to new experiences.

In the comments, many agree that time feels faster as they get older and share their own stories. Some say starting new hobbies or traveling helps slow down time. Others find that having children or big changes also make time feel slower. Some say routines make time disappear, while others find comfort in routine. There’s discussion about the brain science and if culture or stress also matter. Some wonder if technology and being busy make time feel even shorter now. People feel sad about time passing quickly, but others see it as a reason to live more fully and try new things at any age.

Now let’s turn to the end of the Safe C++ proposal. This plan aimed to add a “safe” part to C++ that works like Rust, helping avoid common bugs without breaking old code. Programmers could mark safe sections, follow strict rules, and slowly move from unsafe to safe code. The proposal included a “borrow checker” and ways to mix safe and unsafe code, but some problems were not solved, like error messages and templates. Now, the proposal is not moving forward. The C++ committee will focus on “Profiles” instead. Profiles add safety by limiting how you can use C++ features, but don’t add new language parts. This is easier to add and less risky for old code.

In the comments, some are sad that Safe C++ is gone, while others say C++ should not copy Rust. Some are happy with Profiles, saying they are practical and will help more people. Others think Profiles are too weak. Some say no safety plan will work until the C++ community really wants change. Others say C++ must stay flexible. A few point out that C++ already has safe coding styles. Some hope Profiles will at least start movement toward better safety, while others still wish for bigger changes. The comments show a split: some want strong safety, others want to keep C++ as it is, and many see Profiles as a small but welcome step.

Next, we have an article explaining how Ruby runs code using JIT, or Just-In-Time compilation. The article looks at tools like YJIT and ZJIT. When you write Ruby code, each method is turned into an Instruction Sequence, or ISEQ, which is bytecode. When a method is used a lot, Ruby may JIT-compile it, creating machine code that runs faster. Ruby keeps both the bytecode and the machine code for each method, so it can return to bytecode if things change. Ruby decides what to compile by counting method calls. At first, Ruby runs bytecode, but after a method is called enough times, it compiles it to machine code. JIT code makes guesses to run faster, but if things change—like different data types or turning on debugging—Ruby stops using JIT code and returns to bytecode. Not every method is JIT-compiled, because compiling uses memory and time.

The comments are positive. Some say the explanation helped them understand Ruby’s JIT. Others note that keeping both bytecode and machine code is common. Some wish for faster JIT compilation or tuning for different programs. Others warn that JIT can bring new bugs or make debugging harder. There are questions about JIT and large Rails apps, and some share their own experiences with Ruby JIT in production. Some compare Ruby’s JIT to Python’s new plans, and a few discuss the trade-offs between memory, speed, and safety.

Let’s move to PHP. Mago is a new toolchain for PHP, built in Rust, that helps developers write better and faster PHP code. Mago works as a linter, formatter, and static analyzer. It checks for mistakes, style problems, and bugs, all in one place, and runs very fast thanks to Rust. Mago can lint code with custom rules, do deep static analysis to catch type errors, fix some problems automatically, and format code to follow best practices. It also lets you see your code’s structure using its AST feature. Mago takes ideas from tools like Clippy and OXC, as well as PHP tools like Psalm and PHPStan. It’s open source and easy to install, with support for Homebrew, Composer, and Cargo.

In the comments, some people are excited about Mago’s speed and like that it’s written in Rust. Others say PHP already has good tools, but they want to see if Mago can be better. Some like having one tool for linting, formatting, and static analysis together, which is helpful for teams. There are questions about Mago’s performance on big codebases, if it can replace older tools, and if it finds bugs as well as other analyzers. Some hope it’s easy to set up in CI/CD pipelines. The community feels positive but wants to see real-world results before switching.

Now let’s talk about learning a new language. One article shares the experience of trying the Gleam programming language for the first time by writing a parser for old AOL Instant Messenger chat logs. Gleam is a statically-typed, functional language inspired by Elixir. The writer is new to functional languages and is used to Go and Python. They find that Gleam doesn’t have built-in command-line parsing, but there’s a simple third-party library. The build command creates BEAM bytecode, not a native binary. The writer struggles with the lack of if statements, loops, and list index access, and learns to use map and pattern matching instead.

They explain how to split strings into lines, map over them, and use pattern matching to process only chat message lines. They use Result types for error handling, which is new to them. The writer enjoys Gleam’s pipeline syntax, example-heavy docs, and warnings for unused variables, but finds error handling with Result types a bit awkward in pipelines. They feel the core language and standard library are small, and rely a lot on third-party packages. In the end, they share the code and say Gleam is fun and teaches them new ways of thinking, even if it’s sometimes uncomfortable.

Comments agree that Gleam is a good way to learn functional programming, and the author’s struggles are normal for people moving from imperative to functional. Pattern matching, pipelines, and immutable data take time to get used to, but are rewarding. Some mention the small standard library is a problem for new languages, but hope Gleam will grow. Some wish Gleam made it easier to create standalone executables. Others argue that functional purity and strict types can make some tasks harder, but also prevent bugs. There are tips from experienced functional programmers: think less about loops and more about chaining transformations and using pattern matching. Many like that Gleam is approachable, and hope for more docs and libraries.

That’s all for today’s episode. We covered open-source challenges, complex systems, AI-powered fun, C and threads, FPGA retrocomputing, the feeling of time, safe C++, Ruby’s JIT, new PHP tools, and learning functional programming with Gleam. Thanks for listening, and see you next time on Hacker News Daily Podcast.