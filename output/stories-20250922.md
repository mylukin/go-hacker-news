# Hacker News 故事摘要 - 2025-09-22

## 今日概述

Today’s top Hacker News stories are about new AI models that can work with text, images, and audio, big AI data centers, and tools for building better web and offline apps. Users also talk about laptop battery life, fixing real software bugs with AI, and creative ways to carry laptops. There’s lots of talk about open source, privacy, and making tech more useful for everyone. If you like AI, programming, or hardware, today’s stories have something interesting for you.

---

## Qwen3-Omni: Native Omni AI model for text, image and video

- 原文链接: [Qwen3-Omni: Native Omni AI model for text, image and video](https://github.com/QwenLM/Qwen3-Omni)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45336989)

Qwen3-Omni is a new AI model from Alibaba Cloud that can handle text, images, audio, and video together, and can reply in real time with both speech and text. This model supports many languages and has been tested to work very well on different tasks like speech recognition, translation, image understanding, and video analysis. Qwen3-Omni uses a special design called MoE (Mixture of Experts) with two main parts: a “thinker” for understanding and a “talker” for speaking.

The model can take many types of input at once—for example, you can show it a picture, play a sound, and ask a question in text, and it will answer. It works with 119 languages for text, 19 for speech input, and can reply in 10 languages using different voices. Qwen3-Omni is open source and has detailed guides (“cookbooks”) showing how to use it for things like speech recognition, music analysis, object detection, video description, and more.

You can run Qwen3-Omni using popular tools like Hugging Face Transformers and vLLM, or through Alibaba’s DashScope API. There are web demos and Docker images to make starting easier, but you need strong hardware—running the full model with long videos can use over 100 GB of GPU memory. The model supports both text and spoken output, and you can choose different voice types for the audio reply.

In benchmarks, Qwen3-Omni gets top or near-top scores on many tasks, sometimes beating strong models like GPT-4o and Gemini 2.5 Pro, especially on audio and video understanding. For example, it does well in multilingual speech recognition, music tagging, image math, and video scene analysis. It also has a special “Captioner” model that gives detailed, accurate captions for audio inputs.

In the top Hacker News comments, people are excited about the broad abilities of Qwen3-Omni, saying it’s impressive to see open source models catching up to or even beating closed models from big tech companies. Some users are happy that there are clear guides and Docker support, making it easier to try the model. Others point out the high hardware requirements, saying that most people won’t be able to run the largest models at home, but cloud or smaller versions could help.

A few developers note that the model’s multi-language support is very useful for global projects. Some ask about privacy, since running models locally can help keep data secure, but the need for big GPUs is a problem. There are also questions about how well Qwen3-Omni works for real-time applications, like live translation or voice assistants, and some users share tips for speeding up inference or saving memory.

One commenter mentions that Alibaba’s approach of sharing detailed benchmarks and usage examples is good for the open source community. Another suggests that open models like this can drive faster progress, since more people can test and improve them. Some users are curious how Qwen3-Omni’s results hold up in real-world, noisy environments versus controlled benchmarks. Finally, a few people compare Qwen3-Omni to other models like LLaVA, noting that strong multimodal support is becoming the new standard for AI.

---

## Choose Your Own Adventure

- 原文链接: [Choose Your Own Adventure](https://www.filfre.net/2025/09/choose-your-own-adventure/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45337450)

This article tells the story of the “Choose Your Own Adventure” book series and how it became so popular. It explains how these books let readers make choices that changed the story, which was new and exciting for kids in the late 1970s and 1980s.

The first book, “The Cave of Time,” invited children to pick what happened next by turning to different pages. This second-person style was rare and made readers feel part of the adventure. The idea started with Edward Packard, who created stories with his daughters and wondered what would happen if a book had different endings, depending on your choices. Packard struggled to find a publisher at first, but eventually, a small press called Crossroads released his book. Another writer, Ray Montgomery, joined in, and soon agent Amy Berkower helped bring the idea to Bantam Books, a big publisher.

The books sold very well, especially to boys, and reached millions of children. They covered many themes—time travel, deep-sea diving, the Wild West, and more. The series used simple choices, but for many kids, this was their first taste of interactive storytelling. Over time, the format inspired other series and even computer games, like Infocom’s text adventures and Dungeons & Dragons books. The “Choose Your Own Adventure” books were copied by many, but nothing matched their popularity.

Sales dropped in the late 1980s as computers offered more advanced interactive stories. Bantam stopped the series in 1999, but the books are still remembered fondly. Some attempts to revive the series have been made, and digital successors like “Choice of Games” continue the spirit of interactive storytelling, though now aimed at older readers.

In the Hacker News comments, many users share their childhood memories of these books. Some say “Choose Your Own Adventure” was their first experience with branching stories, and it made them love reading. Others recall how the books led them to video games and programming, as they wanted to create their own stories.

Several people discuss the simplicity of the format, with a few noting that after a while, you could see the limits—most stories only lasted a few choices before ending. A few users say they preferred gamebooks with more rules and dice, like “Fighting Fantasy,” which felt more like real games. Some mention that “Choose Your Own Adventure” helped kids who didn’t like regular books to enjoy reading.

There’s some debate about the sales numbers—some think the often-quoted 250 million figure is too high, and that the real number is closer to 100 million. A few comments talk about how the books handled violence and choices, saying the deaths were often funny or silly instead of scary. Others point out that the books usually pictured boys on the covers, which might have turned away some girls.

A couple of people note the legal battles over the brand, especially when Netflix made an interactive “Black Mirror” episode. Some users say it’s sad that the series ended as just a nostalgic memory, while others are happy that interactive fiction lives on in digital formats. Overall, there’s a strong feeling of nostalgia and respect for how “Choose Your Own Adventure” inspired both readers and game developers.

---

## Cap'n Web: a new RPC system for browsers and web servers

- 原文链接: [Cap'n Web: a new RPC system for browsers and web servers](https://blog.cloudflare.com/capnweb-javascript-rpc-library/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45332883)

Cap'n Web is a new library for remote procedure calls (RPC) between browsers and web servers, written in TypeScript. It is made by Cloudflare and is related to Cap’n Proto, but designed for the web.

Cap’n Web uses object-capability security and supports calling functions both ways—client to server and server to client. You can pass functions and objects by reference, so the other side gets a “stub” and can call it like a normal function. The protocol is based on JSON, so messages are easy to read and debug. Cap’n Web works over HTTP, WebSocket, and postMessage, and supports all major browsers, Node.js, and Cloudflare Workers. It is open source, under the MIT license, and the library is very small (under 10 kB). 

A big feature is “promise pipelining”: you can chain calls together without waiting for each one, so only one network trip is needed. It also has good support for TypeScript, letting you use interfaces for type checking. Cap’n Web also solves some problems that are hard in other RPC systems, such as returning new objects from RPC calls (like authenticated sessions), and handling secure methods naturally without extra code. 

It is easy to set up: on the client, you just connect and call methods; on the server, you extend a base class and add your methods. Batch mode lets you send many calls in one HTTP request. There is also a special `.map()` for working with arrays, allowing you to process lists server-side without extra network trips.

Compared to GraphQL, Cap’n Web tries to offer the same “no waterfall” benefit, but sticks to JavaScript and avoids new languages or schemas. You just write normal code, and the system handles the complex parts.

In the Hacker News comments, some users were excited about the object-capability model and promise pipelining, saying these ideas are powerful and rare in web tech. Others liked how easy the setup is and praised the clear TypeScript integration. A few people pointed out that while Cap’n Web is simple for JavaScript, it could be hard to connect with non-JS systems, since there are no schemas to describe the API for other languages. Some worried about security, especially if type checks only happen at compile time, not runtime. Others compared Cap’n Web to gRPC and GraphQL, wondering how it scales, or if tooling is mature enough for big projects. Some users liked the open source license and small size, but others wanted to see performance benchmarks and more real-world examples. There was also debate about using RPC in general, with some arguing REST is easier to debug, while others said modern async programming makes RPC much safer than before. A few developers were excited to try Cap’n Web for new projects, but some said they would wait until it is less experimental.

---

## Why haven't local-first apps become popular?

- 原文链接: [Why haven't local-first apps become popular?](https://marcobambini.substack.com/p/why-local-first-apps-havent-become)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45333021)

This article talks about why local-first or offline-first apps are not common, even though they seem like a great idea. Local-first apps should be fast, private, and work without the internet, but most apps do not handle offline support well.

The main problem is syncing data between devices. When you let users change data on different devices, sometimes while offline, you need to make sure all devices agree on the final state later. There are two big challenges: the order of changes and handling conflicts when two devices change the same thing in different ways.

For example, if Device A sets a value to 3 while offline and Device B sets the same value to 5, which one should be the final value when they sync? Traditional apps use a backend server to keep everything in order, but this does not work for offline-first apps.

The article explains a tool called Hybrid Logical Clocks (HLCs). HLCs help devices agree on the order of events without needing a central server or perfectly synced clocks. They combine the local clock time and a counter, so even if clocks are slightly off, devices can sort events in the right order.

But ordering is not enough. Sometimes, two devices change the same data, like a bank balance, in different ways. To solve this, apps can use CRDTs (Conflict-Free Replicated Data Types). CRDTs make sure all devices reach the same final state, no matter in which order changes arrive. One simple way is "last-write-wins," where the most recent change (by timestamp) is kept.

The article says a good local-first app needs a strong local database like SQLite. The author’s team built a SQLite extension that stores all changes with their timestamps. When syncing, devices just accept the newest change and ignore older ones. This makes syncing easy, reliable, and works on many platforms.

Now, let’s look at what people said in the comments. Some users agree that syncing is very hard and that’s why most apps avoid true offline support. Others think that users do not demand offline features, so developers do not spend time building them. A few commenters point out that big companies like Google and Apple could do more to make offline-friendly tools, but so far, they focus on cloud-based solutions.

Some developers share their own struggles with building offline apps, saying that testing and debugging sync issues takes lots of time. Others mention that for most simple apps, syncing is not worth the effort. On the other hand, some say that privacy and speed are big reasons to use local-first apps, and hope that new tools (like the one in the article) will make it easier.

A few people ask about handling more complex data or business rules, wondering if the simple "last-write-wins" method is really enough. Some think that users do not trust apps to keep data safe when offline, or they worry about losing their work. There are also comments about how internet access is now so common that many users do not care about offline features.

Finally, some commenters are excited about new open-source tools that promise better offline support. They hope more developers will try building local-first apps now that the main problems have clearer solutions.

---

## OpenAI and Nvidia announce partnership to deploy 10GW of Nvidia systems

- 原文链接: [OpenAI and Nvidia announce partnership to deploy 10GW of Nvidia systems](https://openai.com/index/openai-nvidia-systems-partnership/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45335474)

OpenAI and Nvidia said they will work together to build huge new AI data centers with Nvidia hardware, planning at least 10 gigawatts of computing power. This deal may be worth up to $100 billion, with the first part coming in 2026 using Nvidia’s new Vera Rubin platform. The companies say this partnership is needed to train and run the next generation of AI models, aiming for “superintelligence.” OpenAI will use Nvidia as its main hardware partner, and they will design hardware and software together. OpenAI’s leaders say strong computing power is the key to future AI progress and business growth. They note that hundreds of millions of people already use their AI and that this new infrastructure will help reach even more users. Both companies plan to work with other big tech players like Microsoft and Oracle to build out this advanced AI system. They believe this will help OpenAI’s mission to make AI that helps everyone.

In the Hacker News comments, some people are amazed by the scale—10 gigawatts is more than the total power used by some countries. Others wonder about the energy cost and environmental impact of so much computing power. A few users think this partnership shows just how dominant Nvidia has become in the AI hardware market. Some worry that such big investments will make it hard for smaller companies to compete in AI. There are also questions about if this much compute is really needed for better AI, or if it just leads to bigger and more complex models. Others discuss the risk of putting too much power in the hands of a few companies. Some point out that the timeline—first systems ready in 2026—shows that building this kind of infrastructure takes a lot of time and planning. A few users are excited about the technology and what new AI models might be possible with so much hardware. Others remain cautious, saying we need to watch for possible negative effects, like increased energy use or less market competition.

---

## Fine-grained HTTP filtering for Claude Code

- 原文链接: [Fine-grained HTTP filtering for Claude Code](https://ammar.io/blog/httpjail)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45338561)

The article talks about a new tool called httpjail, made to control and filter HTTP(S) requests from coding agents like Claude Code. The goal is to help developers keep their code agents safe and to stop them from doing things they should not, such as deleting databases or leaking secrets.

The problem is that coding agents are getting stronger, but security tools have not kept up. Sometimes, a developer might let an agent run with too many permissions, or an agent may be tricked by a bad prompt. Httpjail is made to stop these risks. It works by blocking all network traffic except for the traffic you allow. You can write rules in JavaScript or shell scripts to decide which requests are okay. For example, you can allow only requests to a certain API, only allow GET requests, or use a whitelist file with allowed hosts.

Httpjail is more flexible than normal firewalls because you can make very detailed rules. On macOS, it uses environment variables like HTTP_PROXY to control requests. This is called weak mode, and it works if the app follows the rules. For HTTPS traffic, httpjail does TLS interception. It creates its own fake certificate authority, signs certificates for each request, and makes sure programs trust this CA by setting environment variables for common tools, like curl, Node.js, Python, and Git.

However, the weak mode is easy to escape: an agent can just ignore the proxy. Even in strong mode, a clever agent might use tricks, like starting a new container, to get around the network rules. Httpjail tries to solve this by letting you run agents inside Docker containers with network limits.

For the best safety, you can run httpjail on a separate server and only allow web traffic through it. You can install httpjail with cargo, and there is a GitHub repo for more info.

In the comments, some users like the idea and think httpjail is a useful step for safer AI agents and dev tools. They say this tool helps stop accidental or risky agent actions. Others point out that on macOS, the weak mode is not very secure, because programs can avoid it. Some suggest that more work is needed to make sure agents cannot escape, like better OS-level controls. A few worry about the problems of TLS interception, such as breaking some HTTPS features or causing trust issues in browsers and other tools. There are also comments about how hard it is to keep network rules up to date, since IP addresses and endpoints change often. Some users ask for better support on Windows or for more examples of real-world use. Others note that for many developers, these tools may be too complex or too much effort, but they agree the problems are real and growing.

---

## Diffusion Beats Autoregressive in Data-Constrained Settings

- 原文链接: [Diffusion Beats Autoregressive in Data-Constrained Settings](https://blog.ml.cmu.edu/2025/09/22/diffusion-beats-autoregressive-in-data-constrained-settings/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45337433)

The article talks about how two kinds of AI models—autoregressive and diffusion—perform when there is not much training data. It explains that, in the past, making models better was mostly about giving them more data and more computer power.

The main idea is that soon, we may have more computer power than new data to use. This will make it hard to keep improving models by just using bigger datasets. The article compares autoregressive (AR) models, like the ones used in GPT, and diffusion models, which are popular in image generation. Both are now being tested in new areas, like text and robotics. 

Autoregressive models learn by predicting the next word in a sentence, using left-to-right order. Diffusion models learn by randomly hiding words and then trying to guess them, which is like data augmentation. This means they can get more value from the same data, especially when the data is reused many times.

Tests in the article show that, when you have little data but can train for many rounds (epochs), diffusion models start to beat AR models. AR models do better at first, but then start to overfit (learn too much from the small data), while diffusion models keep getting better even after many rounds. Diffusion models do not overfit as quickly and can use the same data hundreds of times before performance drops. 

The article also finds that diffusion models do better on real tasks when data is limited, and they work better because they see data in many different ways, not just left-to-right. If you give AR models more data variety (like mixing up word order), they start to catch up, but diffusion is still better in low-data situations. 

In short, if you do not have much data but can train for a long time, you should use diffusion models. If you have lots of data but less computer power, AR models are better.

People in the comments had many thoughts about this. Some said the results make sense, because data augmentation is a known way to help with small datasets. Others wondered if these results would hold for much bigger models or real-world tasks, and if diffusion’s higher computer cost is always worth it. Some pointed out that autoregressive models are easier to use and are already in many products, so switching to diffusion could be hard. A few commenters asked if hybrid models could combine the best parts of both. Others were excited about using diffusion in fields like robotics or healthcare, where data is often limited. Some also noted that, as we run out of new data, research like this will become more important. A few people wanted to see more test results on tasks outside of language, while others questioned if the study’s setup matched real industry needs. Overall, many people saw this as a useful guide for picking models, but agreed that practical choices depend on the task, data, and available compute.

---

## SWE-Bench Pro

- 原文链接: [SWE-Bench Pro](https://github.com/scaleapi/SWE-bench_Pro-os)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45335452)

SWE-Bench Pro is a test to see if AI tools can fix real software problems in big codebases, not just simple bugs. The project gives an AI a codebase and an issue, and the AI must make a patch that solves the problem, just like a real software engineer would. This benchmark is harder than earlier tests because it focuses on long-horizon tasks, which means the problem might need changes in different parts of the code, not just one spot. 

The dataset is open and can be downloaded using Python code. To run the tests, you need Docker and a service called Modal, which helps run many tests at once. There are public and private leaderboards, so teams can see how well their AI systems do compared to others. The project also provides ready-made Docker images to help people get started quickly.

To check if your AI patches work, you use the provided script, which runs the patch inside a container and checks if the issue is fixed. The test supports many workers at once, so you can run many tests in parallel. Most files in the repo are scripts, setup files, and the code to run the benchmark.

In the comment section, many people are excited that AI is being tested on “real” software engineering problems, not just simple code snippets. Some say this is a big step for AI code tools, since real bug fixes often need understanding many files and project context. Others point out that AI models still have trouble with very complex or unclear issues, and that human review is still needed. A few worry that benchmarks like this might not capture the real teamwork and thinking that happens in software projects. Some developers share tips for making the setup easier, like using cloud resources instead of running Docker locally. There’s also a debate about whether these benchmarks are enough to trust AI with important code, or if they only show progress on narrow tasks. Finally, a few people wonder what happens if AI tools start submitting patches to real open-source projects, and whether that will help or hurt the code quality.

---

## I'm spoiled by Apple Silicon but still love Framework

- 原文链接: [I'm spoiled by Apple Silicon but still love Framework](https://simonhartcher.com/posts/2025-09-22-why-im-spoiled-by-apple-silicon-but-still-love-framework/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45332859)

This article compares the author’s experience using two laptops: an Apple MacBook with Apple Silicon and a Framework 13 with an AMD processor. The main topic is how the MacBook holds its battery much better during sleep than the Framework laptop.

The author left the MacBook closed but unused for three weeks, and it still had 90% battery left. In contrast, the Framework laptop loses battery quickly, even when just sleeping for a few days. The Framework can lose 3-4% battery each hour during sleep, which is much worse than the MacBook. The author tried different Linux systems on the Framework, like Fedora, Arch Linux, and Fedora Silverblue. Even though Fedora Silverblue works well, the battery problem remains. The author likes the idea of Framework laptops because they are easy to repair and upgrade. But he feels sad that, outside of Apple Silicon, modern laptops still have poor battery life. He wonders if getting an ARM mainboard for the Framework in the future would help but learns that it is a difficult change, not just a simple swap. In the end, he still loves using the Framework laptop, but he keeps it plugged in so it is always ready.

In the comments, many people agree that Apple Silicon laptops have amazing battery life, especially in sleep mode. Some users say that Linux laptops often have problems with sleep and battery drain, and this is not just a Framework problem. Others mention that Apple controls both hardware and software, which helps them optimize battery use better than Windows and Linux laptops. A few readers discuss how ARM chips are more efficient than x86 chips, but switching to ARM is hard because of software support. Some users defend Framework, saying their mission of repairability and freedom is still important, even if battery life is not perfect. Others wish Linux could catch up with Apple’s power management. A few people suggest tricks to save battery on Linux, like using hibernate instead of sleep. There are also comments about how most people just plug in their laptops, so battery life might not matter as much for some. Some users hope future Framework models with ARM chips will solve this problem. Others say that, even with battery flaws, owning a repairable laptop feels good.

---

## Is a movie prop the ultimate laptop bag?

- 原文链接: [Is a movie prop the ultimate laptop bag?](https://blog.jgc.org/2025/09/is-movie-prop-ultimate-laptop-bag.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45332196)

This article talks about why the author uses a movie prop grocery bag as a laptop bag. He once went to a Cloudflare board meeting with his laptop in a real brown paper grocery bag, which made people comment on his odd choice. He says he likes to carry his laptop in bags that do not look special. He thinks the best bag is one that does not look like it holds a laptop, because it draws less attention. Real grocery bags are weak and tear easily, so he found a better solution: a fake grocery bag made for movies. This bag looks like paper, but is actually made from fabric. It does not make noise, and it is much stronger than real paper. It is also the right size for his old MacBook Pro, especially when in a sleeve. He jokes that his question in the headline is answered by Betteridge’s Law, which says the answer to any headline question is usually “no.” But he still likes the bag because it is discreet and not flashy.

Hacker News readers had many opinions on this idea. Some people like the idea of using bags that do not look valuable, for security reasons. They say ordinary bags can help avoid theft. Others share their own tips, like using diaper bags, old backpacks, or even lunch boxes to hide laptops. Some users mention risks: a bag that looks too plain might get thrown away by accident, or security at airports could be suspicious. A few people say they prefer strong, well-padded computer bags to protect their laptops from drops. There are comments about style versus function, with some choosing comfort and protection over hiding the laptop. One person shares a story of getting their laptop stolen from a fancy laptop bag and now only using cheap-looking bags. Another user points out that movie prop bags can be expensive, and wonder if the idea is practical for everyone. A few people just joke about the idea, saying it is “peak nerd” or that it would make a funny scene in a hacker movie. Some readers appreciate the creativity and fun behind the choice, even if they would not try it themselves. Overall, people seem to enjoy the story, and it starts a lively talk about laptop bag hacks and safety.

---

