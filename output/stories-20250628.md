# Hacker News 故事摘要 - 2025-06-28

## 今日概述

Today’s top Hacker News stories cover a legal fight over the “JavaScript” name, a new open protocol for connecting AI tools, and how people use ham radio for fun and emergencies. There are deep dives into how AI servers work, student projects building CPUs, huge numbers in computer science, and problems with social media addiction. Other stories include safer ways to run shell scripts and new music by Erik Satie. If you like software law, AI, hardware projects, or tech history, today’s stories have something for you.

---

## JavaScript Trademark Update

- 原文链接: [JavaScript Trademark Update](https://deno.com/blog/deno-v-oracle4)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44407139)

The article talks about a legal fight over the “JavaScript” trademark, which is owned by Oracle. The creator of Node.js is upset because Oracle used a screenshot of the Node.js website to prove they use the name, even though Node.js was never an Oracle product. The fraud claim against Oracle was dismissed, but the main argument is now about whether “JavaScript” is a generic term and if Oracle has abandoned it. The author says everyone uses “JavaScript” to mean the language, not any Oracle product, and thousands of people support this idea. The next steps are for Oracle to answer every point in the case, then both sides will gather evidence. The goal is to make “JavaScript” a free name, so no company owns it, and developers do not need to worry about legal issues when using the word.

Many people in the comments wonder why Oracle is fighting to keep the trademark when they do not make money from it. Some think Oracle should give up the trademark to win goodwill from developers. Others say Oracle is just acting like a big company, holding on to anything valuable, even if it does not help them. A few point out that companies often keep lawyers busy with work like this, even if it is not needed. Some users remember that Sun Microsystems, before Oracle, also used legal tricks to protect their products, so it is not new behavior. There are debates about whether Oracle’s reputation is really hurt by this, since their stock is up.

Some comments discuss trademark law, saying “JavaScript” may have become a generic term, like “Kleenex” for tissues. Others say the law is not clear, and it’s hard to win such cases. A few people did not even know JavaScript was a trademark, and find it strange that Oracle owns the name. Some think the whole fight is silly, but others see it as important for the community. There are also side discussions about Oracle’s impact on open source, with mixed opinions—some say Oracle does good work, while others think they mostly buy and control other companies’ projects. A few commenters suggest just renaming JavaScript, but most think the name is too widely used to change now. Finally, some people think Oracle will never give up the trademark easily, while others hope this legal challenge will finally set the name free for everyone.

---

## MCP: An (Accidentally) Universal Plugin System

- 原文链接: [MCP: An (Accidentally) Universal Plugin System](https://worksonmymachine.substack.com/p/mcp-an-accidentally-universal-plugin)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44404905)

The article talks about MCP, a protocol made for connecting AI models to tools and data, but shows how it can work as a universal plugin system for many things, not just AI. The author compares MCP to USB-C and car cigarette lighters—simple ports that let you plug in anything, leading to unexpected uses. The idea is that MCP was meant for AI assistants, but if you remove the AI, you have a way for any app to connect to any tool or service easily. This could mean, for example, if someone makes an MCP server for Spotify, any app could use it to play music without knowing anything about Spotify’s code. The article also gives fun examples, like a toaster with HDMI output, to show how open protocols can lead to creative and strange uses.

MCP is described as a protocol where each server lists what it can do, and any client (AI or not) can discover and use those functions. The author notes this “accidental” universality, since every MCP server made for one use can be used by many others. This could allow for endless combinations and mashups, making software more flexible. The article compares this to past protocols like HTTP and Bluetooth, which started with narrow goals but now run much of the modern world because people found new uses for them. The author’s team is building an app called APM where all plugins are just MCP servers, making it very flexible. The article ends with a note that every protocol gets used in ways its creators never planned, and maybe that’s what makes them great.

Many Hacker News commenters agree that MCP makes interoperability popular again and say it’s easy to connect tools now, but some are skeptical about how long this trend will last. Some say MCP is not really new—APIs, Unix pipes, and other plugin systems have done similar things for years. A few people think the only new thing is that MCP makes it required to list all available functions in a simple way, making it easy for AIs (and maybe people) to use tools without special setup. Others worry that companies will soon lock down their APIs again, just like before, limiting the open ecosystem.

Some comments discuss technical details: MCP requires every server to have a “list-tools” endpoint, which is not always true for REST APIs or gRPC. People like that MCP includes both a human-readable description and a JSON schema for every function. However, a few say this informality makes MCP less reliable for strict machine-to-machine uses. There’s debate about whether MCP is really different from REST, gRPC, or older systems like COM, ActiveX, and SOAP, or if it’s just better marketing. Some are excited that MCP can make apps more scriptable and open, while others worry that we’ve seen similar hype before, and it always ends with closed systems and lost freedom. Still, many developers are trying MCP, finding it easy with the right libraries, and hope the attention will help solve problems quickly. Overall, there’s excitement about what’s possible, mixed with caution based on past tech cycles.

---

## 2025 ARRL Field Day

- 原文链接: [2025 ARRL Field Day](https://www.arrl.org/field-day)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44407245)

ARRL Field Day is a big annual event where ham radio operators in the US and Canada set up radios outdoors on the fourth weekend of June and try to talk to as many people as they can. The event mixes fun, learning, emergency practice, and a bit of friendly competition, drawing more than 31,000 people each year.

During Field Day, clubs and individuals set up temporary stations in parks, fields, and other public places. The goal is to make radio contacts using different bands and modes, often in less-than-ideal conditions, to show how radio can help during emergencies. It’s also a chance to show the public and new people what ham radio is all about, with many clubs inviting visitors to join and learn. There are no prizes or certificates, but results are published, and some people try to get the best scores for bragging rights. Special bonus points can be earned, for example, by making a contact through a satellite. There’s a locator online to find events nearby, lots of rules to follow, and many clubs use this time to test their skills, meet others, and have fun outdoors—sometimes even camping and cooking together.

People in the Hacker News comment section have a lot to say. Some share good memories, like helping a club reach top scores using special satellite equipment, or enjoying late-night radio and group meals. Others find Field Day too busy or stressful, saying the airwaves get crowded and it’s hard to have a simple, friendly chat. A few operators with small, low-power radios avoid Field Day because it’s hard to make contacts when big stations fill the air. Some don’t like the contest-like rush and prefer more relaxed events, like Parks on the Air or special themed weekends. There are comments about clubs not being welcoming or being too focused on their own members, which can make newcomers feel left out. Still, some people say the event is great for learning, teamwork, and trying things you can’t do any other time, like setting up in a park or working together on antennas. Even with mixed feelings, many agree Field Day is a unique tradition and a special time for ham radio fans.

---

## Life of an inference request (vLLM V1): How LLMs are served efficiently at scale

- 原文链接: [Life of an inference request (vLLM V1): How LLMs are served efficiently at scale](https://www.ubicloud.com/blog/life-of-an-inference-request-vllm-v1)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44407058)

This article explains how vLLM, an open-source tool, runs large language models (LLMs) quickly and at scale. It shows what happens step by step when you send a prompt to a vLLM server for AI text generation.

First, when you send a prompt, it reaches an API server that checks your request and passes it to something called AsyncLLM. AsyncLLM changes your text into tokens (numbers for the model) and sends this to the EngineCore using a special communication method. EngineCore is the heart of vLLM—it decides how to group many requests together (this is called batching) and manages which tokens go where. The Scheduler inside EngineCore keeps track of all the requests and tries to use the GPU as much as possible by grouping tokens smartly.

Next, vLLM uses a “continuous batching” system. This means it can handle different requests together, filling up the GPU so it works faster. There are two main steps: the prefill phase (where it processes all your input tokens at once) and the decode phase (where it generates new tokens one by one). Special memory blocks on the GPU called KV caches help the system remember important information for each request, so it doesn’t redo work.

When it’s time to run the model, vLLM groups all tokens from the batch into big tensors and sends them through all the model layers on the GPU. The model computes the next token for each request based on these tensors. Once the new tokens are ready, they are sent back through AsyncLLM, changed back from tokens into text, and finally streamed back to you.

This whole process lets vLLM handle many users at once, making it good for big AI services. Each part of the system has a special job, and together they make serving LLMs much more efficient.

From the comments, the author says writing the article helped them understand vLLM better and is open to questions. One reader thanks the author but is confused about the “prefill” phase—specifically, why all prompt tokens can be processed at once and why this is faster than generating new tokens. They ask if watching a long video on transformers would help them understand. The author is friendly and encourages more discussion.

The discussion shows that some readers find vLLM’s batching logic tricky to understand, especially how the prefill phase works. There’s interest in learning more about the technical side, but also a wish for clearer explanations. Some people say the article is helpful for understanding modern LLM serving, while others want more background before the technical details. The comments are welcoming, and the author is ready to help readers learn more.

---

## We ran a Unix-like OS Xv6 on our home-built CPU with a home-built C compiler

- 原文链接: [We ran a Unix-like OS Xv6 on our home-built CPU with a home-built C compiler](https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44404164)

This article tells the story of a student project where a group built their own CPU, created a C compiler for it, and then made the Unix-like operating system Xv6 run on it. The project was part of a university course at the University of Tokyo, where groups learn by building everything from scratch, including CPU hardware on an FPGA and software tools.

The team first designed their own CPU using a custom instruction set. They wrote the logic in a hardware description language, then turned it into a real chip using synthesis tools. Waiting for these tools to work could take 30 minutes or more, so the team often played video games during this time. Instead of using an existing compiler like GCC, they decided to make their own C89 compiler, called Ucc, because it seemed more fun and one member already had a small prototype.

Porting Xv6 to their CPU was difficult. Xv6 is made for x86, expects certain data sizes, and uses the stack in ways that did not match their setup. The group had to figure out which CPU features were needed for an OS, like interrupts and virtual memory. They learned a lot by first porting Xv6 to the MIPS architecture, which helped them understand low-level OS needs.

As they worked, they improved their CPU, called GAIA, and their simulator, adding support for debugging and virtual memory. A major bug they found was due to how their CPU used virtual addresses for cache indexing, which led to problems when two addresses pointed to the same physical memory. They fixed this with a method called "page coloring."

After much debugging and changing the compiler to match more standard data sizes, they finally got Xv6 to run on their simulator and later on real hardware. They added games like Minesweeper and 2048 to make it fun. For better input handling, they even added new system calls not present in the original Xv6.

The project finished with the team running the required ray-tracing program on Xv6, on their own CPU. They shared their work so others could try it in a web browser. Later student groups kept pushing the limits, running their own OS or even Linux on custom CPUs.

In the comments, many people share similar stories from university. One person talked about porting MINIX3 to the Raspberry Pi, which was very hard due to poor emulation and documentation. They had to debug using only serial output, which was slow and painful. Others agreed that working with hardware can be very hard, especially without good tools like JTAG or GDB.

Some users remembered their own projects, like building simple CPUs but not going as far as running an OS and compiler. They recommended games and courses like Turing Complete or nand2tetris for learning about CPU and OS building in a more guided way.

Commenters pointed out that when you build everything from hardware up, every bug is your own, and you can’t blame anyone else. Debugging is much harder, and sometimes you only have blinking LEDs or GPIO pins for output. Still, most people agreed these projects are fun and teach a lot, even if they are very challenging and time-consuming. Many admired the team for finishing such a big and detailed project.

---

## BusyBeaver(6) Is Quite Large

- 原文链接: [BusyBeaver(6) Is Quite Large](https://scottaaronson.blog/?p=8972)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44406171)

The article talks about new discoveries about the Busy Beaver function, especially BB(6), which is the maximum steps a 6-state Turing machine can take before stopping. In the past, people thought BB(6) was already very big, but new results show it is much bigger—so big that even trying to imagine it is almost impossible.

The Busy Beaver function, BB(n), grows faster than any normal math function. For 5 states, BB(5) is about 47 million, but for 6 states, the new lower bound is now a number like 2 pentated to 5, or 2 tetrated to 2 tetrated to 2 tetrated to 9. These are numbers so big that even if you tried to write them out, you could never do it—not in the universe, not even in all possible universes. The article explains how these numbers are found: by building clever Turing machines that do things like repeating Collatz-like steps or using exponentiation inside their loops. Each new result comes from finding a machine that runs even longer before stopping. Some people now think BB(7) could be even bigger, maybe even bigger than famous huge numbers like Graham’s number.

The author also talks about the limits of math. At some point, the value of BB(n) becomes independent of the normal set theory axioms (ZFC). This means that math itself cannot prove what BB(n) is for some large n, even though in theory there is a right answer. For example, for BB(643), no proof inside ZFC can say exactly what number it is. Now, because of these new huge numbers for BB(6), people wonder if this limit happens much earlier—maybe even for BB(7) or BB(8).

In the Hacker News comments, many people are amazed at how fast BB(n) grows, and how these numbers go from something humans can imagine to something far beyond. Some debate if BB(7) is bigger than Graham’s number. A few think it probably is, since BB(n) quickly outgrows any number you can define with normal math operations. Others are surprised that a simple Turing machine with just a few states can lead to questions that math cannot answer. There is talk about how proving BB(n) for large n is not about the number itself, but about what math can show.

Some comments explain that BB(n) is always a real number, but for large n, no proof system like ZFC can prove exactly what it is. Others point out that even if you had the answer, you could not check it without even stronger math. There are debates about philosophy—what counts as a number, and if these numbers really "exist" or are just ideas. People also discuss how these huge numbers make them rethink what math and computation can do, and how limits like the halting problem and Gödel’s incompleteness theorems show up in real questions about small Turing machines. Some find it strange that with very simple rules, you can get problems that are impossible for math to fully solve. Overall, the comments show a mix of excitement, confusion, and deep thought about the limits of mathematics and computation.

---

## Addictions Are Being Engineered

- 原文链接: [Addictions Are Being Engineered](https://masonyarbrough.substack.com/p/engineered-addictions)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44405057)

The article talks about how many social media apps start with good ideas but end up making people addicted. The writer tried to build a new social platform, hoping it would help people connect in real life, but it failed. He realized the main problem is not just one app—it’s how all social media is designed and funded. At first, these apps seem nice and focus on real connections and being authentic. But after they get money from investors, they must grow fast. Growth becomes more important than people’s well-being.

To keep growing, companies use tricks to keep people on the app longer. They use algorithms to show things that make you feel strong emotions, like anger or envy, because that keeps you scrolling. The more time you spend, the more money they make from ads. This makes people addicted, not by accident, but by design. Even if the creators start with good intentions, the system pushes them to focus on engagement and money. The article says that it’s very hard for individual people to fight this; the problem is too big for things like screen time limits or digital detox.

The writer suggests some possible solutions: fund social platforms like public services instead of with ads, make algorithms more open, or measure user happiness instead of just user numbers. He thinks maybe the answer is to make social media less important, and help people connect offline more. The real problem is the system that rewards addiction and attention, not the people using or building the apps.

In the comments, many people agree that outside investment, like venture capital, is a big reason why social platforms change for the worse. Some say that once a company takes investor money, the real “product” is the company itself, not the app or the users. Others argue that companies are forced to make decisions that help investors, even if it’s not best for users. But a few people push back, saying there is no strict law that companies must always put profit first—sometimes it’s just the culture or incentives.

Some think that the problem goes deeper than just funding. They point out that people often don’t want to pay for social networks, making ads the only way to make money. Others believe that human nature is the real problem—people want exciting, emotional content, and that’s why these platforms become addictive. A few suggest that small, paid, or non-profit social networks could work, but building a big community is very hard without lots of money. There are also calls for more regulation, like how we control gambling or tobacco, but others say it’s difficult to regulate something as complex as social media algorithms.

Some commenters share ideas for better models, like worker-owned companies, co-ops, or open-source networks, but admit these are hard to scale. Others think we should just spend more time offline and stop building so many social networks. There is debate about whether addiction is really the right word for what is happening, with some saying it’s just strong habit, not true addiction. Overall, the comments show people want change, but they don’t agree on what will fix the problem or if it can be fixed at all.

---

## Show HN: Vet – A tool for safely running remote shell scripts

- 原文链接: [Show HN: Vet – A tool for safely running remote shell scripts](https://getvet.sh)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44407661)

This article talks about a tool called “vet” that helps you run remote shell scripts more safely. Many people use commands like `curl ... | bash` to install software, but this can be risky if the script is bad or changes without you knowing.

Vet tries to make this process safer. First, it downloads the script to a safe place instead of running it right away. It then checks if the script has changed since you last ran it. Vet also uses a tool called ShellCheck to look for mistakes or signs of bad code in the script. Before doing anything, it asks you if you really want to run the script. You can use vet by typing `vet https://example.com/install.sh` in your terminal. To install vet itself, you use a curl command, just like other tools.

In the comments, one person asks for a demo or video to show how vet works. They want to know if it uses a pager or editor, and how it shows problems found by ShellCheck. Another person says that most remote scripts are installers, and asks how you can really know if the software you install is safe. They point out that vet only checks the installer script, not the actual program it downloads, which could also be unsafe. Someone else agrees and says vet is a good step, but not a full solution to the bigger problem.

A few people say they like the idea. One person thinks it would be cool if vet could use AI to find more security problems, but the creator of vet replies that using AI can be risky because it may send your code to outside servers. That’s why vet uses ShellCheck, which runs offline and gives the same result every time. The creator also says they hope future AI can be used safely on your own computer. Another user says they sometimes trust install scripts just because everyone else does, and that vet helps make this a little safer. Overall, people think vet is a useful tool, but it can’t solve all security problems on its own.

---

## Unheard works by Erik Satie to premiere 100 years after his death

- 原文链接: [Unheard works by Erik Satie to premiere 100 years after his death](https://www.theguardian.com/music/2025/jun/26/unheard-works-by-erik-satie-to-premiere-100-years-after-his-death)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44403594)

Some never-heard pieces by French composer Erik Satie will be played for the first time, 100 years after he died. These new works give us a fresh look at Satie, who is best known for simple, dreamy piano music like the Gymnopédies.

The article talks about how these music pieces were found and why they matter. Satie wrote many strange and playful pieces. Some of his music, like "Vexations," was meant to be played 840 times in a row, showing his odd sense of humor. Satie also liked to poke fun at music rules from his time, breaking them on purpose. He often made fun of serious composers and boring music lessons. 

Satie’s music is used a lot in movies, ads, and even video games, though many people do not know his name. His style is simple, calm, and easy to remember, which is why his music is still popular today. The new pieces are more traditional than his famous works, but they help us see the bigger picture of his music. Some fans say Satie’s tunes are great for relaxing or focusing. Others point out that different recordings and performers can change how his music feels—a slow version might sound very different from a fast one.

People in the comments talk about Satie’s personality and music. Some wonder if he is famous for being odd or for his songs; most agree it’s the music that lasts. Many mention that Satie’s music is everywhere, even if people don’t know it’s his. Some think YouTube helped make him popular again, while others say his music was well-known long before the internet. A few people share personal stories—how they first heard Satie in games, movies, or childhood.

There are also comments about how old music can still feel fresh and important. Some say only a few old pieces become super popular, and Satie is lucky to have several hits. One person recommends trying different versions of Satie’s music, since every performer adds their own style. There’s a mention of “furniture music,” a term Satie used for background music. Finally, people talk about how learning to play Satie’s music can be both easy and hard, but always rewarding.

---

