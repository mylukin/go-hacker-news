Hello everyone, this is the 2026-01-29 episode of Hacker News Daily Podcast. Today, we have a rich mix of stories on AI, software tools, space tech, open source, and even new hope for cancer treatment. Let’s dive in.

We start with a big update from OpenAI. The company says it will stop offering several older ChatGPT models—including GPT-4o, GPT-4.1, GPT-4.1 mini, and o4-mini—starting February 13, 2026. This follows earlier plans to retire the GPT-5 Instant and Thinking models too. For now, API users are not affected.

OpenAI explained that after first removing GPT-4o, they brought it back because some users needed more time to switch, and many liked GPT-4o’s friendly and warm style. User feedback helped improve new models like GPT-5.1 and GPT-5.2, which are now better at creative tasks and more customizable. Users can now choose different styles and tones, and control how ChatGPT responds—like making it more friendly or enthusiastic. OpenAI says most people now use GPT-5.2, and only a tiny 0.1% still pick GPT-4o each day. They are also working to make ChatGPT less strict and more creative, and have added features like age prediction to keep young users safe. OpenAI promises to be clear about changes, but says retiring old models is hard. Still, it helps them focus on the most popular ones.

The Hacker News community is split. Some users are frustrated about losing models they prefer, especially GPT-4o’s style. Others think it makes sense to focus on newer, better models. Some worry about losing choices and breaking workflows. There are questions about whether new models are really better at creativity and warmth, or just different. Trust and transparency are big topics—people want to know why models are retired and how feedback is used. Developers point out that switching models can break tools and integrations, and some feel OpenAI moves too fast without giving users enough time. On the other hand, some like the new customization options and feel OpenAI is listening to feedback. In summary, some see progress, while others want more stability and choice.

Next, Google has launched Project Genie, a new tool for making and exploring interactive worlds, now open to AI Ultra subscribers in the US. Project Genie comes from Google DeepMind and lets you build, explore, and remix digital environments using AI. You can sketch worlds with text or images, create your own character, and choose how to move—walking or flying. Genie 3, Google’s world model, generates the path ahead in real time as you explore, so the world changes and grows with you. You can remix other people’s worlds, download videos of your adventures, and use the “World Sketching” feature with Nano Banana Pro for more control over the look and camera view.

The tool is early and has limits: the worlds are not always realistic, character control can be slow, and some features are missing. Google plans to add more and improve realism, and hopes to expand access later.

Hacker News comments show excitement about new possibilities for game development and creative storytelling. Some think this could help small teams or solo creators make rich games or stories. Others are more skeptical, saying the worlds are simple for now and not very realistic. There are worries about the paywall, ownership of AI-generated worlds, and how much control users really have. Some compare Project Genie to older world builder tools, asking if it will last. Privacy is also a concern, as users wonder what Google will do with the data. Some hope Google will open up the tech for outside developers, while others worry it will stay locked inside Google’s ecosystem.

In gaming news, a new project called PS2Recomp is making it possible to run PlayStation 2 games natively on modern PCs, instead of using emulators. PS2Recomp recompiles PS2 games so they can work directly on Windows or Linux. The PS2 had special hardware, and most emulators try to copy this, which needs strong computers and can have bugs. PS2Recomp takes a different path: it converts the PS2 game code into something your PC can run, for better speed and fewer problems.

Right now, it’s not simple to use—each game must be processed with the tool first. But once a game is recompiled, you can enjoy higher resolutions, better frame rates, and HD texture packs. It also lets fans make remasters or fix old problems.

Other consoles have seen similar projects, like native PC versions of Mario 64 and Zelda, even adding ray tracing and new controls. If PS2Recomp succeeds, we may see classic games like Metal Gear Solid 2, Gran Turismo, or God of War running natively on PCs with new features.

Many commenters are amazed by the technical challenge. Some think this is the best way to keep old games alive, since original hardware is rare and emulators are not perfect. Others point out that recompiling every game is a big job, and wonder how long it will take before many games are supported. There are worries about legal issues if recompiled games are shared. Some are excited about mods and upgrades. Many remember the struggles of emulating PS2 games in the past and hope this will make things easier. Overall, people are excited but know this is early work, and look forward to seeing which games get support first.

On AI benchmarks, a new article shares daily results for Claude Code Opus 4.5, a tool that helps with software engineering tasks. The team tests how well Claude solves 50 real programming problems each day, using a trusted task set and always the latest version. The daily pass rate is compared to a baseline of 58%. One day, Claude passed 50%, with a 7-day average of 53% and a 30-day average of 54%. The tracker uses statistics to decide if drops are normal or a real problem. Over the last month, a real drop of about 4% was found—big enough to matter.

Commenters are glad to see someone checking AI tool quality in a clear, open way. Some ask if 50 daily tests are enough, or if more would help. Others worry about “degradation” after updates, so they value outside tracking. Some want to know if other models, like Codex, are also tracked. There are technical comments on the statistics and requests for better alerts or ways to see trends. Most agree that regular, public benchmarks are very useful for the AI community.

Switching to health news, a new study shows that using three drugs together can stop pancreatic cancer tumors from growing and stop the cancer from coming back, at least in mice. Pancreatic cancer is very hard to treat. The scientists targeted three pathways: RAF1, EGFR family receptors, and STAT3, using drugs RMC-6236, Afatinib, and SD36. In mice with human-like tumors, the combo made tumors shrink and not come back for over 200 days, with no strong side effects. The results were similar on human cancer tissue grown in mice.

One big problem with cancer drugs is that tumors often become resistant. This combo seems to stop that, at least in mice. The researchers hope this leads to new trials for people.

Commenters are excited, saying new treatments for pancreatic cancer are badly needed. Some note that results in mice do not always happen in humans, so more testing is needed. Others ask about cost and side effects, and discuss the need for safety. Personal stories show hope for faster progress, but some explain how cancer cells can be tricky and find new ways to survive. There is talk about the long road to drug approval, and hopes that this approach could help other tough cancers too. Many stress the need for open data and more research, seeing this as a good step, but not a cure yet.

Now, let’s talk about making AI coding agents smarter with up-to-date Next.js docs. The team at Vercel tried two ways to help AI agents use new Next.js 16 APIs that the models did not already know. First, they used "skills," special tools agents can call for extra help. Second, they put a small, compressed docs index in a file called AGENTS.md, which always stays in the agent’s context.

Skills did not work well by default. The agent often did not use them unless told directly. Even with clear instructions, the agent used the skill about 95% of the time and reached a 79% pass rate. But the AGENTS.md approach, with just an 8KB compressed index, got a perfect 100% pass rate, because the agent always had the docs nearby.

Skill instructions were fragile—small wording changes led to big changes in agent behavior. By contrast, the AGENTS.md file meant the agent always had the docs and could use them at any time. They solved the “context bloat” problem by compressing the docs index. For framework authors, the article suggests using AGENTS.md for general knowledge, as it works better right now. Skills are still useful for special, action-based tasks.

Many commenters are surprised the simpler AGENTS.md approach works better than skills. Some worry about context limits and if this method will work for bigger projects. A few think skills will improve as models get better. Some like compressing info to fit more into the agent’s memory. Some suggest mixing both methods for now, but most agree AGENTS.md is a good fix today and like the data-driven approach.

Next up, AgentMail is a new tool that lets software agents have their own email inboxes, like real people. It’s part of the Y Combinator Summer 2025 group. The idea is to help AI agents use email like a human—reading, sending, and replying to emails. AgentMail gives each agent a real email address, and developers can connect inboxes to their software using AgentMail’s API. It supports IMAP and SMTP, handles spam, security, and privacy, and has tools for parsing emails and attachments. The goal is to help agents join human email conversations and automate tasks in sales, support, and business operations.

In the comments, some are excited about letting agents join email threads, seeing many uses in customer service and automation. Others worry about trust, security, and how AgentMail stops spam or mistakes. Developers want details about pricing and scaling, and some wonder about handling email’s many edge cases. Privacy is a concern if agents read sensitive emails, and some worry this could lead to more email noise. Still, others think it could free up human time for better work.

Now to a new benchmark called OTelBench, which tests if AI models can add OpenTelemetry tracing to code—a basic task for SREs. The team tried 14 top AI models across 11 programming languages, asking them to instrument microservices for tracing. Even the best model, Claude Opus 4.5, only got 29% of tasks right. Many models failed to understand the business context and often made mistakes in the traces.

C++ tasks had the highest success, likely because they were simpler. Go had more tests and lower rates. Java, Swift, and Ruby did poorly. The cost and speed to run these models varied, with cheaper models sometimes matching more expensive ones.

OpenTelemetry is hard for AI because it needs understanding of many languages and real business flows, and there’s not much public training data for these tasks. The main takeaway: AI is still far from replacing human SREs for tracing jobs. But on some tasks, models did much better, so there is hope.

Commenters were not surprised by the low scores, pointing out that tracing is hard, even for humans. Some said the benchmark is useful and shows where AI tools need to improve. Others said the lack of training data is a big reason models struggle, and some think the cost is too high for little gain. Still, a few are hopeful that with better data and feedback, AI might get much better at this work in the next few years.

Let’s move to open source. Flameshot is a free and open source screenshot tool for Linux, Windows, and Mac. It lets you take screenshots, edit them right away, and upload them to Imgur. You can draw shapes, add arrows, blur parts, write text, and more. Flameshot can be started from the system tray, terminal, or with keyboard shortcuts. It supports many commands, like delayed screenshots, saving to folders, copying to the clipboard, or capturing one monitor only. There’s a special version for Windows with better command-line output, and you can set up shortcuts on most desktops. Flameshot works best with desktops that support D-Bus and have a tray, but sometimes you need extra extensions, especially on Gnome. Settings can be changed in a config file, and you can copy settings between Linux and Windows. Installation is easy, with packages for most platforms, and building from source is simple.

In the comments, many say they love Flameshot for its editing tools and quick sharing. Some say it’s their favorite screenshot tool, especially on Linux. Others like that it does not collect data or show ads. Some had trouble with Wayland or with the tray icon, and a few want a simpler interface or better HiDPI support. Some still prefer other tools, but admit Flameshot is strong for quick edits. Uploading to Imgur is very useful for sharing, and some like that it works well with scripts. Many are happy it’s open source and lightweight, and gave tips on setting up shortcuts or shared how they use it in their workflow.

Our final story is about space and weather. Europe’s new weather satellite, Meteosat Third Generation-Sounder (MTG-S), has sent back its first pictures from space. The satellite sits 36,000 kilometers above Earth and uses an Infrared Sounder to measure temperature and humidity. The first images show warm and cold areas, with dark red for high temperatures and blue for cooler spots, usually cloud tops. Another image shows humidity, with blue for more water vapor and red for dry air.

The satellite can also track big events like volcano eruptions, showing how ash clouds move. MTG-S gives new data every 30 minutes, so weather experts can watch storms as they happen. It works with another satellite, MTG-Imager, to give even more details, like cloud shapes and lightning.

What makes MTG-S special is its hyperspectral instrument, which can look at light in many tiny slices to make very detailed maps of the air—helping predict storms and dangerous weather faster and better. It is the first European satellite to have this tech in geostationary orbit.

The mission took 15 years to build, a joint project of ESA, Eumetsat, and many companies, and also carries the Sentinel-4 mission to look for air pollution.

Many commenters are excited about the new technology and clear images. Some say it’s great that Europe now has its own advanced weather satellite. Others talk about how it will help warn people about storms and floods earlier. There are technical questions about sensors and how data is shared, and some hope the data will be open for researchers. There are worries about space junk, but most agree the benefits for weather and safety are worth it. Many thank the teams for their hard work, saying this is a proud moment for European science.

That’s all for today’s episode. Thanks for listening to Hacker News Daily Podcast. We’ll be back tomorrow with more top stories and community highlights.