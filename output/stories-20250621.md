# Hacker News 故事摘要 - 2025-06-21

## 今日概述

Today’s top Hacker News stories focus on privacy tools for web browsing, new ways to avoid online distractions, and the hardware behind Google’s AI. There are also stories about creative programming languages, the history of stainless steel, tools to help with Makefiles, and hidden features in git. Other highlights include startup experiments, new writing software, and an open-source film projector. If you like privacy, tech history, or creative tools, today’s stories have something for you.

---

## LibRedirect – Redirects popular sites to alternative privacy-friendly frontends

- 原文链接: [LibRedirect – Redirects popular sites to alternative privacy-friendly frontends](https://libredirect.github.io)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44344246)

LibRedirect is a browser extension that sends you from popular websites like YouTube, Twitter, Reddit, and Instagram to privacy-friendly alternative frontends. The goal is to help users avoid ads, heavy web pages, and tracking by big companies. Instead of YouTube, you might go to sites like Invidious or Piped; for Twitter, you could use Nitter; for Reddit, you get Libreddit or Teddit. There are alternatives listed for over 50 well-known sites, covering music, maps, search, and more. This lets you read, watch, or search without as many ads, trackers, or scripts. The extension is easy to use and tries to make web browsing lighter and more private.

Many people like the idea because it saves bandwidth and blocks ads. Some users say they don’t want to load giant web pages just to see a tweet or watch a short video. Others think it’s great, but note a problem: many of these alternative sites (called "instances") go offline often or are slow. Some want the extension to switch between good working instances automatically, rather than picking only one that might die.

A few commenters are worried about privacy and security. They say that when you use these alternatives, your data might end up with random strangers instead of big companies. For example, using FreeTube or Piped means your history could be seen by whoever runs the instance, or by services like Cloudflare. Some people are okay with this trade-off if it means no ads; others think it’s too risky.

There’s also debate about using VPNs. Some say using a VPN with YouTube is safer, but others point out that this doesn’t really hide you and could add risks, like fingerprinting or giving data to the VPN company. Some people suggest using simple user scripts instead of big extensions, but others argue that’s too hard for most people and only works for one site at a time.

A few users want the opposite: a way to go from these lightweight sites back to the official, full-featured versions. There’s also talk about browser makers possibly blocking these types of tools in the future, especially as companies fight back against privacy workarounds.

Some users mention another tool, Farside, which picks working instances automatically, but this means you have to trust Farside itself not to track you. In the end, people like the idea of more privacy and less bloat, but there are mixed feelings about trust, ease of use, and how long these solutions will keep working.

---

## Using an $8 smart outlet to avoid brainrot

- 原文链接: [Using an $8 smart outlet to avoid brainrot](https://www.neilchen.co/blog/kasa)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44346450)

This article is about using a cheap $8 smart outlet to help stop wasting time on distracting websites. The author wrote a script that checks if the smart plug is on or off, using its WiFi and API features.

When the smart plug is turned on, the script blocks certain websites by changing the computer’s `/etc/hosts` file. The blocklist includes Twitter, Instagram, YouTube, and Reddit. If the user wants to visit those sites, they must get up and turn off the plug, which is ideally placed far away. This extra physical step makes it harder to visit these sites without thinking. It helps the user break the habit of mindlessly browsing. The author notes that editing the `/etc/hosts` file by hand is still possible, but the physical switch adds helpful friction. The smart plug also has a manual switch for easy toggling. The setup is simple and uses common technology available to most people. The script is shared online for others to use. This method tries to solve the problem of digital distractions in a low-cost, creative way.

People in the comments think the idea is clever and new. One person said they never thought of using a smart plug as a way to trigger scripts. They liked the idea and want to try it for other uses too. Some wonder if the system will work long-term, or if users will just go back to editing the hosts file. There is hope that the extra step will be enough to keep people from getting distracted. Others think about using the idea for different projects, showing that the approach can be flexible. Some see it as a fun experiment in self-control. Overall, readers think it is a smart, simple hack for a common problem.

---

## TPU Deep Dive

- 原文链接: [TPU Deep Dive](https://henryhmko.github.io/posts/tpu/tpu.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44342977)

This article is about Google’s TPU chips—special hardware made for AI tasks—and how they are different from GPUs. The writer explains that TPUs are designed for high speed and energy efficiency, mostly by using special hardware (like systolic arrays) and smart software (the XLA compiler).

First, TPUs were created when Google saw that their growing AI services (like voice search) would need much more computing power than CPUs or GPUs could give. Now, TPUs run most of Google’s big AI models and services. A single TPU chip, like TPUv4, has two main computing parts called TensorCores, plus a lot of on-chip memory—much more than what GPUs have. The main parts inside are the Matrix Multiply Unit (MXU) for fast math, the Vector Unit (VPU) for simpler tasks, and different memory buffers for moving data.

TPUs have fewer cores than GPUs, but they can still do more work, because their design is focused on doing lots of matrix math at once. This is possible thanks to systolic arrays: grids of small computing elements that pass data to each other, working perfectly for dense matrix operations like those in neural networks. The downside is that they don’t work as well if your data is sparse.

Another big difference is how TPUs handle memory. Unlike GPUs, which use caches to deal with random memory access, TPUs avoid caches and use “ahead-of-time” compiled programs. The XLA compiler decides all memory moves before running, which saves energy and makes things fast—but it also means less flexibility if your program changes a lot.

Scaling up, TPUs are built to connect together very well. You can group them into trays, racks, pods, and even bigger clusters. Special connections (like ICI and OCS) let you join many chips in 3D shapes, making communication fast and flexible. You can also choose how to group the chips for your job, which can improve speed for different types of parallel computing. These systems are designed so that if some chips fail, the rest keep working. Google’s compiler handles all the complicated details for you, so running models on many chips just needs a few code changes.

The article also shows real pictures of TPU hardware to help readers understand how these chips, boards, and racks look in real life.

In the comments, people talk about why Google doesn’t sell TPUs directly. Some say renting them makes more money and keeps Google ahead of rivals. Others note that selling hardware would need extra support and could help competitors catch up. There’s also a discussion about company value—Google’s stock price doesn’t fully reflect the value of its TPUs or AI work, and market cap isn’t always logical. Some point out that Broadcom helps build TPUs and should get some credit too.

Technical readers ask which algorithms work well on TPUs’ systolic arrays. Most agree that anything based on big matrix multiplication is a good fit, including some advanced math methods. Others share resources, like JAX’s scaling book, to help learn more.

Some comments dive into how TPUs and GPUs handle deterministic results—TPUs can be more predictable in timing and output, but rely more on a smart compiler, while GPUs are more flexible but less predictable. A few people wonder how the author learned so much about TPUs without working at Google; others explain that Google’s research cloud lets outsiders experiment with TPUs.

Overall, readers appreciate the article’s details and discuss both business and technical sides of TPUs, from hardware design to real-life usage and company strategy.

---

## Sound As Pure Form: Music Language Inspired by Supercollider, APL, and Forth

- 原文链接: [Sound As Pure Form: Music Language Inspired by Supercollider, APL, and Forth](https://github.com/lfnoise/sapf)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44342731)

The article introduces Sapf, a new programming language for making and transforming sound, inspired by Forth, APL, and Supercollider. Sapf is designed to let you write short code that can create complex audio by using lazy sequences, auto-mapping, and a simple stack-based style.

Sapf uses postfix (concatenative) syntax, where you write commands left to right, and each word takes its arguments from a stack. This style comes from Forth and Joy, and it means you don’t need things like parentheses or commas. The language is functional, and most data types are immutable, making it easy to use in parallel or threaded programs. Sapf takes ideas from APL, especially how it handles arrays: you can apply functions to entire lists at once, and use special operators for mapping, scanning, and reducing. For audio, Sapf treats sound as infinite sequences, so you can work with streams of data lazily. The language comes with only a few data types—numbers, strings, lists, forms (dictionaries), functions, and refs (the only mutable type). There are helpful features like auto-mapping, which means when you give a list to a function, it can process all items at once. The “each” operator lets you map functions deeper inside nested lists. The language also supports creating and transforming sound signals, with simple examples for things like sine waves and analog effects. Comments, numbers (with suffixes like k for kilo), strings, and variable binding are all simple and clear. You can also define functions easily, and the language provides ways to work with forms (like records or objects), and nested data. Lastly, the article provides command-line setup instructions and mentions Sapf’s focus on being concise, expressive, and fun for live audio programming.

In the comments, many people are excited about Sapf’s approach, especially how it mixes APL’s array features with the stack-based Forth style. Some mention that similar audio languages exist, like Sporth or TidalCycles, and share links to other projects. One commenter points out that Sapf’s code examples actually sound good, which is rare for early-stage music languages. There’s curiosity about how to run Sapf on Linux, since it’s built for macOS and uses Apple-specific code, which could be a problem for some users. Several people discuss the challenge of switching from SuperCollider, which is powerful and well-supported, to a new language like Sapf, and wonder if there are bridges or translators between them. Others share their experience with audio programming on Linux, suggesting tools like KXStudio or Pipewire to help with sound setup. Some users have had trouble running other music languages, like SonicPi or SuperCollider, under Ubuntu, while others say they work fine, hinting that audio configs can be tricky. A few commenters talk about how digital tools can make “analog” sounds, offering tips on using harmonics, resonant filters, sub-oscillators, and detuning. In general, the community finds Sapf’s design “cool” and hopes for more cross-pollination between array languages (like APL) and stack-based languages (like Forth), suggesting that these two groups could create even more powerful tools together.

---

## Harry Brearley, the creator of stainless steel (2016)

- 原文链接: [Harry Brearley, the creator of stainless steel (2016)](https://nautil.us/the-father-of-modern-metal-235939/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44346529)

This article is about Harry Brearley, a poor boy from Sheffield, England, who became the creator of stainless steel. The story follows his journey from a curious child in steel factories to a well-known metallurgist and inventor.

Brearley was born in 1871 into a poor family, living in a small, crowded house. As a child, he was very curious and liked to watch workers in different jobs, especially in steel factories. He started working young, doing hard, low-paid jobs, but was not happy until he found work in a steel laboratory, cleaning bottles. There, the chief chemist James Taylor noticed Harry’s interest and began teaching him math, science, and practical skills. Harry learned quickly, became a lab assistant, and developed a love for steel and learning.

Brearley read many books and worked hard to understand metals. He became skilled in analyzing steel and solving problems. He worked with his brother Arthur and other experts, writing books and making new discoveries. At one point, he managed a steel factory in Russia during the revolution, where he learned to innovate and work with new people.

Later, working at Brown-Firth in Sheffield, Brearley was asked to solve problems with gun barrels. He experimented with adding chromium to steel. In 1913, he noticed one new steel didn’t rust, even after being left in water overnight. He realized this “stainless steel” didn’t corrode like normal steel. At first, his bosses and local knife makers didn’t see the value, saying the metal was hard to work with and not good for cutlery. But Brearley kept pushing, finally convincing a cutlery manager to try it. The new knives stayed shiny and rust-free.

Eventually, stainless steel became popular for many uses—cutlery, engine parts, medical tools—changing industries. Even though others had made similar alloys before, Brearley’s determination and focus made him known as the father of stainless steel. He faced disagreements with his employers over credit for the invention and had to fight for recognition. Brearley’s story shows how hard work, curiosity, and not giving up can lead to big discoveries.

In the comments, one user focused on a small detail: the algebra book Brearley used as a boy. They identified it as “Todhunter’s Algebra,” and shared links to learn more about it, pointing out you can read the book online for free. This shows how even small parts of a story can catch readers’ interest—sometimes the details matter as much as the big events.

The comment section did not debate the article’s main story but instead added to the background, providing extra reading for curious people. Some readers might enjoy learning about the education tools of the time, while others might simply be impressed by Brearley’s journey from poverty to important inventor. By sharing links and facts, the commenters help the story connect to broader history and encourage others to keep learning, just as Brearley did.

---

## Mbake – A Makefile formatter and linter, that only took 50 years

- 原文链接: [Mbake – A Makefile formatter and linter, that only took 50 years](https://github.com/EbodShojaei/bake)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44323905)

Mbake is a new tool for formatting and checking Makefiles, which are files used to automate building software. The tool gives rules to make Makefiles look clean and work better, and it can even suggest or add missing `.PHONY` lines, which help avoid build errors.

Mbake works by fixing spacing, tabs, and line breaks. It can join lines that are split, and remove extra spaces at the ends of lines. For `.PHONY` targets, mbake can find which rules do not create files and should be marked as phony, then add or group these lines automatically if you want. You can set up your own rules in a config file. Mbake can be used from the command line or as a VSCode extension, and you can run it in CI/CD systems to check Makefiles are formatted right before merging code. The tool is written in Python and is easy to install with pip. It also supports plugins, so you can add your own formatting rules.

Some people in the comments say there were tools like this in the 1990s, so the idea is not fully new. One user asks if you can ignore rules inline, but it seems this is not in the README yet. Some do not like having `.PHONY` lines grouped together, preferring them near each rule. There are also people who do not like Make itself, saying using only environment variables is a bad experience. Others reply that Make is simple, found everywhere, and lets you manage builds in a clear way. Some users point out that Make is easy to use across many systems, but not always on Windows, where it can be hard to get working. 

There is talk about performance and language choice. Some wish the tool was not in Python, saying it is slow for large files, and suggest Perl or Java would be faster. Others reply that Python is common and easy for developers, so it makes sense for the author to use it. Some people joke about language debates, saying it is easy to argue but the real work is writing the tool. One person says you do not have to write Make commands by hand, as editors can run them for you, and Make is not all about environment variables. Some like Make because you can just run `make run` on any project, and it works the same on any machine. Others prefer simple shell scripts, especially on systems without internet or package managers. In the end, most agree tools like mbake are helpful, and it is good to have more options for keeping Makefiles clean and correct.

---

## Git Notes: Git's coolest, most unloved­ feature (2022)

- 原文链接: [Git Notes: Git's coolest, most unloved­ feature (2022)](https://tylercipriani.com/blog/2022/11/19/git-notes-gits-coolest-most-unloved-feature/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44345334)

This article talks about git notes, a hidden feature in git that lets you attach extra information to any commit, file, or folder in your repository. The main point is that git notes are very powerful, but almost nobody uses them because they are hard to find and not very easy to use.

With git notes, you can add comments or metadata to commits without changing the commit itself. For example, you can record who reviewed the code, what tests were run, or other important details—helpful if you want to keep track of things after a commit is already part of history. The article shows how the main git project uses notes to link commits to email discussions. Other people use notes to track time spent, testing information, or even do code reviews.

There are tools, like Gerrit's reviewnotes plugin and Google’s git-appraise, that use git notes to save reviews and test results right in the git repo. This means you can see everything offline, using just git, without needing to visit a website. You can even run distributed code review, and all the data stays with your code history.

But git notes have problems. The interface is confusing, and the feature is hidden in git’s commands. Most UI tools, like GitHub, do not show git notes, and even removed support for them years ago. If you want to use notes on files or folders (not just commits), it gets much harder. Even the article’s author says they forget git notes exist.

The article ends by saying git notes could help make git more independent from platforms like GitHub. Instead of keeping all project history and reviews locked in one website, git notes let you share everything with the code itself.

In the comments, some readers say they have used git for years without knowing about git notes. Others think git notes are cool, but doubt big companies like GitHub will ever support them more. They point out that companies make money by keeping useful features (like code review and discussions) inside their own websites, not in the open git history. Some people defend GitHub, saying it offers a good service and lets users download their data, but agree that business reasons make features like git notes less likely to become popular. Overall, readers seem interested and surprised by this little-known part of git, but also see why it stays hidden.

---

## P-Hacking in Startups

- 原文链接: [P-Hacking in Startups](https://briefer.cloud/blog/posts/p-hacking/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44308328)

The article talks about how startups often fall into the trap of “p-hacking” when running experiments, like A/B tests, to improve their products. It explains that the need to move fast can lead to wrong conclusions from data, making teams believe they have found improvements when they really haven’t.

First, the article shows that when you test several versions of something (like website layouts), the chance of a false positive (thinking something works when it doesn’t) gets much higher if you don’t adjust your statistics. For example, if you test four layouts and use the normal p-value cutoff (0.05), your real risk of a false positive jumps to almost 1 in 5. The article says you should use methods like the Bonferroni correction to lower this risk, even if it makes results harder to find.

Second, it warns against looking for “some win” in the data after you run the test. For example, if changing the layout doesn’t improve signups, but you find retention goes up a bit, it’s tempting to claim victory. But checking lots of metrics increases the chance of finding a random improvement. The article suggests pre-registering your metrics—deciding what you’ll measure before doing the test—to keep results honest.

Third, the article points out the danger of checking results over and over during a test and stopping early when you see a “win.” Doing this is like running many tests, so the odds of a false positive go up fast. The author says you should either wait until your planned end date or use special methods (sequential testing) that adjust for early peeking.

In short, the article’s advice is to plan experiments carefully, stick to your original plan, use the right math corrections, and not be afraid of negative results. This way, you’ll actually learn what works, instead of just shipping random changes.

In the comments, many people agree that p-hacking is common—not just in startups, but also at big tech companies. Some think that most teams do not understand statistics well and rarely use the best testing methods, like ANOVA or Bayesian approaches. Others say that in real-world startups, there often isn’t enough data or time to wait for perfect results, so teams just pick the option that looks best and move fast. A few commenters argue that being too strict with statistics can waste time and money, especially when small changes are not important for success.

Several people suggest that for startups, it’s better to focus on big, obvious improvements and not stress about tiny statistical differences. Some mention that sometimes just trusting your product sense or doing quick user tests is more useful than running lots of A/B tests. There’s debate over how much rigor is really needed—some say overtesting slows teams down, while others point out that bad experiments lead to bad decisions. A few commenters share alternative ideas, like using permutation tests or focusing on effect size over p-values. Others discuss the pressure on teams to always show positive results, even when the data isn’t strong.

Overall, the comment section shows a split between those who want high-quality testing and those who prefer speed and practical results, with many agreeing that the right approach depends on the size and stage of the company.

---

## Show HN: I'm building an app to replace Overleaf and Notion

- 原文链接: [Show HN: I'm building an app to replace Overleaf and Notion](item?id=44317242)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44317242)

Someone is building a new writing app to replace Overleaf and Notion, aiming to help people write and organize complex documents like theses. This app has a modern editor, works in the browser, lets you invite coworkers to write together, and helps you organize documents with categories.

The app is inspired by LyX, but you do not need to know LaTeX to use it. You can export your work in many styles, such as IEEE papers or theses. It uses a custom block editor that works well even with big documents. Each part of the document is its own editable block. If you like plain text, you can add Markdown blocks. The app has built-in citation management, cross-references, and footnotes. You can add Mermaid diagrams, write math equations (inline or display), and use "to-do" sections for better organization. The app is available both online and as a Mac app, and you can try it at monsterwriter.com.

In the comments, some people like the idea but worry about storing their research in the cloud. One person does not want to download unknown files, and wishes for a Windows version. Another asks if the payment is really one-time or if there will be extra charges for big upgrades. Some users understand developers want to earn money for ongoing work, but want clear rules about updates and support.

Others say the app looks clean and well-designed. A few users want an open-source version, or note that org-roam for Emacs is a great open-source competitor. Some feel using Emacs is hard to learn, but powerful if you can use it. One user says they tried many tools for their PhD but ended up building their own system in Obsidian, wishing for something ready-made. Another agrees, saying tools like Notion and Overleaf look nice but do not solve all problems, and that LaTeX can be a pain compared to HTML.

Some people think using many small tools together is better than one big tool, and say files and folders are still the best way to organize work. There are also comments about other tools like Scrivener, Obsidian, and Paperpile, with one user asking why someone uses Paperpile instead of Zotero, since Obsidian works well with Zotero. Overall, people are interested but have many different needs and strong opinions about writing and research tools.

---

## LaborBerlin: State-of-the-Art 16mm Projector

- 原文链接: [LaborBerlin: State-of-the-Art 16mm Projector](https://www.filmlabs.org/wiki/en/meetings_projects/spectral/laborberlin16mmprojector/start)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44340386)

This article is about building a modern, open-source 16mm film projector because old projectors are getting hard to repair and use. The team decided to upgrade an existing projector (the Eiki RT) with new tech like a super-bright LED, water cooling, and digital controls instead of making a brand-new machine from zero.

Most old projectors are from the 1960s–1990s and are breaking down, with parts and service hard to find. The group wanted their design to be modular, use open parts (many 3D-printable), and be flexible for artists and film archivists. They tested several models and picked the Eiki RT since it is strong, easy to get, and has space inside for upgrades. The biggest challenge was finding a light source as bright as the original halogen bulbs but cooler and longer-lasting. They tested LEDs from 200W to 800W, used water cooling, and finally matched and even beat the brightness of old bulbs. Instead of the old spinning shutter, they used a digital “flicker” by turning the LED on and off very fast.

Their first prototype could run at different speeds, had a digital shutter, and used custom buttons and controls for brightness, frame rate, and more. They showed it at a festival, comparing it to other projectors. The new projector was much brighter, had good colors, but showed some problems like flicker, especially at high brightness. They found out this was from small issues with the mechanical claw, electronics, and maybe even just human eyes noticing flicker more at high brightness. After fixing these, they compared their projector’s image to other models and found it sharper and whiter. The team is sharing all their work openly so others can copy or improve it.

In the comments, some people loved seeing film tech getting support, especially with open-source parts and LEDs. Others worried the project is too complex and would be better if it focused on simple, useful features for more people. There was debate about the future of film—some think film is dying out, while others say there are still strong communities and new movies shown on film. One comment explained that variable speed is important for old silent films, which were shot at different frame rates. Some pointed out that color problems in projection often come from the film aging, not the projector, and this project could help with color correction during projection.

Technical people discussed why the LED needs so much power to match old bulbs—LEDs spread their light, making it harder to direct all the brightness through the lens. Others warned about using computer water-cooling parts for this, since they can break down over time. There were also talks about using projectors for archiving: some say scanning is better, but others feel projection keeps the original “feeling” of film. A few users wished for better, open-source film scanners as well. In general, the project got praise for helping keep film alive, but people want it to be practical, easy to build, and useful for both artists and archivists.

---

