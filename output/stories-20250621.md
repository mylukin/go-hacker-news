# Hacker News 故事摘要 - 2025-06-21

## 今日概述

Today’s top Hacker News stories cover new tech and creative tools. There’s news on Google’s AI chips, a browser extension for privacy, and a new music programming language. Other stories talk about better ways to run experiments, an open-source film projector, updates for coding tools, and a website to learn about type inference. There are also stories about the history of charts and Denmark’s metal detector program, showing how people and technology can work together.

---

## TPU Deep Dive

- 原文链接: [TPU Deep Dive](https://henryhmko.github.io/posts/tpu/tpu.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44342977)

This article explains how Google’s TPUs (Tensor Processing Units) work and how they are different from GPUs. TPUs are special chips built for AI tasks like training large neural networks, focusing on high speed and energy efficiency.

TPUs use a design called systolic arrays, which are grids of compute units passing data between each other. These arrays are very good at doing matrix multiplication and convolution, which are common in deep learning. Inside each TPU chip, there are TensorCores that handle the main math work, plus big memory blocks for fast data access. Unlike GPUs, TPUs have fewer cores but much bigger on-chip memory, and their external memory (HBM) is smaller. This makes them less flexible but very efficient for their specific jobs.

TPUs also rely on ahead-of-time compilation. Instead of using caches to handle unpredictable memory access, TPUs use the XLA compiler to plan memory use before running the program. This cuts down on energy use and helps the hardware run faster, but it means TPUs are less flexible and depend a lot on the compiler. For example, JAX code needs to be recompiled when input shapes change.

On a larger scale, TPUs are built to connect many chips together. Four chips make a tray, 64 chips make a rack, and 4096 make a “pod.” These chips are linked by high-speed connections (ICI and OCS), forming 3D torus networks. This allows for different ways to split up work (“slices”) and helps with running big jobs or several jobs at once. The OCS connections make it easy to reconfigure and share resources, which improves performance and reliability.

For even larger tasks, multiple pods can be grouped using slower data center networks, as was done for training models like PaLM. Google tries to make scaling up easier by letting the XLA compiler handle most of the hardware communication, so users don’t have to change much code.

In the comments, some readers ask about how TPUs and GPUs affect determinism in language models (LLMs). One reply says LLMs are usually deterministic, except for random sampling steps, which can be turned off. Others discuss what kinds of algorithms run well on TPUs. Most agree that any task that can be turned into large, dense matrix multiplications (like SVD, eigendecomposition, or solving linear systems) will work well. Some mention that the JAX scaling book is a good resource for learning how to use TPUs.

A few people are surprised by the depth of knowledge in the article and wonder if the author works at Google. Another points out the author probably used Google’s TPU Research Cloud, and anyone can get experience with TPUs through Google Cloud. One commenter clarifies a technical point: it’s not just caches that use energy, but also the memory management units (MMUs) that handle loading and storing data. TPUs save energy by not having MMUs and using a “push” system instead of a “pull” system for data.

Overall, readers find the article detailed and helpful for understanding how TPUs are built and why they are so powerful for AI. Some wish for more public documentation, while others share extra resources for learning more.

---

## A web extension to redirects YouTube, X, etc. to privacy-friendly front ends

- 原文链接: [A web extension to redirects YouTube, X, etc. to privacy-friendly front ends](https://libredirect.github.io)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44344246)

This article is about LibRedirect, a web extension that sends you from popular sites like YouTube, Twitter, Reddit, and Instagram to other websites that care more about your privacy. The extension supports many big services and shows a list of privacy-friendly frontends for each, like Invidious for YouTube, Nitter for Twitter, and Libreddit for Reddit.

LibRedirect works by automatically changing the website link when you try to visit a major site. For example, if you go to YouTube, the extension can send you to Invidious or Piped instead. These frontends often remove ads, tracking, and need for accounts. The article lists many supported sites and their privacy-friendly alternatives, such as ProxiTok for TikTok or Wikiless for Wikipedia. Some frontends have more than one choice, so you can pick your favorite. The extension also works with search engines, maps, and text sharing sites, offering replacements like SearXNG or OpenStreetMap. You do not need to log in or give personal data to use most of these frontends. LibRedirect is made to help you avoid tracking and to give you a simpler, cleaner browsing experience. The main goal is to put control back in your hands and keep your data safe. The project has a Mastodon link for updates and support.

In the comments, people share both positive and negative points. One user says the extension works, but many of the privacy-friendly sites die or get blocked quickly, so it can be hard to find a working instance. Another person brings up Farside, a similar project, and asks why someone should use LibRedirect instead. Some think using a browser extension is risky for security, and suggest using a userscript instead. But others reply that userscripts can have wide permissions and be even more dangerous if you do not check the code. There is also debate about privacy: one user points out that using frontends like FreeTube or Piped just moves your data from big companies to random server owners, which might not be better. Someone suggests using a second browser session with a VPN, so you trust a bigger company with privacy promises instead of unknown strangers. Another commenter says that scripts should be simple and written by yourself to reduce risk. There is also talk about some frontends needing to solve CAPTCHAs, which can be annoying. Overall, people agree that privacy is important, but they argue about the best way to reach it and who to trust with your data.

---

## Sound As Pure Form: Music Language Inspired by Supercollider, APL, and Forth

- 原文链接: [Sound As Pure Form: Music Language Inspired by Supercollider, APL, and Forth](https://github.com/lfnoise/sapf)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44342731)

This article talks about a new programming language called sapf, made for creating and changing sound. Sapf is inspired by Supercollider, APL, and Forth, and is meant to be a simple but powerful way to work with audio.

The language uses a stack and postfix notation, like Forth, so you write things in a way where you put numbers first and then the operations. Sapf is mostly functional, and it uses lazy lists, which can be infinite, to represent sounds and events. It tries to make working with lists as easy as APL does for arrays, with automatic mapping and high-level functions so you don’t need to write loops. This helps make short, readable programs that can do a lot.

Sapf has only a few data types: real numbers, strings, lists, forms (like dictionaries), functions, and refs (which are mutable). Most data is immutable, so you can run many threads safely. The syntax is designed to be as simple as possible—no extra symbols like brackets or commas are needed for most things. Functions are created easily, and the language supports mapping functions over lists, scanning, and reducing with special operators.

There are special ways to handle lists, like the “each” operator (@), which lets you apply a function to every part of a list, even inside nested lists. Sapf also supports multi-channel audio by expanding signals over lists, so you can make stereo or multi-channel sounds simply. There are examples in the README that show how to make different sounds, like a simple sine wave or more complex patterns.

To use sapf, you download the program, set some environment variables, and run it in the terminal. There is built-in help and many example programs. The language is still new and not as well-known as others, but it tries to give an elegant and artistic way to make music with code.

In the comments, many people are excited about sapf’s design. One user says the language seems complex at first, but the concatenative style is actually good for audio work. Some mention that other Forth-like audio languages exist, such as Sporth, and share links to similar tools. Many agree that mixing ideas from APL (arrays) and Forth (stacks) is a strong combination for music programming, and that more languages should try this.

Some users ask if sapf can be used with other tools like Supercollider, or if it can run on Linux. There are questions about compiling it outside of MacOS, since it uses some Mac-only code. Other users share tips on music languages that work well on Linux, such as Supercollider, Pure Data, Csound, and TidalCycles, and offer advice on setting up audio systems on Ubuntu.

A few point out that the creator of sapf is also the person who made Supercollider, which impresses them. Some users wish for easy installation, like a Linux binary or a Flatpak, because they find it hard to get other music languages working on their systems. Others suggest trying web-based music tools, like Strudel or Glicol, for people who have trouble with installs.

Overall, people like the creative ideas behind sapf and are interested in its mix of functional programming, stacks, and audio synthesis. There is hope for better cross-platform support and more ways to connect sapf with other audio languages in the future.

---

## P-Hacking in Startups

- 原文链接: [P-Hacking in Startups](https://briefer.cloud/blog/posts/p-hacking/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44308328)

The article explains how startups can fall into “p-hacking” when running experiments to improve their products. P-hacking happens when teams try lots of things quickly and report small improvements as big wins, often because they don’t use proper statistics.

First, the article shows how testing many versions of a feature (like four new website layouts) increases the chance of getting a false “winner.” If you only accept results with a p-value below 0.05, but you test four layouts, the odds of a random win go up to almost 1 in 5. This is because you’re running several tests, not just one. To fix this, you should use methods like the Bonferroni Correction, which makes your threshold for success lower (for four tests, the cutoff becomes 0.0125 instead of 0.05).

Second, the article warns about changing your goal after seeing the results. For example, if your new layouts didn’t improve signups, but you see a small win in user retention, you might be tempted to claim success there instead. But checking more and more metrics just raises your odds of finding a random win, not a real one. The article suggests pre-registering your main goal before the test starts and sticking to it.

Third, the author talks about “peeking”—checking results before the experiment is finished. If you stop early when you see a positive result, you’re more likely to catch a random swing and not a real effect. The right way to peek is to use stricter thresholds for early results, or better yet, just wait until the planned end.

In short, the article says startups should slow down and use better methods: decide on goals before testing, correct for multiple tests, and avoid fishing for any “good” result in the data. This makes experiments more trustworthy, even if it feels slower.

Hacker News commenters bring many views. Some say these problems are not just for startups—big tech companies face them too, often with even messier decision-making. Others point out that many teams don’t use the best statistical tools anyway, and often misunderstand p-values. Some suggest using simpler ways, like just picking the option with the most signups, especially when the stakes are low and you must pick something.

Many argue that startups do not need the same level of rigor as medical research, since the cost of being wrong is usually just fewer sales, not serious harm. Some say that speed is more important for startups, and being “good enough” is better than perfect. There’s a debate about how much rigor is right—some commenters warn that too much waiting can slow down product growth and waste time, while others say that being too loose leads to many false wins and confusion.

Commenters also discuss alternative methods, like Bayesian approaches or permutation tests, which might be better in some cases. Several people mention that sample sizes in startups are often too small to get statistically solid answers, so trusting your gut or product sense is sometimes necessary, especially early on.

There’s also talk about the human side: people want to show results to bosses, so they may fish for any positive finding, which makes the problem worse. Some mention that it’s important to know what you really care about: if you need strong evidence, be strict; if you just need to keep moving, it’s okay to be less careful, as long as you’re honest about the risks.

A few people note that statistical tools are getting better and more accessible, but learning to use them well is still hard. Finally, some warn that focusing only on numbers can distract from bigger issues, like whether your product is good at all. In the end, there’s no single answer—startups must balance speed, learning, and risk, using just enough rigor to fit their goals and resources.

---

## LaborBerlin: State-of-the-Art 16mm Projector

- 原文链接: [LaborBerlin: State-of-the-Art 16mm Projector](https://www.filmlabs.org/wiki/en/meetings_projects/spectral/laborberlin16mmprojector/start)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44340386)

This article is about a project to build a modern, open-source 16mm film projector, because old projectors are hard to repair and not good for new artistic and archival needs. The team wants their projector to use bright, adjustable LEDs, modular parts, and common lenses, so artists and archivists can show films easily and safely.

They tested different old projector models and chose the Eiki RT because it is strong, has space for new parts, and is available worldwide. Their main challenge was replacing the traditional halogen lamp with a high-power LED, which needed special water cooling to prevent overheating. The 800W LED they picked was much brighter than the old bulbs, but they also had to solve problems with flickering and color. They used open-source electronics and control systems, and tried to make the design simple, so anyone could build or copy it with basic tools—no special machines or expensive parts needed.

The team showed their prototype at a festival in Barcelona, where experts gave feedback. The new projector was much brighter and had good color, but flickering was worse than with old bulbs, especially at higher brightness. They found out the flicker came from both mechanical and electronic issues, so they worked on fixing those. Later tests compared the new projector to others using halogen and Xenon lamps, and the LED prototype gave the brightest and sharpest image, though color differences across prints were still a problem.

In the Hacker News comments, many users liked the project and remembered working as projectionists or with film. Some people said the project should focus on the most important features, because the film community is small and many advanced features are only used by a few people. Others argued that film, especially 35mm and 16mm, is still alive in some cities and special theaters, and young people are interested too.

Some commenters debated the technical side. They were surprised that a huge 800W LED was needed to match the brightness of a much smaller halogen bulb, and suggested this is because LEDs spread light in all directions, making it hard to focus. People suggested looking at different LED or laser setups for better efficiency. There were also tips about how to cool big LEDs and warnings about using computer water coolers, which may not work long-term in projectors.

Others talked about why projectors are important for archiving film. Some said scanners can copy the film better, but projectors are needed to check the film’s condition, show it to people, and keep the original viewing experience. A few users pointed out that film colors fade over time and this new projector might help show old films more accurately, which is good for preservation. There was also debate about whether features like variable speed are needed—some said they are important for historic or special films, while others thought they were too niche.

Overall, the community found the project interesting and valuable, especially for keeping film culture alive and helping archivists. But they also advised keeping it simple, focusing on reliability, and learning from both old and new technology.

---

## Remote MCP Support in Claude Code

- 原文链接: [Remote MCP Support in Claude Code](https://www.anthropic.com/news/claude-code-remote-mcp?campaignId=13926158&source=i_email&medium=email&content=Oct2024AnalysisTool&messageTypeId=140367)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44312363)

Claude Code now supports remote MCP servers, letting you connect outside tools and data to your coding workflow. This means you can use things like Sentry or Linear with Claude Code, getting real-time details about your projects or errors right inside your coding tool.

With MCP servers, Claude Code pulls in info from your favorite third-party services. For example, if you add the Sentry MCP server, you can see error reports and fix issues without leaving your terminal. If you use Linear, you can track project status and issues, making it easy to switch between planning and coding without lots of browser tabs. The ecosystem of MCP servers is growing, so more features are coming all the time.

Adding a remote MCP server is simple—you just add the vendor’s link to Claude Code. You don’t need to run your own server, and the vendor handles updates and scaling. Claude Code also uses OAuth, so you can connect safely without managing API keys or passwords. This update makes it easy for anyone to bring more tools into their coding setup with less hassle. You can find guides and a list of recommended MCP servers on Anthropic’s website.

In the comments, many users are excited about how fast the MCP ecosystem is growing. Some say the spec changes too quickly, making it hard to keep up, and wish for more stable, well-documented updates. Others point out that security is often not the top priority, but the speed of development is impressive—people are even using MCP tools to make new MCP servers faster.

One user notes that big purchases, like the Cursor editor, now look outdated next to Claude Code’s new abilities, calling it a smart move for the founders but risky for buyers. Others share open source tools like WitsyAi and Ninja that help people use or build MCP servers, and even mention projects for running MCP servers on devices like Raspberry Pi. There’s also talk about multi-agent features and how this could change coding, with tools like Claude Code Flow adding more ways for agents to work together. Lists of useful MCP servers and tools are being shared, and several people are already trying out these new connections in their own projects. Overall, the community is excited but hopes for more stability and better security in the future.

---

## Finally, a Makefile formatter (50 years overdue)

- 原文链接: [Finally, a Makefile formatter (50 years overdue)](https://github.com/EbodShojaei/bake)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44323905)

This article is about a new tool called mbake, which formats and checks Makefiles, something people have wanted for a long time. Makefiles are used to automate build steps in many software projects, but they can get messy and hard to read.

mbake helps by making Makefiles look clean and consistent. It fixes things like tabs for commands, spacing around operators, and extra spaces at the end of lines. It also joins lines that should go together and keeps complex lines as they are. One special feature is how it handles .PHONY targets, which tell Make not to look for files with certain names. mbake can group these, add them if missing, and even figure out which targets are phony by looking at the commands, not just the names.

You can install mbake with pip or as a VSCode extension. It works from the command line and has many options, like checking a file, formatting it, showing what would change, or making a backup. There are also settings you can change in a config file, like how many spaces to use, how to handle newlines, and if mbake should add .PHONY automatically.

The tool can be used in continuous integration, so teams can check formatting in their code pipelines. The code is organized in a way that makes it easy to add new rules or plugins. The main idea is to make only the changes needed, work fast, and always keep the Makefile working right.

In the comments, some people are happy to see this tool and say it does not need to be complex to be useful. One person asks if you can tell mbake to skip certain rules, which could help with special cases. Another suggests making mbake work with pre-commit hooks, so formatting happens automatically before code is committed.

Some users discuss Makefiles themselves. One person does not like Make and thinks using environment variables is confusing. Others reply that Make is simple, widely available, and usually does not use many environment variables. They say tools like Docker also use environment variables, and people still use them a lot. Another user prefers to use shell scripts instead of Make in places without internet access, but others point out that Make is on almost every system. Finally, someone says Make is good because it does most of what you need, is everywhere, and is easy for new people to understand, especially in CI pipelines.

---

## Type Inference Zoo

- 原文链接: [Type Inference Zoo](https://zoo.cuichen.cc/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44307667)

Type Inference Zoo is a website where you can try out different type inference algorithms right in your browser. It is made for people who want to learn or work with how programming languages figure out types automatically. The site lets you play with examples and see how type inference works, using the same easy-to-read syntax for all the algorithms. You do not need to install anything or write extra code just to test an idea. The playground is interactive, so you can change examples and see the results right away. This is helpful for students, language designers, or anyone curious about type systems. The code on the site is made to be clearer than the math-heavy notation you often find in research papers. This means you can focus on learning the main ideas, not on struggling with hard-to-read formulas. The site also aims to save time by using the same system for different algorithms, so you don’t have to start over each time. Everything is in one place and easy to use.

In the comments, one person was impressed by how much useful work comes from Bruno Oliveira’s research groups, which helped inspire this and other tools. Another user shared a link to CP, a programming language with special types, showing interest in related projects. Someone else said they had wanted to build something like this for a long time but found it difficult and was happy to see it finally exist. People agree the tool is very useful, especially for those who want to understand or build programming languages. There is excitement that the site makes hard ideas more simple and hands-on. Some comments highlight the value of clear code over complex math when learning type inference. Others point out that interactive tools like this make learning faster and more fun. A few users mention this could be a great teaching tool for classes or self-study. Some wish there were more features or examples but still like the main idea. There is a sense that the tool fills a real need in the programming community. Overall, the feedback is positive and shows that type inference, though tricky, can become much more approachable with the right tools.

---

## The bad boy of bar charts: William Playfair (2023)

- 原文链接: [The bad boy of bar charts: William Playfair (2023)](https://blog.engora.com/2023/05/the-bad-boy-of-bar-charts-william.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44309734)

This article is about William Playfair, who invented bar charts and pie charts but also lived a wild life full of scams, spying, and trouble. Playfair was active during big events like the French Revolution and the start of the United States, and he was often involved in shady business deals during these times.

He was born in Scotland in 1759 and started working young after his father died. He first worked with inventors and famous people like James Watt, but his life soon took a turn. In London, he started a business that failed and faced accusations of dishonesty. In Paris, he sold steam engines and was around powerful people, even being present at the storming of the Bastille. He was involved in a land scheme that tricked French elites and caused a big scandal in the United States, which even involved George Washington.

Back in London, Playfair tried to start a bank, but it failed too, with more talk of fraud. He spent time in debtors’ prison, where he wrote some of his most important books. He also worked as a spy and gave secrets to the British government, including plans for the French semaphore system. He came up with the idea to print fake French money to hurt France’s economy, which may have helped bring down the French government.

Later, he tried to blackmail a rich noble but failed again. Despite all this, Playfair’s big idea was to use pictures, not just words, to explain numbers. In 1786, he made the first bar chart to show Scotland’s trade with other countries. He later created the first pie chart to show the size of countries and their parts. He also used early line charts to show changes in money over time. Playfair had to teach people how to read these new charts because no one had seen them before.

In the comments, some readers pointed out the funny side of a man known for fraud also making charts that are sometimes used to mislead people. Others joked about his last name and how it fits his life. Some readers said the blog was a great find and liked learning about Playfair’s wild story. There was also talk about Florence Nightingale, who made important charts too, and someone shared a link to another blog post about her. Some readers suggested that Playfair’s life would make a good TV show, with all its drama and excitement. Overall, people enjoyed discovering the strange and interesting history behind such common things as bar charts and pie charts.

---

## Denmark's Archaeology Experiment Is Paying Off in Gold and Knowledge

- 原文链接: [Denmark's Archaeology Experiment Is Paying Off in Gold and Knowledge](https://www.scientificamerican.com/article/denmark-let-amateurs-dig-for-treasure-and-it-paid-off/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44309191)

Denmark has a special program that lets hobbyists use metal detectors to look for old artifacts, and it has led to some big discoveries of gold and ancient objects. The article talks about how these finds are not just valuable in money, but also give new knowledge about history, like finding the oldest written mention of the Norse god Odin in Denmark.

The program works by encouraging people to report what they find instead of hiding it or selling it on the black market. Those who find something important get paid—sometimes a lot, like $150,000 for a big Viking gold find. This makes people more willing to share their discoveries with museums and scientists. When someone finds gold or other artifacts, experts can study where the objects were buried and what they can teach us about the past. For example, a special gold disk called a bracteate was found with runes that mention Odin, which helps historians understand old beliefs and writing. The program also tries to protect scientific value by having professionals document the layers of earth and objects around the main find, which helps with dating and understanding the context.

Some of the article’s details are debated. For example, while the bracteate is the oldest written mention of Odin in Denmark, some people point out that Romans wrote about similar gods earlier, but used different names. Still, the Danish find is important because it uses the actual word “Odin” written in runes, not a Roman version. The program has also helped uncover how symbols, like the swastika, were used in old cultures before the Nazis, and how myths and gods changed over time.

In the comments, people share different views and stories. Some wish they could use metal detectors in their own countries, but face strict laws. Others suggest cool ideas, like building metal detectors in shoes to search more easily. There is debate about whether it is easy or hard to sell found gold on the black market; some say it’s simple to melt and sell, while others think it’s risky or not worth it. Many agree that paying finders encourages honesty—most people would rather get a reward than break the law.

Some worry that amateurs might destroy the scientific context if they dig things up wrong, making it harder for experts to learn from the finds. People also disagree about what should happen to artifacts: some think museums keep too many items locked away, while others say we need to keep them for future research, since new technology might open up new ways to study them. There’s talk about how gods like Odin may have changed roles over time, and whether the new finds really change what we know about history. Finally, many like how Denmark’s system lets regular people help with archaeology, leading to more discoveries and shared excitement.

---

