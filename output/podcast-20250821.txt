Hello everyone, this is the 2025-08-21 episode of Hacker News Daily Podcast. Today, we cover stories about water use in the US, tricky Python pattern matching, new AI project rules, the shift in building AI products, DeepSeek’s latest model, SVG path guides, confusing AI job titles, a group chat AI startup, cave diving in Budapest, and using wearable data for health.

Let’s start with water in the US. A recent article explains how water is used and why it often gets less attention than other infrastructure. Most US water comes from rain or snow, but only 2% is actually used by people—the rest returns to the air or flows to the sea. The water system works much like electricity: large pipes and treatment plants move water from lakes, rivers, or underground aquifers to homes and businesses.

In 2015, Americans used about 322 billion gallons of water each day. Most is fresh water; 74% from surface sources, 26% from underground. Water use can be “consumptive” (used up and not returned) or “non-consumptive” (returned after use). Thermoelectric power plants are the biggest user, with 41% of water use, but most of that is returned to nature, just warmer. Irrigation for crops is next at 37%, and most of that is consumptive, lost to plants or soil. Alfalfa, orchards, corn, and rice use the most irrigation water. Homes and businesses use about 12%, and Americans use much more water per person than people in Europe. Industry uses 4.5%, mainly for making paper and steel, but most of that water is returned. Data centers use about 66 million gallons per day for cooling, which is small compared to farming.

California, Texas, and Idaho use the most water, mainly due to their size and farming needs. Most irrigation happens in the west, where rainfall is low. In some states, irrigation is a big part of total water use, and overuse in some places is causing underground water sources to shrink. Water use peaked in 1980 and has dropped since, even as groundwater use stays the same.

Commenters talk about how total water numbers can be misleading if most water is returned to nature, saying we should focus more on consumptive use. Some are surprised by power plant water use and wonder if new energy sources could help. Others discuss the amount of water used for crops like alfalfa and rice and question if our food choices need to change. There’s debate about data centers—some worry about their growth in dry areas, but others say their value per gallon is much higher than in farming. People share stories of water shortages and call for better management. Some say the US is lucky to have so much water, but local shortages are still serious. Many agree we need more investment in water infrastructure, and that understanding the difference between consumptive and non-consumptive use is important for good decisions. While some hope the trend of lower use will continue, others warn that climate change and growing populations mean the US should not be complacent.

Next, there’s an article about Python’s new pattern matching and how it can be tricked using Abstract Base Classes (ABCs) and the __subclasshook__ method. The author shows that you can make an ABC that matches any class with certain features, even if it doesn’t inherit from the ABC. For example, you could match all classes with palindromic names or create a NotIterable ABC for pattern matching. The article also explains how to match objects based on attributes, not just type, and how to build complex match rules using functions that create new ABCs at runtime. The author warns that these tricks can make code confusing and are not for real projects.

In the comments, many readers call these tricks clever but dangerous, saying __subclasshook__ can break the idea of pattern matching and make code hard to read. Some are surprised that pattern matching depends so much on isinstance, which can be changed. A few wonder if there are safe uses, maybe for testing. Others share that similar tricks exist in other languages. One person notes that overusing magic methods makes code hard to learn. Some joke that these are fun to know but not for code you want to maintain. There’s talk about whether Python should block these patterns or at least warn when ABCs are used in matching. Many agree the lesson is to understand how pattern matching works under the hood, so you don’t get caught by surprise.

Moving on to open source, the Ghostty project now requires contributors to say if they used AI tools to help write code. The maintainer explains that AI-written code often needs closer review, and it’s not fair to make reviewers help if the real author is an AI tool. The project is not against AI, but wants honesty and respect. Some suggest adding a checklist for pull requests or having GitHub mark commits that involved AI. Most people agree this is common sense and helps keep code quality high. There’s some debate about small AI help, but the rule’s documentation covers that too. Some wonder if such rules will spread to other projects. Overall, most reactions are positive, with many developers saying honesty about AI use is important, even if there are different ideas about how to do it.

Next, an article discusses how building AI products is very different from building old software. In the past, user actions led to predictable results, and teams could measure and control each step. New AI models like ChatGPT are unpredictable, can take any input, and give different answers each time. You cannot test every possible case, and the cost to run these models is higher, but the answers are not always reliable.

Teams now need to act more like scientists, always testing, learning from data, and watching real users. As new models come out, you may need to change your product, because each model acts in new ways. Data is now key, not just for training AI, but for seeing how users really use the product. All teams must work together to understand users and make better decisions.

Commenters agree that AI is a big change, and old ways do not fit anymore. Some share stories about unpredictable results. Others worry that not being able to explain or predict AI is dangerous, while some say that old methods are still useful. A few point out that users do not like it when AI makes mistakes, and that this could hurt trust. Some developers feel frustrated by the new “science” approach. Others are hopeful, saying AI opens new doors for products and creativity, but agree it is a hard and uncertain time.

Now, DeepSeek has released a new AI model called DeepSeek-V3.1, which aims to be better at solving tasks and acting as an agent. There are two modes: “Think” and “Non-Think.” “Think” mode is faster and better for multi-step tasks. The API now supports longer inputs, up to 128,000 tokens, and works with the Anthropic format and stricter function-calling options in beta. The model is more efficient for programming and reasoning, and both the base and full model weights are open source. Current pricing discounts end on September 5, 2025.

In the comments, users are excited by the fast improvements and open-source release. Some ask about real-world performance compared to other models, and a few share benchmarks or tests. There are worries about pricing changes and hope that it stays affordable. Several users praise the long context window and ask about the best way to use each mode. Some want better documentation and more API examples. There’s interest in the strict function-calling feature for safe app building. A few compare DeepSeek’s open approach to more closed providers and hope this continues.

Switching gears, there’s a detailed guide on SVG path elements. SVG paths let you draw lines, curves, and arcs in images. The article explains commands like M for move, L for line, Q for quadratic Bézier curves, C for cubic Bézier curves, and A for arcs. Bézier curves let you make smooth lines, and arcs draw parts of ellipses with several parameters. You can close shapes with Z, use relative commands, and chain smooth curves. The article includes many code examples and interactive diagrams. The author also mentions a paid course on SVG animations.

Many commenters say this guide is very clear and helpful, especially for understanding the arc command. Some share their struggles with SVG paths and agree that interactive examples make learning easier. People discuss using tools like Inkscape or online editors, and some warn that browser support for complex SVG can be tricky. Others say knowing SVG paths helps with icons, charts, and animations. Some want more about animating paths or using them in web apps. Overall, readers think it’s a great resource, even for experienced developers.

Now, let’s talk about AI job titles. The article explains how titles like “Applied AI Engineer” or “AI Researcher” are often confusing and keep changing. Titles have three parts: modifiers (like “Applied” or “Forward Deployed”), domains (like “AI,” “ML,” or “Gen AI”), and roles (like “Engineer,” “Researcher,” or “Architect”). “Forward Deployed” means working closely with customers, “Applied” means using AI to solve real problems, not building models. The roles explain if someone is building, researching, or advising. The article gives examples and explains how “Researcher” and “Scientist” can mean different things depending on the company. The “Gen AI” label became popular after ChatGPT, but is now less clear.

In the comments, some say this confusion is common in other fields too. Others think companies use big titles to attract talent or make jobs sound important. Some like the “Applied” and “Forward Deployed” labels, but agree there’s a lot of overlap and confusion. A few say job seekers need to look at the description, not just the title. Some joke about how titles will get even more confusing as AI grows. Overall, people like the cheat sheet, but say you should always read the job ad carefully.

Switching to startups, Text.ai is a new company backed by Y Combinator, looking for a founding full-stack engineer to help build an AI-powered group chat app. The AI will stay in group chats, learn about the group, and help with planning and decisions. The job is for someone who can build mobile apps with React Native and backend in Python, and wants to shape the product and company. The role is fast-paced and hands-on, with high pay and equity.

Comments are mixed. Some are excited about AI making group chats smoother, while others worry about privacy and trust. A few question if AI can really solve group decision problems, since people have different needs. The technical challenge is seen as big but interesting. Some like the chance to shape the whole product, while others warn that startups can be risky and stressful. There are also questions about how the company will handle privacy and data consent. Some say they would wait to see if users really want this before joining. Overall, people see both the potential and the challenge.

Next, there’s a story about scuba diving in a cave system under Budapest, called Molnár János. The cave is filled with warm, clear water from natural springs and is hidden below the city. It’s been explored for many years, but still has new tunnels being found. Divers need special training and equipment, as cave diving is risky. The water is so clear that divers can see far ahead, and scientists study the cave to learn about its history. The cave is protected to keep it clean and safe, and some divers travel from other countries just to visit.

Many commenters are surprised that such a cave exists under Budapest. Some share stories of other hidden places under cities. A few talk about the dangers of cave diving and the strict rules needed. Others are excited to visit, while some wonder about the risk to the city from so many tunnels. There are jokes about life above while divers swim below, and people discuss the science of the water’s clarity and warmth. Some locals say they never knew the cave was there. People also talk about how rare it is to have a diving spot like this in a city.

Finally, an article looks at how data from wearable devices, like step counts and sleep times, can predict health better than just raw sensor data. The authors built a big machine learning model using over 2.5 billion hours of data from 162,000 people. Instead of just looking at heart rate or steps every second, they focus on higher-level behaviors—like sleep or movement patterns over weeks. The model did very well on 57 health tasks, and combining behavior with raw data improved predictions. This suggests wearables could help support better health tools in the future.

In the comments, some are excited about smarter health care, while others worry about privacy and who owns the data. A few developers are impressed by the huge model and wonder if smaller teams could do the same. Some say behavior data can be noisy or misleading, for example if a device is worn wrong. There are also concerns about bias, since people who wear these devices might not represent everyone. One user points out that mixing behavior and raw data could help spot problems earlier. Others ask if these models could one day warn users about poor sleep or stress in real time. Overall, people think this research is promising, but needs more real-world testing before it can be fully trusted.

That’s all for today’s episode. Thanks for listening to Hacker News Daily Podcast. See you next time.