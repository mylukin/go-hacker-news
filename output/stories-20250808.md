# Hacker News 故事摘要 - 2025-08-08

## 今日概述

Today’s top Hacker News stories are about offline AI workspaces for privacy, creative hardware projects, and tools for online privacy like Tor. There are stories on new developer tools, database choices, and why large AI models can’t run at home yet. Space history and amazing space photos are also popular, along with a look at Disney’s risky movie and a company speeding up geolocation with Rust. If you like tech, privacy, or creative projects, today’s stories have something for you.

---

## I want everything local – Building my offline AI workspace

- 原文链接: [I want everything local – Building my offline AI workspace](https://instavm.io/blog/building-my-offline-ai-workspace)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840013)

This article talks about building an offline workspace for AI, where everything runs on your own computer—no cloud, no sending data to outside servers. The author wanted to use large language models (LLMs) like ChatGPT, but only locally, and also run code and browse the internet in a safe, private way.

They started by picking tools that could do each job: Ollama for running LLMs on your machine, Assistant-UI for a chat interface, Apple’s new “container” tool for running code inside a virtual machine (VM), and Playwright for automated web browsing. Instead of running code directly on the computer, the code runs inside a container or VM. This keeps your system safe if something goes wrong. They tried to build a Mac app, but it was too hard, so they stuck with a local web app. Picking models in the chat app was tricky because tool support is not always clear—sometimes a model says it can use tools, but really can’t. They used the “coderunner” tool to let the LLM send code to the VM, and it worked for things like editing videos or images, or even installing new tools. For privacy, they made sure files are only shared in a special folder, and code never touches the main system. There are limits: it only works on Apple Silicon Macs, and the browser part can be blocked by websites as a bot.

In the Hacker News comments, many people liked the idea of running AI tools fully offline for privacy and control. Some said they also want to avoid cloud tools, but worry that local models are still not as good as big cloud ones. Others pointed out that Apple’s “container” tool is new and still buggy. A few users asked about running this setup on Linux or Windows, since not everyone has a Mac. Some thought the system is still too complex for less technical users. There was debate about how much privacy you really get, since even local tools can have bugs or leaks. Some commenters shared tips for better isolation, like using QEMU or Firecracker instead of Apple’s container. Others liked that the project is open source and easy to try. A few also wondered if local AI will ever match the power of huge cloud models. Finally, people agreed that tools like this help give users more choice and control over their data.

---

## Ultrathin business card runs a fluid simulation

- 原文链接: [Ultrathin business card runs a fluid simulation](https://github.com/Nicholas-L-Johnson/flip-card)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44835879)

This article is about a very thin business card that can run a fluid simulation. The card is small and has a computer chip inside that shows moving water on a tiny screen.

The business card is made by a hardware engineer. It uses a low-power microcontroller and a small OLED display. The card can fit in your wallet, just like any normal business card. When you press a button, the card turns on and shows a simulation of how water moves in a box. The water moves smoothly, like a real liquid. The card uses a simple physics model to make the water movement look real. The simulation runs fast, even though the chip is weak and small. The engineer wrote special code to make it work well on the limited hardware. The card also has a USB port for charging or updating the software. It is open-source, and you can find the code and plans online. The maker wanted to show that even small devices can do interesting things.

In the comments, many people are impressed by the creativity and engineering. Some developers say this card is a fun way to show hardware skills. Others ask about battery life and how long the card can run the simulation. A few wonder if the card could have more features, like games or different effects. Some users talk about similar “hacker business cards” they have seen before. A couple of people discuss how the fluid simulation works and share links to similar projects. One person worries the card may be too expensive to give away to everyone. Others think it is a great way to stand out at job fairs or conferences. Some wish the card was easier to build for beginners. Overall, most comments are positive and praise the project for being fun and inspiring.

---

## Tor: How a military project became a lifeline for privacy

- 原文链接: [Tor: How a military project became a lifeline for privacy](https://thereader.mitpress.mit.edu/the-secret-history-of-tor-how-a-military-project-became-a-lifeline-for-privacy/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44838378)

This article talks about Tor, a tool that helps people stay anonymous online, and how it started as a secret U.S. military project before becoming important for privacy. It explains that Tor is a network of servers around the world, and when you use the Tor Browser, your internet traffic is encrypted and bounces between these servers, making it hard for anyone to see what you’re doing or where you are.

Tor was first built to help military and intelligence agents communicate secretly, not just to hide the message content but also to hide who was talking to whom. The key idea behind Tor is “onion routing”—your data is wrapped in several layers of encryption, and each server along the way peels off one layer, only knowing where the data comes from next, not where it started or where it will end. This means no single server ever knows both the sender and the receiver.

The article says that for Tor to work well, lots of people need to use it—not just spies, but normal users too. This way, it’s hard to tell who is who, and high-risk users can hide among regular people. The project grew with help from both the U.S. Navy and “cypherpunks”—hackers and activists who cared about privacy. Together, they shaped Tor into a public tool used by everyone from journalists and activists to regular internet users.

The story also talks about a wider fight over privacy. In the 1990s, there were big arguments about encryption—some people wanted strong privacy, others wanted more control for police and governments. Tor’s history shows how privacy is not just about individuals hiding; it’s about power—who controls information, and who gets to watch whom. The article points out that some governments still try to limit privacy, saying it’s for safety, but privacy tools are also important to protect people from abuse and keep them safe from powerful groups.

Commenters on Hacker News had many thoughts. Some praised Tor for helping people in countries with censorship, allowing them to reach blocked news and social media. Others worried that Tor is often linked with crime, which makes it hard for regular people to use without being judged. A few mentioned that, because Tor is partly funded by the U.S. government, they wonder if it’s really safe and private, or if it could be compromised.

Several users pointed out technical problems, like slow speeds and some websites blocking Tor users. Others said that more people should use Tor for normal browsing, to help everyone, not just those with something to hide. Some worried that new laws, like the UK’s Online Safety Act, could make privacy tools illegal or force companies to weaken encryption, making everyone less safe.

There was also debate about the balance between privacy and stopping crime. Some said strong privacy is important for everyone, while others felt that police need some way to catch criminals online. A few shared stories about using Tor to get around censorship in their own countries or to research sensitive topics without fear. Overall, most commenters agreed that tools like Tor are important for a free and open internet, but they need more support and better public understanding.

---

## Jim Lovell, Apollo 13 commander, has died

- 原文链接: [Jim Lovell, Apollo 13 commander, has died](https://www.nasa.gov/news-release/acting-nasa-administrator-reflects-on-legacy-of-astronaut-jim-lovell/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840582)

Jim Lovell, the commander of Apollo 13 and a key NASA astronaut, has died at age 97. NASA’s acting leader shared a statement honoring Lovell’s long career and his impact on space history.

Lovell helped guide the United States through important space missions. He flew in both the Gemini and Apollo programs. In Gemini, he tested how people could work and live in space. As Command Module Pilot of Apollo 8, he was one of the first people to orbit the Moon. This showed a Moon landing was possible. But Lovell is best known for leading Apollo 13. During that mission, an explosion damaged their ship. Lovell stayed calm and helped his team get home safely. NASA says his quick thinking and strong leadership saved lives and taught them much for future missions. Lovell was also famous for his humor, earning the nickname “Smilin’ Jim.” He served as a Navy pilot before joining NASA. NASA says his life showed courage and hope, inspiring today’s explorers.

In the comments, many people share their sadness and deep respect for Lovell. Some recall where they were during Apollo 13 and say Lovell’s actions made a big difference in space safety. Others talk about how the Apollo 13 story inspired them to work in science or engineering. A few point out Lovell’s teamwork and steady hand under pressure. There are comments about how astronauts back then took big risks that helped everyone learn. Some people thank Lovell for his service in the Navy as well. One comment mentions movies and books about Apollo 13 that helped make his story famous. Others discuss how space travel has changed, but Lovell’s example is still important. Some users compare today’s missions to the old days and say we still need heroes like Lovell. A few share personal memories of meeting him or hearing him speak. Many agree he was a real leader and his legacy will last for a long time.

---

## Efrit: A native elisp coding agent running in Emacs

- 原文链接: [Efrit: A native elisp coding agent running in Emacs](https://github.com/steveyegge/efrit)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840654)

Efrit is a new tool that helps you write and edit code using AI, all inside Emacs. It works natively with Emacs Lisp (elisp), the scripting language Emacs uses.

Efrit lets you ask questions, get code suggestions, and even edit your code with AI help, without leaving Emacs. You can give it prompts like “write a function to reverse a list,” and it will answer right away. Efrit is designed to be fast and easy to use, and it does not need an internet connection because it runs models on your own computer. This makes it private and secure, as none of your code gets sent away. It works well for both simple tasks—like fixing a bug—and bigger jobs—like generating whole functions. The author explains that Efrit uses llama.cpp under the hood, so it can run popular AI models. You can also use it with other languages, not just elisp, if you write the right prompts.

Many comments on Hacker News are excited about this tool. Some people love that it stays inside Emacs, so they don’t have to switch to other apps. Others like that it’s local and private, which is rare for AI tools. A few users wonder if the AI is really good enough to help with real code, or just simple stuff. Some are concerned about how much memory or CPU it uses, since AI models can be heavy. Others ask how easy it is to install and set up Efrit. There’s talk about using it for languages beyond elisp, and some share tips for making the prompts better. A few say they’ll watch the project to see how it grows. Overall, people seem interested, but some want to see real-world tests before using it every day.

---

## Build durable workflows with Postgres

- 原文链接: [Build durable workflows with Postgres](https://www.dbos.dev/blog/why-postgres-durable-execution)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840693)

This article explains why the team chose Postgres for building a durable workflow system. Their goal was to pick a data store that could save workflow state, recover from crashes, and scale well with many users.

The writers say Postgres is a solid choice because it has strong technical features, not just because it is popular and open-source. First, Postgres allows workers to safely pick tasks from a queue without fighting over the same data, thanks to its row-locking system. This helps many workers process tasks at the same time, making the system fast and scalable. Second, Postgres’s relational model and support for SQL make it easy to monitor workflows. You can make powerful queries to see what happened, find errors, or check the status of any task, which is harder in simple key-value databases. To keep queries fast, they use special indexes on important fields like time, executor, and status, but avoid indexing everything to reduce overhead. Third, Postgres transactions let them give stronger safety: they can make sure a workflow step happens exactly once, not twice, even if there is a crash. By running both the workflow step and its checkpoint in a single transaction, they avoid errors from duplicate actions.

In the Hacker News comments, many people like the idea of using Postgres for workflow storage. Some share their own success stories building systems on top of Postgres, saying it is reliable and easy to manage. Others point out that Postgres is very familiar to most developers, so teams can avoid learning new tools. A few users warn that using a database as a queue can cause problems at very large scale, and special care is needed to tune performance. Some suggest that for extreme workloads, purpose-built queue systems might work better, but agree that for most cases, Postgres is a good default. There is also discussion about exactly-once semantics—some users are impressed by the use of transactions, while others note that this only works if all steps happen inside the database. Overall, the comments show respect for Postgres’s flexibility and praise its strong feature set, especially for teams that want safety and simplicity.

---

## Ask HN: How can ChatGPT serve 700M users when I can't run one GPT-4 locally?

- 原文链接: [Ask HN: How can ChatGPT serve 700M users when I can't run one GPT-4 locally?](item?id=44840728)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840728)

Someone on Hacker News asked how ChatGPT can handle 700 million users, but they cannot run GPT-4 on their own computer. The main point is about the big difference between OpenAI’s huge system and what one person can do at home.

The article explains that running GPT-4 needs a lot of computer power. GPT-4 uses special chips called GPUs, and it needs many of them. These chips are expensive and use a lot of electricity. A normal computer does not have enough memory or speed to run such a big model. OpenAI has big data centers with many GPUs working together. They use smart tricks to split the work between the chips. They also use special software to make everything faster. This is why OpenAI can serve many people at the same time.

The article also says that OpenAI does not run a separate GPT-4 for each user. Instead, they share the model between many users. When a user sends a question, the system finds space to answer it. Sometimes, people must wait if too many users are asking questions at once. OpenAI also uses smaller versions of the model for easy questions. All these things help them to serve millions of people.

In the comments, some people say it is normal that you cannot run GPT-4 at home because it is huge. Others ask if smaller models will get better and if people can use those instead. Some think OpenAI is smart to use big data centers, but they worry about energy use and costs. A few people hope in the future, hardware will get better and cheaper so everyone can run big models. Some users share ways to run small AI models on home computers, but they agree those are not as strong as GPT-4. One person wonders if OpenAI will let people run models locally one day. Another says that sharing the big model with many people is efficient. Some worry about privacy when using cloud AI. Others are just amazed at the size and power of modern AI.

---

## Disney 1985 film The Black Cauldron was an experiment that failed

- 原文链接: [Disney 1985 film The Black Cauldron was an experiment that failed](https://www.bbc.com/culture/article/20250807-the-radical-film-that-became-a-disaster-for-disney)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44840982)

Disney’s 1985 movie The Black Cauldron was meant to change the company’s image, but it ended up being a big failure. The film was Disney’s first try at a darker, high fantasy story, and it got a PG rating, which was new for the studio.

The story follows a boy trying to stop an evil cauldron from making an undead army. The movie looked different from earlier Disney films—there were no songs, and the tone was much scarier. Disney used new technology, including computer animation and 70mm film. Many young animators worked on it, some of whom later became famous, like Tim Burton and John Lasseter.

But making the film was hard. Older Disney staff and new animators disagreed on how things should look. The story was based on a long book series, and it was tough to fit everything into one movie. During production, Disney’s leadership changed, and the new bosses were not sure about the film. One executive, Jeffrey Katzenberg, even cut 15 minutes from the movie very late in the process, upsetting the animators.

The movie cost a lot—$44 million, which was more than any Disney cartoon before. Still, it did very poorly at the box office and didn’t impress critics or audiences. Young kids found it too scary, and older viewers thought it was confusing or boring. After the failure, there were layoffs at Disney animation.

Some say The Black Cauldron almost ended Disney animation, but experts in the article believe that’s not true. The idea only became popular years later. While the movie’s loss was serious, Disney was already working on its next animated film, The Great Mouse Detective, which did much better. Roy E. Disney, Walt Disney’s nephew, is said to have saved animation at the company by insisting it continue. Four years later, Disney made The Little Mermaid, starting a new, very successful era.

In the Hacker News comments, people have different views. Some remember being scared by the film as kids and say it didn’t feel like a Disney movie at all. Others think Disney was right to try something new, even if it failed. A few say the animation and technology were ahead of their time, but the story was too dark and messy for Disney’s usual audience. Some commenters defend the film, calling it an interesting experiment, while others say it was simply a bad movie. There are also jokes about how Disney learned to stick to safer stories after this. Many agree that the movie helped push the studio to improve, leading to better films later on. Some discuss how big companies sometimes need to take risks, and even failures can lead to future success.

---

## Astronomy Photographer of the Year 2025 shortlist

- 原文链接: [Astronomy Photographer of the Year 2025 shortlist](https://www.rmg.co.uk/whats-on/astronomy-photographer-year/galleries/2025-shortlist)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44837434)

The article shows the shortlist for the Astronomy Photographer of the Year 2025, sharing some of the best space photos taken around the world. These photos include a red Moon over Shanghai, detailed shots of comets, the Milky Way, and rare events like solar eclipses and planet alignments.

Some photos needed years of planning, like the Blood Moon rising beside Shanghai’s skyscrapers, or were built from hundreds of exposures, such as the Dragon Tree Trails in Yemen. There are images from many places: Norway’s blue Northern Lights, the vast Milky Way over Utah, a golden Moon above the Italian Dolomites, and a solar prominence eruption on the Sun that stretched over 500,000 km. Others show the Solar System’s planets, close-ups of galaxies, and even the rare Northern Lights in California. Some entries used creative techniques: combining data from NASA’s satellites to create a “neon” Sun, or stacking images to capture solar eclipses and Baily’s Beads. The shortlist also includes a lunar occultation of Saturn and a comet over Hawaii, moments that happen rarely and are hard to capture.

The contest had over 5,880 entries from 68 countries, showing how popular astrophotography is. Each photo has a story, such as waiting years for the right Moon position, or traveling far to see a comet. There’s also a special category for young photographers and a community spirit among both new and experienced people who love space.

In the comments, many people praise the skill, patience, and creativity of the photographers. Some are amazed by the technical details, like using hundreds of exposures or stacking images from different times. Others discuss how much planning and luck is needed to get the perfect shot, especially for rare events. Some users share their own struggles with astrophotography, mentioning weather, light pollution, or equipment limits. A few wish the images had more technical info, like camera settings or post-processing steps, to help others learn. There are also debates about “how much editing is too much,” with some saying it’s part of the art, and others preferring more natural looks. Several comment on the beauty and inspiration of the images, saying they make space feel close and real. Others talk about sharing these photos with children or using them in schools to spark interest in science. A few suggest more focus on “naked eye” astronomy, so everyone can enjoy the sky, with or without expensive gear. Many are excited to see the final winners in September, while some joke about how their own photos never look this good. Overall, most agree that these images remind us of the wonder and size of the universe.

---

## How we replaced Elasticsearch and MongoDB with Rust and RocksDB

- 原文链接: [How we replaced Elasticsearch and MongoDB with Rust and RocksDB](https://radar.com/blog/high-performance-geocoding-in-rust)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44836463)

Radar needed to make their geolocation APIs faster and cheaper, so they replaced Elasticsearch and MongoDB with a custom Rust database called HorizonDB using RocksDB. They serve over a billion API calls per day, helping users with things like geocoding, searching places, and routing.

Before, different services and databases handled different tasks. Elasticsearch was used for forward geocoding and MongoDB for reverse. This setup was expensive and hard to scale. Elasticsearch sent too many queries across servers, and MongoDB couldn't handle large data updates or easy rollbacks.

With HorizonDB, they built a single, fast system. It uses Rust for speed and memory safety, and RocksDB as a storage engine. Rust lets the team use modern features and run safe, multi-threaded code in one process. RocksDB helps manage huge data sets on regular hardware.

They also use other tools:  
- S2 for spatial indexing, allowing quick lookups on maps.  
- FSTs for fast prefix and string searches, caching common queries to return answers quickly.  
- Tantivy as an in-process search index, so everything runs in one place instead of sending requests to another service.  
- FastText to help the search understand similar words and handle typos.  
- LightGBM for machine learning, helping figure out what users mean in their queries.  
- Apache Spark to process lots of data before loading it into the system.

Results: Their new system is faster, easier for developers, and much cheaper. They shut down many old databases and saved a lot of money. Now, they can update or add new data in a day, and everything scales better.

Hacker News commenters liked the technical depth and the clear results. Some praised using Rust for performance and memory safety and liked seeing open-source tools used together. A few people asked if the team considered using Postgres with PostGIS or other database solutions, wondering about the trade-offs. Others warned that maintaining a custom database can get tricky—bugs or scaling problems could show up later. Some admired the clever use of FSTs and in-process search, while others wanted to know how hard it was to train the machine learning parts. A few wondered about the team’s hiring and if this approach would fit smaller companies. Many agreed the story was a good example of how simple, focused tools can beat more complex stacks for certain workloads.

---

