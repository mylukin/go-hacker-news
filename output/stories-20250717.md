# Hacker News 故事摘要 - 2025-07-17

## 今日概述

Today’s top Hacker News stories cover big updates to AI assistants, new Apple language models, and changes in AI coding tools. There are also stories about open-source robot hands, running your own part of the Internet, and the world of artistic perfumes. Many stories discuss privacy, trust, and the risks or benefits of using AI. If you are interested in new tech, creative ideas, or digital independence, you will find something worth reading today.

---

## Mistral Releases Deep Research, Voice, Projects in Le Chat

- 原文链接: [Mistral Releases Deep Research, Voice, Projects in Le Chat](https://mistral.ai/news/le-chat-dives-deep)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44594156)

Mistral just added many new features to their AI assistant, Le Chat, making it better for deep research, voice chats, and organizing your work. The update brings tools like Deep Research mode for fast, structured reports, a new voice system called Voxtral, stronger support for many languages, Projects for organizing chats, and advanced image editing.

With Deep Research, Le Chat can plan, ask follow-up questions, search sources, and build clear reports, almost like working with a helpful research partner. For example, if you ask about upcoming NYSE IPOs, Deep Research gives a full summary with facts, dates, and numbers, all backed by sources. This is more detailed than simple search results, showing companies like Figma, Chime, and McGraw Hill, their values, dates, and what they do. The report explains why IPO activity is growing in 2025, gives tables, and highlights key companies in tech, health, and crypto.

Voice mode lets you talk to Le Chat instead of typing, which is handy for brainstorming or quick questions on the go. The new model, Voxtral, aims for fast, natural speech recognition. For reasoning and problem-solving in different languages, Le Chat now supports mixed-language conversations, powered by their Magistral model. You can get clear answers in English, Spanish, Japanese, Arabic, and more, even switching languages mid-sentence.

Projects help you keep chats, files, and ideas together by grouping them in special folders. This makes it easier to manage long-term work or team projects. Image editing is now smarter too: you can change details in a picture by just typing what you want to change.

Looking at the top Hacker News comments, many users are excited about the new features, especially Deep Research and Projects. Some think Le Chat is getting closer to being a real research assistant, not just a chatbot. Others like the voice mode and say it could help people who are busy or on the move. A few developers tried the new features and found Deep Research gives good references, though sometimes it still makes mistakes or includes fake links.

Some users worry about privacy if Le Chat collects lots of data, especially in companies. Others ask how well the voice mode works with different accents, and if the multilingual support is as good as claimed. A few people want to know if the image editing will compete with tools like Midjourney or DALL-E, or if it is more basic.

There are concerns about AI assistants replacing human researchers or writers, but some think these tools just help people work faster. A few commenters mention that the new features could make Le Chat useful for students, journalists, and teams, but only if the data is trustworthy. Some users like that Mistral does not require a credit card to try the app, while others wonder about the business model and if features will stay free. Overall, the mood is curious and positive, with people eager to test the updates but watching closely for any problems.

---

## Apple Intelligence Foundation Language Models Tech Report 2025

- 原文链接: [Apple Intelligence Foundation Language Models Tech Report 2025](https://machinelearning.apple.com/research/apple-foundation-models-tech-report-2025)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44596275)

Apple’s new tech report talks about two big language models for Apple Intelligence. One model is small and runs right on your device, while the other is larger and runs on Apple’s cloud.

The on-device model has about 3 billion parts and is made to work fast with Apple’s own chips. It uses smart tricks like sharing memory and using very small numbers to save space and power. The server model is even bigger and uses a special design called Mixture-of-Experts. This makes it work well and keeps costs down, while still giving good answers. Both models can understand many languages, look at pictures, and use tools to help users. Apple trained the models using lots of data from the web, books, and even fake (synthetic) data. They made sure to collect this data in a safe and legal way.

After training, Apple improved the models with extra lessons from humans and special feedback methods. The models passed tests and did as well as, or better than, similar open-source models. Apple also made a simple tool for developers, so they can use these models in their apps with just a few lines of Swift code. The models are built with privacy in mind, using things like Private Cloud Compute. Apple also checks the models carefully for safety and quality, including filters for bad content and tests for different countries.

In the Hacker News comments, some people praise Apple for running strong models directly on devices, saying this could help privacy and make things faster. Others think the server model is interesting, but wonder how “private” Apple’s cloud really is. A few users like that Apple is open about their tech, but wish the models themselves were fully open-source. Some developers are excited about the easy Swift tools and look forward to trying them. Others are more careful, saying Apple’s history with developer tools is mixed. There’s also debate about how “responsible” Apple’s AI is, with some doubting that filtering and safety checks will be perfect. Some users worry about data collection, but others trust Apple more than other big tech companies. Overall, people agree this is a big step for Apple, but they want to see how well it works in real life.

---

## Perfume reviews

- 原文链接: [Perfume reviews](https://gwern.net/blog/2025/perfume)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44588319)

This article is about a person who tries many unusual perfumes after reading a Twitter thread about weird, arty scents. The writer had never cared about perfume before and usually just wanted to not smell bad, but got curious about perfumes that are strange or artistic.

The article explains that there is a big world of indie and experimental perfumes, not just the normal sweet or flowery ones found in malls. Some perfumes are made to smell like burning leaves, farms, cold winter towns, the ocean, or even scenes from horror movies like “Room 237” from The Shining. These perfumes are not always expensive to try, because you can buy small samples for a few dollars each.

The writer wanted to see if perfume could really be an art form, so they bought about 39 different samples. They tried scents like “Room 237” (meant to be creepy), “Asphalt Rainbow” (smells like city streets and food), “Lampblack” (smells like ink and old books), “Acqua di Sale” (smells like the ocean), and “MegaMare” (smells like marshes). Some of these brought back personal memories, like fishing with a grandparent. Others were interesting but not pleasant to wear.

The writer noticed that perfume reviews online were very different—some people loved a scent, others hated it. Many perfumes just smelled chemical to the writer, but some made them feel like perfume really can be art. They liked how some scents changed over time or told a story. They especially liked incense-style perfumes, and found that “Kyoto” was their favorite, probably because of good memories about Kyoto from books and movies.

After trying all the samples, the writer decided not to turn perfume into a hobby, but did buy two bottles: Acqua di Sale (for work) and Kyoto (for personal use). They expect these bottles to last many years. Extra samples were even used to try to keep mice away from cables.

Looking at the Hacker News comments, many people were surprised that perfume can be so different and artistic. Some said they never thought about perfume as art before, but liked how this article explained it. A few readers said they also tried strange perfumes, and shared their favorites, like scents that smell like old books or wood smoke.

Others found it funny how much people disagree in perfume reviews, just like with wine or coffee. Some said they get “nose-blind” after a short time and can’t smell perfumes anymore, which matched the author’s experience. There were comments about how trying samples is a good way to explore without spending much money, and a few people gave tips on where to buy samples cheaply.

One reader mentioned that smells can be powerful for memory, and that a certain perfume brings back childhood memories. Another said they were inspired to try some new scents, while some said they were happy just not to smell bad and didn’t want to bother with perfumes at all. A few warned that it’s easy to buy too many samples and waste money, but most agreed that exploring new scents can be fun and surprising. Overall, the comments showed a mix of excitement, curiosity, and amusement about the world of weird perfumes.

---

## Hand: open-source Robot Hand

- 原文链接: [Hand: open-source Robot Hand](https://github.com/pollen-robotics/AmazingHand)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44592413)

This article is about Amazing Hand, an open-source robot hand you can build yourself. The hand is low-cost, 3D printable, and designed to be both expressive and useful for real robots like Reachy2.

The hand has four fingers, each with two moving parts, and uses eight small motors inside the hand—no cables or outside actuators needed. The design uses flexible plastic shells, making the fingers move more like a real hand. All the files to print and build the hand are free to use, and you can find the full list of parts and step-by-step guides online. If you want to control the hand, you can use either a Python script with a serial bus driver or an Arduino with special connectors. There are example programs for both options, so you can get started even if you are new to robotics.

The hand weighs about 400 grams and costs under 200 euros to build. All the CAD files and assembly instructions are available, with extra tips for printing and putting the hand together. The project includes guides to calibrate the fingers and notes about making left or right hands, as well as how to connect two hands to a robot. The motors used can sense torque, position, and temperature, but the project warns that the hand is not fully tested for picking up things safely yet. There are plans to add smarter features, like fingertip sensors and more finger options.

The article gives updates from the community, a to-do list of future improvements, and links to a Discord group for help. Thanks are given to contributors who helped with testing, software, and design.

In the comment section, some people are excited to see an open-source robot hand that is affordable and easy to build. They say this makes it much easier for students and hobbyists to try robotics. Others talk about how the hand’s design, with all motors inside and no cables, is smart and simple. A few mention that using 3D printing means anyone can make replacement parts or change the design. Some users ask questions about the strength of the hand and if it can pick up heavy things. Others want to know if it can be used for real tasks, or if it is mostly for learning. There are suggestions to add a thumb or more sensors for better control. Some people share ideas to use this hand for prosthetics, but others explain that real prosthetic hands need more testing and safety features. Overall, most people like the project and its open-source spirit, and they look forward to seeing it get better.

---

## All AI models might be the same

- 原文链接: [All AI models might be the same](https://blog.jxmo.io/p/there-is-only-one-model)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44595811)

This article says that many AI models might actually be learning the same things, even if they look different. The author explains this by talking about a guessing game called "Mussolini or Bread," where people can narrow down ideas because everyone shares a similar understanding of the world.

The main point is that both humans and AI build models of the world in similar ways. The author says that when AI tries to compress a lot of data, it gets better at understanding and generalizing, just like people do. Bigger models are better at compression and this means they are smarter and more efficient. The article brings up the Platonic Representation Hypothesis (PRH), which says that as AI models get bigger, they start to use the same features and see the world in the same way. There are examples from vision and language research that show different models begin to “think” alike.

The author also talks about how, if these models are really similar, we should be able to translate between their “embedding spaces”—the way they represent ideas and data. They worked on a project (vec2vec) that tries to do this using a method called CycleGAN, which was first used to translate images of horses to zebras and back. Their results show that it is possible to move between different AI models’ representations, even without knowing the exact pairs of data.

The article also shares results from “mechanistic interpretability,” where researchers look inside models and find that different models often have similar inner parts. Sparse autoencoders, tools for finding features in data, also show that different models learn many of the same key ideas. This means that the PRH could help us build better tools for understanding and translating between models, and maybe even help us decode things like lost languages or animal communication in the future.

In the Hacker News comments, some people liked the idea and said it matches what they’ve seen when working with different models. They point out that many AI models, when trained on the same data, end up being similar because the world itself is the same for everyone. Others are more skeptical, saying that models can still have important differences, especially if they are trained on different kinds of data or have different goals.

A few users warn that too much focus on similarity could hide real risks—like if all models make the same mistakes. Some people are excited about the practical uses, such as being able to move data between models or break open “black box” systems. Others question if it will work for things like translating whale speech or ancient languages, since we might not have enough data or context. A commenter mentions that even if models are similar, the ways they fail can be very different and hard to predict.

Some users say the ideas in the article are not new and have been discussed in other AI fields for years. A few bring up the limits of compression as a way to measure intelligence, saying it can miss important parts of real understanding. Finally, there’s interest in how this could help with security, privacy, and open-source models, but people agree there are still many open questions.

---

## Anthropic tightens usage limits for Claude Code without telling users

- 原文链接: [Anthropic tightens usage limits for Claude Code without telling users](https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44598254)

Anthropic, the maker of the AI chatbot Claude, changed how much code people can run without telling anyone first. People noticed that they could not use Claude Code as much as before, and there was no warning or message about this change.

The article explains that Claude Code was popular because it helped many programmers write and test code. Before, users could run a lot of code every day, but suddenly, the limits got much tighter. Now, users hit the usage limits much faster, which means they cannot get as much work done with Claude as before. The company did not update their website or send emails to explain the new rules. Some users say their daily work is now difficult or impossible, and they feel upset because they trusted the service.

The article says that clear communication is important for tools like this. If people know about changes early, they can plan or look for other options. Claude is used by many people for work and projects, so quiet changes can cause big problems. Some users even pay for Claude, so they expect good service and honesty. The article points out that AI companies often change rules quickly, but not telling users is a bad business move. If users do not trust the company, they may stop using the tool.

In the comments, many people are frustrated by the silent change. Some say it feels unfair and sneaky. Others remember when other AI tools made sudden changes too, so they think this is a common problem with new tech companies. A few people defend Anthropic, saying maybe they had to cut usage to save money or keep their service running. One commenter suggests that all AI companies should explain limits clearly from the start. Some users say this is why they do not like to rely too much on one tool or company. Others think that better communication would have kept users happy, even with strict limits. There are also people who say they will try other AI tools now, or go back to old ways of coding. Overall, most people in the comments agree that trust is lost when companies make surprise changes.

---

## My experience with Claude Code after two weeks of adventures

- 原文链接: [My experience with Claude Code after two weeks of adventures](https://sankalp.bearblog.dev/my-claude-code-experience-after-2-weeks-of-usage/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44596472)

This article is about the writer’s experience using Claude Code, an AI coding tool, for two weeks after switching from another tool called Cursor. The writer shares details about how Claude Code helps with coding tasks, reviewing code, managing large projects, and its differences from other tools.

Claude Code is used to write and fix code, understand big codebases, and ask questions about projects. The writer started using it more after Cursor began to limit how many API requests users could make. Claude Code offers different models like Sonnet 4 and Opus 4, which the writer finds very powerful—Sonnet 4 is fast and good for most tasks, while Opus 4 is helpful for solving tough bugs. The writer finds Claude Code’s workflow helpful, especially for reviewing code changes, resolving merge conflicts, and keeping notes. They use tricks like making the AI write notes to files and keeping important context in scratchpad files. The writer also explains that context management—knowing when to start a new chat or compact information—is important for using the tool well.

Claude Code has features like subagents, which help manage and search large codebases. The writer likes how it uses these agents to search code in parallel. There are commands and shortcuts for doing tasks like running shell commands, reviewing pull requests, and using custom instructions with “memorize”. The writer shares tips, like using Shift+Tab to switch modes, and learning how to “@” files for easier access. They also compare Sonnet and Opus models: Sonnet is better for most long tasks, while Opus is best for hard problems.

The writer plans to try more custom commands and multi-agent setups, hoping to automate more tasks and improve prompts. They point out that Claude Code’s command-line interface encourages curiosity and exploration, but its UI is not as friendly as Cursor’s and some features, like copy-pasting, could be better.

In the Hacker News comments, many readers share their own experiences with Claude Code and other AI coding tools. Some agree that Claude Code is strong for large codebases and like its context management. Others find the learning curve steep and miss better UI features. A few users discuss the high cost of subscriptions, saying it might be too expensive for most solo developers, while some think it’s worth it for professional work. There are suggestions for improving search speed and adding more models. Some users compare Claude Code to other tools like GitHub Copilot and Cursor, weighing the pros and cons of each. People also talk about the need for better copy-pasting, UI integrations, and easier ways to manage sessions. A few are excited about the idea of custom commands and multi-agent workflows. Others warn that relying too much on these tools can make it easy to miss important bugs or misunderstand code changes. Some readers like the article’s practical tips and thank the writer for sharing real-world advice. Overall, commenters share both positive and critical feedback, showing interest in how AI tools are changing coding work.

---

## Creating an Autonomous System for Fun and Profit

- 原文链接: [Creating an Autonomous System for Fun and Profit](https://blog.thelifeofkenneth.com/2017/11/creating-autonomous-system-for-fun-and.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44563711)

This article is about how one person set up their own autonomous system (AS) on the Internet, just for fun and to learn, not because it was needed. The author explains that the Internet is made up of many separate networks, each managed by different groups, and usually, regular people never need to think about this.

For most homes, you get Internet from an ISP, plug in your router, and that’s it. You don’t need to know about things like BGP (Border Gateway Protocol) or autonomous systems. But if you want to be your own ISP, or run your own part of the Internet, you need your own public IP addresses, an autonomous system number (ASN), and a router that can talk to other networks using BGP. This lets the rest of the Internet know how to reach you.

The article then explains why home users don’t need to worry about this: your ISP handles it all. The author decided to set up his own AS mostly as a challenge from a friend, and because it was a cool technical project. He lists out the steps: first, you need a company (even a simple business license will do), then you need to get a block of public IP addresses (which is hard because IPv4 addresses are running out). The author got some IPv6 space from a friend, using a simple letter of permission.

Next, you need to find other networks to connect with (“peering”). This is important so your network can talk to the rest of the Internet, and you need at least two connections to get your own public ASN. Then, you apply for an ASN through an organization like ARIN, pay the fee, and wait for approval. After that, you need a powerful router that can handle the full routing table of the Internet—not just a normal home router, but something like a Cisco Catalyst 6506, which is big, heavy, and uses a lot of power but is cheap if you buy it used.

Finally, you put everything together, set up the network in a data center, and connect it all. The process was complicated, not necessary, and mostly done for the challenge and the experience. The author is proud to say that he is now truly “part of the Internet.”

In the comments, some people are impressed and think the project is fun and educational. Others mention that running your own AS is much harder now because IPv4 addresses are hard to get and expensive. Some say it used to be easier years ago, but now the rules are stricter and the costs are higher. A few users share their own stories of running small ISPs or networks and discuss the technical challenges, like keeping up with the growing size of routing tables.

Other commenters point out that most people and even most companies don’t need to do any of this—cloud providers and hosting services handle all the hard work for you. There are also warnings: running an AS means you have to manage security, handle abuse complaints, and deal with a lot of paperwork. Some people admire the “just for fun” attitude, while others say it is too much work for not much real benefit.

A few users debate if having your own AS gives you any real independence, since you still depend on bigger networks for connections. There’s also some talk about the social side—making friends and trading favors is important for setting up peering. Overall, people think it’s a cool project, but only for those who really want to learn how the Internet works deep down.

---

## Don't Fall for AI: Reasons for Writers to Reject Slop

- 原文链接: [Don't Fall for AI: Reasons for Writers to Reject Slop](https://mythcreants.com/blog/dont-fall-for-ai-nine-reasons-for-writers-to-reject-slop/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44598534)

This article lists nine reasons why writers should not use AI to create stories or art. The main idea is that AI-generated content, often called “slop,” is bad for writers, readers, and even for the world.

First, the article says AI doesn’t understand stories or emotions. It just predicts words, so its writing is often flat and confusing. AI can’t create deep characters or strong plots. Second, AI output is built on stolen work from real artists and writers, who are not paid for it. Big tech companies make money, but creative people lose out. Third, most readers do not want to buy books made with AI—they feel tricked and see it as unfair. Fourth, using AI can cause scandals if people find out you used it, which can ruin your reputation. Fifth, if too many indie writers use AI, people might stop trusting all indie books. Sixth, you may lose copyright protection if you use AI-generated content, making it easy for others to copy your work. Seventh, using AI too much can make your own writing skills weaker, because you stop practicing. Eighth, AI causes harm in many ways: it spreads lies, promotes hate, makes scams easier, uses lots of water and electricity, and takes jobs from people. Ninth, the article says that only you can write with your own voice—AI cannot replace real personal stories.

In the comment section, many people agree that using AI is a shortcut and takes away real skill. Some say learning to write takes time but is worth it, and AI removes the joy and pride in doing hard work. Others point out AI’s problems with logic and understanding, sharing funny examples of bad AI answers. A few commenters use AI for brainstorming or to help with writer’s block, but still prefer to write their own stories. Some people think AI might be helpful for people with disabilities who can’t create art in traditional ways. There is also talk about whether AI can be used ethically, but many believe it always depends on copying human work. Some warn that using AI too much is like cheating yourself, and that it is unfair to readers and other writers. A few comments discuss the need for good laws and rules about AI, but others think regulation is hard or gets blocked by politics. Finally, a few people are not totally against AI, but say we must be careful and mindful about how we use it, always remembering the value of real human creativity.

---

