# Hacker News 故事摘要 - 2025-07-03

## 今日概述

Today’s top Hacker News stories look at classic tools rewritten in Rust, new ideas about work and career, open-source robots, creative wind-powered machines, and how software caching works. Other stories cover Google’s new privacy tool, smarter ways to sort data, startup jobs, real-time speech translation, and what makes a city’s food unique. If you like technology, creative projects, or data, there’s something here for you.

---

## Introducing tmux-rs

- 原文链接: [Introducing tmux-rs](https://richardscollin.github.io/tmux-rs/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44455787)

The article talks about someone rewriting tmux, a popular terminal tool, from C to Rust as a hobby project. The author used a tool called C2Rust to start, but later rewrote the code by hand for better results.

First, the author explains that C2Rust could turn C code into Rust, but the output was messy and hard to read. For example, named constants became numbers, and there were many extra type casts. Because of this, the author decided to translate each C file to Rust manually, making sure the code was clear and correct.

The build process was complicated. At first, the author used both C and Rust together, but later changed things so that Rust was the main language, linking in the remaining C code. This made it easier to keep everything working as more code was translated.

While translating, the author found several bugs. One bug happened because a function was declared wrong in C, causing memory errors. Another bug was from a small mistake in how a struct was defined in Rust, making the data line up differently than in C.

The author explains how some C features, like raw pointers and goto statements, needed special care in Rust. For example, C pointers became "raw pointers" in Rust, which are less safe and harder to use. Goto statements were replaced with labeled loops and blocks in Rust. The author also had to reimplement macros for data structures and rewrite the parser from yacc to a Rust tool called lalrpop.

For editing, the author mostly used Vim with macros to speed up the translation, but also tried AI tools like Cursor. The AI tools didn’t save much time, but did help reduce finger pain from typing so much.

In the end, the codebase is now fully in Rust, but it is still not very safe or stable yet. The next step is to make the code "safe Rust." The author released version 0.0.1 for others to try and give feedback.

In the Hacker News comments, some people praised the ambition and effort of porting such a big project. They liked seeing tmux in Rust but worried about bugs and stability, since tmux is important for many users. Some thought using C2Rust was clever, while others agreed that hand translation is better for long-term maintainability.

A few commenters discussed the challenges of translating C to Rust, especially with tricky things like pointer types, memory layout, and macros. There was talk about whether projects like this should aim for "idiomatic" Rust or just a working translation. Some loved the idea of eventually having a safer tmux, while others wondered if it’s worth the effort compared to improving the original C code.

People also shared tips about build systems and using tools like lalrpop. A few were curious if AI could soon make this kind of port easier. Others reminded that even after a rewrite, testing and fixing bugs is a huge job.

Overall, the community was excited to see progress, but very aware of the big risks and hard work needed to fully replace the trusty C version of tmux.

---

## Flounder Mode – Kevin Kelly on a different way to do great work

- 原文链接: [Flounder Mode – Kevin Kelly on a different way to do great work](https://joincolossus.com/article/flounder-mode/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44455933)

This article is about Kevin Kelly and his unique way of doing meaningful work, called “Flounder Mode.” Instead of chasing big titles or building a huge company, Kelly has spent his life exploring many different interests and projects.

Kelly worked on the Whole Earth Catalog, helped start the WELL online community, and co-founded WIRED magazine. He has written books and essays on many topics, advised on movies, and traveled widely. He helped with early ideas in the quantified self movement (like tracking your health with gadgets), and his “1,000 true fans” idea inspired the creator economy. He also works on long-term art and science projects, like building a giant clock designed to run for 10,000 years.

The author of the article shares her own story. She had a promising career at big tech companies like Google and Stripe but wasn’t interested in climbing the corporate ladder. She preferred working on fun projects, helping with company culture, and trying new things, even if it meant her resume looked strange to recruiters. She sometimes felt unsure and worried she had chosen the wrong path, especially when comparing herself to colleagues who chased titles and promotions.

Meeting Kevin Kelly in his studio, she notices how his space is full of interesting objects, books, and stories. Kelly explains that he simply follows his interests and doesn’t think much about traditional success. He says greatness is overrated and comes with big problems. Instead, he believes in working with joy, curiosity, and without being obsessed with money or fame. To him, the process of doing is more important than reaching a defined goal.

The article compares Kelly’s happy, creative approach to the more extreme, stressful culture often found in tech, where people believe you must suffer to be great. The author wonders why it seems strange to want to have a “good day, most days” at work, and why enjoying your work isn’t seen as ambitious enough. After spending time with Kelly, she feels inspired to value joy and curiosity in her own career.

In the Hacker News comments, many people appreciate Kelly’s way of working and find his story inspiring. Some say that having an “illegible” or unusual career path can lead to more interesting experiences and personal growth. Others share their own worries about not following the traditional path, and feel encouraged by Kelly’s example. A few commenters point out that it’s hard to ignore pressure from society or family to be successful in obvious ways, like getting promotions or making lots of money.

Some people debate whether Kelly’s approach is possible for everyone. They mention that financial freedom, luck, or privilege may make it easier to follow your interests. Others argue that you can still bring curiosity and joy to any job, even if you have to work for money. There are also comments about balancing ambition and happiness—some say it’s okay to want both, and that suffering isn’t required for achievement.

A few commenters admire Kelly’s “1,000 true fans” idea and say it changed how they think about making a living from creative work. Others feel that the tech world needs more role models like Kelly, who can show that being kind, balanced, and happy is valuable too. Some worry that the “tortured genius” model is too common in Silicon Valley and that it leads to burnout. Overall, most people agree that Kelly’s joyful, curious approach to work is refreshing, and wish more people could feel free to “flounder” in their careers.

---

## Launch HN: K-Scale Labs (YC W24) – Open-Source Humanoid Robots

- 原文链接: [Launch HN: K-Scale Labs (YC W24) – Open-Source Humanoid Robots](item?id=44456904)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44456904)

K-Scale Labs is a new company making open-source humanoid robots. The team just launched and shared their work on Hacker News.

The robots from K-Scale Labs are designed to be affordable and easy to build. They use 3D-printed parts and off-the-shelf motors, so you do not need expensive, special equipment. The software is fully open-source, which means anyone can see, use, or change the code. The company wants more people to build and improve robots together. Their first robot is called "K-Humanoid." It is about as tall as a child, and it can walk, wave, and pick up small things. They use ROS (Robot Operating System) for the control software, which is a popular tool in robotics. The project includes clear instructions and parts lists, so hobbyists and schools can build the robot too. K-Scale Labs has videos showing the robot moving and doing simple tasks. They hope these robots will help people learn about robotics and make new things. The team says they want to build a community to share ideas and improvements.

People in the comments are excited about open-source hardware and robotics. Some say it is great to see affordable robots for learning and research. Others ask how strong or safe the robot is, especially if it falls or is used by kids. A few worry about the cost, since even cheap motors and parts can add up. Some commenters want to know if the robot can do more complex jobs, like using tools or running. Others share ideas for making the robots better, such as adding sensors or cameras. Some people remember past open-source robot projects and hope this one lasts longer. There are questions about how easy it is for beginners to build and program the robot. A few users offer to help or join the community. Overall, the main feeling is hope that open-source robots can help more people get into robotics.

---

## Wind Knitting Factory

- 原文链接: [Wind Knitting Factory](https://www.merelkarhof.nl/work/wind-knitting-factory)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44458890)

The article talks about the Wind Knitting Factory, a special knitting machine powered by wind and attached to the outside of a building. When the wind blows, the machine uses its large blades to turn and knit a long scarf that hangs down the wall. The speed of knitting depends on how strong the wind is—more wind makes the machine knit faster, less wind makes it knit slower. The scarf grows longer and longer until it reaches a window. Then, it is pulled inside where people can watch it get even longer. From time to time, the scarf is cut, finished, and turned into scarves for people to wear. Each finished scarf has a label showing when and how it was made by the wind. The project is meant to show how wind, even in a city, can be used for small production. It also makes the whole process of making something very visible to the public.

Top comments on Hacker News called this project creative and fun. Some people like that it mixes art, engineering, and green energy in a new way. Others say it is a smart way to show people how energy from nature can be used for making things. A few users wonder how well it works if the wind stops or if the yarn gets tangled. Some ask if it is practical for real use, or just for art. There are jokes about hoping the wind blows in the right direction, or how long someone must wait for a scarf on a calm day. Others note that this kind of project can inspire people to think more about clean energy and local production. A few users share ideas for other things that could be made with wind power, not just scarves. Some people mention they would love to own a scarf made by the wind. Overall, most comments are positive and say this project is both charming and meaningful.

---

## Caching is an Abstraction, not an Optimization

- 原文链接: [Caching is an Abstraction, not an Optimization](https://buttondown.com/jaffray/archive/caching-is-an-abstraction-not-an-optimization/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44432506)

This article says people often think caching is just for making software faster, but the author believes caching is really an abstraction—a way to make programs simpler and cleaner. The author explains that instead of always deciding exactly when and what data should be kept in memory, we use caching to handle this job for us, creating a clear separation between how we get data and where it is stored.

The article asks why we use general caching rules like LRU (Least Recently Used) or LFU (Least Frequently Used), instead of managing everything ourselves. The answer is that caching provides a useful boundary in our software: we can just ask for data, and the caching system decides if it should come from memory, disk, or elsewhere. This lets us write simpler code, because we don’t have to manage every detail.

Databases and operating systems use these ideas all the time. For example, when you read from disk, the OS pulls data into memory automatically—the “page cache”—so next time it’s faster. This kind of caching is baked into how modern systems work.

There are problems too. Sometimes abstractions like the page cache can be misused, causing issues with things like saving files (`fsync`). It also raises questions about whether we should separate these concerns or not.

The author warns that focusing only on tuning caching algorithms can be a distraction. The real problem is wanting your data to be fast and available, not just “winning” at the cache game.

But in the real world, data access is unpredictable. We can't always know what data will be needed next, so we rely on rules and guesses (heuristics). That’s why smart caching is still important. Caching is such a strong abstraction that it’s worth the effort to study and improve it.

Finally, the article says the best abstractions are often invisible—until they cause problems. That makes it easy to forget how important they are.

Many Hacker News commenters liked the idea of caching as an abstraction, not just an optimization. Some said they used to think of caches only as ways to speed up code, but now see how they help organize big systems. Others pointed out that caching mistakes can cause bugs or hard-to-find problems, especially with consistency and when caches are out of sync.

A few people thought the article was too harsh on cache tuning. They said that, in practice, picking the right caching algorithm can really improve performance, especially in systems with limited memory. Some shared stories where custom caching—based on their own data patterns—worked better than standard rules like LRU.

Others reminded everyone that caching is not a magic fix. If you cache the wrong data or forget to clear your cache, you can end up with slow or broken systems. More than one person said that, sometimes, the best choice is to not use a cache at all and keep things simple.

One commenter compared cache layers to plumbing: you don’t notice them until there’s a leak. Another said that abstractions are good, but you need to know how they work underneath, or you’ll run into trouble when things go wrong.

A few also discussed how new hardware, like fast SSDs, might change how we use caches in the future. Most agreed that, while caching can be tricky, it’s still a powerful tool—if used with care.

---

## Opening up ‘Zero-Knowledge Proof’ technology

- 原文链接: [Opening up ‘Zero-Knowledge Proof’ technology](https://blog.google/technology/safety-security/opening-up-zero-knowledge-proof-technology-to-promote-privacy-in-age-assurance/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44457390)

Google has released its Zero-Knowledge Proof (ZKP) code as open source to help with online privacy, especially for age checks in Europe. This move supports new EU rules that want safe digital IDs and more privacy for users.

Zero-Knowledge Proof is a way to prove something is true—like being over 18—without showing any other personal data. This means people can prove their age to websites without sharing their name, birthdate, or ID number. The open source ZKP tools are free for anyone to use, including developers, businesses, and researchers. Google worked with Sparkasse, a big bank in Europe, to make sure this technology fits the needs of banks, governments, and the new “EUDI Wallet” digital ID system coming in 2026. By sharing the code, Google hopes different groups can build better privacy solutions and speed up digital wallet projects across the EU. The idea is to help both users and companies trust online systems more, since less private information is shared or stored.

People on Hacker News had a lot to say about this. Some are happy Google is making ZKP code public, saying it can help make the internet safer and give users more control. Others worry about how hard ZKP can be to use or check for mistakes, so they ask for more open review and testing. A few users point out that even with good tools, rules and companies might still collect too much data, so technology alone is not enough. Some are hopeful that governments and banks will use this code, but others fear big companies might still find ways to track users. There are also developers excited to play with the code and maybe use it in their own apps. A few people remember past times when “open source” did not always mean “easy to use” or “free from problems.” Some question if Google did this to help the community or just to meet EU rules. Overall, the community sees this as a good step, but they want careful testing and clear rules to protect privacy for everyone.

---

## An Algorithm for a Better Bookshelf

- 原文链接: [An Algorithm for a Better Bookshelf](https://cacm.acm.org/news/an-algorithm-for-a-better-bookshelf/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44432351)

This article talks about a new algorithm to organize books on a bookshelf, which is a problem that also shows up in computer science when keeping big lists sorted. In libraries and in data structures, it is important to leave some empty space on shelves or in lists, so adding new items is easier and does not need moving everything. 

The “bookshelf problem,” also called the “list labeling” problem, is about how to add new books (or data) to a sorted list with the least effort. If you always put new books at the start, you will have to move all the other books each time, which is slow when you have many books. In 1981, computer scientists found a better way, called a "smooth" algorithm, that only needs about log₂(n) moves each time. For years, no one could beat this method, and many believed it was the best possible.

Later, researchers found that if the algorithm is both random and not smooth, it might do better. In 2016, a "history-independent" algorithm was made. This means the final order does not reveal how books were added or removed before. This idea came from privacy research and helped protect the data’s history. Then, in 2022, a new algorithm got the cost per book down to log₁.₅(n) moves by using randomness and being “lazy”—it did not rush to fix crowded spots on the bookshelf, making it harder for anyone to force a lot of work.

Now, the newest algorithm mixes “history independence” and the ability to respond to attacks, but in a smart, random way. It adapts to problems, but the timing is random, so nobody can guess how to break it. The new method cuts the average number of moves per new book to about log(n) × (log(log n))², which is very close to the theoretical best. This could make the new solution useful in real databases or social networks, where big data can arrive all at once in one spot.

The researchers say it is still hard to use these new algorithms in real systems, and more work is needed. But if someone can make a practical version that really reaches log(n) cost, it could replace binary search trees and change how sorted data is handled.

In the comments, many people say they never thought about how leaving space on a shelf relates to computer algorithms, and they enjoy seeing math and real life connect. Some programmers wonder how this could help with real databases or memory systems. Others say the problem is interesting, but it may be hard to use these new ideas in practice because real systems have other challenges. A few say they still like binary search trees because they are simple and work well, but they are open to new ideas if they can be made easy and fast. Some readers are excited about the “history independence” idea and think it could help with privacy in data storage. There is also debate about how much randomness helps in algorithms, with some saying it is powerful, and others saying it can make debugging harder. Overall, people are curious to see if these new algorithms will become important in practice or stay mostly an academic win.

---

## Converge (YC S23) well-capitalized New York startup seeks product developers

- 原文链接: [Converge (YC S23) well-capitalized New York startup seeks product developers](https://www.runconverge.com/careers)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44459146)

This article is a job posting from Converge, a New York startup backed by Y Combinator, looking for product engineers. Converge builds tools to help online stores track where their customers come from and improve their marketing.

The company is small, with only five people, but already has more than $1 million in yearly revenue and over 180 customers. They say this is a rare chance to join a startup with strong product-market fit as the sixth employee. Converge competes with big names like Segment, Fivetran, and Google Tag Manager, but offers new hires ownership over entire products, not just small features. Their platform is used every day by one-third of their users, which is much higher than most SaaS companies. The company processes about 20 million customer actions each day and handles $3 billion in sales yearly, so there are real engineering challenges.

Converge values urgency, deep understanding, humility, and simplicity. They have raised $5.7 million from respected investors. The main open position is a senior full-stack engineer with at least four years of experience, skilled in React, backend development, and databases. They want people who can work across the stack, handle full product ownership, and understand how their work affects the whole system. The compensation is $175,000 to $230,000 plus equity, with health and retirement benefits. Their interview process is fast and includes a paid “Superday” where candidates work with the team on real problems. The founders all have technical backgrounds and strong connections from past jobs and school.

In the Hacker News comments, some people are impressed by how much the small team has achieved, saying it shows strong product-market fit and good business sense. Others note that the salary is high for startups but normal for New York, and like that equity is offered. A few commenters wonder about the work-life balance, since the company says it values urgency and has a small team with a big workload. Some people are excited by the chance to own an entire product, while others worry about the pressure and expectations that might come with it. There’s interest in the technical challenges, and some ask if remote work is possible or if they must be in New York. Others point out that competing with big companies is tough, but being small and focused can be an advantage. A few people share their own experience working at early-stage startups, saying it can be fun but also stressful. Some like the paid trial day in the interview process, calling it fair and useful for both sides. Overall, people see both risks and rewards in joining a company like Converge, and agree that it could be a good fit for the right person.

---

## High-Fidelity Simultaneous Speech-to-Speech Translation

- 原文链接: [High-Fidelity Simultaneous Speech-to-Speech Translation](https://arxiv.org/abs/2502.03382)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44458877)

This article talks about Hibiki, a new AI model for real-time speech-to-speech translation. The goal is to let people talk in different languages and understand each other right away, with both the words and the voice sounding natural.

Hibiki is a decoder-only model, which means it focuses on turning input into output efficiently. It uses a “multistream language model” to handle both the original and target languages at the same time, listening and translating as you speak. The model creates both text and audio tokens, so it can do both speech-to-text and speech-to-speech translation. A key problem with real-time (simultaneous) translation is deciding when to start translating; you can’t just wait for the person to finish talking. Hibiki solves this by using another translation system to guess the best timing for each word, creating training data that helps the model learn when to translate. After being trained, Hibiki can adapt in real time, so it doesn’t need to wait for full sentences. In tests with French-to-English translation, Hibiki offers very good translation quality. It also keeps the speaker’s voice and style, making the translation sound more like the original person. The system is simple enough to work on devices in real time, not just in the cloud. The authors share code, models, and audio demos so others can try it out.

In the comments, some people are excited about the progress in speech technology and think this could help break down language barriers. Others worry about the cost and speed of running such models on normal devices, especially for less common languages. A few mention that keeping the speaker’s voice and emotion is very important for real conversations, and they are curious how well Hibiki does this. Some users point out that real-time translation is still hard for messy or noisy speech, like accents or background noise. There is also interest in how the delay (lag) feels to users who are waiting for the translation. A few are concerned about privacy if the translation happens in the cloud, while others like that Hibiki can run on a device. Some wonder how well it can handle jokes, slang, or cultural differences. There are technical questions about how the model actually aligns speech and translation. Others hope this technology will be open source and help people around the world talk to each other more easily.

---

## Stalking the Statistically Improbable Restaurant with Data

- 原文链接: [Stalking the Statistically Improbable Restaurant with Data](https://ethanzuckerman.com/2025/07/03/stalking-the-statistically-improbable-restaurant-with-data/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44457215)

The article looks at what kinds of restaurants you’re likely to find in a typical American city, and which ones are surprising or rare. The author collected data from the Google Places API for over 340 US cities with more than 100,000 people to see patterns in restaurant types.

He explains that some cities have “statistically improbable” restaurants—like great Nepali or Gambian food in small towns—which often point to unique local communities, like refugee or student groups. To understand what’s “improbable,” he first builds a picture of the “average” city’s restaurant mix, calling his imaginary city “New Springfield.” Based on the data, New Springfield would have about 305 restaurants: around 20% are fast food (with lots of Starbucks, Dunkin’, McDonalds, Subways, etc.), about a third are “American” (like diners, BBQ, steakhouses), and the rest serve international foods, with Mexican, Chinese, and Italian being the most common. He notes the data is messy—cities differ a lot, and the Google API sometimes misses restaurants or mislabels them.

He finds that bigger cities have more restaurants, but not always as many as you’d expect—cities known for their “creative economies” (like Austin, Seattle, San Francisco) have more restaurants than average, while some large cities have fewer. Smaller cities near big ones often have fewer restaurants, probably because people travel to the bigger city to eat out.

He uses vectors (lists of numbers showing restaurant types per city) to find the cities closest to this “average” mix—places like Lexington, KY, and Columbus, OH are most “typical.” Some cities, like Garden Grove, CA, or Quincy, MA, are very unusual, often because of big immigrant groups or special local culture. He also looks at outliers: for example, Fremont, CA, has a lot of Afghan restaurants thanks to Afghan immigrants, and Newark, NJ, has more African and Brazilian restaurants than most cities.

He tries to spot trends: more fast food is found in fast-growing suburbs, not just poorer areas. Richer and more urban cities (San Francisco, Seattle) have fewer fast food outlets. Cities near the Mexican border or with large Latinx populations have the most Mexican restaurants, while places like Quincy, MA, have very few, reflecting the local demographics. He lists the top cities for every kind of restaurant, like Indian, Korean, or Vietnamese, showing how some foods cluster in certain places.

In the Hacker News comments, many people liked the idea and shared stories about finding surprising restaurants in unexpected places. Some users pointed out that Google’s categories are confusing—what counts as “Mediterranean” or “Middle Eastern” is unclear, and some cuisines are missing from the data. Others wondered how much self-labeling by restaurants affects the results, or noted that chains can distort the “average” city picture.

Some commenters thought the focus on cities over 100,000 left out interesting small towns, where rare restaurants might stand out more. A few brought up the limits of Google’s data: it misses hidden gems, new places, or mislabels cuisines, so the numbers aren’t perfect. Others discussed how migration patterns and local colleges shape food scenes, agreeing with the article’s points about refugee or student populations. Several people liked the open-source approach and said they’d love to play with the data or see code samples. Finally, there was debate about what makes a place’s food scene “average” or “special”—some felt the quest for “average” is less interesting than finding the oddballs.

---

