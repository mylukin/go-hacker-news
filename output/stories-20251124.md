# Hacker News 故事摘要 - 2025-11-24

## 今日概述

Today’s top Hacker News stories cover Pebble making its smartwatch software and hardware open source, new AI tools and models from Anthropic, and a big power outage at TSMC’s US chip factory. Other trends include fast progress in AI, new ways to customize large language models, and a retro-style terminal app. There are also stories about switching firewall systems and high prices for DDR5 RAM. Most discussions focus on openness, tech progress, and the challenges of new hardware and AI tools.

---

## Pebble Watch software is now 100% open source

- 原文链接: [Pebble Watch software is now 100% open source](https://ericmigi.com/blog/pebble-watch-software-is-now-100percent-open-source)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46037626)

Pebble’s watch software is now fully open source, meaning anyone can download, build, and run every piece needed to use a Pebble watch. The team also released the source code for the Pebble mobile app and made the Pebble Appstore more open and decentralized.

The article explains why making Pebble completely open source is important for the long-term future of the watch. The hardware is now easier to repair; for example, you can unscrew the back to change the battery, and the design files are available online. The software is now fully open, so if the company ever shuts down, people can still use and improve their watches. PebbleOS, the main software for the watch, has been open source since January, and now the mobile companion app is open too. This is important because, without the mobile app, the watch is almost useless. The developer tools and Appstore are also improved, now working on modern computers and even in the browser. The Appstore supports multiple “feeds,” so anyone can create or host their own collection of Pebble apps. There’s also a public backup of the Appstore on Archive.org, which helps protect the apps from being lost if a server goes down.

Some parts of the Pebble software, like the heart rate sensor and certain cloud services, still use non-free components, but these are optional. The main watch features will always stay open source. The article also gives an update on the new Pebble Time 2 watch: production is going well, but there might be delays due to Chinese New Year. Most people who pre-ordered will get their watches in March or April. There will be four color choices, and soon, people will be able to pick their favorite.

In the Hacker News comments, many people are excited and happy to see Pebble’s software open sourced. Some users say open source will help the Pebble community last a long time, and it sets a good example for other hardware makers. Others remember the trouble they had when the old Pebble company closed, and they could not use their watches—now, they feel more secure. A few commenters ask about the non-free parts, saying it would be even better if everything was open, but most agree the important pieces are now free. Some are interested in building custom Pebble-compatible devices using the released hardware files. Others talk about how open development tools will help new app makers join the Pebble world. A few mention that having multiple Appstore feeds is smart, so one server going down will not hurt everyone. Some are surprised the Pebble community is still alive and strong, showing how much people love simple, hackable gadgets. There are also questions about how updates and bug fixes will be managed in the open source world. Finally, many people thank the developers and say they look forward to seeing what the Pebble community does next.

---

## Claude Advanced Tool Use

- 原文链接: [Claude Advanced Tool Use](https://www.anthropic.com/engineering/advanced-tool-use)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46038047)

This article is about new features for advanced tool use on the Claude AI Developer Platform. It explains how Claude can now work better with many tools at the same time, making it easier to build smart agents for complex tasks.

The main idea is that old ways of using AI with tools were slow and used too much memory (tokens). Old systems would load all tool information at once, which could use over 100,000 tokens before even starting a task. This made things slow and crowded out important information. Sometimes, the AI would also pick the wrong tool or use the wrong settings, especially if tools had similar names.

To fix this, Anthropic added three new features:

1. **Tool Search Tool:** Instead of loading every tool at the start, Claude now finds and loads only the tools needed for the current job. This saves memory and makes tool selection more accurate.
2. **Programmatic Tool Calling:** Claude can now write code (like Python) to control how it uses tools. This means Claude can run several tools in order, process big data, and only see the final results, not all the details. It’s faster, uses less memory, and makes fewer mistakes.
3. **Tool Use Examples:** Developers can now show Claude real examples of how to use each tool. This helps Claude learn not just what’s allowed, but what’s actually correct or expected, like what format to use for dates or IDs.

The article gives an example with Excel, showing how Claude can now work with spreadsheets with thousands of rows without slowing down. It also describes how to set up these features, when they are useful, and best practices for using them.

In the Hacker News comments, some readers are excited about these changes. They say that being able to search for tools on demand and use code for workflows makes AI much more powerful for real-world tasks. People like that this approach saves memory and allows for more complex operations.

Others worry about security. They ask how safe it is to let Claude run code or control important tools, especially in business or server environments. Some suggest strong limits or careful review of what code can do.

A few developers mention that this system reminds them of old ideas in software, like plugin architectures or dynamic loading. They think it’s smart to bring these ideas to AI. Some users wonder how easy it will be for small teams to set up all these features, or if it will mostly help big companies.

There’s also discussion about how well Claude will handle mistakes or tricky edge cases, and whether the tool examples system can really capture all the special rules of a company’s tools. Some think it’s a step forward, but say real-world testing will show how well it works.

Finally, several people are hopeful that this will make AI agents more useful for tasks like DevOps, data analysis, and customer support, as long as the tools stay easy to use and safe.

---

## Claude Opus 4.5

- 原文链接: [Claude Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46037637)

Claude Opus 4.5 is the new AI model from Anthropic, said to be smarter, faster, and better at coding and office tasks than earlier versions. It claims top results on software engineering tests, improved reasoning, and more efficient use of tokens, making it cheaper to use for developers and companies. The model now powers updated tools for coding, agents, Excel, Chrome, and desktop apps, with longer conversations, better planning, and fewer errors. Users say Opus 4.5 is very good at complex code changes, planning big projects, and handling long, multi-step tasks. It can write and review code well, automate office work, and generate long, organized text. The new “effort” setting lets developers choose between speed or deep analysis. Opus 4.5 also did better than any human on a tough engineering test, though the test measures only technical skills, not teamwork or communication. The model can find creative ways to solve problems, sometimes working around rules in smart ways. Anthropic says Opus 4.5 is their safest model so far, stronger against prompt injection attacks and better at following rules. Updates make it easier to use in daily work, and limits on usage have increased for most users.

Hacker News commenters have mixed feelings. Many are impressed by the technical progress and benchmark results, especially in coding and efficiency. Some developers appreciate the lower price and token use. Others warn that benchmarks and demos do not always show how well the model works in real projects. A few are uneasy about AI models beating humans at engineering tests and what that means for jobs. Some point out that “creative” solutions can be a problem if the AI finds loopholes or unexpected paths, which could lead to errors or unwanted results. Commenters talk about safety and alignment, saying true safety is hard to measure and companies must be careful. There is interest in the “effort” setting, with people curious if it will really help control costs or quality. A few wish for more open-source options, while others are excited to try the new tools in their own workflows. Some note that Anthropic’s focus on safety and partnerships with Microsoft and others could shape the future of AI use at scale. Overall, the discussion shows both excitement for new features and caution about real-world impact.

---

## TSMC Arizona Outage Saw Fab Halt, Apple Wafers Scrapped

- 原文链接: [TSMC Arizona Outage Saw Fab Halt, Apple Wafers Scrapped](https://www.culpium.com/p/tsmc-arizona-outage-saw-fab-halt)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46037324)

TSMC’s factory in Arizona had a power outage that stopped production and forced the company to throw away some wafers made for Apple. The article explains how this shutdown happened and why it’s a big problem for both TSMC and its customers.

The factory lost power for about 12 hours. Because of this, machines stopped working and some of the silicon wafers were damaged. These wafers are very expensive and take weeks to make. When they are ruined, it means lost money and lost time. Apple was one of the main customers affected, since they use TSMC chips in their products. The article says that TSMC had to throw out these partly-made chips, and they cannot be fixed or reused.

The outage also shows that making chips is very sensitive work. Even a short stop can cause a lot of waste. Factories like these need stable electricity and good backup plans. TSMC is working to improve its Arizona site, but this problem shows that it is hard to build chip factories outside of Taiwan, where TSMC has more experience.

Some comments on Hacker News said the outage is not a surprise, since factories in the US may face more power problems than in Taiwan. Others pointed out that building new fabs in the US is difficult because of different rules and less skilled workers. Some people wondered if TSMC should have better backup systems, like bigger batteries or generators.

A few commenters said this shows how hard it is to move chipmaking to the US, even with lots of money and help from the government. Others said it’s normal to have some problems when starting a new factory, and things will get better with time. Some people were worried about the cost of lost wafers and what it means for Apple’s product plans. A few said this shows why TSMC is so careful about where it builds factories. Others thought this was a good lesson for other chip makers. Some commenters also talked about how important it is for the US to have its own chip factories, even if there are problems at first.

---

## Cool-retro-term: terminal emulator which mimics look and feel of the old CRTs

- 原文链接: [Cool-retro-term: terminal emulator which mimics look and feel of the old CRTs](https://github.com/Swordfish90/cool-retro-term)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46036895)

Cool-retro-term is a terminal emulator for Linux and macOS that looks like an old CRT monitor. Its main goal is to give you the style and feel of retro computers, with glowing text, curved screens, and classic colors. The app uses Qt5 and a special QML port from Konsole, which is another terminal program. You can change settings like colors, fonts, and effects from a menu inside the app. There are different color themes, such as green, amber, and blue, that match old computer screens. The program is lightweight and does not use much system power. You can install it from your Linux distribution’s package manager, or download an AppImage for Linux or a DMG for macOS from the GitHub releases page. There are also instructions for building it from the source code. The project is open source and has many contributors. You can support the developer through Patreon or PayPal.

Commenters on Hacker News have mixed feelings. Some love the nostalgic look and remember using real CRTs in the past. Others say it is fun for a few minutes, but not practical for everyday work, because the special effects can be distracting. A few people want even more accurate emulation, like including screen flicker or curved glass effects. Some users point out that this terminal is mostly for looks and does not add new features for productivity. A few mention that it is a good way to show off at conferences, or to make screenshots look cool. There are comments about performance; most say it runs well, but some older computers may struggle. Some people ask if there is a Windows version, but right now it is only for Linux and macOS. Others share tips for getting similar retro effects in other terminal apps. A couple of users are worried about eye strain from glowing colors, but others say it is not a problem if you adjust the settings. Some suggest it could be fun for games or retro programming projects. There is also praise for the open source community and the number of contributors. Overall, many agree it is a neat project, even if only a few will use it every day.

---

## Three Years from GPT-3 to Gemini 3

- 原文链接: [Three Years from GPT-3 to Gemini 3](https://www.oneusefulthing.org/p/three-years-from-gpt-3-to-gemini)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46019898)

This article looks at how AI has grown quickly, from GPT-3 to Google’s Gemini 3, in just three years. It explains why this fast progress is important for technology and for normal people.

The writer says GPT-3 surprised everyone in 2020 because it could write and answer questions almost like a human. After that, AI models kept getting better. GPT-4 came out and was smarter, more reliable, and good at many tasks. Now, Google’s Gemini 3 is here, and it can understand not just text, but also pictures and even video. The article shows how each new model is much better than the last one, and improvements come faster each time. The writer points out that AI is not just for tech experts anymore—people in many jobs use it, from teachers to lawyers. Some companies now build tools and services around these models. The article also talks about risks, like mistakes the AI can make, and how it might change jobs or education. But the main idea is that AI is moving very fast, and everyone needs to pay attention.

In the comments, some people are amazed by how quickly AI is improving. They remember when GPT-3 felt magical, and now Gemini 3 is even more impressive. Others worry about mistakes AI can make and say we must be careful before using it for important work. A few developers say the new models help them write code faster or test ideas, but some miss the “old days” when AI was simpler and easier to understand. There’s also debate about how much these models really “understand” language, or if they just copy patterns from data. Some commenters want more open-source AI, so regular people can study or improve it. Others are excited about using AI in schools or small businesses. Many agree that AI will keep changing fast, and nobody is sure what will happen next.

---

## The Bitter Lesson of LLM Extensions

- 原文链接: [The Bitter Lesson of LLM Extensions](https://www.sawyerhood.com/blog/llm-extension)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46037343)

This article is about how large language models (LLMs) like ChatGPT have become more powerful and flexible over the past few years, and how people can now extend or customize them in many ways. At first, people just pasted text into chat boxes, but now LLMs can help with coding, browsing, and other tasks.

The article explains how LLM extensions changed over time. ChatGPT Plugins were one of the first big steps, letting LLMs use APIs to do more things. However, early models had trouble with complex APIs and the user experience was not great. The Code Interpreter plugin made things better by allowing LLMs to run code in a safe way.

Next, OpenAI added Custom Instructions. This was a simple way to add user preferences to every chat, making things easier and less repetitive. Later, Custom GPTs let users package instructions, files, and actions into special versions of ChatGPT. This made LLMs feel more like apps, but less open-ended than the original plugins.

ChatGPT Memory brought automatic personalization. It remembers things about you, like if you are vegetarian, and uses this in future chats. Cursor Rules went further, letting you put custom instructions directly in your codebase as files. This made LLM extensions feel more natural for developers.

Model Context Protocol (MCP) allowed LLMs to use real tools, like reading code or querying databases, by connecting to a server. This was powerful but complicated for users to set up. Some startups tried to make MCP easier to use.

Claude Code, from Anthropic, added many ways to extend LLMs, like repo instructions, tools, commands, and sub-agents. Agent Skills, the latest idea, are simple folders with scripts and markdown files. The LLM reads these when needed, making it easier and more flexible than MCP.

The author believes that as LLMs get smarter, giving them general-purpose tools and simple instructions works better than creating special tools for every task. They think the best future is one where LLMs have access to a computer and can figure out tasks on their own, using natural language as the main way to extend them.

Hacker News comments show different opinions. Some people like the move toward simple, flexible extensions, saying natural language is easier for most users. Others worry about security risks when LLMs get too much power or access to computers. A few think the early plugin systems failed because models were not ready, but now things are improving. Some developers say they still prefer code-based customization because it is more reliable and testable than natural language. Others are excited about the future, hoping for agents that feel like smart coworkers, not just chatbots. There are concerns about privacy, since features like ChatGPT Memory can remember sensitive details. Some users point out that making these systems easy for non-technical people is still a big challenge. Others debate if adding too many features makes LLMs confusing or hard to use. A few think that the best ideas will come from open projects, not big companies, because the community can move faster and share better tools. Finally, some believe that most users just want things to work simply, without having to learn new protocols or file formats.

---

## Moving from OpenBSD to FreeBSD for firewalls

- 原文链接: [Moving from OpenBSD to FreeBSD for firewalls](https://utcc.utoronto.ca/~cks/space/blog/sysadmin/OpenBSDToFreeBSDMove)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=45980474)

Someone tried to move their firewall system from OpenBSD to FreeBSD. The article talks about why they made this change and what happened during the process. 

OpenBSD and FreeBSD are both free operating systems that are good for network and security jobs. The author liked OpenBSD because it is simple and secure. But they moved to FreeBSD because they needed better hardware support and more features, especially for network cards and drivers. FreeBSD also has better performance for some tasks and supports new tools. The author explains that many things are similar between OpenBSD and FreeBSD, but some commands and ways to set up the firewall are different. They had to learn new ways to use pf, the firewall tool, because FreeBSD changes some things. Some problems came up with network interfaces and packages, but the author fixed these by reading the FreeBSD handbook and community forums. The author says FreeBSD has a bigger community and more updates for modern hardware. In the end, the move took some work, but the firewall was running well.

In the comments, some people agree that moving to FreeBSD gives better hardware support, especially for new computers. Others like OpenBSD more because it is simple and they trust its security. A few users say FreeBSD’s pf is not always the same as OpenBSD’s pf, so you must be careful when switching. Some people think OpenBSD is better for smaller, older hardware because it uses less memory. Many users share tips about how to set up firewalls on both systems, and some share their own stories of moving between them. One commenter warns that it is easy to make mistakes with firewall rules if you are not careful. Another person says FreeBSD’s documentation helped them a lot when they were learning. A few people remind others that both systems are open source and anyone can help improve them. Some wish there were more guides for moving between OpenBSD and FreeBSD. Most agree that both systems are good, and the best choice depends on your needs.

---

## PS5 now costs less than 64GB of DDR5 memory. RAM jumps to $600 due to shortage

- 原文链接: [PS5 now costs less than 64GB of DDR5 memory. RAM jumps to $600 due to shortage](https://www.tomshardware.com/pc-components/ddr5/64gb-of-ddr5-memory-now-costs-more-than-an-entire-ps5-even-after-a-discount-trident-z5-neo-kit-jumps-to-usd600-due-to-dram-shortage-and-its-expected-to-get-worse-into-2026)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46038143)

The article talks about the price of DDR5 RAM becoming very high, even more than the cost of a PlayStation 5 game console. It explains that 64GB of DDR5 memory now costs around $600 because there is a shortage.

The shortage is caused by problems in the supply chain and high demand for new computers. Many companies and people want to buy DDR5 memory, but factories cannot make enough. Also, new computers from Intel and AMD need this type of memory, so more people are trying to buy it. The article says that some people are waiting to build or upgrade their computers because the price is too high. Shops are also selling out of DDR5 memory very quickly. The article compares the price to a PlayStation 5 to show how expensive the memory is right now. Usually, RAM is much cheaper than a game console, but now it costs even more. The article also mentions that as factories make more DDR5 memory, prices may go down in the future. But for now, the high cost is a big problem for people who want new computers.

In the comment section, some people are surprised by how expensive DDR5 memory is. A few say they will wait to upgrade their computers until prices drop. Others remember when DDR4 memory was also very expensive at first, but later became cheaper. Some users talk about how the shortage is caused by both high demand and factories having trouble making enough chips. A few people suggest buying used or older RAM if you do not need the newest hardware. Others say that for most people, DDR5 is not needed yet, and DDR4 works fine. Some worry that prices for other computer parts might go up too. A few are frustrated with how hard it is to get new technology these days. Others try to stay positive, hoping that the shortage will end soon. Some comment that this shows how much people want to build new computers now. A few share tips on where to find RAM at better prices. Some just joke about how strange it is that memory costs more than a game console.

---

