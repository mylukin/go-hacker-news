Hello everyone, this is the 2025-06-27 episode of Hacker News Daily Podcast. Today, we have stories about creative pilots, new ways to generate images, history, programming tools, and more. Let’s get started.

Our first story is about a British Airways pilot named James Harding, who used his coding skills to create interactive graphs and a globe showing every flight in his career. Over the years, he tracked nearly 1.9 million nautical miles—enough for nine trips to the Moon or almost 87 laps around the Earth. He spent 5,800 hours in the air, with more than 2,100 flights and 1,400 landings. His last flight was a nine-hour trip from Denver to London. The dashboard he built shows details like day versus night landings, how pilot roles are split, and how things like Russian airspace restrictions have changed routes to Asia, making flights longer. There’s a destination matrix, and special notes on flights, such as an emergency landing in Spain. He logs all this data using a logbook app and exports it to make these charts.

In the comments, many people praise the beautiful visuals and the idea of using programming to make sense of a pilot’s career. Some ask about the technical side, like how he gets his data—it’s a SQLite file from logbook software. Others suggest features, like tracking radiation exposure or altitude. There’s talk about how pilots share flying time, and whether they can code during flights—most do their side projects between flights, not in the cockpit. Some people hope this dashboard could become a product for other pilots. There are also discussions about tools for mapping flights, career changes from engineering to flying, and even the high cost of pilot training. The mood is supportive, with technical tips, jokes, and plenty of curiosity about mixing aviation and software.

Next, we look at new progress in computer vision. Apple researchers built a model called TarFlow, which uses a method called Normalizing Flows to generate images. Normalizing Flows take random noise and turn it into images, and can reverse the process too. Until now, many thought these models were not as strong as diffusion models or GANs. But TarFlow adds Transformer blocks—like those used in language models—and looks at small image patches in different orders. It also uses tricks like adding noise during training, denoising after training, and guidance to control the style and content. With these ideas, TarFlow creates images that match top diffusion models in quality and even does better at measuring how well it fits the data.

In the Hacker News comments, people are surprised to see Normalizing Flows back in the spotlight. Some note the clever use of Transformers for images. Others ask about model speed, cost, and if TarFlow is easier to use in real projects. There’s healthy skepticism, but also excitement that this may start a new wave of research in image generation.

Now for a strange bit of history. In the early 1900s, some parents in the United States sent their children through the mail. Back then, it was sometimes cheaper to mail a child by train than to buy a ticket. The kids were handed over to postal workers, who made sure they arrived safely, with a label pinned to their clothes. This happened mostly in small towns, where everyone knew the mailman. After a few years, the post office made new rules to stop this.

One top comment jokes about a child in a tote bag, saying “the child is not included.” Others ask if adults could be mailed—one person points out that Henry Box Brown did mail himself to freedom, but now packages over 70 pounds are not allowed. People are surprised by the level of trust in those days, and some reflect on how rules and attitudes have changed.

Next up, we have a story about programming with arrays. Many languages either have very simple array types or use complex dependent types, which can be slow and hard to use. The Star calculus is a new system that gives arrays richer types using records and variants. It helps catch mistakes with shape and indices early. With algebraic subtyping, you can get type inference like in ML languages, but with more safety and less complexity.

One commenter is excited and wants a language that is both type-safe and easy for math. Another notes the challenge of naming axes: in real code, array shapes change often, so keeping labels updated can be hard. The main topic is the balance between clarity, safety, and the extra work that comes with richer types.

Now let’s talk about SymbolicAI, a Python library that mixes logic programming with large language models. It uses “primitives” called Symbols, which can act as normal Python values or switch to AI-powered “semantic mode” to understand meaning. For example, the AI can see that “feline” matches a sentence about cats. You can chain operations for complex logic. SymbolicAI also has “contracts,” which are rules to check inputs and outputs, making your code safer when using LLMs. It supports many AI engines and lets you manage settings easily.

Commenters like the mix of symbolic and neural ideas, saying it helps make LLMs more reliable. Some wonder if the tool is too complex for most projects, or if developers will just use basic LLM features. There’s praise for the open-source license, and some users hope for more examples and easier setup. Overall, people are curious to see how “neuro-symbolic” programming will grow.

Our next story is about Qwen VLo, a new AI model that can both understand images and edit them based on instructions, even across different languages. It can generate or edit pictures step by step, such as changing the style or objects in an image. It works with many image sizes and formats, and uses a unique way to build images from top to bottom and left to right, making edits easier to see as they happen. The model is still early, and sometimes makes mistakes.

In the comments, many people are disappointed that the model’s weights are not open for everyone to use, unlike earlier Qwen models. There are debates about what “open source” means in the context of AI. Some users talk about technical issues, like the model sometimes changing parts of an image you didn’t want, or giving images a yellow tint. Others argue about using words like “understand” when talking about these models. Some feel the outputs are not yet useful outside research, while others are interested in the details of how the model works.

Next, we have a fun tech demo: sending data between devices using ultrasound. The article shows how you can use normal computer speakers and microphones to send high-pitched sounds above 18,000 Hz, which most people can’t hear, to transmit data. The author first tried Morse code, but then used frequency shift keying, where different tones represent 0 and 1 bits. The system works, but it’s slow and not very reliable, especially with background noise.

In the comments, people remember older uses of ultrasound to sync phones at events or for products like Chromecast. One Google engineer says the problem is that dogs can hear these sounds and get upset. Others point out that “ultrasound” is usually much higher than what consumer hardware can play. There’s discussion about technical limits, sample rates, and other tools like GGWave. Some users share their own tests and small website design complaints.

Next is a job post from Spark AI, a new San Francisco startup building AI tools for clean energy projects. They are hiring a founding full-stack engineer, offering a high salary, equity, and visa sponsorship. The company helps developers of solar farms and batteries by making it easier to find and use complex information. The team is small, works in person, and uses modern tech like TypeScript and NodeJS. You’ll work closely with founders, build features quickly, and help shape the company.

In the comments, users mention the focus on in-person work and the generous compensation. Some are excited to see AI used for clean energy. There’s talk about the high cost of living in San Francisco, but people see it as a good chance to make a real impact and grow with a mission-driven team.

Another story looks back at how one person helped make the Pomological Watercolor Collection—over 7,000 fruit paintings from the late 1800s and early 1900s—publicly available. The author used the Freedom of Information Act, wrote blog posts, and learned Python to upload the images to Wikimedia Commons. This project led to a new coding career. The fruit paintings are now used in art, research, videos, and even as keepsakes.

In the comments, people thank the author, share their own uses for the images, and discuss public domain licensing. Some mention how learning to code for this project changed their lives. The feeling is one of gratitude and inspiration, with jokes and friendly banter.

Our last story is about “Learn OCaml,” a web tool for learning the OCaml programming language through online exercises. Users can sign up, solve problems, and track progress without needing to install anything. Teachers can see feedback and help students. The tool aims to make OCaml more accessible, especially for beginners.

Commenters are happy to see more interactive resources for learning functional programming. Some hope the tool covers advanced topics, while others wish for similar platforms in other languages. There’s discussion about how OCaml is used in real projects, and how this kind of tool could grow the community. Most people are positive and hope to see more resources like this in the future.

That’s all for today’s episode. Thanks for listening to Hacker News Daily Podcast. See you next time!