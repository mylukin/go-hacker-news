# Hacker News 故事摘要 - 2025-05-02

## 今日概述

Today on Hacker News, stories cover privacy, intellectual growth, tech regulations, and new tech. There's debate about removing third-party cookies to protect privacy. An article discusses living an intellectually rich life. TikTok faces a big fine in Europe for privacy issues. A study explores using AI to design rockets, showing promise with learning techniques. Felix86 is a new emulator for RISC-V to boost gaming. Bloom filters in Go offer efficient data checks. A website redesign mimics a terminal but has usability issues. Lastly, a leaked API key raises security worries for major tech firms.

---

## Third party cookies must be removed

- 原文链接: [Third party cookies must be removed](https://w3ctag.github.io/web-without-3p-cookies/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43865132)

The article argues that third-party cookies, which track users across different sites, must be removed to protect privacy on the web. It explains how third-party cookies are used for tracking and profiling users, which is harmful to individual privacy. The article also highlights that while some web features rely on third-party cookies, alternative technologies should be developed to fulfill these needs without compromising user privacy.

Third-party cookies were initially created to help recognize users across sites for things like logins and tracking shopping carts. However, they now enable widespread data collection, often without users' knowledge. This data collection allows tracking networks to centralize user data, leading to privacy concerns. While some browsers have restricted these cookies, not all have followed. The article encourages the removal of third-party cookies and calls for new privacy-preserving technologies to replace them.

In the comments, opinions vary. Some users find the W3C's approach confusing and criticize it for lacking clarity and coherence. Others argue that W3C is still relevant, citing its contributions to web standards like WebAssembly and CSS. There are also discussions about legitimate use cases for third-party cookies, like federated identity and embedded content across domains. Some commenters express skepticism about whether removing these cookies will lead to better privacy, suggesting that other tracking methods like fingerprinting might become more common. Others believe that removing third-party cookies is a necessary step to enhance privacy, though they acknowledge that technical and legislative measures might both be needed to address tracking issues fully.

---

## How to live an intellectually rich life

- 原文链接: [How to live an intellectually rich life](https://utsavmamoria.substack.com/p/how-to-live-an-intellectually-rich)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43868192)

The article explores how to live an intellectually rich life, using various metaphors and examples to illustrate the journey towards intellectual fulfillment. It starts with a playful exercise on Wikipedia, where clicking the first link on any page eventually leads to the Philosophy page. This exercise is used to highlight how fundamental questions of existence often link back to philosophy.

The article discusses the concept of "Epistemic Anxiety," a feeling of unease about not knowing the truth due to information overload and bias. It suggests immersing oneself in diverse ideas to combat this anxiety. John Conway's Game of Life is used as a metaphor for how ideas can thrive or stagnate depending on their environment. The Game of Life illustrates the importance of diversity and abundance in ideas, leading to new and complex thoughts.

The article further explores satisfaction and routine as tools for intellectual growth, emphasizing the importance of curiosity and engaging with diverse communities. It shares stories of notable individuals like Dorothy Hodgkin and Yitang Zhang, highlighting how curiosity and routine led to groundbreaking discoveries.

The Hacker News comments reflect a mix of opinions. Some readers found the article insightful, appreciating the emphasis on curiosity and diverse ideas. Others felt the article was overly lengthy and meandering, preferring more concise writing. Some readers discussed related topics like the value of reading classics or engaging in practical skills. Others noted the article's metaphor-heavy style and questioned the practicality of its advice. Overall, the comments showcase a variety of perspectives on how to lead an intellectually fulfilling life.

---

## Irish privacy watchdog hits TikTok with €530M fine over data transfers to China

- 原文链接: [Irish privacy watchdog hits TikTok with €530M fine over data transfers to China](https://apnews.com/article/tiktok-ireland-european-union-data-privacy-regulation-d386ec74becc716905d7f686d6a448e2)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43868074)

The article talks about a big fine given to TikTok by Ireland's privacy watchdog. TikTok was fined €530 million due to issues with data transfers to China, which is a concern for user privacy.

The fine is part of the European Union's General Data Protection Regulation (GDPR) rules. These rules are meant to protect people's personal data. TikTok's European headquarters is in Ireland, so the Irish watchdog is responsible for handling these cases. The GDPR allows for fines based on a percentage of a company's global revenue. The idea is to make sure that the fines are big enough to be a real deterrent, not just a small cost of doing business. TikTok's global revenue was between $20 billion to $26 billion last year, making this fine about 6% of their European revenue. Some people argue fines should be based more on global profits rather than revenue to truly affect business behavior. Others think that fines should be severe enough to make companies change their ways, even if that means risking bankruptcy.

The comments section on Hacker News has a lot of different views. Some say the fine isn't big enough to stop TikTok from continuing its data practices, comparing it to just a "cost of doing business." Others point out that many big tech companies like Meta and Google have also faced fines for similar issues, showing that this isn't just a case of picking on TikTok because it's a Chinese company. There's also a discussion about whether fines should be based on global revenue or profit. Some users argue that TikTok, and companies like it, act as part of larger government interests, which complicates how we should view their actions. Another point raised is that while fines are a start, they may not be enough to change corporate behavior unless they are coupled with other measures like stricter compliance checks or more severe penalties. Lastly, a few comments note that the EU's approach is more about ensuring privacy and protecting citizens, which might set an example for other regions.

---

## LLMs for Engineering: Teaching Models to Design High Powered Rockets

- 原文链接: [LLMs for Engineering: Teaching Models to Design High Powered Rockets](https://arxiv.org/abs/2504.19394)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43851212)

The article talks about using Large Language Models (LLMs) to design high-powered rockets. It explores how LLMs, which are good at tasks in software engineering, might also be helpful in physical engineering fields. The paper tests LLMs with rocket design tasks and finds that while they have strong basic knowledge, they can't improve their designs effectively when given feedback from simulations. However, by using reinforcement learning (RL), a model with 7 billion parameters can outperform both state-of-the-art models and human experts, showing that RL-trained LLMs could be useful in complex engineering optimization.

In the comments, people discuss the challenges of using LLMs for engineering. Some think that LLMs face difficulties because they can't easily handle images and diagrams, which are crucial in fields like mechanical and electronic engineering. Others highlight how LLMs struggle with understanding complex spatial or mathematical information found in engineering drawings. A few commenters express concerns about the reliability of LLMs, fearing they might make subtle but hard-to-detect errors, similar to past issues with technology like the Xerox bug. Some are optimistic, discussing how LLMs could eventually be trained with specific data, like SPICE for circuits, to improve their capabilities. A key point raised is that while simulations are useful, they are imperfect models of reality, which means LLMs trained on them might not perform well in real-world scenarios. Overall, the discussion reflects a mix of skepticism and hope about the future of LLMs in engineering.

---

## Felix86: Run x86-64 programs on RISC-V Linux

- 原文链接: [Felix86: Run x86-64 programs on RISC-V Linux](https://felix86.com/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43864800)

Felix86 is a new x86-64 emulator designed to run on RISC-V Linux, primarily aimed at improving game performance. Although it's still in the early stages of development, some games are already compatible. The emulator's goal is to allow x86-64 programs to function on RISC-V, which could potentially make RISC-V more attractive for gaming and other applications.

Felix86 differs from similar projects like Box86/Box64, which also support RISC-V with JIT (Just-In-Time) compilation. The community is curious about whether Felix86 is a fork of QEMU or an entirely new effort. The source code is available on GitHub, and some users appreciate the use of serialization formats for instruction definitions instead of traditional C macros. A key discussion point is the potential of RISC-V hardware, which is seen as lagging behind x86 and ARM in raw performance. However, the open nature of RISC-V could lead to a more vibrant ecosystem over time by reducing costs related to licensing.

In the comments, there's a debate about why RISC-V hasn't seen more mainstream adoption. Some users point out that it takes years to develop high-performance CPUs, and RISC-V is still relatively new. Others argue that RISC-V may not yet offer significant cost advantages over ARM, especially when considering the maturity and optimization of existing ARM and x86 processors. There's also a discussion on how RISC-V might gain ground in the future, potentially driven by major manufacturers looking to reduce costs. Meanwhile, some users express excitement about the potential of RISC-V for server hardware and gaming, envisioning a future where emulators like Felix86 push the boundaries of what's possible on RISC-V.

---

## Bloom Filters

- 原文链接: [Bloom Filters](https://eli.thegreenplace.net/2025/bloom-filters/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43866001)

Bloom filters are a smart way to check if something is probably in a set without using much time or space. This technique helps quickly reject items that are not in a specific set, which is useful when reading from disk is slow. Invented by Burton Bloom in 1970, Bloom filters use a bit array and several hash functions to do their work. If all bits point to 1, the item is probably in the set, though it might be a false positive. But if any bit is 0, the item is definitely not in the set. 

In practical terms, Bloom filters can handle a billion items with a small error rate, needing just 1.2 GB of space and making lookups very fast. The article explains how to implement a Bloom filter in Go, using double hashing to create multiple hash functions. It also discusses optimizing the filter to keep the false positive rate low.

In the Hacker News comments, users shared insights and alternatives to Bloom filters. One interesting alternative mentioned is "compact approximators," which provide lower bounds on values instead of just membership checks. Some users talked about similar structures like count-min sketch and Invertible Bloom Lookup Tables, which add and remove data and help with error correction. Others noted that Bloom filters are great for certain tasks, like quickly checking if data might not be in a dataset, saving time on unnecessary disk reads.

People also discussed the efficiency of Bloom filters in various applications, such as databases, spell checkers, and even browser security. Some comments highlighted that while Bloom filters can be fast, they might still have cache misses if the filter is large. Overall, Bloom filters are praised for their speed and efficiency, though they aren't perfect for every situation, especially where security or accuracy is crucial.

---

## Just redesigned my personal site with a TTY-style interface

- 原文链接: [Just redesigned my personal site with a TTY-style interface](https://www.abdisa.me/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43867211)

A developer redesigned their personal website to look like a TTY (teletypewriter) terminal interface. The site mimics a command-line environment, where visitors can type commands to navigate. It includes links to their GitHub, LinkedIn, and Twitter, and humorously suggests running commands like 'help' for guidance.

The main appeal of the site is its playful and nostalgic design, reminiscent of old computer systems. It offers a unique experience, but some people find it difficult to use, especially on mobile devices. The absence of common terminal commands like 'ls' and 'cd' is a noted limitation, as users instinctively try these. There's also a suggestion to make commands clickable for easier navigation on touch devices.

In the comments, opinions vary. Some appreciate the creativity and nostalgia, while others worry about usability, especially for non-technical users like recruiters. Many suggest adding a simpler, more accessible version. Some commenters recall similar projects from the past or share their own experiences with terminal-style sites. A few see it as a fun personal project, valuing the creativity and effort, while others point out practical issues, like mobile compatibility and missing features. Overall, the site sparks a lively discussion on balancing creativity with usability.

---

## Don't watermark your legal PDFs with purple dragons in suits

- 原文链接: [Don't watermark your legal PDFs with purple dragons in suits](https://arstechnica.com/tech-policy/2025/05/dont-watermark-your-legal-pdfs-with-purple-dragons-in-suits/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43866303)

A recent article advises against watermarking legal PDFs with images like purple dragons in suits. The key issue is that court filings have strict formatting rules, and unusual watermarks can detract from the seriousness of legal proceedings. 

The article mentions a case where a lawyer used a cartoon dragon as a watermark in a legal complaint about inadequate prison medical care. The judge directed the lawyer to resubmit the document without the dragon. This incident is seen as unprofessional, and some suggest it might even be a publicity stunt for the lawyer's firm.

In the comments, opinions vary. Some users note that the legal system's formality is essential for fairness, emphasizing that justice should be taken seriously. Others argue that the watermark is a distraction, potentially affecting the case's reception. Some comments highlight the importance of adhering to court rules to ensure the focus remains on the case's merits, not on stylistic choices. There's also discussion about how the legal system values appearance and decorum, with some suggesting that such formality can be exclusionary. Overall, the consensus leans towards maintaining professionalism in legal documents to uphold the integrity of the judicial process.

---

## xAI dev leaks API key for private SpaceX, Tesla LLMs

- 原文链接: [xAI dev leaks API key for private SpaceX, Tesla LLMs](https://krebsonsecurity.com/2025/05/xai-dev-leaks-api-key-for-private-spacex-tesla-llms/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=43865097)

An xAI developer accidentally leaked an API key for private large language models (LLMs) used by SpaceX, Tesla, and Twitter/X on GitHub. This leak, discovered by a security expert, could have allowed unauthorized access to sensitive AI models. The security team was informed, but the key remained active for two months before being removed.

The article explains that the leaked API key could access various private and unreleased AI models. GitGuardian, a security company, identified the exposure and alerted the company. Despite this, the key remained accessible for a significant period, raising concerns about the company's security practices. The leak highlights potential risks, such as attackers using the access for malicious purposes like prompt injection or altering the models.

In the comment section, people shared diverse views. Some found it surprising that the security team redirected the report to a bug bounty program instead of acting immediately. Others discussed the potential legal implications, like ITAR violations if sensitive data was exposed. There was debate about whether the leak involved critical data or something less significant, like internal procedures. Some commenters questioned the competence of both the developer and the organization for not catching the error sooner. Others reflected on the broader issue of secret management and how common such mistakes are in the industry. Finally, discussions on the responsibilities of the company versus individual developers emerged, with some commenters defending the developer, suggesting it indicates wider organizational issues.

---

