Hello everyone, this is the 2025-11-18 episode of Hacker News Daily Podcast. Today, we have many important stories for software developers and tech fans. Let’s get started.

First, Google has launched Gemini 3, their newest and smartest AI model. Gemini 3 is now part of many Google products, like the Gemini app, Google Search, AI Studio, Vertex AI, and a new platform called Google Antigravity. This model is good at handling text, images, video, and even code. Gemini 3 Pro is much better than older versions at solving hard problems and understanding complex ideas. It scores high on reasoning and coding tasks, and a new "Deep Think" mode will soon help with even harder problems.

Gemini 3 can read and translate handwritten recipes, make flashcards from videos, analyze sports clips, and help with planning or organizing your life. For developers, Gemini 3 is strong in coding, building apps, and long-term planning. It works with platforms like GitHub and Replit, and can handle tasks such as booking services or sorting emails. Google says Gemini 3 is also their safest model, with strong protection against attacks and better testing, including outside experts. They are careful with new features, making sure they are safe before everyone can use them.

In the Hacker News comments, people are excited about Gemini 3’s new abilities, especially in reasoning and planning. Developers like that it works with many tools and is open to different platforms. Some are still cautious, saying Google’s AI promises are sometimes too big or hard to use for real work. There are worries about privacy and how much control Google will have. Some users wonder if Gemini 3 can really beat competitors like OpenAI, or if it just scores well on tests. Others point out that Google’s habit of shutting down products makes them nervous to trust Gemini. There are also concerns about the risks of AI agents making mistakes or unwanted changes. Many praise Google’s focus on safety but say real-world results will matter most. Most people agree that only real use and feedback will show if this is truly a new era for AI.

Next, let’s look at Google Antigravity, a new tool for developers that uses AI to help write and manage code. Antigravity offers smart help inside your editor, terminal, and browser at the same time. Its core is an AI-powered editor where you use simple English commands to write or change code. The editor also suggests code as you type. You can manage several AI agents at once and control them with a "mission control" screen, giving feedback to help the AI improve.

Antigravity is free and made for all types of developers. Front-end, full stack, and enterprise devs can all find uses, from automating browser tasks to managing big projects. In the comments, some people are excited about saving time and making coding easier, while others worry about trusting AI with their code. Some like using natural language commands, which helps new coders. A few want to see demos before judging, and others wonder if Antigravity is better than other AI tools. People also ask about privacy and how well it works with sensitive code. Many are curious about the user interface and whether "mission control" will be simple enough. Overall, there is excitement but also some healthy caution.

Now, let’s talk about Gemini 3 Pro’s technical details. This model uses a "mixture-of-experts" design, meaning only some parts of the model work on each task, making it both powerful and efficient. It can handle huge inputs—up to one million tokens—and produce outputs up to 64,000 tokens. Gemini 3 Pro was trained on a wide mix of data: web pages, code, images, audio, video, and user interactions, all filtered for safety and quality. It runs on Google TPUs and uses advanced software like JAX and ML Pathways for fast, energy-efficient training.

Gemini 3 Pro is available through Google products and APIs, so developers can use it without special hardware. It is much better than the old Gemini 2.5 Pro at reasoning, handling many types of data, and working with long documents. It is built for code writing, complex problem-solving, planning, and creative tasks. There are limits—sometimes it makes mistakes, is slow, or times out. Its knowledge is only up to January 2025. Google has strict rules against using it for illegal, harmful, or misleading things.

Safety is a big focus. Gemini 3 Pro was tested by both humans and tools, and Google’s team tried to break it to find weak points. Safety scores are better than before, but there are still limits. In the comments, some are impressed by the open details about the model and its large input and output size. Others worry about user data being used for training and whether safety filters will block useful content. Some call for more open, independent testing. Developers are excited to try it, but want more transparency. The safety claims are seen by some as marketing, but others respect the effort. There is a lively debate about balancing innovation and safety, with calls for both stricter controls and more open access.

Moving on, GitHub had an outage with Git operations like push and pull, making it hard for people to use their code repositories. SSH and HTTP connections both failed, and Codespaces was also affected. GitHub shared updates as they worked on a fix, and things slowly got better after they shipped a solution.

On Hacker News, many people said they rely on GitHub every day, so even short outages cause problems for teams. Some users pointed out that many companies depend too much on GitHub, which is risky. Others shared that keeping backups or mirrors in other places helped them during the outage. Some remembered self-hosted Git servers, which avoided these problems, but they agree GitHub’s features are useful. Some users were frustrated by the updates, while others thought they were good enough. There was discussion about whether self-hosting is worth the extra work, and some joked about taking a break during the outage. The outage made teams think more about disaster recovery plans. Some praised GitHub for fixing things quickly, but others said even small outages matter a lot. Most agree outages are rare, but show how much we rely on cloud tools.

Next, the founder of Mastodon has stepped down as CEO and given ownership to a non-profit. After almost ten years, he says this is the next step for Mastodon and for himself. He explains that Mastodon is now bigger than one person. The project is about community and open values, and he wants to protect these ideas. Being a CEO of a social network is stressful and not always healthy, and small things can wear you down over time. He shared stories about being compared to billionaires or judged for his clothes. One bad user interaction last summer made him realize he needed to step away for his own health.

He believes that saying "no" to ideas that would have pulled Mastodon in too many directions was important. He is proud of how Mastodon grew from a bedroom project to a big part of the internet. While he will not be CEO, he will still help behind the scenes.

In the comments, many thank him for his work and vision. Some say stepping down is brave and good leadership. Others are worried about Mastodon’s future without him, hoping the non-profit keeps things running well. There is respect for his honesty about mental health. Some note Mastodon’s focus on community is rare and hope it stays open and safe. There are also worries about what happens when founders leave, but some say moving to a non-profit protects Mastodon from being bought or changed too much. Users share their own stories about burnout and balancing big projects. Most agree Mastodon is special because it is about helping people connect, not about money or power.

Now, let’s look at a fight in the Pebble smartwatch community, between Core Devices, a new company making Pebble watches, and Rebble, a non-profit keeping Pebble alive. Both groups want Pebble to survive, but disagree over who controls old Pebble app data. Core Devices and Rebble had a deal, but it broke down over ownership of the app store archive—13,000 apps and watchfaces. Rebble wants to limit access, saying the data is theirs. Core Devices’ founder, Eric, thinks the data should be free, maybe on Archive.org, to honor developers and keep Pebble open. Eric says he followed open source rules and tried to work with Rebble, but talks failed.

In the comments, some support Eric, saying open data helps everyone and that Pebble is about sharing. Others side with Rebble, saying they did the hard work to save the data and deserve some control. Some worry about legal risks if the data is shared without developer permission. People hope both sides can work together for the community. There are also notes that open source projects often have fights like this, especially when money or business is involved. Many praise both groups for keeping Pebble alive.

Next, we have a story about one person who made a science fiction story collection using open-source tools, even while working full-time and caring for kids. The author used Python, YAML, and LaTeX to organize, select, and publish the book. Each story was tracked in simple YAML files, making it easy to use Git and Python scripts. A small tool called "se.py" helped manage stats and progress. For printing, the author used LaTeX for professional typesetting, with scripts to convert stories from Word or HTML. Pandoc was used to make ebooks, with scripts to fix the table of contents.

The main lessons were to keep things simple and organized, use reproducible builds, and not worry about knowing everything before starting. In the comments, people praised the use of open formats and using programming for creative work. Some warned that LaTeX can be tricky, and not as polished as tools like InDesign. Others suggested more automation and sharing scripts. There was debate about the trade-off between control and ease of use. Many found the story inspiring and shared advice about backups and long-term projects.

Now, let’s talk about Bild AI, a new startup that wants to use AI to read construction blueprints and make building faster and cheaper. Bild AI is looking for a founding engineer with machine learning, computer vision, and Python skills. The company wants to use smart AI models to understand blueprints, estimate costs, and handle permits—tasks that are slow and full of mistakes when done by hand. They aim to focus on the "intelligence layer," quickly building and testing prototypes. Bild AI is backed by Y Combinator and values honesty, learning, and being ready for tough work. The job is full-time, in-person in San Francisco, and open to new graduates or experienced engineers.

In the comments, people are interested in how Bild AI will solve the blueprint problem, since blueprints can be complex and not always follow rules. Some say any automation can help, but working with construction companies can be hard. Some like that Bild AI hires new graduates, while others worry about the small team size. There is praise for their "model garden" approach—using different AI models for different problems. The biggest challenge may be getting customers to trust the AI’s answers, not just building the tech.

Blender 5.0 is now out, bringing a big update to this free 3D modeling software. Blender is used by artists and developers to make 3D art, movies, games, and more. This version has a cleaner user interface, faster rendering, new tools for modeling, sculpting, and painting, and better animation tools. Blender 5.0 supports more file types and is more stable. Blender remains free and open source, with a large community sharing tutorials and plugins.

Most comments on Hacker News are positive. People are happy Blender keeps improving for free and is now strong enough for professional work. Some say new features finally fix long-standing issues. Others worry that new features might make Blender harder for beginners, and wish for better basics. There is discussion about how Blender can compete with big paid tools, and how its community helps everyone learn. Some share stories about using Blender for fun or work, and talk about ways to support it. Most comments show excitement and respect for the Blender team.

Finally, OrthoRoute is a new GPU-accelerated autorouter plugin for KiCad, a popular circuit board design tool. The author built OrthoRoute because he needed to route a large, complex board that normal tools could not handle. He first tried existing autorouters, but they were too slow. Hand-routing would take months, so he made his own tool using KiCad’s new plugin system. OrthoRoute uses a special FPGA-inspired algorithm and GPU power to route many connections in steps, fixing problems over time.

For very large boards, he rented a powerful GPU in the cloud. The largest board was routed in 41 hours, much faster than months by hand. The tool is open source, and the author invites others to try or improve it. In the comments, people are interested in the technical details, and praise the use of GPU acceleration. Some discuss the pros and cons of autorouting, and ask about design rule checks and hardware needs. Many want to try OrthoRoute on their own projects and suggest new features. There is excitement about new tools that push the limits of PCB design.

That’s all for today’s Hacker News Daily Podcast. Thanks for listening, and see you next time.