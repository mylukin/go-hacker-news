Hello everyone, this is the 2025-11-19 episode of Hacker News Daily Podcast. Today, we have many interesting stories from the world of technology, open source, AI, and finance. Let’s get started.

First, Arduino has changed its Terms of Service and Privacy Policy after being bought by Qualcomm. The new rules are very different from Arduino’s old open and friendly style. Now, Arduino gets a permanent license to anything users upload. There is strong monitoring of AI features, and users are not allowed to look for possible patent problems. Even if you delete your account, Arduino keeps your username for years. All user data, including data from children, will be shared with Qualcomm’s global system. Most importantly, users cannot reverse-engineer or try to figure out how Arduino works without special permission. This is a big move away from open source, which made Arduino popular with teachers, makers, and students. The article also notes recent cloud outages and worries about Qualcomm’s business actions, such as fraud by an executive and high spending.

On Hacker News, many people are upset and sad. Some say this will hurt academic and robotics research. Others plan to move to other boards like the RP2040 or ESP32. A few are not surprised, saying big companies often hurt the community. Some see a chance for new open projects to take Arduino’s place. There are questions about real alternatives and which platforms will become popular. Many call out Qualcomm for not understanding the maker community and only caring about money. Still, some believe the open-source spirit will continue with clones and similar projects. Most agree these new rules are a big mistake, but the maker and hacker community will find ways to move forward.

Next, a very big ship called Dali hit the Francis Scott Key Bridge in Baltimore after a blackout caused by a loose wire. The crash made the bridge fall, killing six workers who were fixing the road. Investigators found the loose wire made a breaker open by mistake, causing two blackouts. This stopped the ship from steering just as it came near the bridge. The wire was not fully pushed in because a label band was in the way. The team tried to steer away, but it was too late. The bridge collapsed, and parts fell onto the ship. Seven workers and one inspector were on the bridge; six died. Quick actions by the ship’s pilots and local workers stopped more cars from driving onto the bridge and saved other lives.

The NTSB chairwoman said finding the loose wire was very hard because the ship has so many wires, but the crash could have been stopped with better checks. The bridge was also not strong enough to resist hits from ships like Dali, which is much bigger than ships in the past. The NTSB warned that many bridges are at risk from large ships, and told 30 bridge owners to check their bridges. They also made new safety suggestions to government groups and ship companies.

On Hacker News, people were shocked that one wire could cause so much trouble. Some talked about how ships and bridges are not updated for today’s bigger ships. Others said ship wiring should be checked more often, and old safety standards do not match today’s needs. There were questions about why the bridge did not have better protection. Some felt sad for the workers who died and asked if better training or faster alerts could help next time. Many praised the quick actions that saved lives. Most agree that more bridge checks and better ship safety rules are needed everywhere.

Now, OpenAI just released GPT-5.1-Codex-Max, a new AI model for coding. It is faster, smarter, and uses fewer tokens, making it helpful for developers who want to build and fix software. Codex-Max can handle very long coding jobs, like big refactors or long debugging sessions, by using “compaction” to remember important details and forget less important parts, so it can work on huge projects without running into memory limits. It is trained with real-world engineering tasks and now works better on Windows and in the Codex command-line tool.

Codex-Max is more efficient and can finish tasks with about 30% fewer tokens. There is also a new “extra high” reasoning mode for even better answers if you do not mind waiting longer. Developers can use it in the CLI, IDE extension, or cloud, and soon through the API. Codex-Max works in a safe “sandbox,” with no outside network access unless you turn it on. OpenAI warns that Codex-Max is not perfect for cybersecurity, so they are adding more protections and recommend developers check the AI’s work before using it in real products. Codex-Max is out now for ChatGPT Plus, Pro, Business, Edu, and Enterprise users, and will soon be the default in Codex tools.

On Hacker News, some people are excited about the improvements, especially long context and better token use for big projects. Others worry about safety and letting AI change code for hours without humans watching. Some think “compaction” could sometimes remove important info and wonder how well Codex-Max tracks complex projects. Many developers still want to review all AI changes themselves. Some hope the model will be on more platforms soon. Others point out that better cybersecurity from AI is good, but attackers might use it too, so safety is important. There is debate about costs and how much this tool will change daily developer work. Overall, the community is interested but cautious, waiting to see real-world results.

Next, researchers found a big security problem in WhatsApp’s contact discovery system. This system helps users find friends by matching phone numbers, but the researchers showed it could be used to check more than 100 million phone numbers per hour and find out which numbers use WhatsApp. By sending many requests to WhatsApp’s servers, the server would answer if a number was linked to an account. They could map over 3.5 billion accounts in 245 countries and learn things like which phone system people used, how old the account was, and how many devices were connected. They even found that millions of people in countries where WhatsApp is banned still have active accounts. Some technical issues were found, like cryptographic keys being reused, which could mean fake WhatsApp apps are in use. About half of the phone numbers from an old Facebook leak were still active on WhatsApp.

Meta worked with the researchers, fixed the problem, and thanked them. They updated WhatsApp to block this kind of mass checking and made profiles less visible to strangers. The researchers deleted all the data they collected. They say outside experts should keep testing big apps for safety.

On Hacker News, some users said this was a known problem with many apps, not just WhatsApp. Others pointed out that using phone numbers as user IDs is risky. People discussed how messaging apps trade privacy for convenience. Some were surprised how much public data can reveal. A few were impressed by the careful and ethical approach. Others felt Meta responded well, but some worried fixes might not be enough. There were calls for more use of usernames instead of phone numbers. Some users worried about metadata, saying true privacy needs more than just technical fixes—it’s also about the whole system’s design.

Now, let’s talk about Meta’s new Segment Anything Model 3, or SAM 3. This tool can find and follow any object in pictures or videos, using both words and images as prompts. Soon, it will be part of Instagram’s Edits app and the Meta AI app to help people edit videos and pictures more easily.

SAM 3 lets you use simple text or draw a box to point out objects you want to find. If you click on an object, SAM 3 can select it, and you can give more hints to improve the selection. This version works on both pictures and videos, so you can track objects as they move. SAM 3 is better than older versions because it can use text prompts and track objects more precisely. You can even download the model to try it yourself. Meta also mentions a new tool called SAM 3D for 3D objects.

On Hacker News, many people are impressed by SAM 3’s text prompts and say it is a big step forward for computer vision. Some are excited about how easy it is to select and track objects. Others mention that being able to use text or drawings could help many people, even those who aren’t technical. Some wonder about speed and size for use on phones or slow computers. People are interested in using SAM 3 for science or robotics. A few worry about privacy and social media use. Some want to know if all features are in the open-source release. Developers are excited to experiment, and most agree it is a big improvement. There are also questions about how this might change jobs in photo or video editing, making things faster and easier.

Next, there is a comparison of different operating systems when hosting a static website with nginx on a small Intel N150 mini PC. The author tested FreeBSD, SmartOS, NetBSD, OpenBSD, Debian, and Alpine Linux, using the same nginx setup for both HTTP and HTTPS. For HTTP, almost all systems reached about 64,000 requests per second, so the OS does not matter much. For HTTPS, FreeBSD, Debian, and Alpine Linux did about 63,000 requests per second, but FreeBSD used much less CPU. SmartOS, NetBSD, and OpenBSD were a bit slower and used more CPU. The differences seem to come from how each OS handles cryptography.

Isolation methods also matter. FreeBSD jails and SmartOS native zones performed almost like bare metal. LX zones were a bit slower, likely because they translate Linux calls. Still, the overhead was not huge. The takeaway is that for static HTTP, OS choice is not important on this hardware. For HTTPS, FreeBSD, Debian, and Alpine are better, with FreeBSD having the most CPU left for other jobs. But real-life needs—like your team’s skills—are often more important than small benchmark differences.

In the comments, many readers agreed that all modern OSes are good for static sites, especially over HTTP. Some said network speed or CDN use often matter more than server speed. A few were impressed by FreeBSD’s TLS performance, while others debated the value of benchmarks. Some shared their own experiences, saying security and familiarity can be better reasons to pick an OS than small speed wins. There were also questions about the test setup and wishes for more tests.

Now, let’s talk about Zoltan Pozsar’s idea called “Bretton Woods III.” He says the freezing of Russian dollar reserves in 2022 made countries rethink if holding U.S. dollars is safe. Pozsar explains there are two types of money: “inside money,” like bank deposits and bonds, and “outside money,” like gold or oil, which has value by itself. The first global system was backed by gold, then after 1971 by U.S. Treasuries. Now, after the sanctions, countries want more outside money to protect themselves.

Pozsar uses Perry Mehrling’s “money view,” which says money has four prices: par, interest, exchange rate, and price level. Central banks can control the first three, but not the price of things like oil or wheat. He says, “You can print money, but not oil or wheat.” The article gives an example: after sanctions, Russian oil now travels farther to Asia, using more ships and time. This means banks must lend more money for longer periods, causing stress in markets.

Pozsar also points out that non-U.S. banks hold huge amounts of dollar assets but do not have the Federal Reserve as a safety net. When there’s a shortage of dollars, these banks can get into trouble, creating big problems for the global system.

On Hacker News, some agree with Pozsar and say freezing Russian reserves made countries lose trust in the dollar, pushing them to buy more gold and commodities. Others think the dollar will stay important because there is no good replacement. A few users say shifting to commodities is hard because they are less flexible. Some worry that more focus on outside money could make global trade slower and more expensive. Others add that controlling real goods means countries will care more about supply chains and security, not just finance. There is also debate about whether central banks really can’t control commodity prices. Some note the risks for non-U.S. banks and say this explains why more countries are making trade deals in their own currencies, but this trend is slow. A few appreciate Pozsar’s focus on the “plumbing” of finance.

Next, researchers found secret signals called “Power Tracks” in stock market trading data. These are small, fast bursts in the data that can predict where a stock’s price will go. They looked at GameStop trading data, built a system to watch for strange bursts, and used math tools to spot patterns. When a burst is found, they collect all the tiny trades and turn the data into a stream of numbers. These numbers are decoded using XOR masks and other encoding tricks.

The system tries to turn the burst into a prediction, like a range of prices the stock might reach soon. Sometimes, several Power Tracks overlap, creating a more complex forecast. The signals are believed to be made by advanced trading computers, possibly to share plans or control the market quietly. The authors say this could be a form of market manipulation and suggest regulators should look for Power Tracks.

In the comments, some readers were impressed by the technical work and the idea of hidden communication in the market. Others were skeptical, saying the findings could be overfitting or seeing patterns in random data. Some pointed out that high-frequency trading often has strange bursts, not all of them secret messages. Several wanted the code and data to try to repeat the results. Some worried about the legal side if people are signaling in this way. There was also talk about whether similar signals might exist in other stocks or in crypto. Some liked the idea that real-time detection could help traders or watchdogs, but warned that if everyone tries to use the signals, they might disappear or change. Overall, there was both excitement and caution.

Finally, Mosaic is a new AI tool that helps people edit videos more easily. The company says their platform uses “agentic” AI, which can make smart decisions to help with video editing. You describe what you want, and the AI edits the video for you—cutting boring parts, making it shorter, or focusing on certain people or objects. Mosaic can also add effects and suggest ways to improve the video. The platform is cloud-based, so users do not need to install anything. Mosaic says they focus on privacy and do not share user videos with others. Early users can sign up to try the beta version.

On Hacker News, some people are excited and say Mosaic could help non-experts make better videos. Others think this tool is perfect for creators who want to work faster. Some wonder how smart the AI really is and if it can handle complex edits. A few worry about losing creative control and say editing is an art. Others point out AI tools often struggle with context. Some want to see real-world examples. People also mention similar tools and are curious about what makes Mosaic different. Some worry about privacy in the cloud. Overall, the community is interested but has many questions about what the AI can really do.

That’s all for today’s Hacker News Daily Podcast. Thank you for listening, and see you next time.