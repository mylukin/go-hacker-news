# Hacker News 故事摘要 - 2025-06-30

## 今日概述

Today’s top Hacker News stories talk about better ways to give AI more helpful information, new tricks for safer C code, and open tools for debugging phones. There are also stories about old tech like DAT players and game compressors, faster tools for AI text, and creative journeys in games and writing apps. Privacy worries come up with a WiFi motion tracker. If you like AI, coding, old tech, or simple software, you will find something interesting today.

---

## The New Skill in AI Is Not Prompting, It's Context Engineering

- 原文链接: [The New Skill in AI Is Not Prompting, It's Context Engineering](https://www.philschmid.de/context-engineering)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44427757)

This article talks about a new idea in AI called “context engineering.” It says that building good AI is not just about writing smart prompts, but about giving the AI all the right information it needs to do the job well. The author explains that context is much more than just a single prompt; it includes instructions, conversation history, facts from past chats, up-to-date info from documents or APIs, and a list of tools the AI can use.

The article gives an example with an AI assistant. If the assistant only sees a simple request to set up a meeting, it might reply in a boring, unhelpful way. But if it also gets your calendar, past emails, and knows who the other person is, it can write a much better, friendlier reply. The difference between a basic demo and a great AI agent is how much useful context you give it. The author says that most failures in AI agents now happen because of missing or poor context, not because of problems in the model or code.

Context engineering is different from prompt engineering. Instead of just writing one good prompt, you design a system that finds and gives all the needed information and tools to the AI, right when it is needed. This system is dynamic, meaning it changes depending on the task. It also matters how you show the information: clear and short summaries are better than long, messy data.

The main point is that building strong AI agents now depends on how well you design the context system, not just the prompt or model. This takes understanding your real business problem, what result you want, and what info or tools the AI needs to succeed.

In the comments, many people agree that context is very important for useful AI agents. Some say that getting the right context is hard and often the real challenge in building good AI. Others note that large models sometimes “hallucinate” or make mistakes when context is missing or unclear. A few users point out that most real-world problems need up-to-date or private information that isn’t in the model’s training data, so context engineering becomes even more important.

Some commenters worry that context engineering could become too complex, with lots of moving parts to maintain. Others share tips for building better context systems, like summarizing old conversations or carefully choosing what data to include. There are also debates about whether context engineering is really “new,” or just a new name for something good software engineers already do—organizing and structuring data for programs.

A few people are excited about new tools and frameworks that help with context engineering, while others warn not to forget about privacy and security when building these systems. Some say that as models and tools get better, context engineering skills will be even more valuable. Overall, most agree that focusing on context, not just prompts, is the key to building smarter, more helpful AI.

---

## I write type-safe generic data structures in C

- 原文链接: [I write type-safe generic data structures in C](https://danielchasehooper.com/posts/typechecked-generic-c-data-structures/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44425461)

This article is about making generic and type-safe data structures in the C language. The author explains a method that uses unions and macros to keep type information, so you can have one data structure (like a linked list) that works with any type, and still get errors from the compiler if you use the wrong type.

First, the author shows that you can use C macros and header includes to create type-specific versions of a data structure, such as a linked list for different types. But this method makes your code hard to read and maintain, and it produces many copies of similar functions. Next, the common method in C is to use `void *` pointers to hold any type of data, but this is not type-safe, and can lead to mistakes that the compiler can't catch. The author then improves this by using a flexible array inside the struct, so the data is stored with the node itself, making memory use and performance better, but it still needs you to pass the size of the data, which is annoying.

Finally, the main idea is to use a union with a special member called `payload` that only exists for type information; it is not used at runtime. A macro then uses the type of this `payload` to make sure that only the right type of item can be added to the list. If you try to add the wrong type, the compiler shows an error. The author explains some tricks to support older C compilers, and mentions that soon (in 2025) compilers will make handling these types easier. The same idea can be used for other data structures, like maps with key and value types. In the end, the author provides a link to more code examples.

In the Hacker News comments, many people like this approach, and say it's a clever way to get type safety in plain C. Some readers are worried about undefined behavior, because casting function pointers is not officially safe in C, but others say it works fine in practice on most systems. Some think the macros make code harder to debug and maintain, and suggest using C++ templates or even Rust for better type safety and cleaner code. Others mention libraries like `stb_ds.h` or GObject that try to solve similar problems, but agree this method is more general. A few people point out that some IDEs and code tools may not work well with these macro-based generics, so auto-completion and navigation can break. There are also comments about how C23 and new compiler versions will make things easier, as struct types with the same fields will finally be seen as the same type. Some users discuss the trade-offs between performance, safety, and code clarity, and a few share their own solutions for generic data structures in C. Overall, the discussion is positive, but with many warnings about the dangers and limits of C's macro tricks.

---

## The hidden JTAG in a Qualcomm/Snapdragon device’s USB port

- 原文链接: [The hidden JTAG in a Qualcomm/Snapdragon device’s USB port](https://www.linaro.org/blog/hidden-jtag-qualcomm-snapdragon-usb/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44426428)

This article talks about a hidden debug feature called EUD (Embedded USB Debug) in Qualcomm Snapdragon devices. Qualcomm recently shared open source code to let people use this feature for debugging.

EUD is a special debug tool built into most Qualcomm chips since 2018. It lets you debug the device using just a USB cable—no need to open the device or use extra hardware. When EUD is turned on, your computer sees a new USB device that gives access to SWD (Serial Wire Debug), which is similar to JTAG, a standard way of debugging CPUs. This makes it much easier and cheaper to debug problems in the kernel or bootloader like U-Boot.

Before, only Qualcomm and their partners could use EUD because the software was private. Now, with the code open, anyone can try it. The author had to fix some small build problems, but soon got it working with OpenOCD (a popular debugging tool). There are extra features, like support for Hexagon DSPs and some improvements for LLDB, which are worth checking out.

The article explains that EUD is especially useful for debugging U-Boot, which usually gives little info when it crashes. EUD could also help with debugging secure software like OP-TEE and TF-A. There are even more hidden tools in EUD, like a UART interface and a trace tool, but these are not ready yet.

There are some limits: EUD might not work on every device, and some options are locked in the chip or need special keys from the device maker. On some phones, EUD is still enabled by accident. Also, you probably can't use EUD to hack higher security parts of the chip.

From the comments, many people are excited to see Qualcomm open up their tools. Some say this will save a lot of money and time, since debuggers are expensive and hard to set up. Others are impressed that you can debug without opening the device or using extra cables. A few users share tips about which devices still have EUD enabled and warn that future phones might lock it down.

Some developers say that open debugging tools are important for Linux and open-source work. Others worry about security, since leaving debug tools open on production devices could be risky. There is also debate about how useful JTAG really is—some agree with Linus Torvalds, who prefers not to use debuggers, while others say it’s a life-saver for tough bugs.

A few people mention problems with building the code on their systems, but they appreciate that the fixes are shared. Some are hopeful that even more Qualcomm tools will become open in the future. Many agree this is a great step for developers and hope other chip companies will do the same.

---

## There are no new ideas in AI only new datasets

- 原文链接: [There are no new ideas in AI only new datasets](https://blog.jxmo.io/p/there-are-no-new-ideas-in-ai-only)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44423983)

This article says most progress in AI does not come from new ideas, but from new datasets. The writer looks at how AI has changed a lot in the last fifteen years, but says the biggest jumps happen when we get new types of data to train on, not when we invent totally new algorithms.

They give examples: In 2012, AlexNet used the big ImageNet dataset and pushed image recognition forward. Transformers in 2017 let researchers use all the text on the internet to train large language models. RLHF (Reinforcement Learning from Human Feedback) made it possible to train models with human labels for good text. Most recently, models learn from “verifiers” like calculators and compilers, which can check their outputs.

The article says that the main methods behind these breakthroughs—like neural networks and reinforcement learning—are actually old ideas, some from the 1940s or 1990s. The real difference came from opening up new data sources, like images, web text, human feedback, or verifier signals. The writer points out research showing that changing the data has a bigger effect than changing the model architecture. For example, a different type of model (an SSM) performed just as well as the transformer model when trained on the same data, showing there’s a limit to what you can learn from a given dataset.

The author thinks the next big step for AI will come from unlocking a new kind of data. They suggest YouTube video data as a likely target since it’s huge and very rich, or even data from robots moving in the real world. They doubt that new AI methods or tweaks will matter much unless they can use new data sources. In short, to make AI better, we should focus on new data, not new ideas.

In the top Hacker News comments, some people agree and say that data is often overlooked but is what really matters. Others say this view goes too far—good algorithms and engineering also matter, especially to make sense of messy, real-world data. A few users point out that collecting and labeling new datasets is expensive and hard, so not everyone can just get more data. Someone notes that even with more data, we might just hit new limits; for example, getting better at math or reasoning may need more than just more data. Another comment reminds us that sometimes, a clever new idea can make old data much more useful, so we should not ignore research. Some users discuss how video and robotic data is hard to process, and it’s not clear if it will bring the next breakthrough. A few people mention “The Bitter Lesson,” which says AI works best when we use lots of computation and data, not clever tricks. There’s also debate about whether progress is really slowing down, or if we just expect too much from each new model. Finally, some warn that using new data sources—like videos or robot sensors—could raise new privacy or safety issues.

---

## The Original LZEXE (A.K.A. Kosinski) Compressor Source Code Has Been Released

- 原文链接: [The Original LZEXE (A.K.A. Kosinski) Compressor Source Code Has Been Released](https://clownacy.wordpress.com/2025/05/24/the-original-lzexe-a-k-a-kosinski-compressor-source-code-has-been-released/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44426864)

The article is about the release of the original source code for the LZEXE compressor, also known as Kosinski, which was used for compressing DOS programs and some Sega game data in the late 80s and 90s. The source code, written by Fabrice Bellard, is now available under an open license, making it free to use and study.  

The author explains that LZEXE and Kosinski are actually the same compression format, something discovered only recently. The released source code is for version 0.91 and is split between x86 assembly for the main compression work and Pascal for the user interface. The code has not been changed since 1990. This release is important because it helps people understand how some old games and BIOS data were compressed, like the ones in the Sonic and Mega CD games. The author had tried to make their own version of the Kosinski compressor before, but found differences in how the BIOS data was compressed, likely due to bugs or different versions of the original tool. Comparing the new source code with old executables may help solve these mysteries. The article also mentions other related compressors used for Sega games, like Saxman, Enigma, and Nemesis, but only the code for Kosinski and Saxman is available now. The remaining two are likely lost because they were custom tools inside Sega.  

In the comments, one reader says they enjoy the blog even though they are not an expert, showing that the topic interests both specialists and casual readers. Another commenter is currently working with Mega CD BIOS data and finds it hard to get matching results when recompressing the data. They ask for help, explaining that small differences or bugs in the compression tool can cause big problems, like the system freezing. This shows that even small technical details in compression tools matter a lot for people trying to edit or restore old game software. Some readers are excited to see this old code shared, as it helps with research and game modification. Others wish more lost tools like Enigma and Nemesis could be found, but understand that might not happen. There are also comments about how amazing it is to see code from so long ago, and how open source releases like this help the community keep classic games alive. Overall, the post and comments reflect a mix of nostalgia, technical curiosity, and hope for more discoveries in the future.

---

## They don't make 'em like that any more: Sony DTC-700 audio DAT player/recorder

- 原文链接: [They don't make 'em like that any more: Sony DTC-700 audio DAT player/recorder](https://kevinboone.me/dtc-700.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44426171)

This article talks about the Sony DTC-700, a digital audio tape (DAT) player and recorder from 1990. The author explains how DAT was much better than cassette tapes, giving CD-quality sound and easy recording at home.

Cassette tapes were popular because you could record music from the radio or vinyl and make mix tapes for friends. But cassettes had problems like background noise and low sound quality. DAT fixed these problems by recording sound digitally, at a quality even higher than CDs. You could connect a CD player to a DAT recorder and make a perfect copy—though, at first, the different data rates made it tricky. The DTC-700 was Sony’s more affordable DAT player, but even then it was still expensive. It had many features, like several types of inputs, a headphone jack, and a display with track information.

DAT, however, never became popular at home. It was used more by professionals. Original music for DAT was rare, mostly because music companies feared people would copy music without any loss in quality. To protect their music, they pushed for laws and taxes on DAT recorders, making them even pricier. The DTC-700 and other DAT machines added copy protection codes to limit what could be copied, which annoyed many users.

DATs also had reliability problems. The tape and head mechanism was complex and wore out quickly—especially since Sony used many plastic parts inside. In the end, the article says DAT failed not just because of price or reliability, but because everyone who wanted one already had it. The sound quality could not get any better, so there was no reason to upgrade. Plus, easier digital recording on computers soon made DAT machines unnecessary.

Now, people sometimes buy old vinyl or cassette players for nostalgia, but DAT doesn’t have the same fan base. The author doubts DAT will ever come back into style.

Commenters on Hacker News shared several views. Some felt nostalgia for DAT, praising its clear sound and remembering using it in studios. Others pointed out how frustrating the copy protection was, especially for musicians and engineers. Many agreed that DAT’s mechanical parts broke often, making repairs difficult and expensive. A few remembered the high cost: only studios or wealthy hobbyists could afford DAT recorders.

Several people mentioned how, today, computers easily do what DAT once did, with even better results. Some wondered if there was any point to DAT, since there were so few albums released for it and it never became a collector’s item like vinyl. Others said the format was too late, arriving just as computers and other digital tools were taking over. One commenter joked that “they don’t make them like this anymore—probably for good reason.” Still, a handful said they missed the excitement of new audio tech from that era, even if DAT itself was too complicated and short-lived.

---

## Show HN: TokenDagger – A tokenizer faster than OpenAI's Tiktoken

- 原文链接: [Show HN: TokenDagger – A tokenizer faster than OpenAI's Tiktoken](https://github.com/M4THYOU/TokenDagger)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44422480)

This article talks about TokenDagger, a new tool for breaking up text into tokens, which is faster than OpenAI’s Tiktoken. TokenDagger is open-source and made for people working with large language models or AI projects.

The main point is that TokenDagger can tokenize text much faster than Tiktoken, the tool OpenAI uses. The author shows speed tests where TokenDagger is 2 to 6 times faster. TokenDagger works with many different AI models, like GPT-2, GPT-3, and Llama. It is written in Rust, which helps make it very fast and safe. The author also provides Python bindings, so you can use TokenDagger in Python projects. The tool is easy to install and use, with clear commands and examples. TokenDagger supports Unicode and handles emojis and different scripts well. The creator says the tool is helpful for anyone who needs to process lots of text, like for chatbots or search engines. The article has links to the GitHub page and sample code. The author invites developers to try TokenDagger and give feedback or help improve it.

In the comments, many people are excited about a faster tokenizer. Some are happy that it is open-source and easy to use in Python. A few users share their own speed test results and agree that TokenDagger is much faster. Some ask how the tool compares in accuracy to Tiktoken and if it handles all edge cases. Others are curious if it supports all the same AI models as Tiktoken. One person wonders if the speed matters for most users, since tokenization is usually not the slowest part of working with big models. Another commenter likes that the tool is written in Rust, saying Rust is good for performance and safety. Someone else asks about installing it on different systems and if there are pre-built binaries. A few users suggest adding more documentation and benchmarks for other languages. Some mention that better tokenization could help lower costs when using paid AI APIs. Overall, the comments are positive and many people want to try TokenDagger in their projects.

---

## End of an Era

- 原文链接: [End of an Era](https://www.erasmatazz.com/personal/self/end-of-an-era.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44426845)

This article is about a game designer who spent many years trying to make interactive storytelling into real art. He started in the early 1980s, working on games like Gossip and Excalibur, hoping to create something deeper than typical video games.

His journey was full of challenges. After Atari collapsed, he worked as a freelance designer. He wanted to make a new kind of Arthurian game, but publishers only wanted games like Doom or Myst. When the Markle Foundation gave him money, he built the Erasmatron, a tool for others to make interactive stories. Sadly, almost nobody used it.

He kept going, making Storytron—a better version of Erasmatron. The central idea was a "toy language" with only the words needed for the story’s world. Players could build sentences using verbs for actions, actors, props, and places. But again, nobody was interested. He realized that people didn’t want to spend the time learning his system, even though it was easier than many professional tools.

He tried again with a project called Siboot, but he didn’t like the result. He was disappointed and stopped. Later, near his 70th birthday, he decided to make one last Arthurian game, "Le Morte d’Arthur." This time, he was proud of the result, even if few people played it. He saw it as real interactive art.

He tried to share his technology with others, especially the storytelling community at the Narrascope conference. He built a simpler web-based tool, but technical problems and a failed video lecture meant his final push also didn’t gain interest. He realized that while he succeeded when making games for himself, he failed when trying to create tools for others.

In the end, he compared himself to Charles Babbage, who invented the computer before the world was ready. He accepted that maybe the world just isn’t ready for his ideas yet.

Hacker News commenters had many thoughts. Some people felt sad for the author, saying his work was ahead of its time and that the industry just wasn’t ready for deep, interactive stories. Others pointed out that complicated tools often fail if users don’t see quick results or if learning is too hard. A few commenters remembered playing or hearing about his past games and praised his creativity and persistence.

Some thought that simpler tools or games might have succeeded, suggesting the author aimed too high for the current market. Others noted how creative work can feel lonely, especially when it’s not understood by others. There were comments about how commercial success and artistic success don’t always match; a project can fail in business but still inspire people.

A few users wondered if interactive storytelling will ever become popular, or if people just prefer linear stories in books and movies. Some compared the author’s journey to other failed inventions that only found value much later. Others encouraged him, saying that even if few people used his tools, his work showed what’s possible.

One commenter suggested that making art for yourself, not for the market, is sometimes the best way. Another said the story of Merlin and Arthur at the end was a beautiful way to explain the value of striving, even if you don’t win. Overall, the discussion was thoughtful, with respect for the author’s long effort and a shared hope that one day, his ideas might find their moment.

---

## Show HN: New Ensō – first public beta

- 原文链接: [Show HN: New Ensō – first public beta](https://untested.sonnet.io/notes/new-enso-first-public-beta/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44421776)

Ensō is a simple writing app, and this article announces its new public beta release with a focus on reducing distractions. The developer explains they want the app to be clean and easy to use, following a philosophy called “Make It Stupid Simple” (MISS).

The new Ensō has a redesigned user interface, moved most controls to the menu bar, and offers 5½ accessibility-friendly themes for different lighting situations, including very dark themes for OLED screens. There’s a new “Coffeeshop Mode” where your typing is hidden from people behind you, which is useful for privacy in public places. Users can also change text size and toggle autocorrect settings, which was not possible before. A new text rendering engine makes typing feel smoother and easier to read, aiming for a comfortable, notebook-like experience. The app will now be in the App Store by default, since users found Gumroad payments confusing or “shady.” The developer explains that while the App Store can be slow, it makes updates and payments easier. The Gumroad version will stay as a backup but won’t get updates. There is no analytics in this version—no data is sent over the network—and the developer gets feedback directly from users. Some features are still missing, like RTL (right-to-left) language support and more personalization, but these are planned soon. The article also mentions possible future ideas, like a Windows or Linux version, a Quick Save feature, and a “Toybox” menu with experimental tools. The developer describes working on the app like carpentry, slowly and carefully, and shares that making a good theme switcher is surprisingly hard.

In the Hacker News comments, many people like the focus on simplicity and privacy, and praise the “Coffeeshop Mode” for being creative and practical. Some users ask about Windows and Linux support, and the developer replies that these may come later if there’s enough interest. A few commenters wonder if the app is “too simple” and miss some features from other editors, but others say that fewer features help them concentrate. Some people discuss the price, debating if $10 is fair for a minimalist app. Others appreciate the lack of analytics and respect for privacy, saying it’s rare today. Several users talk about the choice to use the App Store, with mixed feelings: some trust it more, while others dislike Apple’s control. There are also questions about accessibility, and users are glad to see support for different themes and controls. A few ask about open-source options or web versions, and the developer confirms the web version will stay free. Some wish RTL support would arrive sooner, especially for non-Latin script users. Overall, many are happy to see a tool built with care and clear communication, even if it’s not for everyone.

---

## Xfinity using WiFi signals in your house to detect motion

- 原文链接: [Xfinity using WiFi signals in your house to detect motion](https://www.xfinity.com/support/articles/wifi-motion)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=44426726)

Xfinity now lets some users turn on a feature called WiFi Motion in their homes. This uses the WiFi signals from your Xfinity Gateway and your connected devices to tell when something moves around your house.

The WiFi Motion feature is not a full security system and is not watched by real people. It works by looking for changes in WiFi signals between your router and your devices. If you want to use it, you need to turn it on in the Xfinity app. You also need certain hardware, like specific Xfinity routers and devices that are always on and connected to your WiFi (not using WiFi extenders or sleeping). You choose which devices help detect motion, and you can set how sensitive the system should be—high, medium, or low. There are special settings to avoid getting alerts from small pets, and you can adjust these in the app. The system may not work well in every home, especially if your WiFi is weak in some rooms or your devices go to sleep. You can check motion history, set up notifications, and turn the feature off anytime.

Some important details: Xfinity says you are responsible for following any laws about motion detection in your area. Also, they may share motion data with police or courts if asked. The feature is only in early access, so not every customer can use it yet.

People on Hacker News have strong opinions about this. Some think it’s a clever way to use tech you already have, and like that you don’t need extra hardware. Others worry a lot about privacy, since Comcast can see detailed data about movement in your house and might share it with others. Some users think it’s not very useful because it’s not reliable—WiFi signals can be blocked by walls, furniture, or if devices go offline. A few people mention that this kind of motion detection is not new, but using it in home WiFi is a fresh idea. There are concerns about false alarms, especially with pets or kids, and people wonder if neighbors' movements could trigger alerts in apartments. Some wish the system was more open or worked with other brands. Others think it’s just another way for Comcast to gather more data about their customers. A few users are excited to try it, but many say they would never turn it on because of privacy or trust issues with Comcast.

---

