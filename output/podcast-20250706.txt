Hello everyone, this is the 2025-07-06 episode of Hacker News Daily Podcast. Today, we have stories about Apple AI safety filters, a retro web OS, the rise of AI in Show HN, async queues in interviews, AGI progress, Jane Street's India ban, a Git-based task tool, functions as infinite vectors, tracking the ISS with DNS, and building Rust with GCC.

Let’s start with a project that exposes the safety filters from Apple’s new AI models, known as Apple Intelligence. This project shows how Apple controls what its AI can say by using special filter files. The files are encrypted, but the project’s scripts help you get the decryption key from your own machine—using tools like LLDB to grab the key from Apple’s safety process, and then a Python script to unlock the filters. Inside, the filters are organized by model and stored as JSON files. Each file has lists of phrases or patterns: some words the AI must block, others it should remove or replace. There are also regular expressions to catch bad phrases, not just exact matches. If the AI tries to say something on the reject list, it gets blocked. Some filters are empty, but the goal is to stop the AI from breaking Apple’s safety rules. The repo includes all scripts and even already-decrypted files from June 28, so you can check the rules yourself.

In the comments, some people like the transparency—now we can see how Apple is keeping the AI safe. Others worry that sharing these filters might help people find ways to trick or bypass the system. Some say all big AI models use filters, so it’s not a surprise. There’s debate on whether Apple’s approach is better than other tech companies. Some users want the option to turn the filters off, while others think strong defaults are important for safety. There’s also talk about who gets to decide what should be blocked, and if these controls will get stronger over time. The comments show a split: some value openness and control, while others focus on safety and rules.

Next, let’s look at a web-based operating system that copies the old Apple Lisa, using only 1-bit graphics. It’s called LisaGUI. You can use it right in your browser, and it works without any JavaScript, which is very rare for web apps today. The look and feel are just like the 1980s Lisa—black and white, with windows, menus, and icons. You can open apps, move windows, and play with simple features. It’s fast and lightweight, since there’s no extra code. The creator says it’s just a technical demo, not a real OS, but there’s a detailed page about how it works.

Hacker News users are impressed that it works so well without JavaScript. Some feel nostalgic, remembering the old Lisa or Macintosh. People discuss how hard it is to make interactive sites without modern web tech, and some ask technical questions about how input and drawing are handled. Others say this project could help teach web basics. There’s talk about accessibility—some want more keyboard support. While a few wish for more features, most enjoy the retro style and share links to similar projects. The overall feeling is that it’s a fun and clever use of simple web tools.

Now let’s talk about the number of AI projects on Hacker News, especially in Show HN posts. A writer, annoyed by the flood of AI posts, used the Hacker News BigQuery dataset to check the numbers. In 2018, there were about 11,000 Show HN posts. By 2024, that grew to over 17,000, and it’s still rising. To see how many were about AI, he searched for keywords like “AI,” “GPT,” or “.ai.” In 2018, only one out of 63 Show HN posts was AI-related. By 2025, it’s more than one in five—a big jump.

But are these AI posts more popular? The data says no: AI Show HN posts get fewer comments and, on average, fewer votes. The writer thinks this is because building AI wrappers is now easier, so there are more low-effort projects. Some people in the comments agree, saying the Show HN page is full of “Chat with your PDF” clones and simple wrappers. Others say it’s normal for new tech to flood the site. Some defend the flood, saying more projects mean more innovation. A few want better ways to filter or tag AI posts, while others enjoy seeing new tools, even if most are simple. The overall mood is mixed—some want fewer AI posts, some are fine with it, and most say the community will need to adapt to all the new projects.

Next up, a common programmer interview question: how to write an async queue so only one request goes to the server at a time. The writer likes this question because it checks many useful skills. The basic problem is: if a client app calls a server, but the server can only handle one request at a time per user, how do you make sure not to send a new request until the last one is done? A simple queue is not enough—you need an isProcessing flag to know if a request is running. The full solution adds requests to a queue, starts processing if nothing is busy, and moves to the next request when one is done.

Interviews add more twists: maybe each request must wait a certain time before sending, or you need to let users cancel or retry requests, or handle priorities. The point is to see if candidates can update their code when requirements change, and if they really understand async code.

The writer tried the question on AI tools like Replit Agent with Claude Sonnet 4.0. The AI did well on simple parts, but made mistakes as things got harder. The writer says it’s good to let candidates use AI now, because strong programmers use these tools—but humans still need to check and fix the code.

In the comments, some people praise the question for testing real understanding. Others say it can be tough for those who don’t know JavaScript’s single-threaded model. Some warn that candidates might just copy code from AI without understanding. Others say AI is good at the basics, but still struggles with changing rules. There’s also debate on whether interviews should focus less on puzzles and more on real work problems. Many agree that writing tests is the best way to check if someone really understands their code.

Now let’s talk about AGI—Artificial General Intelligence. One article says AGI is not coming soon, even though current AI is very impressive. The writer tried using large language models like ChatGPT for real work, but found they don’t improve over time like humans do. When you give feedback to a person, they get better. But with AI, you can’t give high-level feedback that sticks. Every new session, the model forgets what it learned. Even with detailed instructions, it doesn’t gain the “tacit knowledge” that people do.

There are ways to improve AI, like RL fine-tuning, but these are slow and not as flexible as human learning. The writer thinks that until AI can learn on the job, it won’t replace most white-collar work. Right now, AI can do small tasks, but not whole jobs that need memory and judgment. The writer is hopeful for the long term, but says real progress will need new algorithms and ideas, not just more hardware. If AGI doesn’t arrive in the next ten years, it may take much longer.

In the comments, some agree and say AI is not reliable for complex jobs. Others are more optimistic, saying that AI progress has surprised us before, and sometimes things move quickly. Some say better interfaces or using AI with human teams could solve some problems. A few worry about AGI risks, and others debate what “general intelligence” really means. Many agree that today’s AIs are powerful, but not ready to fully take over complex work, and real AGI will need more than bigger models.

Now to finance news. Jane Street, a big US trading company, has been banned from trading in India. The Indian financial regulator also froze $566 million of Jane Street’s money. The regulator says Jane Street did “pump and dump”—pushing up a stock’s price and selling fast for profit. Jane Street and another company, Tower Research, are accused of working together to move prices in the Indian stock market, with many trades making prices jump. The regulator says this hurt normal investors. Jane Street denies wrongdoing and says they follow all rules. The investigation looked at thousands of trades from 2021 and 2022, and found Jane Street used fake trades to make stocks look more popular. Now Jane Street can’t trade in India, and their money is frozen while the investigation continues.

In the comments, some say the regulator did the right thing to make markets fair. Others say high-speed trading is complex, and it’s hard to tell if rules were broken. Some point out that “pump and dump” is a strong charge and needs proof. Others note that banning foreign firms could scare away investors, while some say it’s good for India to protect its markets. Some worry that freezing so much money could make foreign companies afraid to do business in India. Many agree that markets should be fair for everyone, not just big trading firms.

Next, we have Backlog.md—a command-line tool to manage project tasks in any Git repo using simple Markdown files. It’s made for both humans and AI agents to work together in software projects. The tool creates a “backlog” folder in your repo, and each task is a Markdown file. You can create, list, and edit tasks from the terminal, or open a web UI for a Kanban board in your browser. All changes are saved as Markdown, so everything is tracked in Git. Backlog.md is private, offline, and open source. It runs on Mac, Linux, and Windows, and you can assign tasks, add labels, and manage dependencies with simple commands.

On Hacker News, many users like that it’s simple and private, using text and Git instead of big web services. Some say it’s perfect for small teams or solo developers. Others point out that Markdown files could get messy in huge projects, and searching or filtering might be slow. There are questions about scaling with big teams and handling merge conflicts. Some like the link with AI agents, while others want more details on how that works. There are comparisons to tools like Todo.txt, Trello, or GitHub Issues. Many like having everything in one place, with control and privacy.

Let’s turn to math and programming. One article explains how to think of functions as vectors with infinite dimensions. This lets us use linear algebra tools—like vectors and matrices—to study functions. The article shows that vectors are often lists of numbers, and as you add more, they start to look like functions. You can add functions together, or scale them, just like vectors. Linear operators, like differentiation, are like big matrices that change one function into another. For polynomials, differentiation can be written as a matrix. Diagonalization, a common idea in linear algebra, also helps with functions: if you find eigenfunctions for an operator, you can simplify problems. Exponentials are eigenfunctions for differentiation.

The Laplacian operator, which uses the second derivative, has nice eigenfunctions like sines, cosines, and exponentials. This leads to the Fourier series, where any periodic function can be seen as a sum of waves. This is useful for compression and signal processing, since you can drop small coefficients to simplify data. The article also talks about geometry processing and graphics, like using spherical harmonics for functions on spheres.

Many readers say the article is a clear explanation of a tricky subject. Some like how it connects calculus, linear algebra, and signal processing. A few mention that not all functions make a perfect vector space, and some details are tricky. Some wish for more practical examples or code. There’s praise for related resources, like 3Blue1Brown’s videos. Some say this view helped them understand Fourier transforms, while others still find the jump to infinite dimensions tough. There’s also talk about using these ideas in programming and graphics.

Now, a fun hack: tracking the International Space Station’s location using DNS. Instead of a website or app, the author updates a DNS LOC record with the ISS’s position every 15 minutes, so anyone can use a DNS query to get the latest coordinates. The DNS LOC record holds latitude, longitude, and altitude. The author uses an API to get the ISS’s position, then converts the data to the right format, and updates the DNS record using deSEC’s API. The TTL matches the update rate. The author calls this a “silly” use of DNS, but it shows how flexible DNS is. There’s a hint that other hidden records are in the DNS for people to find.

In the comments, people love the idea and call it “cool” and “fun.” Some say it’s just the kind of geeky project they like. There’s talk about technical details—like how Windows tools handle DNS LOC records. Some joke that DNS now has a record for everything. Others wonder what other live data could be shared with DNS. The comments mix joking, technical tips, and real interest in old protocols used in new ways.

Our last story is about building the Rust compiler using GCC instead of the usual LLVM—a big technical challenge. The article explains how the author tries to make the Rust compiler work with the GCC backend, called rustc_codegen_gcc. The process has three steps: start with the normal compiler using LLVM, rebuild it with the GCC backend, and check if the output matches. If both outputs are the same, the process works.

The author found three big bugs. The first is with the #[inline(always)] attribute on recursive functions—GCC tries too hard to inline them, causing errors, while LLVM only treats it as a hint. The fix is to treat #[inline(always)] as a normal inline in some cases, but this might make code slower. The second bug is about handling 128-bit integers in switch statements. The GCC JIT library can only handle 64-bit constants easily, so the workaround is to use a ladder of if statements. The third issue is a crash from misaligned memory access in packed structures with 128-bit integers. The fix is to make sure the compiler generates unaligned memory loads when needed.

The author says these fixes help the compiler build itself further, but there are still problems, like high memory usage and stack overflows in some GCC passes. In the comments, many people are excited about the progress, saying it could help Rust run on more platforms. Others worry about the complexity of supporting both LLVM and GCC. Some praise the debugging efforts, and others question if GCC JIT will ever fully support 128-bit types. There’s respect for the hard work, and many see this as a big step for the Rust ecosystem, even if there are challenges ahead.

That’s all for today’s episode. Thanks for listening to the Hacker News Daily Podcast. See you next time!