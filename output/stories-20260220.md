# Hacker News 故事摘要 - 2026-02-20

## 今日概述

Today’s top Hacker News stories are about Google making Android less open, problems with Dependabot alerts, and the ggml.ai team joining Hugging Face to support open AI. Other big topics include a security flaw at a diving insurance company, Wikipedia blocking Archive.today, Facebook's feed getting worse, new open-source 3D scanning tools, a map of US mines, blue light screen filter myths, and Anthropic’s new AI security tool. Many stories focus on open source, privacy, security, and changes in big tech platforms.

---

## Keep Android Open

- 原文链接: [Keep Android Open](https://f-droid.org/2026/02/20/twif.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47091419)

The article is about F-Droid warning users that Google is moving forward with plans to make Android more closed, which could block open app stores like F-Droid. Many people think Google has stopped these changes, but that is not true—Google is still planning to make it harder to install apps from places other than the Play Store.

F-Droid says Google’s public statements have confused people. Google talked about a new way to install apps, but there are no details, and nothing is finished. Because of this, F-Droid and other open app stores are showing banners in their apps to warn users. They want people to tell their local governments that Android should stay open.

F-Droid also shares updates about their apps. F-Droid Basic has a new test version with better translations, app export, install history, and other small updates. Some apps like Conversations are trying new ways to work without Google code, which might help apps be fully open source everywhere. Apps like Dolphin Emulator, ProtonVPN, and Nextcloud also have updates, and many smaller apps got fixes or new features.

Some apps were removed, and a few new ones were added. In total, more than 287 apps were updated this week. F-Droid asks users to subscribe to their news feed and to donate if possible.

In the comments, many people worry that Google is slowly closing Android, making it more like iOS where users can only get apps from one store. Some think this will hurt user freedom and small developers. Others argue that tighter controls make phones safer, and most people do not care about open app stores. Some say Google has too much power and governments should step in, while others say users should just switch to different phones or operating systems if they do not like it. A few are hopeful that open-source communities will find workarounds. Some doubt F-Droid’s warnings and want to see real actions before worrying. Others share tips for keeping Android open, like using custom ROMs or alternative app stores. Many agree it is important to keep talking about this issue so people do not forget.

---

## Turn Dependabot Off

- 原文链接: [Turn Dependabot Off](https://words.filippo.io/dependabot/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47094192)

The article says Dependabot, a tool that suggests dependency updates on GitHub, creates too much noise and is not helpful, especially for Go projects. It argues that Dependabot often sends security alerts and pull requests even when the real risk to the project is very low or not present at all.

The author gives an example: after a small security fix in a Go library, Dependabot sent thousands of alerts and pull requests to projects that were not really affected. Even a project that did not use the vulnerable part of the code received an alert. The author explains that this happens because Dependabot cannot check if the vulnerability actually matters for the project; it only checks if the library is used, not if the risky part is used. This leads to many false alarms.

Instead, the author recommends using better tools like govulncheck, which can tell if your project really uses the risky part of a library. Govulncheck looks at your code and dependencies and only warns you if your project is in danger. The article shares how to add govulncheck as a GitHub Action, so it runs every day and only notifies you about real problems.

The author also says you should not update all your dependencies just because there is a new version. Instead, run your tests every day with the latest versions to catch any problems early, but only update when it fits your project. This helps avoid rushing or breaking things for no good reason, and also protects you from possible bad updates.

False alerts make people stop paying attention to real warnings. The article says security tools must avoid false positives to help open source maintainers and users. The author shares that noisy alerts waste time for everyone, including people who maintain open-source software.

Now, let’s talk about what people on Hacker News said. Some agree that Dependabot is annoying and makes lots of useless pull requests. They say too many alerts make it hard to know which ones are real problems. Others think Dependabot is still useful for staying up-to-date, especially in big projects where no one checks dependencies by hand.

A few users agree with the author about govulncheck and want more smart tools that check if a vulnerability really affects your code. Some people say the real problem is that security tools are too simple and need better filtering. Others point out that for non-Go languages, there is no tool like govulncheck yet, and for those projects, Dependabot is still the best option.

Some maintainers say they get tired from Dependabot’s constant pull requests and start ignoring all alerts, which is risky. Others defend Dependabot, saying it helps them fix important issues quickly if they do not have much time. A few suggest using both Dependabot and smarter tools together.

There are also comments about how security teams and open source maintainers should work together to make things better. Some people say GitHub should improve Dependabot to avoid false alarms, while others think project owners should take more control of their update process. In the end, most agree that too much noise is bad, and smarter checking of real risks is the way forward.

---

## Ggml.ai joins Hugging Face to ensure the long-term progress of Local AI

- 原文链接: [Ggml.ai joins Hugging Face to ensure the long-term progress of Local AI](https://github.com/ggml-org/llama.cpp/discussions/19759)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47088037)

Ggml.ai, the team behind llama.cpp, is joining Hugging Face to help keep local AI projects open and strong for the future. The main idea is that the same team will keep working on ggml and llama.cpp, but now with more support from Hugging Face, which means more resources and better long-term plans.

The article says nothing big will change for users or the open-source community. Ggml and llama.cpp will stay community-driven and open source. The team will still make all the important choices. Hugging Face will help give the project steady funding, better user experience, and closer links with their popular Transformers library. This should make it easier to use different AI models with llama.cpp and help more people run AI on their own devices.

Since 2023, ggml.ai has grown fast, making it easy for people to use strong AI models at home or on their laptops. They worked with many developers and hardware makers, and llama.cpp is now used in many projects. Hugging Face has already worked closely with ggml, adding new features, helping with files, and making sure things work well together. Now, the plan is to connect the two groups even more, aiming for things like “single-click” model support and making local AI as easy as cloud AI. Both teams want to make open AI even more powerful and easy to use for everyone.

In the comments, most people are very happy about the news. Many say “congrats” and thank the team for their hard work. Some Hugging Face members welcome ggml.ai, saying they are excited to keep working together. Others say this is great for local AI and open-source software, and they hope the project grows even more now.

Some users talk about the importance of staying open and community-driven. A few say that Hugging Face is a good partner and are glad the project was not bought by a big company that might close things down. One person worries a bit about the project now being under U.S. rules, and wonders if this could hurt independence or privacy in the long run. Another commenter hopes the team does not lose focus on what made llama.cpp special, even as it works more with Hugging Face’s tools.

Someone asks if the plan to work with the Transformers library (which is in Python) means llama.cpp will lose its focus on being simple C++. The team replies that they want to keep things easy and open, even as they add more features. There are also questions about other projects like whisper.cpp, and some concern about how decisions were made, with one person wishing there was more open talk before the partnership.

Overall, the mood is very positive, with lots of thanks and excitement for what comes next. Some users are careful, hoping the project will stay open and free, and that the new partnership helps, not hurts, the community.

---

## I found a Vulnerability. They found a Lawyer

- 原文链接: [I found a Vulnerability. They found a Lawyer](https://dixken.de/blog/i-found-a-vulnerability-they-found-a-lawyer)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47092578)

This article is about a security engineer who found a big problem with a diving insurance company’s website. The problem was simple: every user got a number as an ID, and everyone got the same default password, which most people never changed.

Anyone could guess a number, type the default password, and see private information—names, addresses, phone numbers, emails, even info about children. The author made a simple script to check if the problem was widespread, and it was. The author reported the issue to both the company and the national security office in Malta, following the proper rules. Instead of getting thanks, the company’s lawyers sent legal threats, saying the author could be a criminal for reporting this and should keep everything secret. They asked the author to sign a document promising to never talk about the issue and to hand over a passport copy, with only a few hours to reply.

The author did not agree to stay silent but did confirm deleting all private data found. The company blamed users for not changing their passwords, even though it was the company that made the system weak. The author explained that the law (GDPR) says the company must protect user data, especially when children are involved, and must notify users if their data is at risk. There was no proof the company warned anyone. The author also said this reaction—legal threats instead of fixing the issue and thanking the finder—is common and hurts security. The right way would be: fix the problem, thank the finder, and tell affected people.

In the comments, many people were angry at the company for using lawyers instead of fixing the root cause. Some said this is why security problems often go unreported—people are scared of legal trouble. Others pointed out that blaming users for weak passwords is wrong when the system was designed badly. A few said the author did everything right and followed the law, and that more clear rules are needed to protect people who report bugs. Some suggested that public pressure is the only way to make companies take security seriously. Others worried that laws like GDPR are not enforced well if companies can act like this. There were also calls for better education for both companies and the public about responsible disclosure. Some commenters even shared their own stories of being threatened after reporting bugs. Overall, most agreed: it’s a big problem when companies care more about their image than user security.

---

## Wikipedia deprecates Archive.today, starts removing archive links

- 原文链接: [Wikipedia deprecates Archive.today, starts removing archive links](https://arstechnica.com/tech-policy/2026/02/wikipedia-bans-archive-today-after-site-executed-ddos-and-altered-web-captures/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47092006)

Wikipedia decided to block and remove all links to the archive site Archive.today after learning the site took part in a DDoS attack and changed saved web pages. Archive.today was used on almost 400,000 Wikipedia pages, with about 695,000 links, often to help users see content behind paywalls or check sources.

The main reason for the ban is that Archive.today’s owner used code to attack a blog that wrote about them. The archive site also changed saved pages by adding the blogger’s name in places it did not belong, as a way to get back at the blogger. This breaks trust, because archive sites should keep web pages unchanged. Wikipedia editors agreed the site became unsafe and unreliable. They said if a site can change what’s in an archive, people can’t use it to check facts or prove what was once online.

Wikipedia gave editors instructions: if the original source is still up, just use that. If not, use other archive sites like the Internet Archive. Archive.today is not the same as the Internet Archive, which is a trusted nonprofit. Wikipedia is also asking editors to remove links to all related Archive.today domains.

The person who runs the blog attacked by Archive.today said he is happy about Wikipedia’s choice. He hopes Wikipedia will build its own archive system in the future. The article shares that Archive.today’s operator sent threats to the blogger, including saying they would link his name to bad content online. Wikipedia editors found proof that Archive.today changed saved web pages to harm the blogger’s reputation.

People in the comments have mixed feelings. Some say Wikipedia made the right call, since trust and safety are most important. They note that an archive service must not change history or attack people. Others are sad to lose Archive.today, because it could save pages the Internet Archive cannot, especially ones behind paywalls. Some worry it will be hard to find or replace all the old links, and that some sources may be lost. A few people think the ban is too harsh, saying not everyone who used Archive.today did so for bad reasons. Others ask if Wikipedia can really check every archive link for changes, or if this will happen with other archive sites too. Some hope Wikipedia will make its own archiving tool, so it does not have to rely on outside sites.

---

## Facebook is cooked

- 原文链接: [Facebook is cooked](https://pilk.website/3/facebook-is-absolutely-cooked)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47091748)

This article talks about how Facebook’s main feed is now full of strange, low-quality content, much of it AI-generated. The author logged into Facebook for the first time in years and was shocked by what he saw.

Most of the feed was not from his friends or pages he follows. Instead, there were many “thirst trap” photos of young women, mostly fake and made by AI, with random captions. There were also odd AI videos, like a policeman giving a boy a new bike, and basic relationship memes. Some content was mildly sexual, and suggested questions by Meta (Facebook’s owner) sometimes made things worse or even sexist. The author notes that with today’s AI, it’s difficult to tell what is real and what is fake, but some posts were clearly AI due to weird details like strange text or logos. When checking the comments, it seemed like bots might be talking to other bots. The author wonders if this feed is just an odd result of his old account and lack of activity, or if it’s a common experience now. He feels uncomfortable seeing these AI images, especially ones that look like underage girls, and decides to leave Facebook again.

In the Hacker News comments, many people agree Facebook’s feed is now very bad and filled with spam and low-quality content. Some users say this shift started when Facebook began pushing more algorithm-chosen posts instead of just showing friends’ updates. Others point out that AI-generated images and spam have made it even worse recently. A few think the experience is different if you use Facebook often and have an active network, but most agree the main feed is now mostly junk. Some users suggest Facebook is trying to copy TikTok’s endless, addictive feed. Others miss the old Facebook, which was more about real people and less about random viral posts. There are also worries about the effect of AI and bots on social media in general. Some people say they only use Facebook now for groups or messages, not the feed. A few mention that older people or people in other countries might still use Facebook differently, but for most tech-savvy users, Facebook feels broken.

---

## OpenScan

- 原文链接: [OpenScan](https://openscan.eu/pages/scan-gallery)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47093724)

OpenScan is a project that makes open-source 3D scanners for people who want to create 3D models. The Scan Gallery page shows what users can do with OpenScan hardware and software. The gallery has many 3D models, like a giant butterfly, a flower, a small soldier figurine, an ammonite fossil, and even a security key. Some scans use professional cameras and focus stacking, while others use regular phones. The models are uploaded to Sketchfab, so anyone can view or use them. OpenScan offers different hardware, from the Classic to the Mini, and also cloud software for easier scanning. The project is community-driven, with users sharing scans and helping each other. OpenScan tries to keep prices stable instead of using random discounts. They also include all taxes and fees in US shipping prices. The team invites people to join their Discord and social media to learn more or share ideas.

In the Hacker News comments, some people are excited about OpenScan being open-source and affordable. Many like that you can use regular cameras or even phones to get good results. Some users ask about the quality of scans and compare them with expensive commercial scanners. Others discuss the process of photogrammetry and how easy or hard it is for beginners. A few people share their own experiences using OpenScan and say the community is helpful. Others wish for even simpler software or more guides for new users. Some comment on the importance of stable prices, saying it’s better for hobbyists. There are also questions about OpenScan’s cloud service and how it handles privacy. A few users talk about possible uses in education or museums. Some mention that 3D scanning is useful for preserving objects or making digital art. Overall, the comments show support for OpenScan and interest in making 3D scanning more open and easy for everyone.

---

## Show HN: Mines.fyi – all the mines in the US in a leaflet visualization

- 原文链接: [Show HN: Mines.fyi – all the mines in the US in a leaflet visualization](https://mines.fyi/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47094149)

This article is about mines.fyi, a website that shows all the mines in the US on an interactive map. The site uses Leaflet, a map tool, to help people explore where mines are and what they produce.

The website lists active mines across the US, including sand, gravel, limestone, granite, and even shell mines. Each mine has details like its name, operator, location (for example, Texas), what materials it digs up, and if it’s still working. You can click on a mine to see even more info, such as the company that owns it and the type of mining (like surface or facility). The map is easy to use and you can zoom in or out to see different regions with clusters of mines. The data seems to come from public sources, and mines.fyi puts it together in a simple, clean design. Users can search for specific mines or filter by material type. The goal is to make mining data open and easier for everyone to see, whether you’re curious, work in mining, or want to know what’s near your home. The website lists both large companies and smaller local operators. It also includes links to pages about each mine and company for further detail. The data covers a wide range, from common sand pits to industrial and specialty material mines. This kind of tool can help people understand where mining happens and which resources are important in different areas.

In the comments, many users are impressed by how clear and fast the website is. Some say it’s useful for people who care about environmental impact or for those looking for work in mining. Others like to explore the data just out of curiosity, to see what’s being dug up near their town. A few users ask about the data source and how often it’s updated—some are surprised to see mines they thought were closed still listed as active. There are suggestions to add more filters, like showing only abandoned or hazardous mines. Some people mention privacy or safety worries, for example, if this data could be misused. Others recommend linking the site with resources on the environmental effects of mines. One comment points out that mining is a big part of the local economy in some places. Another user shares that they found new mine sites they never knew about. Finally, several comments praise the project as a great example of making public data easier to understand and use.

---

## Blue light filters don't work – controlling total luminance is a better bet

- 原文链接: [Blue light filters don't work – controlling total luminance is a better bet](https://www.neuroai.science/p/blue-light-filters-dont-work)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47091606)

This article says that blue light filters on screens do not really help you sleep better. The writer is a neuroscientist and explains that many people use these filters, thinking they help with sleep and jet lag, but the science does not support this idea.

The main point is that your body's clock (circadian rhythm) is controlled by a small part of the brain called the SCN. This clock resets based on signals from special cells in your eyes (ipRGCs), which react to light, especially to cyan (a mix of blue and green), not just blue. Most blue light filters, like Apple’s Night Shift, only remove some blue and green light, cutting about half the amount that these eye cells notice. However, this reduction is very small compared to the full range of light your eyes can handle. 

The article also shows that our perception of color changes with filters, but this does not mean your sleep will improve. Studies show that halving the amount of light from your screen does not greatly change melatonin levels or sleep patterns, unless the room is already quite dark. If you turn up your screen brightness to compensate for the color change, the effect is even less helpful. Purely getting rid of all blue or cyan light would make your screen hard to use.

The writer found that many people—about 25% of iPhone users and 33% of Mac users at night—use these filters, likely because popular sources and influencers say blue light is bad. But better ways to help your sleep include using dark mode (which can cut 92–98% of screen brightness), lowering your screen brightness, getting more bright light during the day (like going outside or using strong lights indoors), and, if needed, taking a very small dose of melatonin.

In the comment section, many readers agree that blue light filters do not make a big difference. Some say they use blue light filters because they feel more comfortable or the screen looks softer at night, not because of sleep. Others point out that dark mode and dimming the screen are much more effective for reducing eye strain and helping with sleep. A few users mention that too much light at night, of any color, can disrupt sleep, so lowering total brightness matters more than changing color.

Some commenters are surprised by how popular blue light filters are, even though evidence is weak. Others share that using filters makes screen colors look strange or ugly, which can be annoying. There are also people who say they have seen no change in their sleep from using blue light filters, but notice a real difference when they dim their screens or use dark mode. Lastly, a few warn about taking too much melatonin and agree with the article that low doses are best if you try supplements. Overall, most people find that controlling brightness and using dark mode works better than using blue light filters.

---

## Making frontier cybersecurity capabilities available to defenders

- 原文链接: [Making frontier cybersecurity capabilities available to defenders](https://www.anthropic.com/news/claude-code-security)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=47091469)

Anthropic has launched a new tool called Claude Code Security, which helps teams find and fix security problems in software code. The tool uses AI to spot both common and complex vulnerabilities, even those that standard tools often miss.

Most security tools today only look for known issues by matching code against rules. They are good for catching simple problems, like weak passwords, but often miss tricky bugs hidden in how different parts of software work together. Claude Code Security is different because it “reads” code more like a human expert, tracing how data moves and finding hard-to-spot issues.

When Claude finds a possible bug, it double-checks its own work to reduce false alarms. It gives each finding a severity score and a confidence rating, so teams can focus on the most serious problems first. All changes are reviewed by humans before anything is fixed, making sure that nothing risky happens automatically.

Anthropic has tested Claude in real-world events and found over 500 hidden bugs in open-source projects—problems that even expert reviewers missed for years. The company uses Claude on its own code too, and now wants to share these security tools with more teams, especially open-source projects.

The article says that soon, most software will be checked by AI like Claude, both by attackers and defenders. The hope is that defenders can use these new tools to fix problems before hackers find them.

In the comments, some people are excited about using AI to catch more bugs and help small teams who can’t afford big security staff. Others worry that attackers will use the same AI tools to find security holes faster than ever. One commenter points out that if both sides use the same technology, it could become a race—whoever acts faster wins.

A few people talk about the risk of false positives, where the AI reports problems that aren’t real, and how that could waste developer time. Some are happy that Claude doesn’t make changes automatically, so humans still control what gets fixed. Other users hope that the tool will support more programming languages in the future.

Some commenters mention trust—they want to know how much private code is shared with Anthropic, and whether the tool can be run locally. There are also requests for free access for open-source projects, and suggestions for better ways to handle the many bugs that might be found. Overall, people see this as a big step forward for defenders, but with new risks to consider.

---

