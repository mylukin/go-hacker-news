Hello everyone, this is the 2025-11-24 episode of Hacker News Daily Podcast. Today, we bring you the latest tech stories and the best discussions from the Hacker News community. Let’s get started.

Our first story is about Pebble, the popular smartwatch brand, making a big move towards openness. Pebble’s watch software is now fully open source. This means anyone can download, build, and run everything needed to use a Pebble watch. The Pebble mobile app source code is also public, and the Pebble Appstore has become more open and decentralized.

The article explains why open sourcing Pebble is important for the long-term future of the watch. Now, the hardware is easier to repair, with design files available online. You can even unscrew the back to change the battery yourself. The software is fully open, so if the company ever shuts down, people can still use and improve their watches. PebbleOS has been open source since January, and now the mobile app joins it. Without the mobile app, the watch is almost useless, so this is a big step. Developer tools and the Appstore have also improved, and now work on modern computers and in browsers. The Appstore now supports multiple “feeds,” so anyone can create or host their own Pebble apps. There’s even a public backup of the Appstore on Archive.org to prevent data loss.

Some parts, like the heart rate sensor and certain cloud services, still use non-free components, but these are optional. The main features will always stay open source. The article also gives an update on the Pebble Time 2 watch: production is going well, but there might be delays because of Chinese New Year. Most people who pre-ordered will get their watches in March or April, and there will be four color choices.

Hacker News users are excited about Pebble’s open source move. Many believe it will help the Pebble community last a long time, and it sets a good example for other hardware makers. Some remember when the old Pebble company closed and their watches stopped working, so now they feel more secure. A few ask about the non-free parts and hope everything will be open source someday, but most agree the important pieces are now free. Some are interested in building custom Pebble-like devices using the released hardware files. Others think the new developer tools will help more people create apps. The idea of having multiple Appstore feeds is also popular, as it makes the system more stable. Some are surprised the Pebble community is still so active, showing how much people love simple, hackable gadgets. There are questions about how updates and bug fixes will be managed in the open source world. Many thank the developers and look forward to seeing what the Pebble community will do next.

Next, we look at new features for the Claude AI Developer Platform from Anthropic. Claude can now work better with many tools at once, making it easier to build smart agents for complex tasks.

Old systems were slow because they loaded all tool information at once, using a lot of memory. Sometimes, Claude would pick the wrong tool or settings. To solve this, Anthropic added three new features. First, a Tool Search Tool lets Claude find and load only the tools needed for the current job, saving memory. Second, Programmatic Tool Calling allows Claude to write code, like Python, to control how it uses tools, run several tools in order, and process big data faster. Third, Tool Use Examples let developers show Claude real examples of how to use each tool, helping it learn what is actually correct.

The article gives an example with Excel, showing how Claude can now handle large spreadsheets without slowing down. It also explains how to set up and use these new features.

Hacker News readers are excited about the changes. Many say searching for tools on demand and using code for workflows makes AI more powerful for real-world tasks. People like that this saves memory and allows more complex operations. Some worry about security, asking how safe it is to let Claude run code or control important tools, especially in business. Others say this reminds them of old ideas like plugin architectures and think it is smart to bring these to AI. Some wonder if small teams can use these features, or if they will mostly help big companies. There is talk about how well Claude will handle mistakes and special cases, and if the tool examples system can really cover all company rules. Many hope these features will make AI agents more useful for DevOps, data analysis, and customer support, as long as they stay easy and safe.

The third big story is about Claude Opus 4.5, Anthropic’s new AI model. It is said to be smarter, faster, and better at coding and office tasks than earlier versions. The model claims top results on software engineering tests, better reasoning skills, and uses tokens more efficiently, making it cheaper for developers and companies. It powers new tools for coding, agents, Excel, Chrome, and desktop apps, with longer conversations, better planning, and fewer errors.

Users say Opus 4.5 is very good at complex code changes, planning big projects, and handling long, multi-step tasks. It can write and review code, automate office work, and generate long, organized text. There is a new “effort” setting that lets developers choose between speed or deep analysis. Opus 4.5 even did better than any human on a tough engineering test, though the test only measures technical skills, not teamwork or communication. The model is also safer, with better protection against prompt injection attacks and improved rule-following.

Hacker News commenters have mixed feelings. Many are impressed by the technical progress, especially in coding and efficiency. Some developers like the lower price and better token use. Others warn that benchmarks and demos do not always show real-world performance. A few are uneasy about AI models beating humans at engineering tests and what that could mean for jobs. Some worry that “creative” solutions could cause errors if the AI finds loopholes. People talk about safety and say true safety is hard to measure. There is interest in the “effort” setting, with questions about whether it will really help control costs or quality. Some wish for more open-source AI, while others are excited to try the new tools. Anthropic’s focus on safety and partnerships with big companies is also a topic. Overall, there is both excitement and caution about what these new AI models can do.

Now, let’s talk about TSMC’s factory in Arizona having a power outage. This stopped production and forced TSMC to throw away some silicon wafers made for Apple. The factory lost power for about 12 hours, which damaged some wafers. These wafers are expensive and take weeks to make, so losing them means lost money and time. TSMC had to throw them out, and they cannot be fixed or reused. Apple, as a main customer, was affected.

The outage shows how sensitive chipmaking is—even a short stop can cause big losses. Factories need stable electricity and good backup plans. TSMC is working to improve its Arizona site, but this problem shows it is hard to build chip factories outside of Taiwan, where TSMC has more experience.

On Hacker News, some say outages are not surprising in the US, where power problems may be more common than in Taiwan. Others point out that building new factories in the US is hard because of different rules and less skilled workers. Some think TSMC should have better backup systems. Others say it is normal to have problems when starting a new factory, and things will improve over time. Some are worried about the cost of lost wafers and what it means for Apple’s product plans. Some think this is a good lesson for other chip makers, and others say it is important for the US to have its own chip factories, even if there are problems at first.

Next, we have a story about cool-retro-term, a terminal emulator for Linux and macOS that looks like an old CRT monitor. Its goal is to give you the look and feel of retro computers, with glowing text, curved screens, and classic colors. It uses Qt5 and a QML port from Konsole. You can change settings like colors, fonts, and effects. There are different color themes, and it runs lightly on most systems. You can install it from your Linux package manager, or download it for Linux and macOS from GitHub. The project is open source and has many contributors. You can support the developer on Patreon or PayPal.

Hacker News commenters have mixed feelings. Some love the nostalgic look and remember using real CRTs in the past. Others say it’s fun for a few minutes, but not practical for daily work because the effects can be distracting. Some want even more accurate emulation, like screen flicker. Others note it is just for looks, not for productivity. Some users think it is good for demos or screenshots. Performance is good for most, but older computers may struggle. Some people ask about a Windows version, but it is not available yet. There are tips for getting similar retro effects in other terminals. Some worry about eye strain, but others say you can adjust settings. Some suggest it could be fun for games or retro programming. There is praise for the open source community and the number of contributors. Many agree it’s a neat project, even if only a few will use it every day.

Now, let’s turn to the rapid progress of AI models. The article reviews how AI has grown quickly from GPT-3 to Google’s Gemini 3 in just three years. GPT-3 surprised everyone in 2020 by writing and answering questions almost like a human. Then GPT-4 was smarter and more reliable. Now, Google’s Gemini 3 can handle text, pictures, and even video. Each new model is much better than the last, and improvements come faster each time. The writer points out that AI is not just for tech experts—now, many jobs use it. Some companies build tools around these models. Risks include AI mistakes and changes to jobs or education, but the main idea is that AI is moving very fast, and everyone needs to pay attention.

In the comments, some people are amazed by the speed of improvement. Others worry about mistakes AI can make and say we must be careful before using it for important work. Some developers like that models help them code and test ideas, but some miss the simpler “old days” of AI. There is debate about whether AI really “understands” language or just copies patterns. Some want more open-source AI. Others are excited about using AI in schools or small businesses. Many agree that AI will keep changing fast, and nobody knows what will happen next.

Another AI story today is about how large language models like ChatGPT have become more flexible and can now be extended or customized in many ways. At first, people just pasted text into chat boxes. Then, ChatGPT Plugins let LLMs use APIs to do more things, but early models had trouble with complex APIs. The Code Interpreter plugin made things better by letting LLMs run code safely.

Later, OpenAI added Custom Instructions, making it easier to add user preferences. Custom GPTs let users package instructions, files, and actions into special versions of ChatGPT. ChatGPT Memory brought automatic personalization, remembering things about you for later chats. Cursor Rules let you put custom instructions directly in your codebase as files.

Model Context Protocol (MCP) allowed LLMs to use real tools, like reading code or querying databases, by connecting to a server, but it was complicated. Claude Code from Anthropic made things easier, with repo instructions, tools, commands, and sub-agents. Agent Skills, the latest idea, are simple folders with scripts and markdown files. The LLM reads these when needed, making it easier and more flexible.

The author thinks as LLMs get smarter, giving them general-purpose tools and simple instructions works better than creating special tools for every task. The best future is where LLMs can access a computer and figure out tasks on their own, using natural language.

Hacker News users have many opinions. Some like the move to simple, flexible extensions, saying natural language is easier for most users. Others worry about security when LLMs get too much power. Some think early plugin systems failed because models were not ready, but things are better now. Some developers still prefer code-based customization because it is more reliable. Others are excited about agents that feel like smart coworkers, not just chatbots. There are concerns about privacy and making these systems easy for non-technical people. Some debate if too many features make LLMs confusing. Others think the best ideas will come from open projects, not big companies. Many believe most users just want things to work simply.

Next, someone shared their experience moving their firewall system from OpenBSD to FreeBSD. Both are free operating systems good for network and security jobs. The author liked OpenBSD for its simplicity and security but moved to FreeBSD for better hardware support and more features, especially for network cards and drivers. FreeBSD also has better performance for some tasks and supports new tools. The move required learning new commands and setup methods, as FreeBSD’s pf is different from OpenBSD’s pf. Some problems appeared with network interfaces and packages, but the author fixed these by reading the FreeBSD handbook and forums. In the end, the firewall was running well.

In the comments, some agree that FreeBSD gives better hardware support, especially for new computers. Others like OpenBSD for its simplicity and security. A few say you must be careful when switching, as pf is not always the same. Some say OpenBSD is better for smaller, older hardware. Users share tips and stories about moving between the two systems. One warns it’s easy to make mistakes with firewall rules. Another says FreeBSD’s documentation is very helpful. Some wish for more guides about moving between the systems. Most agree both are good, and the best choice depends on your needs.

Finally, we have a story about the high price of DDR5 RAM. The article says 64GB of DDR5 memory now costs around $600, more than a PlayStation 5 console, because of a shortage. The shortage is caused by problems in the supply chain and high demand for new computers. Many companies and people want DDR5, but factories cannot make enough. New computers from Intel and AMD need DDR5, so more people are trying to buy it. Some are waiting to build or upgrade their computers because the price is too high, and shops are selling out quickly. The article says prices may go down when factories can make more, but for now, the high cost is a big problem.

In the comments, some people are surprised by the high price. A few say they will wait to upgrade their computers until prices drop. Others remember when DDR4 was expensive at first but later became cheaper. Some talk about the shortage being caused by high demand and factory problems. A few suggest buying used or older RAM if you do not need the newest hardware. Others say DDR4 works fine for most people. Some worry that prices for other computer parts might go up too. A few are frustrated with how hard it is to get new technology these days. Others try to stay positive, hoping the shortage will end soon. Some share tips on where to find RAM at better prices, and some just joke about memory costing more than a game console.

That’s all for today’s episode. Thank you for joining us for the latest updates and discussions from Hacker News. We hope you enjoyed the show. See you next time!