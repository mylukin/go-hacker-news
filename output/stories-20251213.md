# Hacker News 故事摘要 - 2025-12-13

## 今日概述

Today’s top Hacker News stories talk about VPNs not always sending your traffic where they say, and a company moving from microservices back to a simple system. Other stories cover saving Anthony Bourdain’s lost lists, making random text with Markov models, learning the Gleam language, old computer games, fake social media accounts in elections, costly university software, tips for writing release notes, and creating small web tools. If you like tech honesty, simple tools, or internet history, today’s news has something for you.

---

## VPN location claims don't match real traffic exits

- 原文链接: [VPN location claims don't match real traffic exits](https://ipinfo.io/blog/vpn-location-mismatch-report)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257339)

This article looks at whether VPN services really send your internet traffic through the countries they claim. The author studied 20 big VPN providers and found that most do not send your data through the countries they say—they use “virtual” locations.

Out of 20 VPNs checked, 17 had traffic exit from a different country than promised. Many VPNs claim to have servers in over 100 countries, but in reality, the traffic often goes through just a few data centers in places like the US or Europe. The study looked at over 150,000 VPN exit IP addresses and found 38 countries that were only “virtual”—the VPN said your traffic was in that country, but it never actually was.

Only three providers—Mullvad, IVPN, and Windscribe—matched their claimed locations with real traffic. For others, over half their listed locations were not real. For example, if you picked “Bahamas” on some VPNs, your data actually went through the US. If you picked “Somalia,” your data might exit in France or the UK instead.

This happens because VPN companies sometimes mark locations as “virtual” for technical or legal reasons. They might do this to avoid problems in risky countries, or because it is cheaper and faster to use data centers elsewhere. But often, VPNs don't tell users that these are virtual locations.

The article also explains that old IP location databases often trust what VPNs say about their IP addresses. These databases can be very wrong—sometimes by thousands of kilometers. The author’s company uses real-time tests (measuring how fast data travels to different places) to find the actual location.

The main advice is: do not trust country lists on VPN websites too much. Many “locations” are not real. If you need your traffic to exit in a true location for privacy or legal reasons, choose a VPN that is honest about where its servers are.

In the Hacker News comments, some people were not surprised by these results. They said that running real servers in many countries is hard and expensive. Some said it can be a good thing—using “virtual” locations can be safer, faster, and more reliable than hosting in risky countries.

Others worried that VPN companies should be more honest. Users might choose a location for safety or to access certain content, and they could get in trouble if the real location is different. Some users shared how they check the real exit point by running tests like ping or traceroute.

A few commenters praised VPNs like Mullvad and IVPN for being transparent. Others pointed out that most users probably just want to watch streaming content, so they may not care about real locations. Some said that honesty is most important for people who need VPNs for privacy or political reasons.

Several people suggested that VPN providers should clearly mark which locations are virtual. Others thought that regulators should make VPN companies show the truth in their marketing. Some users said this is a good reminder to read privacy policies and test VPNs before trusting them.

---

## Why Twilio Segment moved from microservices back to a monolith

- 原文链接: [Why Twilio Segment moved from microservices back to a monolith](https://www.twilio.com/en-us/blog/developers/best-practices/goodbye-microservices)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257714)

Twilio Segment started with microservices—a way to split software into many small, single-purpose parts—but found big problems as the system grew. At first, microservices helped by isolating problems and letting teams work on parts separately, but over time, the number of services and repos became too much to handle.

The main product needed to send lots of user events (like clicks or logins) to over 100 partner APIs, each with different rules and formats. At first, one queue managed all events. But if one partner’s API was slow or broken, the whole system slowed down. To fix this, they made a separate service and queue for each partner. This helped at first, but soon there were over 140 services and repos.

Managing so many services meant lots of time spent fixing broken tests, keeping shared libraries up to date, and scaling each service for traffic spikes. Shared code became a headache because updating a library meant testing and redeploying every service. Over time, different services used different library versions, making the system messy.

The team realized the overhead was slowing them down, so they decided to merge everything back into one big service—a monolith. They moved all code into one repo, made everyone use the same library versions, and built a new tool (Traffic Recorder) to speed up and stabilize tests. Now, deploying changes was quick, and scaling to meet traffic needs was easier. Productivity improved, and they could handle more changes with less risk.

But there were trade-offs. If one bug brought down the service, everything could crash. In-memory caching was less efficient, and updating a library might break several destinations. Still, with better tests and simpler operations, the benefits were worth it.

Hacker News commenters had lots to say. Some agreed with Twilio Segment’s move, saying microservices are often overused and add too much complexity for small teams. They liked the honesty about trade-offs and pointed out that testing and deployment get harder as microservices multiply. Others said microservices can work well if you invest in the right tools and automation, but that’s expensive and only big companies can usually do it well. A few shared stories of returning to monoliths after struggling with similar issues.

Some people thought Twilio Segment’s problems came from trying to scale microservices too early, before they had the resources or tooling to manage them. Others argued that the real lesson is to build what fits your team and product, not just what’s trendy. There was also talk about how company culture and team size affect whether microservices or monoliths work best. A few warned that monoliths also have limits, and you might need to split things up again as you grow. Most agreed: there is no perfect answer—pick the tech that matches your needs, not just what’s popular.

---

## Recovering Anthony Bourdain's (really) lost Li.st's

- 原文链接: [Recovering Anthony Bourdain's (really) lost Li.st's](https://sandyuraz.com/blogs/bourdain/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46258163)

This article is about someone trying to recover old, lost lists by Anthony Bourdain that were posted on a service called “li.st.” The writer used internet archives, like Common Crawl, to find and restore as much of Bourdain’s content as possible.

They started by reading another person’s collection of partially recovered lists, then tried using Common Crawl to search for more. They wrote a small Python script to search and download old web pages, hoping to find any missing lists. The writer mentions that images from the original posts are gone, and despite trying several ways, they could not recover them. They kept the text exactly as Bourdain wrote it and only changed the layout to look like the original li.st pages.

Some of the lists Bourdain wrote include things he no longer had patience for, favorite views, TV series he’d pick for a desert island, objects he wanted, favorite hotels, food he missed, books he liked, and even lists of now-closed bars in New York. Many lists had photos, but these could not be found. The author also added a table of which pages were still missing. They finished by saying this was a fun digital archaeology project and made the findings public in a GitHub repository, hoping others could help recover more.

In the comments, people shared lots of praise for the project and for Bourdain’s writing. Some said they missed Bourdain and loved seeing his words again. Others talked about the technical side, discussing how hard it is to recover images and data from old web services, especially when content was behind logins or not publicly crawled. A few suggested searching other archives, like the Wayback Machine, or even reaching out to people who worked at li.st for help. Some commenters warned about copyright and whether it’s okay to post Bourdain’s work again. Others were inspired to try and recover lost content from other favorite sites or writers. A few worried that so much of the internet’s early culture is disappearing, and said efforts like this are important. Finally, some gave tips for better web archiving in the future, wishing more people would make public backups before sites vanish for good.

---

## I fed 24 years of my blog posts to a Markov model

- 原文链接: [I fed 24 years of my blog posts to a Markov model](https://susam.net/fed-24-years-of-posts-to-markov-model.html)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257607)

This article is about a programmer who took 24 years of his own blog posts and used a simple Markov model to generate new, random-sounding text. He made a small program called “Mark V. Shaney Junior,” which is based on an old idea from the 1980s, and shared it on GitHub.

The Markov model works by looking at groups of words (trigrams, or three-word sequences by default) and then predicting what word usually comes next. The author likes to write simple programs just for fun and often tweaks old code to try new ideas. He decided to collect all his blog posts—about 200,000 words—and feed them into the Markov program to see what kind of strange or funny sentences it would create. The program produces text that sometimes makes sense but is often a mix of unrelated ideas pulled from different blog posts. For example, it might mix programming tips with thoughts on self-esteem or mathematics.

He explains that if you use a higher order (like four or five words instead of three), the generated text sounds more natural, but if the order is too high, it just copies large parts of the original blog posts. The fun, he says, is in the balance: enough randomness to sound weird, but not so much that it just repeats the original text. He also shows how you can give the program a prompt to start the generated text.

In the comments, many people remember the original Mark V. Shaney bot and share their own stories about early text generators. Some are impressed by how well the program works, especially given how simple the code is. Others point out that Markov models have limits and can’t really understand language—they just mimic patterns. A few commenters suggest improvements, like trying larger datasets, other authors’ works, or higher-order models for more realistic text. Some people joke about the funny and strange sentences the program makes. Others talk about the value of “exploratory programming” and how creating things just for fun can lead to good learning experiences. A few warn that simple models can copy too much from the original, which could be a problem for privacy or copyright. Overall, people like the playful spirit of the project, and some say they want to try it themselves with their own writing.

---

## I tried Gleam for Advent of Code

- 原文链接: [I tried Gleam for Advent of Code](https://blog.tymscar.com/posts/gleamaoc2025/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46255991)

The article is about one developer’s experience using the Gleam programming language for this year’s Advent of Code, which was shorter than usual with only 12 days. The writer explains how the harder puzzles and fast pacing made Gleam a great language to learn during the event.

Gleam’s clean syntax, helpful compiler, and excellent error messages made the coding experience enjoyable. The language’s functional style—parsing input, transforming data, and using pipelines—fit well with Advent of Code problems. The author especially liked how easy it was to print values using the `echo` function, which made debugging simple. However, they missed string interpolation when building output for other tools.

For grid-based puzzles, Gleam’s use of “option” types helped avoid out-of-bounds errors. The built-in list functions like `list.transpose` and `list.combination_pairs` saved time and made the code much simpler. The `fold_until` function allowed for early exits in loops, making some puzzles easier to solve.

There were some pain points. Basic file input/output is not in Gleam’s standard library, so the author had to use an extra package. Regular expressions also needed a separate dependency. Pattern matching on lists had some limits, and comparisons were sometimes more verbose than in other languages. When using big integers, there was a difference between running the code on Erlang and JavaScript, which could be confusing.

The author enjoyed using bitwise operations, like XOR, to solve some puzzles in a clean way. But for one puzzle, they had to call an outside program (glpsol) because Gleam had no built-in support for solving linear equations. The article also mentions how important it was to use the right memoization keys in recursive solutions.

In the comments, many readers were curious about Gleam and its strengths. Some agreed that the language’s error messages and pipelines make coding fun, while others wondered if the lack of standard features like file I/O or regex could be a problem in bigger projects. A few people liked the focus on safety, with options and results, saying this helped avoid bugs common in other languages. Others pointed out that missing string interpolation and verbose comparisons could slow down development for some tasks.

Several commenters shared their own Advent of Code experiences, comparing Gleam to other functional languages like Elm, Haskell, or OCaml. Some liked Gleam’s simple and friendly syntax, especially for people new to functional programming. Experienced users mentioned that while Gleam’s ecosystem is still growing, it’s easy to follow and the community is helpful.

There was some debate about whether functional programming is better for puzzles or production code. A few commenters said that, for them, functional programming made some problems easier to reason about, while others felt it was sometimes less practical for everyday tasks. Some people asked about Gleam’s performance and if it’s ready for larger projects, wondering how well it works outside of puzzles.

Overall, the comment section showed excitement about Gleam, with many people saying they might try it for future coding challenges. Some users suggested improvements or wished for missing features, showing that the language is still evolving. Most agreed that Advent of Code is a great way to learn and test new programming tools.

---

## The Rise of Computer Games, Part I: Adventure

- 原文链接: [The Rise of Computer Games, Part I: Adventure](https://technicshistory.com/2025/12/13/the-rise-of-computer-games-part-i-adventure/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257599)

This article is about the early history of computer games, with a special focus on adventure games and how they became popular. It explains how games were a big reason people bought personal computers in the late 1970s and early 1980s.

In the early days, people got computer games in three main ways: by copying them from friends, typing them in from magazines, or buying them from new software companies. Many early games were simple and were shared freely, following the culture of universities and hobby groups. Magazines and books often printed full game code that people could type into their computers at home. But as games became more complex, this became harder, and people started to buy more games on cassettes or floppy disks.

Most early games were text-based because computers then could only show text, not graphics. Popular games included quizzes, simulations, and especially different versions of Star Trek, where you fought against Klingons using typed commands. As computers got better, with color screens and graphic chips, games started to look more like arcade games with real-time action.

The article tells the story of "Adventure" (also called Colossal Cave Adventure), the first big adventure game. Will Crowther made it for his daughters, using ideas from real caves and Dungeons & Dragons. Later, Don Woods expanded it with more rooms and puzzles, and the game spread quickly through early computer networks. Adventure was all text: you typed short commands to move around and solve puzzles.

Scott Adams was the first person to sell a version of Adventure for home computers, calling it "Adventureland." He made many more games, and his wife Alexis helped design them. These games were hard and sometimes unfair, but that was part of their charm — people wanted a challenge that would last for weeks.

Another famous early adventure game was "Zork," made by a group of MIT students. Zork had better text and more complex puzzles than earlier games. It became very popular and helped start the company Infocom, which sold thousands of copies even though the game was expensive.

The first adventure game with graphics was "Mystery House," made by Ken and Roberta Williams. Roberta loved adventure games and wanted to add hand-drawn pictures, which made the game stand out. Their company, later called Sierra On-Line, became very successful, especially with the King’s Quest series. The article notes that two important early adventure game designers, Alexis Adams and Roberta Williams, were women in an industry mostly run by men.

In the Hacker News comments, some people shared memories of playing these early games, saying they felt magical and sparked their interest in computers. Others pointed out how hard and sometimes frustrating the puzzles were, but also how this made winning feel special. Some commenters praised the open and sharing culture of early computing, where people swapped games and code freely. A few mentioned that adventure games encouraged learning to code, since players often wanted to fix bugs or change things themselves. There was also discussion about how much easier it is to find hints and walkthroughs now, compared to the past when you had to figure everything out on your own. Some users talked about the gender gap in early gaming, appreciating that the article highlighted women like Roberta Williams. Others debated whether modern games have lost the sense of wonder and challenge found in those old adventure games. A few people even wondered if new types of games today could inspire the next generation in the same way.

---

## Want to sway an election? Here’s how much fake online accounts cost

- 原文链接: [Want to sway an election? Here’s how much fake online accounts cost](https://www.science.org/content/article/want-sway-election-here-s-how-much-fake-online-accounts-cost)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257871)

This article talks about how people use fake online accounts to try to change the results of elections. It explains how much money it costs to buy these fake accounts and what they can do with them.

The article says you can buy fake accounts on popular social media sites for just a few dollars each. Some sellers offer bundles—hundreds or thousands of accounts at once. These accounts can post messages, like or share posts, and follow real people to look more believable. Some are simple bots, while others are made to look like real people, with photos and long histories. The fake accounts can spread false news, argue with real users, or make it seem like an idea is more popular than it really is. The article says that complex fake accounts, made to look very real, cost more money—sometimes $15 or more per account. Cheaper accounts are usually easy to spot and get removed quickly. The article gives examples from real elections where fake accounts were used to push certain messages or attack candidates. It also says that some companies and groups sell services to manage these fake accounts for customers, making it easier for someone to use many accounts at the same time. The article explains that social media companies try to find and remove fake accounts, but there are always new tricks to avoid being caught.

In the comments, some people are worried about how easy and cheap it is to buy fake accounts and use them in politics. Others say that social media companies are not doing enough to solve the problem. Some users point out that it is hard for normal people to tell fake accounts from real ones. A few commenters think that focusing too much on fake accounts ignores other problems in elections, like bad laws or poor media. Some people believe that social media will always have this problem as long as it is open to everyone. Others say that real people can also spread false news, not just bots. A few users suggest that more rules or better technology might help, but others are not sure if anything can really stop fake accounts. Some commenters share their own experiences seeing fake accounts online. Others think that people should be more careful about what they read and share. There is debate about whether fake accounts really change election results or just make noise. Some say it is a big danger, while others think the effect is smaller than many fear.

---

## Workday project at Washington University hits $266M

- 原文链接: [Workday project at Washington University hits $266M](https://www.theregister.com/2025/12/12/washington_university_workday_costs_revealed/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257986)

Washington University in St. Louis spent $266 million on a new Workday software system, after students protested and asked for more details about where the money was going. The project took at least seven years to finish, costing about $16,000 for each student, and replaced 80 old systems that were built in the 1990s.

The university broke down the spending like this: $81 million for finance and HR, $98.9 million for a new student app called Sunrise, and $56.5 million for planning, data, and financial aid work. There will also be $23.8 million for support in 2026 and $5.7 million each year just to keep using the software. The project started with HR in 2018, which went live in 2021, and then the student system rolled out in 2024 and 2025.

Leaders said the old systems were too old and fragile, so they needed to be replaced. With this change, the university moved almost everything into Workday, a cloud-based service, getting rid of many different tools used before. The article also mentions that another school, the University of Washington, did a similar Workday project for $340 million, which also had big problems and delays.

Workday’s CEO said most of their projects are successful, but there have been public troubles in places like Maine and Iowa. The Register reached out to both the university and Workday for more comments.

In the comments, many people were shocked at how expensive the project was. Some said big software projects at schools almost always cost too much and take too long. Others wondered if using Workday was really better than fixing the old systems or building something simpler. A few users pointed out that running old software forever is risky, but moving everything at once is also hard and costly. Some said these high prices are common when big companies or schools buy software, because of slow decisions and many managers involved. Others shared stories of similar projects at their own schools that also ran into problems, saying it seems to happen everywhere. A few defended the university, saying the old systems really were falling apart and needed to be replaced. Others asked why student protests were needed just to get the costs made public. Finally, some commenters suggested that universities should be more careful with money, since students and families always end up paying for these big changes.

---

## Ask HN: How do you handle release notes for multiple audiences?

- 原文链接: [Ask HN: How do you handle release notes for multiple audiences?](item?id=46257486)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46257486)

A user on Hacker News asked how to write release notes for different groups of people, like developers, business users, or end users. They want to know how others manage sharing updates when each group cares about different things.

Some people said they write one set of release notes but use clear sections. They label parts for “Developers,” “Admins,” or “End Users” so everyone can find what matters to them. Others make different versions for each group: a technical list for developers, and a simple summary for users. Some teams use tools that let people filter release notes by interest or role.

Many agree release notes should be short and easy to understand. It helps to focus on what changed, what’s new, and any important fixes. Some write detailed technical changes in a changelog, then create a friendlier version for customers. Teams sometimes send email updates or use in-app messages to highlight the biggest changes.

One person warned not to share too much technical detail with non-technical users—it can be confusing or cause worry. Another said it’s good to link to more detailed notes in case someone wants to learn more. A few people automate the process, using scripts to pull changes from source control and format them for each group.

In the comments, some users said they struggle to keep release notes useful for everyone, and sometimes people just ignore them. Others think release notes are important for trust and transparency, even if they are not always read. A few shared that their teams don’t have a perfect system yet but are always trying new ideas. Some prefer a single, well-organized page with clear labels, while others like sending different notes to each group. One person pointed out that what works for a small team may not work for a big company. Some users suggested asking customers what kind of updates they want. Many agreed that clear, simple language is always best.

---

## Useful patterns for building HTML tools

- 原文链接: [Useful patterns for building HTML tools](https://simonwillison.net/2025/Dec/10/html-tools/)
- HN链接: [Hacker News讨论](https://news.ycombinator.com/item?id=46223882)

This article is about building small HTML tools—simple web apps made with just HTML, CSS, and JavaScript, often all in one file. The author shares patterns and tricks learned from making over 150 of these tools, many with help from large language models (LLMs) like ChatGPT or Claude.

The main idea is to keep each tool simple: use only one HTML file, include JavaScript and CSS inline, and avoid frameworks like React that need extra build steps. This makes the tools easy to copy, share, and host anywhere, like on GitHub Pages. If you need extra libraries, use trusted CDNs to load them. Tools are often prototypes built quickly by prompting LLMs; adding “No React” to your prompt keeps things simple.

The article shows many examples: tools that render SVGs, compare package versions, view social media threads, and more. Copy and paste are important features—many tools work by letting users paste in data, transform it, then copy results out. For debugging, you can make tools that show clipboard data or keyboard events.

To make sharing easy, you can store the state in the URL or use localStorage for bigger or private data like API keys. Tools can fetch data from APIs that support CORS, and some even call LLM APIs directly—though users must provide their API keys. You can use the browser’s file input to process files, or let users download files made by the tool. Advanced tools use Pyodide or WebAssembly to run Python or C code right in the browser.

The author likes remixing old tools to make new ones, and always records the prompts and transcripts for future use. The article encourages readers to start their own collection, explaining how easy it is to set up with GitHub Pages.

In the comments, many people say they love the simplicity of these tools. Some mention nostalgia for the early web, when small, shareable tools were common. Others praise the “no build step” approach, saying it makes things easier for beginners and faster for experts. Several readers are surprised at how powerful browser APIs have become, letting you run Python or even more complex code in the browser.

A few users wish more people used this pattern—one says the web would be better if apps were simpler and more open like this. There’s interest in how the author uses LLMs to help code, with some asking for more details about prompt design. Some express concerns about storing API keys in localStorage, pointing out possible security risks.

Other commenters discuss hosting choices: many agree that GitHub Pages is a great option, but some mention self-hosting for more control. A few people debate the use of CDNs, with one noting that relying on them could cause problems if a library is removed or changed. Some are impressed by the remixing idea—copying and combining old tools to make new ones.

Overall, the reaction is very positive. Readers feel inspired to try building their own HTML tools, and many appreciate the clear, practical guidance.

---

