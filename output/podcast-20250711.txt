Hello everyone, this is the 2025-07-11 episode of Hacker News Daily Podcast. Today, we have a lot of stories for software developers, tech fans, and curious minds. Let’s get started.

First, ETH Zurich and EPFL will soon release a new large language model, trained on Switzerland’s “Alps” supercomputer and designed to be fully open to everyone. This model stands out because it follows strict Swiss and EU rules and aims to work well in over 1,000 languages. The team used data from 1,500 languages—about 60% English, 40% other languages, plus code and math data. There will be two model sizes: 8 billion and 70 billion parameters, both trained with more than 15 trillion tokens. The project is led by EPFL, ETH Zurich, and the Swiss National Supercomputing Centre, with help from other Swiss universities and support from the Swiss AI Initiative. Both the code and model weights will be open-source under the Apache 2.0 license, and the training data will be open and repeatable. One key point is that the team did not use websites that opted out of web crawling, and this did not hurt the model’s performance on normal tasks. The “Alps” supercomputer runs on green energy, with help from NVIDIA and HPE. The goal is to show that public, open AI can compete with private models from the US or China.

There are no comments yet, but the Hacker News community would likely be excited about a true open and multilingual model, especially for smaller or ignored languages. Some might ask if open models can really be as safe or as good as closed ones, or worry about the huge cost and energy needed for training. There could be praise for the focus on open science and strong support from Swiss universities and the EU. Others may compare this release to models like Llama, or wonder if true openness is possible when only a few groups have access to giant datasets and hardware. Many would welcome this as a way to keep AI research public and global, not just in a few big companies.

Next, there is news about the programming language jank and its new close connection with C++. The author describes how jank now lets you manage C++ memory, supports destructors, and handles true and false values just like in C++. You can now use complex C++ types, pointers, and templates in jank code, with improved rules for constructors and new “opaque boxes” for safe pointer handling. Pre-compiled headers now make startup much faster, and many bugs with tricky C++ features have been fixed. All interop is statically typed, so you find mistakes at compile time. There are real examples: from “Hello, world!” to pretty-printing JSON and building UI layouts with a C++ library. The author was inspired by the Clasp project and is now working on packaging, bug fixes, and preparing for an alpha release. They invite others to help or sponsor the work.

In the comments, many are impressed that one developer built such deep C++ integration. Some think jank could help Clojure programmers use fast C++ code, while others worry about C++ complexity and if jank can really handle all its tricky parts. Some ask about performance and if the garbage collector will slow things down, while others praise the static typing. There are questions about pointer safety, comparisons to Clasp and other Lisp-C++ projects, and requests for better docs and Windows support. Some thank the author for being open about funding needs, and hope jank can bridge functional and systems programming. Most are excited but want more real-world use cases before trusting jank for big projects.

Now, a quick update on Windsurf, the AI coding company. OpenAI was planning to buy Windsurf, but that deal has stopped. Instead, Google is hiring Windsurf’s CEO, co-founders, and other top researchers for its DeepMind team, mainly to work on “agentic coding” with Gemini. Google will not buy the whole company, but it gets a license for some of Windsurf’s tech. Windsurf will keep going with new leaders. The price was not shared, but OpenAI’s old offer was said to be $3 billion. Both companies say they are happy about the new partnership.

Hacker News users see this as another example of big tech fighting for top AI talent. Some wonder why OpenAI’s deal failed or if Google gave a better offer. There are comments about how hard it is for small startups to stay independent, and questions about Windsurf’s future without its founders. Some praise Google’s focus on agentic coding, while others say too much AI talent is now in a few big companies, which could slow innovation. Some hope Windsurf’s team can still build new things, while others see this as just how tech works now: big fish eat small fish. There is debate about whether agentic coding is a real change or just a buzzword.

Let’s talk about a hands-on hardware story. One user upgraded their M4 Pro Mac mini’s storage with a third-party 4TB SSD, saving a lot compared to Apple’s prices. The process is tricky—opening the Mac mini is hard, and the power button cable is fragile. The main difference from the basic M4 Mac mini is the longer SSD slot. Since the storage controller is in the main chip, you must do a Device Firmware Update restore after installing the new SSD, using another Mac. The writer found the process mostly easy and the new SSD was fast, beating even Thunderbolt external drives. The upgrade cost $699, much less than Apple’s $1,200 for the same storage.

In the comments, many are glad Mac mini storage can still be upgraded at all. Some think Apple’s prices are too high and like the third-party option, while others warn the upgrade is risky and could void your warranty. Some prefer external drives, but others like the speed of the internal SSD. There are worries about long-term reliability and if Apple might block these upgrades in the future. A few say the DFU process is confusing, and others wish Apple would use standard SSDs. Most agree the upgrade is worth it if you need more storage and want to save money, but you should be careful and know what you’re doing.

Next is a summary of Andrew Ng’s talk at AI Startup School. Ng says moving fast is key for AI startups. He talks about “agentic AI,” which means AI that can act on its own and help teams do more with less. He suggests startups should pick one clear idea, test it quickly with many cheap prototypes, and always learn from user feedback—not just from A/B tests. Ng says learning new AI skills multiplies your abilities, and building with AI is now like building with Legos—it’s easy to try new things. He also suggests that in small teams, engineers can often play the product manager role. Ng warns about AI hype and stresses that human judgment is still most important. He also talks about AI in education, ethics, and the value of open source.

In the comments, people praise Ng for being clear and inspiring. Many thank him for his courses and like his focus on speed and learning. Some pull out key tips, like testing ideas cheaply and getting user feedback fast. Others joke about Ng’s simple style, saying he is down-to-earth. There is debate about whether product managers are needed in small teams. People like that the video is in many languages, and they discuss how agentic AI means more automation. Some say Ng’s advice will help them avoid mistakes. Overall, the talk left people excited and ready to build new things with AI.

Now, a look at a different kind of innovation. Bill Atkinson, the Apple engineer who helped make the first Macintosh, MacPaint, and HyperCard, later became a leader in open, safe psychedelic use. After his tech career, Bill joined a private group called OneLight and helped create the LightWand—a vape pen for using 5-MeO-DMT, also called Jaguar, a very strong psychedelic. Before the LightWand, people had to smoke large doses, which was risky. The LightWand made it easy to use small, safe amounts. Bill taught others how to build and use it, wrote a free guide, and gave away over 1,000 pens. He believed that careful, low doses could help people heal and grow, and that open sharing would make these tools safer and more available.

In the comments, many praise Bill’s openness and his drive to share knowledge. Some remember how HyperCard inspired them to learn programming and see a link between his tech and psychedelic work. Others worry about the risks of promoting psychedelics, but many respect his focus on harm reduction. Some question if open-source sharing can work for such powerful substances, while others say it takes power away from gatekeepers. Bill’s story made many reflect on innovation and using tech skills to help people in new ways.

Let’s move to space news. Astronomers have found a new object, 3I/ATLAS, moving through our Solar System from another star system. This is only the third time such an interstellar object has been seen. ATLAS is brighter and possibly much bigger than earlier ones like ‘Oumuamua and Borisov, though it could be giving off gas, making it look larger than it is. Its path is very strange, and it may have come from the far edge of the Milky Way. Telescopes and even spacecraft are now watching it before it disappears behind the Sun. Scientists want to know what ATLAS is made of. If it is like comets or asteroids from our Solar System, it could mean other star systems are made of the same stuff—a big deal for the search for life. Early signs show it has a reddish color, like other comets. New telescopes will help study it soon.

Hacker News commenters are excited, saying this is a rare and amazing chance to learn about other star systems. Some wish we had a probe ready to chase these objects, but note it is very hard. There is talk about what these objects could teach us about planet formation, and if we might one day catch up to them. Many agree that new technology will help us find more such visitors in the future. Some compare ATLAS to ‘Oumuamua, asking which is more interesting, and say these events remind us how big and surprising space really is.

Now, a quick job post. Activeloop, a company in Mountain View, California, is hiring for AI Search Engineers and Python Backend Engineers. They focus on making big data easier for AI, and want people who write good code and like solving hard problems. The jobs are onsite, use Python and modern tools, and the company is a Y Combinator startup. They also work on open-source projects.

In the comments, some like that the company is doing real AI work, while others wish the jobs were remote. Some ask about pay and work culture, or share that Y Combinator startups are exciting but stressful. There is debate about what “AI search” means and notes about high living costs in Mountain View. Some thank the poster and say they might apply or share with friends.

Let’s talk about a new tool for reinforcement learning. RULER is a general-purpose reward function that uses an LLM as a judge, so you don’t need labeled data or hand-crafted rules. The RL system generates possible answers, RULER removes repeated parts, sends them to the LLM with a simple rubric, and gets scores to use as rewards. RULER was tested on tasks like email search, reasoning, and support, and worked as well or better than older methods. It trains faster and is more stable, giving partial credit and ignoring noisy labels. The code is open-source and works with their ART framework.

Hacker News users like that RULER makes RL easier and removes the need for labeled data. Some worry about LLM bias or mistakes, saying the agent could learn the wrong things. Developers like the open code and clear docs. Some ask if RULER can handle tasks outside the LLM’s training data, or if it will work for very large tasks. There are questions about risks if the rubric is not well designed. Some compare RULER to methods like TAO and say this one is more open and practical. Many are excited about using RULER for real-time learning, but want more benchmarks and real-world tests.

Finally, a story about solving lead poisoning in Bangladesh and New York. For years, many children and pregnant women had high lead levels, but the cause was unknown. After much study, using clues from both the US and Bangladesh, investigators found the source: turmeric spice colored with lead chromate, used to make it look brighter and sell for more. This practice started in the 1980s and spread both in Bangladesh and abroad. Once found, the government warned people, tested and removed bad turmeric, and blood lead levels dropped. The amount of lead-tainted turmeric in markets fell from 47% to zero.

Hacker News comments show surprise that the problem lasted so long and praise the quick action that followed. Some say lead poisoning is still a big problem in many countries and that it’s hard to trace hidden toxins in food. There are calls for more testing of spices and foods, and stories about lead in toys or makeup. Some talk about the big cost of lead poisoning for society. Many agree that education, good tests, and cooperation between countries are needed to solve these problems everywhere.

That’s all for today’s episode. Thank you for listening to Hacker News Daily Podcast. We’ll see you tomorrow with more stories from the world of tech and science.